{"id": "feb7a1a4-a7b0-4e42-bec0-46e82903d9d5", "solution": "import numpy as np\n\nclass QDSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 10\n        self.photon_ratio = 0.1\n        self.q_population = np.random.rand(self.population_size, dim)\n\n    def quantum_update(self, lb, ub):\n        r = np.random.rand(self.dim)\n        binary_position = np.where(r < self.photon_ratio, 1, 0)\n        new_position = (self.q_population + binary_position) % 2\n        new_position = lb + (ub - lb) * new_position\n        return new_position\n\n    def local_search(self, solution, lb, ub):\n        perturbation = np.random.uniform(-0.05, 0.05, self.dim)\n        new_solution = solution + perturbation * (ub - lb)\n        return np.clip(new_solution, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            if evaluations % (self.budget // 2) < (self.budget // 4):\n                # Quantum-inspired exploration phase\n                candidate_solutions = [self.quantum_update(lb, ub) for _ in range(self.population_size)]\n            else:\n                # Local-exploitation phase\n                candidate_solutions = [self.local_search(self.best_solution, lb, ub) for _ in range(self.population_size)]\n\n            for solution in candidate_solutions:\n                value = func(solution)\n                evaluations += 1\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = solution\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_solution, self.best_value", "name": "QDSO", "description": "Introducing Quantum-inspired Dual-search Optimization (QDSO), which leverages quantum superposition concepts and dual-phase search to enhance exploration and exploitation in black-box optimization.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 187, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 264, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/scratch/hyin/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 135, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 40, in __call__\nTypeError: '<' not supported between instances of 'list' and 'float'\n.", "error": "TypeError(\"'<' not supported between instances of 'list' and 'float'\")Traceback (most recent call last):\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 187, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 264, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/scratch/hyin/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 135, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 40, in __call__\nTypeError: '<' not supported between instances of 'list' and 'float'\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "850254bd-54d3-429c-81ea-4f0731110bc9", "solution": "import numpy as np\n\nclass AMSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.memory_archive = []\n        self.archive_size = 20\n        self.population_size = 10\n\n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def update_memory_archive(self, solution, value):\n        self.memory_archive.append((solution.copy(), value))\n        self.memory_archive = sorted(self.memory_archive, key=lambda x: x[1])[:self.archive_size]\n\n    def adaptive_exploration(self, lb, ub):\n        if self.memory_archive:\n            selected_solution, _ = self.memory_archive[np.random.randint(len(self.memory_archive))]\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = selected_solution + perturbation * (ub - lb)\n            return np.clip(candidate, lb, ub)\n        else:\n            return lb + (ub - lb) * np.random.rand(self.dim)\n\n    def local_refinement(self, solution, lb, ub):\n        perturbation = np.random.normal(0, 0.01, self.dim)\n        new_solution = solution + perturbation * (ub - lb)\n        return np.clip(new_solution, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            candidate_solutions = []\n            for _ in range(self.population_size):\n                if evaluations < self.budget // 2:\n                    candidate = self.adaptive_exploration(lb, ub)\n                else:\n                    candidate = self.local_refinement(self.best_solution, lb, ub)\n                candidate_solutions.append(candidate)\n\n            for solution in candidate_solutions:\n                value = func(solution)\n                evaluations += 1\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = solution\n                self.update_memory_archive(solution, value)\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_solution, self.best_value", "name": "AMSO", "description": "Introducing Adaptive Memory-Based Search Optimization (AMSO), which utilizes a dynamic memory archive to adaptively balance exploration and exploitation for enhanced black-box optimization.", "configspace": "", "generation": 1, "fitness": 0.831655247541411, "feedback": "The algorithm AMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83 with standard deviation 0.04.", "error": "", "parent_id": "feb7a1a4-a7b0-4e42-bec0-46e82903d9d5", "metadata": {"aucs": [0.8706189207524145, 0.7926915743304073]}, "mutation_prompt": null}
{"id": "b8e8fa13-3e6f-4b94-adea-aeff77797edd", "solution": "import numpy as np\n\nclass QIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.alpha = 0.9  # Quantum probability amplitude\n        self.beta = 0.1  # Perturbation factor\n\n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def quantum_update(self, particle, lb, ub):\n        random_vector = np.random.rand(self.dim)\n        quantum_position = np.where(random_vector < self.alpha,\n                                    particle + self.beta * np.random.normal(0, 1, self.dim),\n                                    lb + (ub - lb) * np.random.rand(self.dim))\n        return np.clip(quantum_position, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                quantum_particle = self.quantum_update(population[i], lb, ub)\n                value = func(quantum_particle)\n                evaluations += 1\n\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = quantum_particle\n\n                # Update the original particle position based on quantum mechanism\n                population[i] = quantum_particle\n\n        return self.best_solution, self.best_value", "name": "QIPSO", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) that leverages a novel quantum-inspired update mechanism to enhance diversity and convergence in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.5927814587514515, "feedback": "The algorithm QIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.59 with standard deviation 0.03.", "error": "", "parent_id": "850254bd-54d3-429c-81ea-4f0731110bc9", "metadata": {"aucs": [0.5596902142876408, 0.6258727032152622]}, "mutation_prompt": null}
{"id": "f12990a0-6a58-45de-9e32-ef38de60c691", "solution": "import numpy as np\n\nclass QIEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 10\n        self.quantum_population = np.pi * np.random.rand(self.population_size, self.dim)\n\n    def update_quantum_population(self, lb, ub):\n        angles = np.random.uniform(-np.pi / 4, np.pi / 4, (self.population_size, self.dim))\n        self.quantum_population += angles\n        self.solutions = lb + (ub - lb) * 0.5 * (1 + np.sin(self.quantum_population))\n        \n    def quantum_crossover(self):\n        new_population = []\n        for i in range(self.population_size):\n            partner_index = np.random.randint(self.population_size)\n            crossover_point = np.random.randint(1, self.dim)\n            new_individual = np.concatenate((self.quantum_population[i, :crossover_point], \n                                             self.quantum_population[partner_index, crossover_point:]))\n            new_population.append(new_individual)\n        self.quantum_population = np.array(new_population)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            self.update_quantum_population(lb, ub)\n\n            for solution in self.solutions:\n                value = func(solution)\n                evaluations += 1\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = solution\n\n                if evaluations >= self.budget:\n                    break\n\n            self.quantum_crossover()\n\n        return self.best_solution, self.best_value", "name": "QIEA", "description": "Introducing Quantum-Inspired Evolutionary Algorithm (QIEA), leveraging quantum superposition and entanglement principles to enhance global exploration and local exploitation in black-box optimization.", "configspace": "", "generation": 3, "fitness": 0.6264528189373646, "feedback": "The algorithm QIEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63 with standard deviation 0.00.", "error": "", "parent_id": "850254bd-54d3-429c-81ea-4f0731110bc9", "metadata": {"aucs": [0.6273941382205113, 0.6255114996542179]}, "mutation_prompt": null}
{"id": "30cbd730-5866-4fcc-af84-7ab527e8e0c7", "solution": "import numpy as np\n\nclass QIEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.alpha = np.random.rand(self.population_size, self.dim)\n        self.beta = np.sqrt(1 - np.square(self.alpha))\n        self.rotation_angle = 0.01\n\n    def observe(self):\n        return np.where(np.random.rand(self.population_size, self.dim) < np.square(self.alpha), 1, -1)\n\n    def rotate(self, solutions, lb, ub, evaluations):\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if evaluations < self.budget * 0.5:\n                    theta = np.random.uniform(-self.rotation_angle, self.rotation_angle)\n                else:\n                    theta = self.rotation_angle * (self.best_solution[j] - solutions[i][j])\n                self.alpha[i, j] = self.alpha[i, j] * np.cos(theta) - self.beta[i, j] * np.sin(theta)\n                self.beta[i, j] = np.sqrt(1 - np.square(self.alpha[i, j]))\n\n            solutions[i] = np.clip(solutions[i], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        solutions = self.observe() * (ub - lb) / 2 + (ub + lb) / 2\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                solution = solutions[i]\n                value = func(solution)\n                evaluations += 1\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = solution\n\n                if evaluations >= self.budget:\n                    break\n\n            self.rotate(solutions, lb, ub, evaluations)\n            solutions = self.observe() * (ub - lb) / 2 + (ub + lb) / 2\n\n        return self.best_solution, self.best_value", "name": "QIEA", "description": "Quantum-Inspired Evolutionary Algorithm (QIEA) introduces quantum bits representation and quantum rotation gates to the search process, enhancing diversity and convergence in optimizing photonic structures.", "configspace": "", "generation": 4, "fitness": 0.30112996063075587, "feedback": "The algorithm QIEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "850254bd-54d3-429c-81ea-4f0731110bc9", "metadata": {"aucs": [0.3011435909912731, 0.30111633027023865]}, "mutation_prompt": null}
{"id": "e593b3ab-bb4a-4b60-bb51-e29dc22a627d", "solution": "import numpy as np\n\nclass QIES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 10\n        self.quantum_population = np.pi * np.random.rand(self.population_size, self.dim)\n\n    def decode(self, quantum_state, lb, ub):\n        binary_population = np.cos(quantum_state) ** 2\n        solution = lb + (ub - lb) * binary_population\n        return solution\n\n    def quantum_rotation(self, quantum_state, direction_vector):\n        return quantum_state + np.pi * direction_vector * np.random.rand(self.dim)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            candidate_solutions = []\n            for q_state in self.quantum_population:\n                solution = self.decode(q_state, lb, ub)\n                candidate_solutions.append(solution)\n            \n            for solution in candidate_solutions:\n                value = func(solution)\n                evaluations += 1\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = solution\n\n                if evaluations >= self.budget:\n                    break\n\n            # Quantum-inspired rotation to explore new regions\n            direction_vectors = np.random.choice([-1, 1], size=(self.population_size, self.dim))\n            self.quantum_population = np.array([\n                self.quantum_rotation(q, d) for q, d in zip(self.quantum_population, direction_vectors)\n            ])\n\n        return self.best_solution, self.best_value", "name": "QIES", "description": "Introducing Quantum-Inspired Evolutionary Search (QIES), which leverages quantum superposition principles to maintain a diverse population and escape local optima in black-box optimization.", "configspace": "", "generation": 5, "fitness": 0.5801938415746782, "feedback": "The algorithm QIES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.58 with standard deviation 0.04.", "error": "", "parent_id": "850254bd-54d3-429c-81ea-4f0731110bc9", "metadata": {"aucs": [0.5410844364494003, 0.6193032466999562]}, "mutation_prompt": null}
{"id": "3a621683-d663-461e-af61-4b93bf9bfe5e", "solution": "import numpy as np\n\nclass FEAMO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.memory_archive = []\n        self.archive_size = 20\n        self.population_size = 10\n\n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def update_memory_archive(self, solution, value):\n        self.memory_archive.append((solution.copy(), value))\n        self.memory_archive = sorted(self.memory_archive, key=lambda x: x[1])[:self.archive_size]\n\n    def extract_features(self, solutions):\n        if not solutions:\n            return np.zeros(self.dim)\n        return np.mean([s[0] for s in solutions], axis=0)\n\n    def adaptive_exploration(self, lb, ub):\n        if self.memory_archive:\n            feature_vector = self.extract_features(self.memory_archive)\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = feature_vector + perturbation * (ub - lb)\n            return np.clip(candidate, lb, ub)\n        else:\n            return lb + (ub - lb) * np.random.rand(self.dim)\n\n    def local_refinement(self, solution, lb, ub):\n        perturbation = np.random.normal(0, 0.01, self.dim)\n        new_solution = solution + perturbation * (ub - lb)\n        return np.clip(new_solution, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            candidate_solutions = []\n            for _ in range(self.population_size):\n                if evaluations < self.budget // 2:\n                    candidate = self.adaptive_exploration(lb, ub)\n                else:\n                    candidate = self.local_refinement(self.best_solution, lb, ub)\n                candidate_solutions.append(candidate)\n\n            for solution in candidate_solutions:\n                value = func(solution)\n                evaluations += 1\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = solution\n                self.update_memory_archive(solution, value)\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_solution, self.best_value", "name": "FEAMO", "description": "Introducing Feature-Enhanced Adaptive Memory Optimization (FEAMO), leveraging feature extraction from successful solutions to guide more informed search paths and enhance global exploration for black-box optimization.", "configspace": "", "generation": 6, "fitness": 0.827915806965259, "feedback": "The algorithm FEAMO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83 with standard deviation 0.00.", "error": "", "parent_id": "850254bd-54d3-429c-81ea-4f0731110bc9", "metadata": {"aucs": [0.8313605634183892, 0.824471050512129]}, "mutation_prompt": null}
{"id": "7f80fbef-6cf7-4a68-93bf-234c9fc886da", "solution": "import numpy as np\n\nclass QI_AMO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.memory_archive = []\n        self.archive_size = 20\n        self.population_size = 10\n\n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def update_memory_archive(self, solution, value):\n        self.memory_archive.append((solution.copy(), value))\n        self.memory_archive = sorted(self.memory_archive, key=lambda x: x[1])[:self.archive_size]\n\n    def quantum_superposition(self, lb, ub):\n        if self.memory_archive:\n            weights = np.exp(-np.arange(len(self.memory_archive)))\n            weights /= np.sum(weights)\n            idx = np.random.choice(len(self.memory_archive), p=weights)\n            selected_solution, _ = self.memory_archive[idx]\n            quantum_perturbation = np.random.uniform(-0.5, 0.5, self.dim)\n            candidate = selected_solution + quantum_perturbation * (ub - lb)\n            return np.clip(candidate, lb, ub)\n        else:\n            return lb + (ub - lb) * np.random.rand(self.dim)\n\n    def local_refinement(self, solution, lb, ub):\n        perturbation = np.random.normal(0, 0.01, self.dim)\n        new_solution = solution + perturbation * (ub - lb)\n        return np.clip(new_solution, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            candidate_solutions = []\n            for _ in range(self.population_size):\n                if evaluations < self.budget // 2:\n                    candidate = self.quantum_superposition(lb, ub)\n                else:\n                    candidate = self.local_refinement(self.best_solution, lb, ub) if self.best_solution is not None else self.quantum_superposition(lb, ub)\n                candidate_solutions.append(candidate)\n\n            for solution in candidate_solutions:\n                value = func(solution)\n                evaluations += 1\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = solution\n                self.update_memory_archive(solution, value)\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_solution, self.best_value", "name": "QI_AMO", "description": "Quantum-Inspired Adaptive Memory Optimization (QI-AMO) leverages quantum superposition principles and adaptive learning to enhance exploration and exploitation for improved convergence in black-box optimization.", "configspace": "", "generation": 7, "fitness": 0.7630975655224657, "feedback": "The algorithm QI_AMO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.76 with standard deviation 0.00.", "error": "", "parent_id": "850254bd-54d3-429c-81ea-4f0731110bc9", "metadata": {"aucs": [0.7583202601091703, 0.767874870935761]}, "mutation_prompt": null}
{"id": "66c01a23-e20f-455b-bc4a-2824343a8916", "solution": "import numpy as np\n\nclass GE_AMSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.memory_archive = []\n        self.archive_size = 20\n        self.population_size = 10\n        self.gradient_steps = 5\n\n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def update_memory_archive(self, solution, value):\n        self.memory_archive.append((solution.copy(), value))\n        self.memory_archive = sorted(self.memory_archive, key=lambda x: x[1])[:self.archive_size]\n\n    def adaptive_exploration(self, lb, ub):\n        if self.memory_archive:\n            selected_solution, _ = self.memory_archive[np.random.randint(len(self.memory_archive))]\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = selected_solution + perturbation * (ub - lb)\n            return np.clip(candidate, lb, ub)\n        else:\n            return lb + (ub - lb) * np.random.rand(self.dim)\n\n    def local_refinement(self, solution, lb, ub):\n        perturbation = np.random.normal(0, 0.01, self.dim)\n        new_solution = solution + perturbation * (ub - lb)\n        return np.clip(new_solution, lb, ub)\n\n    def estimate_gradient(self, solution, func, lb, ub):\n        grad = np.zeros(self.dim)\n        sigma = 0.01 * (ub - lb)\n        for i in range(self.dim):\n            step = np.zeros(self.dim)\n            step[i] = sigma[i]\n            value1 = func(solution + step)\n            value2 = func(solution - step)\n            grad[i] = (value1 - value2) / (2 * sigma[i])\n        return grad\n\n    def gradient_refinement(self, solution, func, lb, ub):\n        current_solution = solution.copy()\n        for _ in range(self.gradient_steps):\n            grad = self.estimate_gradient(current_solution, func, lb, ub)\n            current_solution -= 0.1 * grad * (ub - lb)\n            current_solution = np.clip(current_solution, lb, ub)\n        return current_solution\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            candidate_solutions = []\n            for _ in range(self.population_size):\n                if evaluations < self.budget // 3:\n                    candidate = self.adaptive_exploration(lb, ub)\n                elif evaluations < 2 * self.budget // 3:\n                    candidate = self.local_refinement(self.best_solution, lb, ub)\n                else:\n                    candidate = self.gradient_refinement(self.best_solution, func, lb, ub)\n                candidate_solutions.append(candidate)\n\n            for solution in candidate_solutions:\n                value = func(solution)\n                evaluations += 1\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = solution\n                self.update_memory_archive(solution, value)\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_solution, self.best_value", "name": "GE_AMSO", "description": "Introducing Gradient-Enhanced Adaptive Memory-Based Search Optimization (GE-AMSO), which integrates gradient estimation to refine solutions dynamically, improving convergence speed and efficiency in photonic structure optimization.", "configspace": "", "generation": 8, "fitness": 0.7905566166783058, "feedback": "The algorithm GE_AMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.79 with standard deviation 0.01.", "error": "", "parent_id": "850254bd-54d3-429c-81ea-4f0731110bc9", "metadata": {"aucs": [0.7808114162463653, 0.8003018171102462]}, "mutation_prompt": null}
{"id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "solution": "import numpy as np\n\nclass QIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.phi = np.pi / 4  # Quantum rotation angle\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def quantum_update(self, particle, global_best, lb, ub):\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = self.phi if r < 0.5 else -self.phi\n            particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (global_best[i] - particle['position'][i]) * np.sin(theta)\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()  # Re-initialize if out of bounds\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update positions based on global best\n            for particle in self.swarms:\n                self.quantum_update(particle, self.best_solution, lb, ub)\n\n        return self.best_solution, self.best_value", "name": "QIPSO", "description": "Introducing Quantum-Inspired Particle Swarm Optimization (QIPSO) that leverages quantum superposition and entanglement principles to enhance search diversity and convergence in black-box optimization.", "configspace": "", "generation": 9, "fitness": 0.8555610830077176, "feedback": "The algorithm QIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.86 with standard deviation 0.09.", "error": "", "parent_id": "850254bd-54d3-429c-81ea-4f0731110bc9", "metadata": {"aucs": [0.7666192840504787, 0.9445028819649565]}, "mutation_prompt": null}
{"id": "790c0d34-72db-426c-915a-4d41175897fa", "solution": "import numpy as np\n\nclass GQIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.f = 0.5  # Differential evolution scaling factor\n        self.cr = 0.9  # Crossover probability\n        self.phi = np.pi / 4  # Quantum rotation angle\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': position, 'best_value': float('inf')})\n        return population\n\n    def quantum_crossover(self, target, mutant, lb, ub):\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = self.phi if r < 0.5 else -self.phi\n            target['position'][i] = target['position'][i] * np.cos(theta) + mutant[i] * np.sin(theta)\n            if target['position'][i] < lb[i] or target['position'][i] > ub[i]:\n                target['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()  # Re-initialize if out of bounds\n\n        target['position'] = np.clip(target['position'], lb, ub)\n\n    def mutate(self, idx, lb, ub):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a]['position'] + self.f * (self.population[b]['position'] - self.population[c]['position'])\n        return np.clip(mutant, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, lb, ub)\n\n                trial = {'position': np.copy(target['position']), 'best_value': float('inf')}\n                self.quantum_crossover(trial, mutant, lb, ub)\n\n                trial_value = func(trial['position'])\n                evaluations += 1\n\n                if trial_value < target['best_value']:\n                    self.population[i]['position'] = trial['position']\n                    self.population[i]['best_value'] = trial_value\n\n                if trial_value < self.best_value:\n                    self.best_value = trial_value\n                    self.best_solution = trial['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_solution, self.best_value", "name": "GQIDE", "description": "Introducing Genetic Quantum-Inspired Differential Evolution (GQIDE) that combines principles of quantum mechanics with differential evolution, using entangled states to adaptively guide the search and crossover operations for diverse and efficient global optimization.", "configspace": "", "generation": 10, "fitness": 0.6315410078041335, "feedback": "The algorithm GQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63 with standard deviation 0.03.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.599575212616394, 0.6635068029918729]}, "mutation_prompt": null}
{"id": "1b246380-8ed5-4fd9-9bae-3169066b6d47", "solution": "import numpy as np\n\nclass AQGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 30\n        self.genes = []\n        self.phi = np.pi / 6  # Quantum rotation angle\n        self.mutation_rate = 0.1\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': position, 'fitness': float('inf')})\n        return population\n\n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        child_position = np.empty(self.dim)\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = self.phi if r < 0.5 else -self.phi\n            child_position[i] = parent1['position'][i] * np.cos(theta) + parent2['position'][i] * np.sin(theta)\n            if child_position[i] < lb[i] or child_position[i] > ub[i]:\n                child_position[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n        return np.clip(child_position, lb, ub)\n\n    def mutate(self, individual, lb, ub):\n        for i in range(self.dim):\n            if np.random.rand() < self.mutation_rate:\n                individual['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n        individual['position'] = np.clip(individual['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.genes = self.initialize_population(lb, ub)\n        \n        while evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size // 2):\n                parent1, parent2 = np.random.choice(self.genes, 2, replace=False)\n                child1_position = self.quantum_crossover(parent1, parent2, lb, ub)\n                child2_position = self.quantum_crossover(parent2, parent1, lb, ub)\n\n                for child_position in [child1_position, child2_position]:\n                    child = {'position': child_position, 'fitness': func(child_position)}\n                    evaluations += 1\n\n                    if child['fitness'] < self.best_value:\n                        self.best_value = child['fitness']\n                        self.best_solution = child['position'].copy()\n\n                    self.mutate(child, lb, ub)\n                    new_population.append(child)\n\n                    if evaluations >= self.budget:\n                        break\n                if evaluations >= self.budget:\n                    break\n\n            self.genes = sorted(new_population, key=lambda x: x['fitness'])[:self.population_size]\n\n        return self.best_solution, self.best_value", "name": "AQGA", "description": "Introducing Adaptive Quantum Genetic Algorithm (AQGA) that combines dynamic quantum-inspired operators and adaptive genetic mechanisms to balance exploration and exploitation for enhanced convergence.", "configspace": "", "generation": 11, "fitness": 0.8477456645247381, "feedback": "The algorithm AQGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85 with standard deviation 0.10.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.9494594341997475, 0.7460318948497286]}, "mutation_prompt": null}
{"id": "3f89542e-0d8d-4a1d-9ef2-723066c61a14", "solution": "import numpy as np\n\nclass QIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.populations = []\n        self.phi = np.pi / 4  # Quantum rotation angle\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': position, 'best_position': position, 'best_value': float('inf')})\n        return population\n\n    def quantum_mutation(self, target_idx, lb, ub):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.populations[a]['position'] + self.F * (self.populations[b]['position'] - self.populations[c]['position'])\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        trial = np.copy(target)\n        for i in range(self.dim):\n            if np.random.rand() < self.CR or i == np.random.randint(self.dim):\n                trial[i] = mutant[i]\n        return trial\n\n    def quantum_update(self, position, global_best, lb, ub):\n        new_position = np.copy(position)\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = self.phi if r < 0.5 else -self.phi\n            new_position[i] = new_position[i] * np.cos(theta) + (global_best[i] - new_position[i]) * np.sin(theta)\n            new_position[i] = np.clip(new_position[i], lb[i], ub[i])\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.populations = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            for idx, individual in enumerate(self.populations):\n                mutant = self.quantum_mutation(idx, lb, ub)\n                trial = self.crossover(individual['position'], mutant)\n                trial = self.quantum_update(trial, self.best_solution if self.best_solution is not None else lb + (ub - lb) * 0.5, lb, ub)\n                \n                value = func(trial)\n                evaluations += 1\n\n                if value < individual['best_value']:\n                    individual['best_value'] = value\n                    individual['best_position'] = trial\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = trial\n\n                if evaluations >= self.budget:\n                    break\n        \n        return self.best_solution, self.best_value", "name": "QIDE", "description": "Quantum-Inspired Differential Evolution (QIDE) combines differential evolution with quantum-inspired mechanisms to enhance exploration and exploitation in high-dimensional black-box optimization.", "configspace": "", "generation": 12, "fitness": 0.5312589768516962, "feedback": "The algorithm QIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.53 with standard deviation 0.02.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.5072191722568744, 0.555298781446518]}, "mutation_prompt": null}
{"id": "29e7a806-214e-4b38-8322-1ab422ca8196", "solution": "import numpy as np\n\nclass AMGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.memory_size = 5\n        self.mutation_rate = 0.1\n        self.memory = []\n        self.best_solution = None\n        self.best_value = float('inf')\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            individual = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': individual, 'value': float('inf')})\n        return population\n\n    def evaluate(self, population, func):\n        for individual in population:\n            if 'value' not in individual or np.isinf(individual['value']):\n                individual['value'] = func(individual['position'])\n        return population\n\n    def select_parents(self, population):\n        idx1, idx2 = np.random.choice(len(population), 2, replace=False)\n        return population[idx1] if population[idx1]['value'] < population[idx2]['value'] else population[idx2]\n\n    def crossover(self, parent1, parent2):\n        alpha = np.random.rand(self.dim)\n        child = alpha * parent1['position'] + (1 - alpha) * parent2['position']\n        return child\n\n    def mutate(self, individual, lb, ub):\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = lb + (ub - lb) * np.random.rand(self.dim)\n            individual['position'] += mutation_vector * (np.random.rand(self.dim) - 0.5)\n        individual['position'] = np.clip(individual['position'], lb, ub)\n\n    def update_memory(self, individual):\n        if len(self.memory) < self.memory_size:\n            self.memory.append(individual)\n        else:\n            worst_index = np.argmax([ind['value'] for ind in self.memory])\n            if individual['value'] < self.memory[worst_index]['value']:\n                self.memory[worst_index] = individual\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n        \n        while evaluations < self.budget:\n            population = self.evaluate(population, func)\n            \n            # Update global best solution\n            for individual in population:\n                if individual['value'] < self.best_value:\n                    self.best_value = individual['value']\n                    self.best_solution = individual['position'].copy()\n                    self.update_memory(individual)\n            \n            # Generate new population\n            new_population = []\n            while len(new_population) < self.population_size and evaluations < self.budget:\n                parent1 = self.select_parents(population)\n                parent2 = self.select_parents(population)\n                child_position = self.crossover(parent1, parent2)\n                child = {'position': child_position, 'value': float('inf')}\n                self.mutate(child, lb, ub)\n                new_population.append(child)\n                evaluations += 1\n            \n            population = new_population[:self.population_size]\n        \n        return self.best_solution, self.best_value", "name": "AMGA", "description": "Introducing Adaptive Memory-Based Genetic Algorithm (AMGA) that combines memory mechanisms with adaptive mutation strategies to dynamically balance exploration and exploitation in optimizing black-box functions.", "configspace": "", "generation": 13, "fitness": 0.6643354374301088, "feedback": "The algorithm AMGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.00.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.6637026594253876, 0.66496821543483]}, "mutation_prompt": null}
{"id": "e495672f-01f5-4f37-897a-ddfc3b764496", "solution": "import numpy as np\nfrom scipy.special import gamma\n\nclass ALFGWO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.alpha = None\n        self.beta = None\n        self.delta = None\n        self.best_value = float('inf')\n        self.wolf_pack_size = 20\n        self.wolves = []\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) / (gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return L * step\n\n    def initialize_wolves(self, lb, ub):\n        wolves = []\n        for _ in range(self.wolf_pack_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            wolves.append({'position': position, 'fitness': float('inf')})\n        return wolves\n\n    def update_positions(self, lb, ub):\n        a = 2 - 2 * (self.evaluations / self.budget)\n        \n        for wolf in self.wolves:\n            A1, A2, A3 = 2 * a * np.random.rand(self.dim) - a, 2 * a * np.random.rand(self.dim) - a, 2 * a * np.random.rand(self.dim) - a\n            C1, C2, C3 = 2 * np.random.rand(self.dim), 2 * np.random.rand(self.dim), 2 * np.random.rand(self.dim)\n\n            D_alpha = np.abs(C1 * self.alpha['position'] - wolf['position'])\n            D_beta = np.abs(C2 * self.beta['position'] - wolf['position'])\n            D_delta = np.abs(C3 * self.delta['position'] - wolf['position'])\n\n            X1 = self.alpha['position'] - A1 * D_alpha\n            X2 = self.beta['position'] - A2 * D_beta\n            X3 = self.delta['position'] - A3 * D_delta\n\n            new_position = (X1 + X2 + X3) / 3\n            flight = self.levy_flight(0.01)\n            wolf['position'] = np.clip(new_position + flight, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.wolves = self.initialize_wolves(lb, ub)\n        self.evaluations = 0\n        \n        while self.evaluations < self.budget:\n            for wolf in self.wolves:\n                wolf['fitness'] = func(wolf['position'])\n                self.evaluations += 1\n                \n                if wolf['fitness'] < self.best_value:\n                    self.best_value = wolf['fitness']\n                    self.alpha, self.beta, self.delta = sorted(self.wolves, key=lambda x: x['fitness'])[:3]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.update_positions(lb, ub)\n\n        return self.alpha['position'], self.best_value", "name": "ALFGWO", "description": "Introducing Adaptive Levy Flight Grey Wolf Optimizer (ALFGWO) that combines Grey Wolf Optimization with Levy flight for better exploration and adaptability in complex search spaces.", "configspace": "", "generation": 14, "fitness": 0.6069030511340682, "feedback": "The algorithm ALFGWO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61 with standard deviation 0.03.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.6360940533480886, 0.5777120489200478]}, "mutation_prompt": null}
{"id": "c00b212f-0e42-4f33-94fe-1159361863e2", "solution": "import numpy as np\n\nclass AHS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.harmony_memory_size = 20\n        self.harmonies = []\n        self.hmcr = 0.9  # Harmony Memory Consideration Rate\n        self.par = 0.3   # Pitch Adjusting Rate\n        self.bw = 0.01   # Bandwidth for pitch adjustment\n\n    def initialize_harmonies(self, lb, ub):\n        harmonies = []\n        for _ in range(self.harmony_memory_size):\n            harmony = lb + (ub - lb) * np.random.rand(self.dim)\n            harmonies.append(harmony)\n        return harmonies\n\n    def pitch_adjustment(self, harmony, lb, ub):\n        if np.random.rand() < self.par:\n            dim_to_adjust = np.random.randint(self.dim)\n            harmony[dim_to_adjust] += self.bw * (2 * np.random.rand() - 1)\n            harmony[dim_to_adjust] = np.clip(harmony[dim_to_adjust], lb[dim_to_adjust], ub[dim_to_adjust])\n\n    def generate_new_harmony(self, lb, ub):\n        new_harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < self.hmcr:\n                harmony_index = np.random.randint(self.harmony_memory_size)\n                new_harmony[i] = self.harmonies[harmony_index][i]\n            else:\n                new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n        \n        self.pitch_adjustment(new_harmony, lb, ub)\n        return new_harmony\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.harmonies = self.initialize_harmonies(lb, ub)\n\n        while evaluations < self.budget:\n            new_harmony = self.generate_new_harmony(lb, ub)\n            value = func(new_harmony)\n            evaluations += 1\n\n            if value < self.best_value:\n                self.best_value = value\n                self.best_solution = new_harmony.copy()\n\n            # Replace worst harmony if the new harmony is better\n            worst_idx = np.argmax([func(harmony) for harmony in self.harmonies])\n            if value < func(self.harmonies[worst_idx]):\n                self.harmonies[worst_idx] = new_harmony\n\n            if evaluations >= self.budget:\n                break\n\n        return self.best_solution, self.best_value", "name": "AHS", "description": "Adaptive Harmony Search (AHS) employs dynamic pitch adjustment and an adaptive harmony memory consideration to balance exploration and exploitation in black-box optimization.", "configspace": "", "generation": 15, "fitness": 0.43642047361184216, "feedback": "The algorithm AHS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.00.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.43677889283479354, 0.4360620543888908]}, "mutation_prompt": null}
{"id": "0be5df60-5345-4dac-aba0-747d7ff0858a", "solution": "import numpy as np\n\nclass AQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.initial_swarm_size = 20\n        self.swarm_size = self.initial_swarm_size\n        self.phi = np.pi / 4  # Initial quantum rotation angle\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def quantum_update(self, particle, global_best, lb, ub):\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = self.phi if r < 0.5 else -self.phi\n            particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (global_best[i] - particle['position'][i]) * np.sin(theta)\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adapt_parameters(self, improvement_rate):\n        # Adjust phi to increase exploration when improvements slow down\n        self.phi = max(0.1, self.phi * (1 + 0.1 * (1 - improvement_rate)))\n        # Adjust swarm size to enhance exploitation when improvements are good\n        self.swarm_size = max(self.initial_swarm_size, int(self.swarm_size * (1 + 0.05 * improvement_rate)))\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        previous_best_value = self.best_value\n\n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n\n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n                    improvement_rate = (previous_best_value - self.best_value) / abs(previous_best_value)\n                    self.adapt_parameters(improvement_rate)\n                    previous_best_value = self.best_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update positions based on global best\n            for particle in self.swarms:\n                self.quantum_update(particle, self.best_solution, lb, ub)\n\n        return self.best_solution, self.best_value", "name": "AQIPSO", "description": "Introducing Adaptive Quantum-Inspired Particle Swarm Optimization (AQIPSO) that dynamically adjusts quantum rotation angles and swarm size based on performance feedback to enhance convergence and robustness in black-box optimization.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('cannot convert float NaN to integer').", "error": "ValueError('cannot convert float NaN to integer')", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {}, "mutation_prompt": null}
{"id": "3dd7402a-5bbd-4a27-a978-9249811aaf4e", "solution": "import numpy as np\n\nclass HQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.phi = np.pi / 4  # Quantum rotation angle\n        self.turbulence_chance = 0.1  # Chance to apply adaptive turbulence\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def quantum_update(self, particle, global_best, lb, ub):\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = self.phi if r < 0.5 else -self.phi\n            particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (global_best[i] - particle['position'][i]) * np.sin(theta)\n            if np.random.rand() < self.turbulence_chance:\n                particle['velocity'][i] *= np.random.uniform(-1.5, 1.5)  # Apply turbulence\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()  # Re-initialize if out of bounds\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update positions based on global best\n            for particle in self.swarms:\n                self.quantum_update(particle, self.best_solution, lb, ub)\n\n        return self.best_solution, self.best_value", "name": "HQPSO", "description": "Introducing Hybrid Quantum-Guided Particle Swarm Optimization (HQPSO) which combines classical PSO with quantum-inspired mechanisms and adaptive turbulence to enhance exploration and convergence in black-box optimization.", "configspace": "", "generation": 17, "fitness": 0.7011157537126731, "feedback": "The algorithm HQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.01.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.7118151244615722, 0.6904163829637741]}, "mutation_prompt": null}
{"id": "0946640c-bd3a-4610-a188-7d521ab3934a", "solution": "import numpy as np\n\nclass AHS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.harmony_memory_size = 20\n        self.harmony_memory = []\n        self.hmcr = 0.9  # Harmony Memory Consideration Rate\n        self.par_min = 0.1  # Minimum Pitch Adjustment Rate\n        self.par_max = 0.5  # Maximum Pitch Adjustment Rate\n\n    def initialize_harmony_memory(self, lb, ub):\n        for _ in range(self.harmony_memory_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = float('inf')\n            self.harmony_memory.append({'position': position, 'value': value})\n\n    def adaptive_pitch_adjustment(self, position, lb, ub, iteration, max_iter):\n        par = self.par_min + ((self.par_max - self.par_min) * iteration / max_iter)\n        if np.random.rand() < par:\n            pitch_adjustment = (ub - lb) * (np.random.rand(self.dim) * 2 - 1) * 0.01\n            position += pitch_adjustment\n        return np.clip(position, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.initialize_harmony_memory(lb, ub)\n\n        while evaluations < self.budget:\n            new_position = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    selected_harmony = self.harmony_memory[np.random.randint(self.harmony_memory_size)]\n                    new_position[i] = selected_harmony['position'][i]\n                else:\n                    new_position[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n            \n            new_position = self.adaptive_pitch_adjustment(new_position, lb, ub, evaluations, self.budget)\n            new_value = func(new_position)\n            evaluations += 1\n\n            if new_value < self.best_value:\n                self.best_value = new_value\n                self.best_solution = new_position.copy()\n\n            worst_index = np.argmax([h['value'] for h in self.harmony_memory])\n            if new_value < self.harmony_memory[worst_index]['value']:\n                self.harmony_memory[worst_index] = {'position': new_position, 'value': new_value}\n\n        return self.best_solution, self.best_value", "name": "AHS", "description": "Introducing the Adaptive Harmony Search (AHS), a novel algorithm that combines harmony search principles with adaptive pitch adjustment and memory consideration to optimize the search process in black-box optimization problems.", "configspace": "", "generation": 18, "fitness": 0.49253485752933834, "feedback": "The algorithm AHS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.49 with standard deviation 0.01.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.4866993994479625, 0.4983703156107142]}, "mutation_prompt": null}
{"id": "fb1623c0-24a3-44e1-948d-860bc8a44166", "solution": "import numpy as np\n\nclass AQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.phi = np.pi / 4  # Quantum rotation angle\n        self.inertia_weight = 0.9  # Inertia weight for adaptive velocity update\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def quantum_update(self, particle, global_best, lb, ub):\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = self.phi if r < 0.5 else -self.phi\n            # Adaptive velocity update\n            particle['velocity'][i] = self.inertia_weight * particle['velocity'][i] * np.cos(theta) + \\\n                                      (global_best[i] - particle['position'][i]) * np.sin(theta)\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()  # Re-initialize if out of bounds\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def dynamic_phi(self, evaluations):\n        # Dynamically adjust phi to balance exploration and exploitation\n        return max(self.phi * (1 - evaluations / self.budget), self.phi / 10)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update positions based on global best\n            self.phi = self.dynamic_phi(evaluations)  # Update phi dynamically\n            for particle in self.swarms:\n                self.quantum_update(particle, self.best_solution, lb, ub)\n\n        return self.best_solution, self.best_value", "name": "AQIPSO", "description": "Introducing Adaptive Quantum-Inspired Particle Swarm Optimization (AQIPSO) with dynamic learning strategies to balance exploration and exploitation in black-box optimization.", "configspace": "", "generation": 19, "fitness": 0.8252778463587372, "feedback": "The algorithm AQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83 with standard deviation 0.04.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.7833899091376189, 0.8671657835798556]}, "mutation_prompt": null}
{"id": "59206941-543b-4896-a02a-43c60867341b", "solution": "import numpy as np\n\nclass HDEQIM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.population = []\n        self.F = 0.7  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.phi = np.pi / 4  # Quantum mutation angle\n        self.best_solution = None\n        self.best_value = float('inf')\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.pop_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': position, 'value': float('inf')})\n        return population\n\n    def quantum_mutation(self, position, best_position):\n        mutated_position = position.copy()\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = self.phi if r < 0.5 else -self.phi\n            mutated_position[i] = position[i] * np.cos(theta) + (best_position[i] - position[i]) * np.sin(theta)\n        return mutated_position\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            new_population = []\n            for target in self.population:\n                indices = np.random.choice(range(self.pop_size), 3, replace=False)\n                a, b, c = [self.population[idx]['position'] for idx in indices]\n\n                # Differential Evolution Mutation\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                trial = np.copy(target['position'])\n\n                # Crossover\n                for i in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[i] = mutant[i]\n\n                # Quantum Mutation\n                trial = self.quantum_mutation(trial, self.best_solution if self.best_solution is not None else lb + (ub - lb) / 2)\n\n                # Selection\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < target['value']:\n                    new_population.append({'position': trial, 'value': trial_value})\n\n                    if trial_value < self.best_value:\n                        self.best_value = trial_value\n                        self.best_solution = trial\n                else:\n                    new_population.append(target)\n\n                if evaluations >= self.budget:\n                    break\n\n            self.population = new_population\n\n        return self.best_solution, self.best_value", "name": "HDEQIM", "description": "Introducing Hybrid Differential Evolution with Quantum-Inspired Mutation (HDEQIM) leveraging differential evolution principles and quantum-inspired mutation for enhanced exploration and exploitation in high-dimensional black-box optimization.", "configspace": "", "generation": 20, "fitness": 0.5162851567256562, "feedback": "The algorithm HDEQIM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.52 with standard deviation 0.04.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.5560869700655217, 0.4764833433857908]}, "mutation_prompt": null}
{"id": "a0b3534c-a549-41fa-92c4-555dddc03242", "solution": "import numpy as np\n\nclass AGSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 30\n        self.temperature = 100.0  # Initial temperature for simulated annealing\n        self.cooling_rate = 0.95\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            individual = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': individual, 'value': float('inf')})\n        return population\n\n    def mutate(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb)\n        mutated_position = individual['position'] + mutation_strength * np.random.randn(self.dim)\n        mutated_position = np.clip(mutated_position, lb, ub)\n        return mutated_position\n\n    def crossover(self, parent1, parent2):\n        alpha = np.random.rand(self.dim)\n        offspring = alpha * parent1['position'] + (1 - alpha) * parent2['position']\n        return offspring\n\n    def simulated_annealing_acceptance(self, candidate_value, current_value):\n        if candidate_value < current_value:\n            return True\n        else:\n            return np.random.rand() < np.exp((current_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            # Evaluate individuals\n            for individual in population:\n                if individual['value'] == float('inf'):\n                    individual['value'] = func(individual['position'])\n                    evaluations += 1\n                    if individual['value'] < self.best_value:\n                        self.best_value = individual['value']\n                        self.best_solution = individual['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Create new generation\n            new_population = []\n            for _ in range(self.population_size // 2):\n                parents = np.random.choice(population, 2, replace=False)\n                offspring1_pos = self.crossover(parents[0], parents[1])\n                offspring2_pos = self.crossover(parents[1], parents[0])\n                \n                for offspring_pos in [offspring1_pos, offspring2_pos]:\n                    offspring_value = func(offspring_pos)\n                    evaluations += 1\n                    if offspring_value < self.best_value:\n                        self.best_value = offspring_value\n                        self.best_solution = offspring_pos.copy()\n\n                    choice = parents[0] if self.simulated_annealing_acceptance(offspring_value, parents[0]['value']) else parents[1]\n                    mutated_offspring_pos = self.mutate({'position': offspring_pos}, lb, ub)\n                    mutated_offspring_value = func(mutated_offspring_pos)\n                    evaluations += 1\n                    if mutated_offspring_value < self.best_value:\n                        self.best_value = mutated_offspring_value\n                        self.best_solution = mutated_offspring_pos.copy()\n                    \n                    new_population.append({'position': mutated_offspring_pos, 'value': mutated_offspring_value})\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update population and temperature\n            population = new_population\n            self.temperature *= self.cooling_rate\n\n        return self.best_solution, self.best_value", "name": "AGSA", "description": "Introducing Adaptive Genetic Simulated Annealing (AGSA) that combines the exploration capabilities of genetic algorithms with the exploitation strength of simulated annealing, adaptively balancing diversity and convergence in global optimization tasks.", "configspace": "", "generation": 21, "fitness": 0.5864922210500525, "feedback": "The algorithm AGSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.59 with standard deviation 0.03.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.5558505628089538, 0.6171338792911512]}, "mutation_prompt": null}
{"id": "bf292bc6-9dc0-4d8e-a9ae-4316ef955c33", "solution": "import numpy as np\n\nclass HEA_ALR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 30\n        self.mutation_rate = 0.1\n        self.learning_rate = 0.05\n        self.best_solution = None\n        self.best_value = float('inf')\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.pop_size):\n            solution = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'solution': solution, 'value': float('inf')})\n        return population\n\n    def mutate(self, solution, lb, ub):\n        mutation = self.mutation_rate * np.random.randn(self.dim)\n        new_solution = solution + mutation\n        new_solution = np.clip(new_solution, lb, ub)\n        return new_solution\n\n    def adapt_learning_rate(self, success_rate):\n        if success_rate > 0.2:\n            self.learning_rate *= 1.2\n        else:\n            self.learning_rate *= 0.9\n        self.learning_rate = np.clip(self.learning_rate, 0.01, 0.1)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n        \n        success_count = 0\n        iteration_count = 0\n        \n        while evaluations < self.budget:\n            new_population = []\n            for individual in population:\n                candidate_solution = individual['solution'] + self.learning_rate * np.random.randn(self.dim)\n                candidate_solution = np.clip(candidate_solution, lb, ub)\n                \n                new_value = func(candidate_solution)\n                evaluations += 1\n                \n                if new_value < individual['value']:\n                    new_population.append({'solution': candidate_solution, 'value': new_value})\n                    success_count += 1\n                else:\n                    new_population.append(individual)\n                \n                if new_value < self.best_value:\n                    self.best_value = new_value\n                    self.best_solution = candidate_solution.copy()\n\n                if evaluations >= self.budget:\n                    break\n            \n            iteration_count += 1\n            if iteration_count % 5 == 0:\n                self.adapt_learning_rate(success_count / self.pop_size)\n                success_count = 0\n\n            population = new_population\n\n        return self.best_solution, self.best_value", "name": "HEA_ALR", "description": "Hybrid Evolutionary Algorithm with Adaptive Learning Rate (HEA-ALR) combining evolutionary strategies with adaptive learning for increased exploration and exploitation balance.", "configspace": "", "generation": 22, "fitness": 0.6530817140098016, "feedback": "The algorithm HEA_ALR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.04.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.695014766416608, 0.6111486616029953]}, "mutation_prompt": null}
{"id": "6b83a186-a852-4ebf-9211-afb90334f8b9", "solution": "import numpy as np\n\nclass AQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.initial_swarm_size = 20\n        self.swarms = []\n        self.phi_range = (np.pi / 6, np.pi / 3)  # Dynamic quantum rotation angle range\n        self.contraction_factor = 0.9  # To dynamically reduce swarm size\n\n    def initialize_swarm(self, lb, ub, swarm_size):\n        swarm = []\n        for _ in range(swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def quantum_update(self, particle, global_best, lb, ub, phi):\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = phi if r < 0.5 else -phi\n            particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (global_best[i] - particle['position'][i]) * np.sin(theta)\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adapt_phi(self, evaluations):\n        # Linearly interpolate phi based on the remaining budget\n        progress = evaluations / self.budget\n        return self.phi_range[0] + progress * (self.phi_range[1] - self.phi_range[0])\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        swarm_size = self.initial_swarm_size\n        self.swarms = self.initialize_swarm(lb, ub, swarm_size)\n        \n        while evaluations < self.budget:\n            phi = self.adapt_phi(evaluations)\n            swarm_size = max(5, int(swarm_size * self.contraction_factor))  # Reduce swarm size over time\n            \n            new_swarms = self.initialize_swarm(lb, ub, swarm_size - len(self.swarms))\n            self.swarms.extend(new_swarms)\n\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n                \n                if evaluations >= self.budget:\n                    break\n\n            for particle in self.swarms:\n                self.quantum_update(particle, self.best_solution, lb, ub, phi)\n\n        return self.best_solution, self.best_value", "name": "AQIPSO", "description": "Introducing Adaptive Quantum-Inspired Particle Swarm Optimization (A-QIPSO) which dynamically adjusts quantum rotation angles and swarm size to enhance exploration and exploitation balance in black-box optimization.", "configspace": "", "generation": 23, "fitness": 0.7224261144432229, "feedback": "The algorithm AQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.03.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.7529026989861973, 0.6919495299002485]}, "mutation_prompt": null}
{"id": "26bf2f9f-38c1-4aba-ae53-86dff9fff16b", "solution": "import numpy as np\n\nclass AQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.initial_phi = np.pi / 4  # Initial quantum rotation angle\n        self.phi_decay = 0.99  # Decay rate for phi to adaptively adjust exploration vs. exploitation\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def quantum_update(self, particle, global_best, lb, ub):\n        phi = self.initial_phi\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = phi if r < 0.5 else -phi\n            particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (global_best[i] - particle['position'][i]) * np.sin(theta)\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()  # Re-initialize if out of bounds\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adapt_phi(self):\n        self.initial_phi *= self.phi_decay\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update positions based on global best and adapt phi\n            for particle in self.swarms:\n                self.quantum_update(particle, self.best_solution, lb, ub)\n            \n            self.adapt_phi()\n\n        return self.best_solution, self.best_value", "name": "AQIPSO", "description": "Introducing Adaptive Quantum-Inspired Particle Swarm Optimization (AQIPSO) with dynamic adjustment of quantum rotation angle and swarm diversity enhancement for improved convergence in black-box optimization.", "configspace": "", "generation": 24, "fitness": 0.661066238437337, "feedback": "The algorithm AQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.02.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.6786681842926986, 0.6434642925819755]}, "mutation_prompt": null}
{"id": "f3e6175c-550b-4a62-b795-5c37aa43313c", "solution": "import numpy as np\n\nclass AQSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.initial_phi = np.pi / 6  # Starting quantum rotation angle\n        self.phi_decay = 0.95  # Decay rate for the rotation angle\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def dynamic_quantum_update(self, particle, global_best, lb, ub, current_phi):\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = current_phi if r < 0.5 else -current_phi\n            particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (global_best[i] - particle['position'][i]) * np.sin(theta)\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()  # Re-initialize if out of bounds\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        current_phi = self.initial_phi\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update positions based on global best with dynamic rotation angle\n            for particle in self.swarms:\n                self.dynamic_quantum_update(particle, self.best_solution, lb, ub, current_phi)\n            \n            # Decay the rotation angle to enhance local exploitation\n            current_phi *= self.phi_decay\n\n        return self.best_solution, self.best_value", "name": "AQSO", "description": "Introducing Adaptive Quantum Swarm Optimization (AQSO) that dynamically adjusts quantum rotation angles and swarm communication strategies to enhance exploration and exploitation in black-box optimization.", "configspace": "", "generation": 25, "fitness": 0.7367386428136234, "feedback": "The algorithm AQSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.00.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.7411719869605731, 0.7323052986666738]}, "mutation_prompt": null}
{"id": "49a6b5d5-0a01-44ea-bac5-266b986b2910", "solution": "import numpy as np\n\nclass MQGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 30\n        self.population = []\n        self.phi = np.pi / 4  # Quantum rotation angle\n        self.local_search_prob = 0.3\n    \n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            fitness = float('inf')\n            population.append({'position': position, 'fitness': fitness})\n        return population\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        child_position = np.zeros(self.dim)\n        for i in range(self.dim):\n            r = np.random.rand()\n            theta = self.phi if r < 0.5 else -self.phi\n            child_position[i] = (parent1['position'][i] + parent2['position'][i]) / 2 + \\\n                                np.sin(theta) * (parent1['position'][i] - parent2['position'][i]) / 2\n            if child_position[i] < lb[i] or child_position[i] > ub[i]:\n                child_position[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()  # Re-initialize if out of bounds\n        \n        child_position = np.clip(child_position, lb, ub)\n        return {'position': child_position, 'fitness': float('inf')}\n    \n    def local_search(self, individual, func, lb, ub):\n        position = individual['position'].copy()\n        for i in range(self.dim):\n            perturbation = 0.1 * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n            position[i] += perturbation\n        position = np.clip(position, lb, ub)\n        fitness = func(position)\n        if fitness < individual['fitness']:\n            individual['position'] = position\n            individual['fitness'] = fitness\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n        \n        while evaluations < self.budget:\n            # Evaluate fitness\n            for individual in self.population:\n                if individual['fitness'] == float('inf'):\n                    fitness = func(individual['position'])\n                    evaluations += 1\n                    individual['fitness'] = fitness\n                    if fitness < self.best_value:\n                        self.best_value = fitness\n                        self.best_solution = individual['position'].copy()\n                    if evaluations >= self.budget:\n                        break\n            \n            # Create new population\n            new_population = []\n            np.random.shuffle(self.population)\n            for i in range(0, self.population_size, 2):\n                if i + 1 >= self.population_size:\n                    break\n                parent1, parent2 = self.population[i], self.population[i + 1]\n                child = self.quantum_crossover(parent1, parent2, lb, ub)\n                new_population.append(child)\n            \n            # Apply local search\n            for individual in new_population:\n                if np.random.rand() < self.local_search_prob:\n                    self.local_search(individual, func, lb, ub)\n            \n            # Replace old population with new population\n            self.population = new_population\n        \n        return self.best_solution, self.best_value", "name": "MQGA", "description": "Introducing Memetic Quantum Genetic Algorithm (MQGA) which combines quantum-inspired operators with local search to enhance diversity and intensify search around promising areas for black-box optimization.", "configspace": "", "generation": 26, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {}, "mutation_prompt": null}
{"id": "03713dbb-5ee2-48fe-8c3a-13f5e2ad9f4a", "solution": "import numpy as np\n\nclass AQIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.phi_base = np.pi / 4  # Base quantum rotation angle\n        self.phi_variable = np.pi / 8  # Variable component for adaptive rotation\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def adaptive_quantum_update(self, particle, global_best, lb, ub, evaluations):\n        for i in range(self.dim):\n            r = np.random.rand()\n            # Dynamic adjustment of the angle based on progress\n            progress = evaluations / self.budget\n            phi = self.phi_base + self.phi_variable * np.sin(np.pi * progress)\n            theta = phi if r < 0.5 else -phi\n            particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (global_best[i] - particle['position'][i]) * np.sin(theta)\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()  # Re-initialize if out of bounds\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update positions based on global best\n            for particle in self.swarms:\n                self.adaptive_quantum_update(particle, self.best_solution, lb, ub, evaluations)\n\n        return self.best_solution, self.best_value", "name": "AQIPSO", "description": "Introducing Adaptive Quantum-Inspired Particle Swarm Optimization (AQIPSO) that dynamically adjusts quantum rotation and swarm diversity to improve convergence in black-box optimization.", "configspace": "", "generation": 27, "fitness": 0.8556132247376014, "feedback": "The algorithm AQIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.86 with standard deviation 0.04.", "error": "", "parent_id": "90218ca7-86c0-467c-9c4e-8fa5e034b1a0", "metadata": {"aucs": [0.8177841160536649, 0.8934423334215379]}, "mutation_prompt": null}
{"id": "246eb468-c235-4a8e-87e5-167fe61a0b4e", "solution": "import numpy as np\n\nclass BioSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': position, 'best_position': position, 'best_value': float('inf')})\n        return population\n\n    def crossover(self, parent1, parent2):\n        alpha = np.random.uniform(0, 1, self.dim)\n        child = alpha * parent1['position'] + (1 - alpha) * parent2['position']\n        return np.clip(child, lb, ub)\n\n    def mutate(self, individual, mutation_rate=0.1):\n        if np.random.rand() < mutation_rate:\n            mutation_vector = np.random.normal(0, 1, self.dim)\n            individual['position'] += mutation_vector\n            individual['position'] = np.clip(individual['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            new_population = []\n\n            for i in range(0, self.population_size, 2):\n                parent1 = self.population[i]\n                parent2 = self.population[(i+1) % self.population_size]\n\n                child1_position = self.crossover(parent1, parent2)\n                child2_position = self.crossover(parent2, parent1)\n\n                new_population.append({'position': child1_position, 'best_position': child1_position, 'best_value': float('inf')})\n                new_population.append({'position': child2_position, 'best_position': child2_position, 'best_value': float('inf')})\n\n            # Mutation\n            for individual in new_population:\n                self.mutate(individual)\n\n            # Evaluate new population\n            for individual in new_population:\n                value = func(individual['position'])\n                evaluations += 1\n                \n                if value < individual['best_value']:\n                    individual['best_value'] = value\n                    individual['best_position'] = individual['position'].copy()\n\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = individual['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Set new population for the next generation\n            self.population = new_population\n\n        return self.best_solution, self.best_value", "name": "BioSwarm", "description": "Bio-inspired Swarm with Adaptive Genetic Operators (BioSwarm) combining genetic crossover and mutation within a swarm framework to enhance exploration and exploitation balance in black-box optimization.", "configspace": "", "generation": 28, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'lb' is not defined\").", "error": "NameError(\"name 'lb' is not defined\")", "parent_id": "03713dbb-5ee2-48fe-8c3a-13f5e2ad9f4a", "metadata": {}, "mutation_prompt": null}
{"id": "69c51126-ec24-4ecf-b914-5412bf79e256", "solution": "import numpy as np\n\nclass QGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 30\n        self.population = []\n        self.phi = np.pi / 4  # Quantum rotation angle\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            individual = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': individual, 'fitness': float('inf')})\n        return population\n\n    def quantum_rotation(self, individual, global_best):\n        for i in range(self.dim):\n            theta = self.phi * (np.random.rand() - 0.5) * 2\n            rotation = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n            delta = global_best[i] - individual['position'][i]\n            individual['position'][i] += rotation @ np.array([delta, individual['position'][i]])[0]\n        individual['position'] = np.clip(individual['position'], self.lb, self.ub)\n\n    def crossover(self, parent1, parent2):\n        alpha = np.random.rand(self.dim)\n        offspring = alpha * parent1 + (1 - alpha) * parent2\n        return offspring\n\n    def mutate(self, individual):\n        mutation_strength = 0.1\n        mutation = (np.random.rand(self.dim) - 0.5) * 2 * mutation_strength\n        individual += mutation\n        return np.clip(individual, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.lb, self.ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(self.lb, self.ub)\n        \n        while evaluations < self.budget:\n            # Evaluate fitness\n            for individual in self.population:\n                individual['fitness'] = func(individual['position'])\n                evaluations += 1\n                if individual['fitness'] < self.best_value:\n                    self.best_value = individual['fitness']\n                    self.best_solution = individual['position'].copy()\n                if evaluations >= self.budget:\n                    break\n            \n            # Apply quantum rotation based on global best\n            for individual in self.population:\n                self.quantum_rotation(individual, self.best_solution)\n            \n            # Selection, Crossover, and Mutation\n            sorted_population = sorted(self.population, key=lambda x: x['fitness'])\n            new_population = sorted_population[:self.population_size // 2]  # Select the top half\n            \n            while len(new_population) < self.population_size:\n                parent1, parent2 = np.random.choice(new_population, 2, replace=False)\n                offspring_position = self.crossover(parent1['position'], parent2['position'])\n                offspring_position = self.mutate(offspring_position)\n                new_population.append({'position': offspring_position, 'fitness': float('inf')})\n            \n            self.population = new_population\n\n        return self.best_solution, self.best_value", "name": "QGA", "description": "Introducing Quantum Genetic Algorithm (QGA) that combines quantum rotation gates with genetic operators to enhance exploration and exploitation in optimizing photonic structures.", "configspace": "", "generation": 29, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)').", "error": "ValueError('matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)')", "parent_id": "03713dbb-5ee2-48fe-8c3a-13f5e2ad9f4a", "metadata": {}, "mutation_prompt": null}
{"id": "2bf12ea0-f201-482c-ad80-2d345ded7ca1", "solution": "import numpy as np\n\nclass QEAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.phi_base = np.pi / 4  # Base quantum rotation angle\n        self.phi_variable = np.pi / 8  # Variable component for adaptive rotation\n        self.learning_factor = 0.7  # Dynamic learning factor for exploration\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def adaptive_quantum_update(self, particle, global_best, lb, ub, evaluations):\n        for i in range(self.dim):\n            r1, r2 = np.random.rand(), np.random.rand()\n            progress = evaluations / self.budget\n            phi1 = self.phi_base + self.phi_variable * np.sin(np.pi * progress)\n            phi2 = self.phi_base - self.phi_variable * np.sin(np.pi * progress)\n            theta1 = phi1 if r1 < 0.5 else -phi1\n            theta2 = phi2 if r2 < 0.5 else -phi2\n\n            # Dual quantum rotators\n            weight = self.learning_factor * (1 - progress)\n            particle['velocity'][i] = (\n                weight * particle['velocity'][i] * np.cos(theta1) +\n                (1 - weight) * (global_best[i] - particle['position'][i]) * np.sin(theta2)\n            )\n\n            particle['position'][i] += particle['velocity'][i]\n\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()  # Re-initialize if out of bounds\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            for particle in self.swarms:\n                self.adaptive_quantum_update(particle, self.best_solution, lb, ub, evaluations)\n\n        return self.best_solution, self.best_value", "name": "QEAPSO", "description": "Introducing Quantum-Enhanced Adaptive Particle Swarm Optimization (QEAPSO) that utilizes dual quantum rotators and a dynamic learning factor to refine convergence and enhance local exploration in black-box optimization.", "configspace": "", "generation": 30, "fitness": 0.6410795496784862, "feedback": "The algorithm QEAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64 with standard deviation 0.06.", "error": "", "parent_id": "03713dbb-5ee2-48fe-8c3a-13f5e2ad9f4a", "metadata": {"aucs": [0.6988018630387928, 0.5833572363181796]}, "mutation_prompt": null}
{"id": "41f1654e-a898-4deb-9e68-cddd9ab3761a", "solution": "import numpy as np\n\nclass QIPSO_HS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.phi_base = np.pi / 4  # Base quantum rotation angle\n        self.phi_variable = np.pi / 8  # Variable component for adaptive rotation\n        self.inertia_weight = 0.9\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.uniform(-abs(ub-lb), abs(ub-lb), self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def adaptive_quantum_update(self, particle, global_best, lb, ub, evaluations):\n        for i in range(self.dim):\n            r = np.random.rand()\n            # Dynamic adjustment of the angle based on progress and velocity\n            progress = evaluations / self.budget\n            phi = self.phi_base + self.phi_variable * np.sin(np.pi * progress)\n            inertia_weight = self.inertia_weight - 0.5 * progress\n            theta = phi if r < 0.5 else -phi\n\n            particle['velocity'][i] = inertia_weight * particle['velocity'][i] + (global_best[i] - particle['position'][i]) * np.sin(theta)\n            particle['position'][i] += particle['velocity'][i]\n            \n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update positions based on global best\n            for particle in self.swarms:\n                self.adaptive_quantum_update(particle, self.best_solution, lb, ub, evaluations)\n\n        return self.best_solution, self.best_value", "name": "QIPSO_HS", "description": "Introducing Quantum-Inspired Particle Swarm Optimization with Hybrid Strategies (QIPSO-HS) that integrates quantum rotation with diversity and inertia adjustment to enhance exploration and exploitation balance in photonic structure optimization.", "configspace": "", "generation": 31, "fitness": 0.7483617403368861, "feedback": "The algorithm QIPSO_HS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.00.", "error": "", "parent_id": "03713dbb-5ee2-48fe-8c3a-13f5e2ad9f4a", "metadata": {"aucs": [0.745392199829741, 0.751331280844031]}, "mutation_prompt": null}
{"id": "99ff2509-a273-4b71-8756-c299af2e4c39", "solution": "import numpy as np\n\nclass QE_ANPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.phi_base = np.pi / 4\n        self.phi_variable = np.pi / 8\n        self.neighborhood_size = 5\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def adaptive_quantum_update(self, particle, global_best, lb, ub, evaluations):\n        for i in range(self.dim):\n            r = np.random.rand()\n            progress = evaluations / self.budget\n            phi = self.phi_base + self.phi_variable * np.sin(np.pi * progress)\n            theta = phi if r < 0.5 else -phi\n            particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (global_best[i] - particle['position'][i]) * np.sin(theta)\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def neighborhood_best(self, particle_index):\n        neighborhood_indices = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[particle_index]['best_position']\n        neighborhood_best_value = self.swarms[particle_index]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        return neighborhood_best\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            for particle_index, particle in enumerate(self.swarms):\n                neighborhood_best = self.neighborhood_best(particle_index)\n                self.adaptive_quantum_update(particle, neighborhood_best, lb, ub, evaluations)\n\n        return self.best_solution, self.best_value", "name": "QE_ANPSO", "description": "Introducing Quantum-Enhanced Adaptive Neighborhood PSO (QE-ANPSO) that integrates local neighborhood exploration with quantum-inspired updates for enhanced convergence in black-box optimization.", "configspace": "", "generation": 32, "fitness": 0.8562236280665734, "feedback": "The algorithm QE_ANPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.86 with standard deviation 0.01.", "error": "", "parent_id": "03713dbb-5ee2-48fe-8c3a-13f5e2ad9f4a", "metadata": {"aucs": [0.8423208953554151, 0.8701263607777315]}, "mutation_prompt": null}
{"id": "573c957c-2ef6-4d66-b66e-ff66b016bfdd", "solution": "import numpy as np\n\nclass EQMS_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.num_swarms = 3\n        self.swarms = []\n        self.phi_base = np.pi / 4\n        self.phi_variable = np.pi / 8\n        self.neighborhood_size = 5\n        self.interaction_frequency = 50\n\n    def initialize_swarm(self, lb, ub):\n        swarms = []\n        for _ in range(self.num_swarms):\n            swarm = []\n            for _ in range(self.swarm_size):\n                position = lb + (ub - lb) * np.random.rand(self.dim)\n                velocity = np.zeros(self.dim)\n                swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n            swarms.append(swarm)\n        return swarms\n\n    def quantum_update(self, particle, global_best, local_best, lb, ub, evaluations):\n        for i in range(self.dim):\n            r = np.random.rand()\n            progress = evaluations / self.budget\n            phi = self.phi_base + self.phi_variable * np.sin(np.pi * progress)\n            theta = phi if r < 0.5 else -phi\n            velocity_contribution = (global_best[i] - particle['position'][i]) * np.sin(theta)\n            neighborhood_contribution = (local_best[i] - particle['position'][i]) * np.sin(theta / 2)\n            particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + velocity_contribution + neighborhood_contribution\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def neighborhood_best(self, swarm, particle_index):\n        neighborhood_indices = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighborhood_best = swarm[particle_index]['best_position']\n        neighborhood_best_value = swarm[particle_index]['best_value']\n        \n        for idx in neighborhood_indices:\n            if swarm[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = swarm[idx]['best_position']\n                neighborhood_best_value = swarm[idx]['best_value']\n        \n        return neighborhood_best\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for swarm in self.swarms:\n                for particle_index, particle in enumerate(swarm):\n                    value = func(particle['position'])\n                    evaluations += 1\n                    \n                    if value < particle['best_value']:\n                        particle['best_value'] = value\n                        particle['best_position'] = particle['position'].copy()\n                    \n                    if value < self.best_value:\n                        self.best_value = value\n                        self.best_solution = particle['position'].copy()\n\n                    if evaluations >= self.budget:\n                        break\n\n                for particle_index, particle in enumerate(swarm):\n                    neighborhood_best = self.neighborhood_best(swarm, particle_index)\n                    self.quantum_update(particle, self.best_solution, neighborhood_best, lb, ub, evaluations)\n\n            if evaluations % self.interaction_frequency == 0:\n                self.synchronize_swarms()\n\n        return self.best_solution, self.best_value\n\n    def synchronize_swarms(self):\n        global_best_positions = [swarms[i][np.argmin([p['best_value'] for p in swarms[i]])]['best_position'] for i in range(self.num_swarms)]\n        \n        for i, swarm in enumerate(self.swarms):\n            for particle in swarm:\n                target_swarm_index = (i + 1) % self.num_swarms\n                target_position = global_best_positions[target_swarm_index]\n                particle['position'] += (target_position - particle['position']) * np.random.rand()\n                particle['position'] = np.clip(particle['position'], lb, ub)", "name": "EQMS_PSO", "description": "Introducing Enhanced Quantum-Driven Multi-Swarm PSO (EQMS-PSO) that leverages multiple swarms with quantum-inspired updates and dynamic interaction strategies for improved exploration and exploitation balance in black-box optimization.", "configspace": "", "generation": 33, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'swarms' is not defined\").", "error": "NameError(\"name 'swarms' is not defined\")", "parent_id": "99ff2509-a273-4b71-8756-c299af2e4c39", "metadata": {}, "mutation_prompt": null}
{"id": "c69fc055-da6c-465c-8a88-e2edafad3396", "solution": "import numpy as np\nfrom collections import deque\n\nclass MO_QPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.phi_base = np.pi / 6\n        self.archive = deque(maxlen=50)\n        self.diversity_threshold = 0.1\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            best_position = position.copy()\n            best_value = float('inf')\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': best_position, 'best_value': best_value})\n        return swarm\n\n    def quantum_update(self, particle, global_best, lb, ub):\n        for i in range(self.dim):\n            r = np.random.rand()\n            progress = len(self.archive) / self.archive.maxlen\n            phi = self.phi_base * (1 + np.cos(np.pi * progress))\n            theta = phi if r < 0.5 else -phi\n            particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (global_best[i] - particle['position'][i]) * np.sin(theta)\n            particle['position'][i] += particle['velocity'][i]\n            \n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def update_archive(self, particle):\n        if len(self.archive) < self.archive.maxlen or any(np.linalg.norm(particle['position'] - archived['position']) > self.diversity_threshold for archived in self.archive):\n            self.archive.append(particle)\n\n    def pareto_dominance(self, a, b):\n        return all(a <= b) and any(a < b)\n\n    def select_global_best(self):\n        if not self.archive:\n            return None\n        \n        non_dominated = [self.archive[0]]\n        for candidate in self.archive:\n            if any(self.pareto_dominance(candidate['best_value'], other['best_value']) for other in non_dominated):\n                continue\n            non_dominated = [c for c in non_dominated if not self.pareto_dominance(c['best_value'], candidate['best_value'])]\n            non_dominated.append(candidate)\n\n        return non_dominated[np.random.choice(len(non_dominated))]['best_position']\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                self.update_archive(particle)\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            global_best = self.select_global_best()\n            for particle_index, particle in enumerate(self.swarms):\n                if global_best is not None:\n                    self.quantum_update(particle, global_best, lb, ub)\n\n        return self.best_solution, self.best_value", "name": "MO_QPSO", "description": "Introducing Multi-Objective Quantum Particle Swarm Optimization (MO-QPSO) that blends quantum-inspired update rules with Pareto dominance to balance exploration and exploitation in complex optimization landscapes.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'bool' object is not iterable\").", "error": "TypeError(\"'bool' object is not iterable\")", "parent_id": "99ff2509-a273-4b71-8756-c299af2e4c39", "metadata": {}, "mutation_prompt": null}
{"id": "44208334-7e28-4f10-b94a-49aba834c893", "solution": "import numpy as np\n\nclass QE_ANPSO_DRA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.phi_base = np.pi / 4\n        self.phi_variable = np.pi / 8\n        self.neighborhood_size = 5\n        self.leader_fraction = 0.2\n        self.dynamic_change_rate = 0.1\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.zeros(self.dim)\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def adaptive_quantum_update(self, particle, leader, leader_followers, lb, ub, evaluations):\n        for i in range(self.dim):\n            r = np.random.rand()\n            progress = evaluations / self.budget\n            phi = self.phi_base + self.phi_variable * np.sin(np.pi * progress)\n            theta = phi if r < 0.5 else -phi\n\n            # Role-based velocity update\n            if particle in leader_followers:\n                particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (leader[i] - particle['position'][i]) * np.sin(theta)\n            else:\n                particle['velocity'][i] = particle['velocity'][i] * np.cos(theta) + (self.best_solution[i] - particle['position'][i]) * np.sin(theta)\n\n            particle['position'][i] += particle['velocity'][i]\n            if particle['position'][i] < lb[i] or particle['position'][i] > ub[i]:\n                particle['position'][i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n        \n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def neighborhood_best(self, particle_index):\n        neighborhood_indices = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[particle_index]['best_position']\n        neighborhood_best_value = self.swarms[particle_index]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        return neighborhood_best\n\n    def dynamic_leadership_change(self, evaluations):\n        num_leaders = max(1, int(self.swarm_size * self.leader_fraction))\n        leaders = sorted(self.swarms, key=lambda x: x['best_value'])[:num_leaders]\n        \n        if evaluations % int(self.budget * self.dynamic_change_rate) == 0:\n            self.leader_fraction = max(0.05, self.leader_fraction - 0.01)\n\n        return leaders\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n\n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n\n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            leaders = self.dynamic_leadership_change(evaluations)\n            leader_positions = [particle['best_position'] for particle in leaders]\n\n            for particle in self.swarms:\n                leader = np.random.choice(leader_positions)\n                self.adaptive_quantum_update(particle, leader, leader_positions, lb, ub, evaluations)\n\n        return self.best_solution, self.best_value", "name": "QE_ANPSO_DRA", "description": "Introducing Quantum-Enhanced Adaptive Neighborhood PSO with Dynamic Role Assignment (QE-ANPSO-DRA) that employs a dynamic leader-follower mechanism to enhance exploration and exploitation balance in black-box optimization.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "99ff2509-a273-4b71-8756-c299af2e4c39", "metadata": {}, "mutation_prompt": null}
{"id": "e003c122-7715-42de-8f6b-328086793a6b", "solution": "import numpy as np\n\nclass SDN_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.neighborhood_size = 5\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def dynamic_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n    def update_particle(self, particle, neighborhood_best, lb, ub, inertia_weight):\n        r1, r2 = np.random.rand(), np.random.rand()\n        cognitive_component = r1 * (particle['best_position'] - particle['position'])\n        social_component = r2 * (neighborhood_best - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component\n        particle['position'] += particle['velocity']\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def stochastic_neighborhood_best(self, particle_index):\n        neighborhood_indices = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[neighborhood_indices[0]]['best_position']\n        neighborhood_best_value = self.swarms[neighborhood_indices[0]]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        return neighborhood_best\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.dynamic_inertia(evaluations)\n            \n            for particle_index, particle in enumerate(self.swarms):\n                neighborhood_best = self.stochastic_neighborhood_best(particle_index)\n                self.update_particle(particle, neighborhood_best, lb, ub, inertia_weight)\n\n        return self.best_solution, self.best_value", "name": "SDN_PSO", "description": "Introducing Stochastic Dynamic Neighborhood PSO (SDN-PSO) that utilizes stochastic neighborhood reshuffling and dynamic inertia adjustments for improved exploration-exploitation balance in black-box optimization.", "configspace": "", "generation": 36, "fitness": 0.9414485163944268, "feedback": "The algorithm SDN_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94 with standard deviation 0.06.", "error": "", "parent_id": "99ff2509-a273-4b71-8756-c299af2e4c39", "metadata": {"aucs": [0.9968280045198527, 0.8860690282690011]}, "mutation_prompt": null}
{"id": "abd2739d-e5ab-4198-8b25-07b5c8352d12", "solution": "import numpy as np\n\nclass Adaptive_Cooperative_SDN_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.neighborhood_factor = 0.25  # factor to dynamically adjust neighborhood size\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def dynamic_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n    def update_particle(self, particle, neighborhood_best, lb, ub, inertia_weight):\n        r1, r2 = np.random.rand(), np.random.rand()\n        cognitive_component = r1 * (particle['best_position'] - particle['position'])\n        social_component = r2 * (neighborhood_best - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component\n        particle['position'] += particle['velocity']\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adaptive_neighborhood_best(self, particle_index, evaluations):\n        neighborhood_size = max(2, int(self.swarm_size * self.neighborhood_factor * (1 - evaluations / self.budget)))\n        neighborhood_indices = np.random.choice(self.swarm_size, neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[neighborhood_indices[0]]['best_position']\n        neighborhood_best_value = self.swarms[neighborhood_indices[0]]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        return neighborhood_best\n\n    def cooperative_learning(self, particle_index):\n        partners = np.random.choice([i for i in range(self.swarm_size) if i != particle_index], 2, replace=False)\n        knowledge = (self.swarms[partners[0]]['best_position'] + self.swarms[partners[1]]['best_position']) / 2\n        return knowledge\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.dynamic_inertia(evaluations)\n            \n            for particle_index, particle in enumerate(self.swarms):\n                neighborhood_best = self.adaptive_neighborhood_best(particle_index, evaluations)\n                cooperative_knowledge = self.cooperative_learning(particle_index)\n                combined_best = (neighborhood_best + cooperative_knowledge) / 2\n                self.update_particle(particle, combined_best, lb, ub, inertia_weight)\n\n        return self.best_solution, self.best_value", "name": "Adaptive_Cooperative_SDN_PSO", "description": "Introducing Adaptive Cooperative SDN-PSO that incorporates adaptive neighborhood sizes and cooperative learning strategy to enhance convergence and robustness in black-box optimization.", "configspace": "", "generation": 37, "fitness": 0.9073874741238583, "feedback": "The algorithm Adaptive_Cooperative_SDN_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.01.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.9014636496950907, 0.9133112985526259]}, "mutation_prompt": null}
{"id": "f2decbbc-c10b-4c68-a4e0-13791c70a16c", "solution": "import numpy as np\n\nclass ASDN_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.neighborhood_size = 5\n        self.velocity_clamp = 0.1\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * self.velocity_clamp\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def dynamic_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n    def adaptive_velocity_clamp(self, velocity, lb, ub):\n        max_velocity = self.velocity_clamp * (ub - lb)\n        return np.clip(velocity, -max_velocity, max_velocity)\n\n    def update_particle(self, particle, neighborhood_best, lb, ub, inertia_weight):\n        r1, r2 = np.random.rand(), np.random.rand()\n        cognitive_component = r1 * (particle['best_position'] - particle['position'])\n        social_component = r2 * (neighborhood_best - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component\n        particle['velocity'] = self.adaptive_velocity_clamp(particle['velocity'], lb, ub)\n        particle['position'] += particle['velocity']\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def stochastic_neighborhood_best(self, particle_index, history_best):\n        neighborhood_indices = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[neighborhood_indices[0]]['best_position']\n        neighborhood_best_value = self.swarms[neighborhood_indices[0]]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        # Integration of cross-iteration learning\n        if history_best['best_value'] < neighborhood_best_value:\n            neighborhood_best = history_best['best_position']\n            neighborhood_best_value = history_best['best_value']\n        \n        return neighborhood_best\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        history_best = {'best_position': None, 'best_value': float('inf')}\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n                    \n                if value < history_best['best_value']:\n                    history_best['best_value'] = value\n                    history_best['best_position'] = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.dynamic_inertia(evaluations)\n            \n            for particle_index, particle in enumerate(self.swarms):\n                neighborhood_best = self.stochastic_neighborhood_best(particle_index, history_best)\n                self.update_particle(particle, neighborhood_best, lb, ub, inertia_weight)\n\n        return self.best_solution, self.best_value", "name": "ASDN_PSO", "description": "Introducing Adaptive Stochastic Dynamic Neighborhood PSO (ASDN-PSO) with adaptive velocity clamping and cross-iteration neighborhood learning for enhanced convergence speed and robustness in black-box optimization.", "configspace": "", "generation": 38, "fitness": 0.9193640692153688, "feedback": "The algorithm ASDN_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.02.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.9005197468989979, 0.9382083915317398]}, "mutation_prompt": null}
{"id": "aab4bd46-0402-43e8-aabc-ebde6289971b", "solution": "import numpy as np\n\nclass AQI_SDN_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.initial_swarm_size = 20\n        self.max_swarm_size = 40\n        self.min_swarm_size = 10\n        self.swarm_size = self.initial_swarm_size\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.neighborhood_size = 5\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def dynamic_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n    def update_particle(self, particle, neighborhood_best, lb, ub, inertia_weight):\n        r1, r2 = np.random.rand(), np.random.rand()\n        cognitive_component = r1 * (particle['best_position'] - particle['position'])\n        social_component = r2 * (neighborhood_best - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component\n        quantum_component = np.random.rand(self.dim) * (particle['best_position'] - particle['position'])\n        particle['position'] += particle['velocity'] + quantum_component\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def stochastic_neighborhood_best(self, particle_index):\n        neighborhood_indices = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[neighborhood_indices[0]]['best_position']\n        neighborhood_best_value = self.swarms[neighborhood_indices[0]]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        return neighborhood_best\n\n    def adaptive_swarm_size(self, evaluations):\n        progress = evaluations / self.budget\n        if progress < 0.3:\n            self.swarm_size = self.max_swarm_size\n        elif progress > 0.7:\n            self.swarm_size = self.min_swarm_size\n        else:\n            self.swarm_size = self.initial_swarm_size\n        self.swarms = self.swarms[:self.swarm_size]\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            self.adaptive_swarm_size(evaluations)\n            \n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.dynamic_inertia(evaluations)\n            \n            for particle_index, particle in enumerate(self.swarms):\n                neighborhood_best = self.stochastic_neighborhood_best(particle_index)\n                self.update_particle(particle, neighborhood_best, lb, ub, inertia_weight)\n\n        return self.best_solution, self.best_value", "name": "AQI_SDN_PSO", "description": "Introducing Adaptive Quantum-Inspired SDN-PSO (AQI-SDN-PSO) which combines quantum position updates and adaptive swarm size adjustments for enhanced convergence in black-box optimization. ", "configspace": "", "generation": 39, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {}, "mutation_prompt": null}
{"id": "2983d80f-0791-4b0f-9d8e-8cd1d5b0ad1f", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.alpha = 0.5  # Learning factor\n        self.beta = 0.5   # Learning factor\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            pbest_position = position.copy()\n            pbest_value = float('inf')\n            swarm.append({'position': position, 'velocity': velocity, \n                          'pbest_position': pbest_position, 'pbest_value': pbest_value})\n        return swarm\n\n    def update_particle(self, particle, gbest_position, lb, ub):\n        r1, r2 = np.random.rand(), np.random.rand()\n        self.alpha = 0.5 + 0.5 * np.random.rand()\n        self.beta = 0.5 + 0.5 * np.random.rand()\n        particle['velocity'] = self.alpha * (particle['velocity'] + \n                                             self.beta * (particle['pbest_position'] - particle['position']) +\n                                             (gbest_position - particle['position']))\n        particle['position'] = np.clip(particle['position'] + particle['velocity'], lb, ub)\n\n    def quantum_behaviour(self, particle, gbest_position):\n        phi = np.random.rand(self.dim)\n        u = np.random.uniform(0, 1, self.dim) < 0.5\n        particle['position'] = np.where(u, particle['position'] + phi * (gbest_position - particle['position']),\n                                        particle['position'] - phi * (gbest_position - particle['position']))\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        gbest_position = None\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['pbest_value']:\n                    particle['pbest_value'] = value\n                    particle['pbest_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n                    gbest_position = self.best_solution\n\n                if evaluations >= self.budget:\n                    break\n\n            for particle in self.swarms:\n                self.update_particle(particle, gbest_position, lb, ub)\n                self.quantum_behaviour(particle, gbest_position)\n\n        return self.best_solution, self.best_value", "name": "AQPSO", "description": "Adaptive Quantum-inspired Particle Swarm Optimization (AQPSO) that leverages quantum behavior and adaptive learning factors for enhanced diverse exploration in high-dimensional photonic structure optimization.", "configspace": "", "generation": 40, "fitness": 0.9324760384151767, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.01.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.9263659628953508, 0.9385861139350025]}, "mutation_prompt": null}
{"id": "5cb6dbf6-1885-4416-aacc-a1edaab7899e", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.alpha = 0.5\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def dynamic_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n    def update_particle(self, particle, global_best, lb, ub, inertia_weight):\n        r1, r2 = np.random.rand(), np.random.rand()\n        cognitive_component = r1 * (particle['best_position'] - particle['position'])\n        social_component = r2 * (global_best - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component\n        particle['position'] += particle['velocity']\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def quantum_update(self, particle, global_best):\n        if np.random.rand() < self.alpha:\n            u = np.random.rand(self.dim)\n            particle['position'] = self.best_solution + 0.5 * np.abs(particle['position'] - self.best_solution) * np.log(1/u)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n\n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n\n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.dynamic_inertia(evaluations)\n\n            for particle in self.swarms:\n                self.update_particle(particle, self.best_solution, lb, ub, inertia_weight)\n                self.quantum_update(particle, self.best_solution)\n\n        return self.best_solution, self.best_value", "name": "AQPSO", "description": "Introducing Adaptive Quantum Particle Swarm Optimization (AQPSO) that employs quantum-behavior-inspired position updates and adaptive learning factors to enhance convergence speed and accuracy in black-box optimization.", "configspace": "", "generation": 41, "fitness": 0.8754217864707082, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88 with standard deviation 0.01.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.8612024818682797, 0.8896410910731367]}, "mutation_prompt": null}
{"id": "eeeb444a-8fd0-4569-aa1a-6539f56959c6", "solution": "import numpy as np\n\nclass ASDN_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.neighborhood_size = 5\n        self.c1_max = 2.5\n        self.c1_min = 1.5\n        self.c2_max = 2.5\n        self.c2_min = 1.5\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n    \n    def dynamic_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n    \n    def adaptive_learning_factors(self, evaluations):\n        c1 = self.c1_max - ((self.c1_max - self.c1_min) * (evaluations / self.budget))\n        c2 = self.c2_min + ((self.c2_max - self.c2_min) * (evaluations / self.budget))\n        return c1, c2\n    \n    def update_particle(self, particle, neighborhood_best, lb, ub, inertia_weight, c1, c2):\n        r1, r2 = np.random.rand(), np.random.rand()\n        cognitive_component = c1 * r1 * (particle['best_position'] - particle['position'])\n        social_component = c2 * r2 * (neighborhood_best - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component\n        particle['position'] += particle['velocity']\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def stochastic_neighborhood_best(self, particle_index):\n        neighborhood_indices = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[neighborhood_indices[0]]['best_position']\n        neighborhood_best_value = self.swarms[neighborhood_indices[0]]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        return neighborhood_best\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.dynamic_inertia(evaluations)\n            c1, c2 = self.adaptive_learning_factors(evaluations)\n            \n            for particle_index, particle in enumerate(self.swarms):\n                neighborhood_best = self.stochastic_neighborhood_best(particle_index)\n                self.update_particle(particle, neighborhood_best, lb, ub, inertia_weight, c1, c2)\n\n        return self.best_solution, self.best_value", "name": "ASDN_PSO", "description": "Introducing Adaptive Stochastic Dynamic Neighborhood PSO (ASDN-PSO) that enhances exploration-exploitation trade-off by introducing adaptive learning factors and stochastic sub-swarms for improved global search capability in black-box optimization.", "configspace": "", "generation": 42, "fitness": 0.8707982946511255, "feedback": "The algorithm ASDN_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.87 with standard deviation 0.02.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.8534118825047738, 0.8881847067974771]}, "mutation_prompt": null}
{"id": "41bbc434-395d-4b5b-8cfc-e9c3ebf4d297", "solution": "import numpy as np\n\nclass AQI_SDN_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.neighborhood_size = 5\n        self.learning_factor_c1 = 2.0\n        self.learning_factor_c2 = 2.0\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def quantum_superposition(self, lb, ub):\n        probability_amplitude = np.random.rand(self.dim)\n        return lb + (ub - lb) * (probability_amplitude > 0.5).astype(float)\n\n    def dynamic_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n    def adaptive_learning_factors(self, evaluations):\n        progress = evaluations / self.budget\n        c1 = self.learning_factor_c1 * (1 - progress)\n        c2 = self.learning_factor_c2 * progress\n        return c1, c2\n\n    def update_particle(self, particle, neighborhood_best, lb, ub, inertia_weight, c1, c2):\n        r1, r2 = np.random.rand(), np.random.rand()\n        cognitive_component = c1 * r1 * (particle['best_position'] - particle['position'])\n        social_component = c2 * r2 * (neighborhood_best - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component\n        particle['position'] += particle['velocity']\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def stochastic_neighborhood_best(self, particle_index):\n        neighborhood_indices = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[neighborhood_indices[0]]['best_position']\n        neighborhood_best_value = self.swarms[neighborhood_indices[0]]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        return neighborhood_best\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                if evaluations < self.budget * 0.1:  # First 10% of budget for quantum superposition\n                    particle['position'] = self.quantum_superposition(lb, ub)\n                \n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.dynamic_inertia(evaluations)\n            c1, c2 = self.adaptive_learning_factors(evaluations)\n            \n            for particle_index, particle in enumerate(self.swarms):\n                neighborhood_best = self.stochastic_neighborhood_best(particle_index)\n                self.update_particle(particle, neighborhood_best, lb, ub, inertia_weight, c1, c2)\n\n        return self.best_solution, self.best_value", "name": "AQI_SDN_PSO", "description": "Introducing Adaptive Quantum-Inspired SDN-PSO (AQI-SDN-PSO) that combines quantum-inspired superposition for diverse initialization and adaptive learning rates for dynamic balance between exploration and exploitation in black-box optimization.", "configspace": "", "generation": 43, "fitness": 0.4602032880912967, "feedback": "The algorithm AQI_SDN_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.00.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.4604131301062496, 0.45999344607634374]}, "mutation_prompt": null}
{"id": "9bd9a39e-330a-44d5-85d5-eb6056f4136e", "solution": "import numpy as np\n\nclass ALFFA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 30\n        self.population = []\n        self.alpha = 1.0\n        self.beta0 = 1.0\n        self.gamma = 1.0\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': position, 'value': float('inf')})\n        return population\n\n    def levy_flight(self, step):\n        # Levy flight step calculation using Mantegna's algorithm\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=step.shape)\n        v = np.random.normal(0, 1, size=step.shape)\n        return u / (abs(v) ** (1 / beta))\n\n    def update_firefly(self, firefly_i, firefly_j, lb, ub):\n        distance = np.linalg.norm(firefly_i['position'] - firefly_j['position'])\n        beta = self.beta0 * np.exp(-self.gamma * distance ** 2)\n        attraction = beta * (firefly_j['position'] - firefly_i['position'])\n        random_walk = self.alpha * self.levy_flight(firefly_i['position'])\n        firefly_i['position'] += attraction + random_walk\n        firefly_i['position'] = np.clip(firefly_i['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n        \n        while evaluations < self.budget:\n            # Evaluate all fireflies\n            for firefly in self.population:\n                firefly['value'] = func(firefly['position'])\n                evaluations += 1\n                \n                if firefly['value'] < self.best_value:\n                    self.best_value = firefly['value']\n                    self.best_solution = firefly['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update fireflies based on pairwise attraction\n            for i in range(self.population_size):\n                for j in range(self.population_size):\n                    if self.population[j]['value'] < self.population[i]['value']:\n                        self.update_firefly(self.population[i], self.population[j], lb, ub)\n        \n        return self.best_solution, self.best_value", "name": "ALFFA", "description": "Introducing Adaptive Levy Flight Firefly Algorithm (ALFFA) which combines Levy flight-based exploration with adaptive light absorption to dynamically balance exploration and exploitation in black-box optimization.", "configspace": "", "generation": 44, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {}, "mutation_prompt": null}
{"id": "a956e114-d165-4fe7-b113-ac529e5767ff", "solution": "import numpy as np\nfrom scipy.spatial.distance import cdist\n\nclass AHCO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 30\n        self.clusters = []\n        self.cluster_assignments = []\n    \n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n    \n    def adaptive_hierarchy(self, data, n_clusters):\n        distances = cdist(data, data)\n        clusters = {i: [i] for i in range(len(data))}\n        while len(clusters) > n_clusters:\n            # find closest pair of clusters\n            min_dist = float('inf')\n            merge_pair = ()\n            for i in clusters:\n                for j in clusters:\n                    if i < j:\n                        dist = np.min(distances[np.ix_(clusters[i], clusters[j])])\n                        if dist < min_dist:\n                            min_dist = dist\n                            merge_pair = (i, j)\n            i, j = merge_pair\n            # merge clusters\n            clusters[i].extend(clusters[j])\n            del clusters[j]\n        return list(clusters.values())\n    \n    def update_clusters(self, population, lb, ub):\n        n_clusters = max(2, int(self.population_size * 0.1))\n        cluster_indices = self.adaptive_hierarchy(population, n_clusters)\n        self.clusters = [population[indices] for indices in cluster_indices]\n        self.cluster_assignments = np.zeros(self.population_size, dtype=int)\n        for cluster_id, indices in enumerate(cluster_indices):\n            for i in indices:\n                self.cluster_assignments[i] = cluster_id\n    \n    def exploit_cluster(self, cluster, func, lb, ub):\n        centroid = np.mean(cluster, axis=0)\n        for i in range(len(cluster)):\n            perturbation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n            candidate = np.clip(centroid + perturbation, lb, ub)\n            if func(candidate) < func(cluster[i]):\n                cluster[i] = candidate\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        \n        population = self.initialize_population(lb, ub)\n        self.update_clusters(population, lb, ub)\n        \n        while evaluations < self.budget:\n            for i, pos in enumerate(population):\n                value = func(pos)\n                evaluations += 1\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = pos.copy()\n                \n                if evaluations >= self.budget:\n                    break\n            \n            self.update_clusters(population, lb, ub)\n            \n            for cluster in self.clusters:\n                self.exploit_cluster(cluster, func, lb, ub)\n        \n        return self.best_solution, self.best_value", "name": "AHCO", "description": "Introducing Adaptive Hierarchical Clustering Optimization (AHCO) that employs dynamic hierarchical clustering to adaptively manage exploration and exploitation, while refining clusters based on local optima to efficiently navigate complex search landscapes.", "configspace": "", "generation": 45, "fitness": 0.580335425300379, "feedback": "The algorithm AHCO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.58 with standard deviation 0.05.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.5294766120726246, 0.6311942385281333]}, "mutation_prompt": null}
{"id": "f00db93b-5283-4107-9cea-895309f87ccb", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.neighborhood_size = 5\n        self.alpha = 0.5  # quantum factor\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def dynamic_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n    def update_particle(self, particle, global_best, lb, ub, inertia_weight):\n        r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n        cognitive_component = r1 * (particle['best_position'] - particle['position'])\n        social_component = r2 * (global_best - particle['position'])\n        quantum_component = r3 * (self.alpha * (global_best + particle['best_position']) / 2 - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component + quantum_component\n        particle['position'] += particle['velocity']\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def global_best(self):\n        global_best = self.swarms[0]['best_position']\n        global_best_value = self.swarms[0]['best_value']\n        \n        for particle in self.swarms:\n            if particle['best_value'] < global_best_value:\n                global_best = particle['best_position']\n                global_best_value = particle['best_value']\n        \n        return global_best\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            global_best = self.global_best()\n\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.dynamic_inertia(evaluations)\n            \n            for particle in self.swarms:\n                self.update_particle(particle, global_best, lb, ub, inertia_weight)\n\n        return self.best_solution, self.best_value", "name": "AQPSO", "description": "Introducing Adaptive Quantum Particle Swarm Optimization (AQPSO) incorporating quantum-inspired position updates and adaptive learning strategies to enhance convergence and diversity in black-box optimization.", "configspace": "", "generation": 46, "fitness": 0.7447972155420197, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.08.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.8205442786466519, 0.6690501524373875]}, "mutation_prompt": null}
{"id": "0b31aed3-c91c-43b6-ae23-922f151117dd", "solution": "import numpy as np\n\nclass QIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.alpha = 0.1  # Quantum rotation angle\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            q_state = np.array([np.exp(1j * self.alpha * np.random.rand()) for _ in range(self.dim)])\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf'), 'q_state': q_state})\n        return swarm\n\n    def quantum_superposition(self, particle, lb, ub):\n        new_position = lb + (ub - lb) * np.abs(particle['q_state'])\n        return np.clip(new_position, lb, ub)\n\n    def update_particle(self, particle, global_best, lb, ub):\n        r1, r2 = np.random.rand(), np.random.rand()\n        cognitive_component = r1 * (particle['best_position'] - particle['position'])\n        social_component = r2 * (global_best - particle['position'])\n        quantum_component = self.quantum_superposition(particle, lb, ub) - particle['position']\n        particle['velocity'] = cognitive_component + social_component + quantum_component\n        particle['position'] += particle['velocity']\n        particle['position'] = np.clip(particle['position'], lb, ub)\n        particle['q_state'] = np.exp(1j * self.alpha * np.random.rand(self.dim))\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            global_best = min(self.swarms, key=lambda p: p['best_value'])['best_position']\n            \n            for particle in self.swarms:\n                self.update_particle(particle, global_best, lb, ub)\n\n        return self.best_solution, self.best_value", "name": "QIPSO", "description": "Introducing Quantum-Inspired Particle Swarm Optimization (QIPSO) that employs quantum superposition states for particles, enhancing diversity and exploration capabilities for robust global optimization.", "configspace": "", "generation": 47, "fitness": 0.4911549111838435, "feedback": "The algorithm QIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.49 with standard deviation 0.08.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.570323908209854, 0.41198591415783303]}, "mutation_prompt": null}
{"id": "6869f023-995d-4fc6-b3cb-276f303928b9", "solution": "import numpy as np\n\nclass QIEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 30\n        self.alpha = 0.05  # Mutation rate\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            q_state = np.random.rand(self.dim)  # Quantum bit state\n            population.append({'position': position, 'q_state': q_state, 'best_value': float('inf')})\n        return population\n\n    def measure(self, q_state, lb, ub):\n        theta = np.arccos(2 * q_state - 1)\n        position = lb + (ub - lb) * ((1 + np.cos(theta))/2)\n        return position\n\n    def update_quantum_state(self, q_state, position, lb, ub):\n        # Perturbate the quantum state\n        new_q_state = np.clip(q_state + self.alpha * (np.random.rand(self.dim) - 0.5), 0, 1)\n        new_position = self.measure(new_q_state, lb, ub)\n        return new_q_state, new_position\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            for individual in population:\n                individual['position'] = self.measure(individual['q_state'], lb, ub)\n                value = func(individual['position'])\n                evaluations += 1\n\n                if value < individual['best_value']:\n                    individual['best_value'] = value\n                    individual['position'] = individual['position'].copy()\n\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = individual['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update quantum states\n            for individual in population:\n                individual['q_state'], individual['position'] = self.update_quantum_state(individual['q_state'], individual['position'], lb, ub)\n\n        return self.best_solution, self.best_value", "name": "QIEA", "description": "Introducing Quantum-Inspired Evolutionary Algorithm (QIEA) that leverages quantum superposition principles to create diverse solution states, enhancing exploration in black-box optimization tasks.", "configspace": "", "generation": 48, "fitness": 0.5704347758183598, "feedback": "The algorithm QIEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.57 with standard deviation 0.03.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.598880152035679, 0.5419893996010405]}, "mutation_prompt": null}
{"id": "eb050f50-1cf6-4c90-87d5-bb30b16a9118", "solution": "import numpy as np\n\nclass QSDN_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.neighborhood_size = 5\n        self.quantum_perturbation = 0.1\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def dynamic_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n    def update_particle(self, particle, neighborhood_best, lb, ub, inertia_weight):\n        r1, r2 = np.random.rand(), np.random.rand()\n        cognitive_component = r1 * (particle['best_position'] - particle['position'])\n        social_component = r2 * (neighborhood_best - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component\n        particle['position'] += particle['velocity']\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def quantum_superposition(self, particle, lb, ub):\n        # Apply quantum perturbation to enhance exploration\n        if np.random.rand() < self.quantum_perturbation:\n            particle['position'] = lb + (ub - lb) * np.random.rand(self.dim)\n\n    def stochastic_neighborhood_best(self, particle_index):\n        neighborhood_indices = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[neighborhood_indices[0]]['best_position']\n        neighborhood_best_value = self.swarms[neighborhood_indices[0]]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        return neighborhood_best\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                # Quantum-inspired exploration\n                self.quantum_superposition(particle, lb, ub)\n                \n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.dynamic_inertia(evaluations)\n            \n            for particle_index, particle in enumerate(self.swarms):\n                neighborhood_best = self.stochastic_neighborhood_best(particle_index)\n                self.update_particle(particle, neighborhood_best, lb, ub, inertia_weight)\n\n        return self.best_solution, self.best_value", "name": "QSDN_PSO", "description": "Introducing Quantum-inspired Stochastic Dynamic Neighborhood PSO (QSDN-PSO) that leverages quantum-inspired superposition and entanglement principles to enhance particle diversity and convergence efficiency in black-box optimization.", "configspace": "", "generation": 49, "fitness": 0.8948143624143444, "feedback": "The algorithm QSDN_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.01.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.8876707503829862, 0.9019579744457027]}, "mutation_prompt": null}
{"id": "dc21caa5-427e-4544-ab54-14ce9157385b", "solution": "import numpy as np\n\nclass AIHN_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.neighborhood_size = 5\n        self.global_influence_weight = 0.5\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def adaptive_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n    def update_particle(self, particle, neighborhood_best, global_best, lb, ub, inertia_weight):\n        r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n        cognitive_component = r1 * (particle['best_position'] - particle['position'])\n        social_component = r2 * (neighborhood_best - particle['position'])\n        global_component = r3 * self.global_influence_weight * (global_best - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component + global_component\n        particle['position'] += particle['velocity']\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def hybrid_neighborhood_best(self, particle_index):\n        neighborhood_indices = np.random.choice(self.swarm_size, self.neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[neighborhood_indices[0]]['best_position']\n        neighborhood_best_value = self.swarms[neighborhood_indices[0]]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        return neighborhood_best\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.adaptive_inertia(evaluations)\n            global_best_position = self.best_solution\n\n            for particle_index, particle in enumerate(self.swarms):\n                neighborhood_best = self.hybrid_neighborhood_best(particle_index)\n                self.update_particle(particle, neighborhood_best, global_best_position, lb, ub, inertia_weight)\n\n        return self.best_solution, self.best_value", "name": "AIHN_PSO", "description": "Introducing Adaptive Inertia and Hybrid Neighborhood PSO (AIHN-PSO) that combines adaptive inertia and hybrid global-local neighborhood influence to enhance convergence speed and solution diversity in black-box optimization.", "configspace": "", "generation": 50, "fitness": 0.8865625614876176, "feedback": "The algorithm AIHN_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.02.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.9061613886638139, 0.8669637343114214]}, "mutation_prompt": null}
{"id": "dd3fb71d-e7c1-4bfa-a92f-5dd8a018111c", "solution": "import numpy as np\n\nclass AQ_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.neighborhood_size = 5\n        self.q_alpha = 0.75  # Quantum-inspired parameter\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def dynamic_inertia(self, evaluations):\n        return self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n\n    def adaptive_neighborhood_size(self, evaluations):\n        return max(3, int(self.neighborhood_size * (1 - evaluations / self.budget)))\n\n    def update_particle(self, particle, neighborhood_best, lb, ub, inertia_weight):\n        r1, r2 = np.random.rand(), np.random.rand()\n        cognitive_component = r1 * (particle['best_position'] - particle['position'])\n        social_component = r2 * (neighborhood_best - particle['position'])\n        particle['velocity'] = inertia_weight * particle['velocity'] + cognitive_component + social_component\n        particle['position'] += particle['velocity']\n        particle['position'] = lb + (ub - lb) * np.exp(-self.q_alpha * np.abs(particle['position']))  # Quantum-inspired position update\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def stochastic_neighborhood_best(self, particle_index, neighborhood_size):\n        neighborhood_indices = np.random.choice(self.swarm_size, neighborhood_size, replace=False)\n        neighborhood_best = self.swarms[neighborhood_indices[0]]['best_position']\n        neighborhood_best_value = self.swarms[neighborhood_indices[0]]['best_value']\n        \n        for idx in neighborhood_indices:\n            if self.swarms[idx]['best_value'] < neighborhood_best_value:\n                neighborhood_best = self.swarms[idx]['best_position']\n                neighborhood_best_value = self.swarms[idx]['best_value']\n        \n        return neighborhood_best\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_weight = self.dynamic_inertia(evaluations)\n            neighborhood_size = self.adaptive_neighborhood_size(evaluations)\n            \n            for particle_index, particle in enumerate(self.swarms):\n                neighborhood_best = self.stochastic_neighborhood_best(particle_index, neighborhood_size)\n                self.update_particle(particle, neighborhood_best, lb, ub, inertia_weight)\n\n        return self.best_solution, self.best_value", "name": "AQ_PSO", "description": "Introducing Adaptive Quantum-inspired PSO (AQ-PSO) that uses quantum-inspired position updates and adaptive neighborhood sizes to enhance convergence in black-box optimization.", "configspace": "", "generation": 51, "fitness": 0.4490026691557284, "feedback": "The algorithm AQ_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.03.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.4180224550285596, 0.4799828832828972]}, "mutation_prompt": null}
{"id": "a3452385-3259-4ced-ad10-2c8f13736f08", "solution": "import numpy as np\n\nclass Q_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.population = []\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.9  # Crossover rate\n\n    def initialize_population(self, lb, ub):\n        return [lb + (ub - lb) * np.random.rand(self.dim) for _ in range(self.population_size)]\n\n    def quantum_mutation(self, agent, lb, ub):\n        alpha = np.random.uniform(0, np.pi)\n        beta = np.random.uniform(0, 2 * np.pi)\n        q_bit = np.array([np.cos(alpha), np.sin(alpha) * np.exp(1j * beta)])\n        q_positions = np.angle(q_bit[1])  # Extract phase information as position\n        return lb + (ub - lb) * ((q_positions % (2 * np.pi)) / (2 * np.pi))\n\n    def mutate(self, target_idx, lb, ub):\n        candidates = list(range(self.population_size))\n        candidates.remove(target_idx)\n        a, b, c = np.random.choice(candidates, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        quantum_mutant = self.quantum_mutation(mutant, lb, ub)\n        return np.clip(mutant + quantum_mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        trial = np.copy(target)\n        for i in range(self.dim):\n            if np.random.rand() < self.CR:\n                trial[i] = mutant[i]\n        return trial\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, lb, ub)\n                trial = self.crossover(target, mutant)\n                \n                trial_value = func(trial)\n                evaluations += 1\n                \n                if trial_value < func(target):\n                    self.population[i] = trial\n                    target_value = trial_value\n                \n                if trial_value < self.best_value:\n                    self.best_value = trial_value\n                    self.best_solution = trial.copy()\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_solution, self.best_value", "name": "Q_DE", "description": "Introducing Quantum-enhanced Differential Evolution (Q-DE) that leverages quantum-inspired mutation strategies for enhanced global search capabilities in optimizing complex black-box functions.", "configspace": "", "generation": 52, "fitness": 0.5419194324108658, "feedback": "The algorithm Q_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.01.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.5326493712260589, 0.5511894935956728]}, "mutation_prompt": null}
{"id": "7072ec22-8dbc-4e0f-8b66-982e162e54bd", "solution": "import numpy as np\n\nclass AQSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.alpha = 0.5\n        self.beta = 0.5\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            quantum_prob = np.ones(self.dim) * 0.5\n            swarm.append({'position': position, 'quantum_prob': quantum_prob, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def adaptive_parameters(self, evaluations):\n        progress_ratio = evaluations / self.budget\n        self.alpha = max(0.4, 0.9 * (1 - progress_ratio))\n        self.beta = min(0.6, 0.1 + 0.5 * progress_ratio)\n\n    def quantum_sample(self, particle, lb, ub):\n        particle['position'] = lb + (ub - lb) * np.where(np.random.rand(self.dim) < particle['quantum_prob'], 1, 0)\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def update_particle(self, particle, global_best, lb, ub):\n        r1, r2 = np.random.rand(), np.random.rand()\n        particle['quantum_prob'] = (self.alpha * particle['quantum_prob'] +\n                                    self.beta * (global_best - particle['position']))\n        self.quantum_sample(particle, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n\n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            self.adaptive_parameters(evaluations)\n            global_best = min(self.swarms, key=lambda p: p['best_value'])['best_position']\n            \n            for particle in self.swarms:\n                self.update_particle(particle, global_best, lb, ub)\n\n        return self.best_solution, self.best_value", "name": "AQSO", "description": "Introducing Adaptive Quantum Swarm Optimization (AQSO) leveraging quantum-inspired probability distributions and adaptive mechanism to balance exploration and exploitation in high-dimensional black-box optimization.", "configspace": "", "generation": 53, "fitness": 0.4472590356683745, "feedback": "The algorithm AQSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.01.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.46083001987616923, 0.43368805146057976]}, "mutation_prompt": null}
{"id": "a745b223-22e8-4f66-8b89-75f519621274", "solution": "import numpy as np\n\nclass QPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def randomized_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.randomized_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "QPSO", "description": "Introducing Quantum-inspired Particle Swarm Optimization (QPSO) that exploits quantum superposition principles and adaptive mutation for enhanced global search capabilities in photonic structure optimization.", "configspace": "", "generation": 54, "fitness": 0.9702574624086009, "feedback": "The algorithm QPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.97 with standard deviation 0.00.", "error": "", "parent_id": "e003c122-7715-42de-8f6b-328086793a6b", "metadata": {"aucs": [0.9689734385162084, 0.9715414863009932]}, "mutation_prompt": null}
{"id": "af791919-d388-44ec-a9ff-373902e0f0b3", "solution": "import numpy as np\n\nclass AQASO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, temperature):\n        r = np.random.rand(self.dim)\n        quantum_factor = np.tanh(temperature * (global_best - particle['position']))\n        particle['position'] += r * quantum_factor * (global_best - particle['position'])\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adaptive_mutation(self, particle, lb, ub, evaluation_ratio):\n        mutation_prob = 0.5 * (1 - evaluation_ratio)\n        if np.random.rand() < mutation_prob:\n            mutation_scale = (ub - lb) * 0.1 * np.exp(-20 * evaluation_ratio)\n            mutation_vector = np.random.normal(0, mutation_scale, self.dim)\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            temperature = 1.0 - evaluations / self.budget\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, temperature)\n                self.adaptive_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "AQASO", "description": "Introducing Adaptive Quantum Annealing Swarm Optimization (AQASO), combining quantum annealing principles with adaptive swarm behavior for enhanced balance between exploration and exploitation in photonic structure optimization.", "configspace": "", "generation": 55, "fitness": 0.5381660131792776, "feedback": "The algorithm AQASO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.04.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.5740463040448012, 0.5022857223137541]}, "mutation_prompt": null}
{"id": "b452f968-1b54-4f48-8004-9b1bba22487a", "solution": "import numpy as np\n\nclass EQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        # Non-linear beta decay\n        beta_decay = beta ** 3\n        particle['position'] = mean_best + beta_decay * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adaptive_mutation(self, particle, lb, ub, evaluation_ratio, diversity_factor):\n        mutation_prob = 0.5 * (1 - evaluation_ratio) + diversity_factor * 0.1\n        if np.random.rand() < mutation_prob:\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n\n        while evaluations < self.budget:\n            diversity = np.std([p['position'] for p in self.swarms], axis=0).mean()\n            diversity_factor = min(1, max(0, diversity / (ub - lb).mean()))\n            \n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n\n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n\n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.adaptive_mutation(particle, lb, ub, evaluations / self.budget, diversity_factor)\n\n        return global_best, global_best_value", "name": "EQPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization (EQPSO) with adaptive learning strategies and non-linear beta decay to improve convergence speed and solution quality.", "configspace": "", "generation": 56, "fitness": 0.9285964799470798, "feedback": "The algorithm EQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.00.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.928408783977117, 0.9287841759170425]}, "mutation_prompt": null}
{"id": "968cef8e-b9e3-4a91-bdf1-f37e63058086", "solution": "import numpy as np\n\nclass ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = []\n        self.best_solution = None\n        self.best_value = float('inf')\n\n    def initialize_population(self, lb, ub):\n        return [lb + (ub - lb) * np.random.rand(self.dim) for _ in range(self.pop_size)]\n\n    def mutate_and_crossover(self, target_idx, lb, ub):\n        idxs = [idx for idx in range(self.pop_size) if idx != target_idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = self.population[a] + self.scaling_factor * (self.population[b] - self.population[c])\n        mutant = np.clip(mutant, lb, ub)\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, self.population[target_idx])\n        return trial\n\n    def chaotic_local_search(self, candidate, lb, ub, iterations=10):\n        chaotic_sequence = np.sin(np.array(range(iterations)) * np.pi * 0.1)\n        for i in range(iterations):\n            perturbation = chaotic_sequence[i] * (ub - lb) * 0.01\n            candidate = np.clip(candidate + perturbation, lb, ub)\n        return candidate\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n        \n        while evaluations < self.budget:\n            for target_idx, target in enumerate(self.population):\n                trial = self.mutate_and_crossover(target_idx, lb, ub)\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < self.best_value:\n                    self.best_value = trial_value\n                    self.best_solution = trial.copy()\n\n                if trial_value < func(target):\n                    self.population[target_idx] = trial\n                elif np.random.rand() < 0.1:\n                    candidate = self.chaotic_local_search(target, lb, ub)\n                    candidate_value = func(candidate)\n                    evaluations += 1\n                    if candidate_value < self.best_value:\n                        self.best_value = candidate_value\n                        self.best_solution = candidate.copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            self.scaling_factor = 0.5 + 0.5 * (1 - evaluations / self.budget)\n            self.crossover_rate = 0.7 + 0.3 * np.sin(evaluations * np.pi / (2 * self.budget))\n\n        return self.best_solution, self.best_value", "name": "ADE", "description": "Introducing Adaptive Differential Evolution (ADE) with dynamic parameter adjustment and chaotic local search for robust optimization of photonic structures.", "configspace": "", "generation": 57, "fitness": 0.7684277275752359, "feedback": "The algorithm ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.77 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.7539959276597592, 0.7828595274907126]}, "mutation_prompt": null}
{"id": "8059ba1e-600a-4845-a992-b4c8981d78f8", "solution": "import numpy as np\n\nclass AQDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': position, 'best_position': position, 'best_value': float('inf')})\n        return population\n\n    def quantum_update(self, particle, global_best, lb, ub, alpha):\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = 2 * np.pi * np.random.rand(self.dim)  # Random angle\n        r = np.random.rand(self.dim)  # Random radius\n        particle['position'] = mean_best + alpha * r * np.sin(phi)\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def differential_mutation(self, target_idx, lb, ub):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        F = 0.8  # Differential weight\n        mutant = self.population[a]['position'] + F * (self.population[b]['position'] - self.population[c]['position'])\n        mutant = np.clip(mutant, lb, ub)\n        return mutant\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for idx, particle in enumerate(self.population):\n                trial_position = self.differential_mutation(idx, lb, ub)\n                trial_value = func(trial_position)\n                evaluations += 1\n                \n                if trial_value < particle['best_value']:\n                    particle['best_value'] = trial_value\n                    particle['best_position'] = trial_position.copy()\n                \n                if trial_value < global_best_value:\n                    global_best_value = trial_value\n                    global_best = trial_position.copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            alpha = 1.0 - evaluations / self.budget\n            for particle in self.population:\n                self.quantum_update(particle, global_best, lb, ub, alpha)\n\n        return global_best, global_best_value", "name": "AQDE", "description": "Introducing Adaptive Quantum Differential Evolution (AQDE) which combines quantum-inspired position updates and adaptive differential mutation strategies for robust global search in high-dimensional photonic structure optimization.", "configspace": "", "generation": 58, "fitness": 0.8153220527897602, "feedback": "The algorithm AQDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.82 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.8042361389917795, 0.8264079665877408]}, "mutation_prompt": null}
{"id": "e23ab03d-cae8-4a67-9a14-e76d530c981f", "solution": "import numpy as np\n\nclass EQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def levy_flight(self, size, alpha=1.5):\n        # Using Mantegna's algorithm for Lévy flight\n        sigma = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) / \n                 (np.gamma((1 + alpha) / 2) * alpha * 2**((alpha - 1) / 2)))**(1 / alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        return u / np.abs(v)**(1 / alpha)\n\n    def update_particle(self, particle, global_best, lb, ub, beta, gamma):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n        \n        if np.random.rand() < gamma:\n            levy_step = self.levy_flight(self.dim)\n            particle['position'] += levy_step * (ub - lb) * 0.1\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            gamma = 0.1 * (1 + np.cos(np.pi * evaluations / self.budget))  # Adaptive mutation probability\n\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta, gamma)\n\n        return global_best, global_best_value", "name": "EQPSO", "description": "Enhanced Quantum Particle Swarm Optimization (EQPSO) incorporates adaptive control of exploration-exploitation balance and a Lévy flight-based mutation strategy for improved convergence in the optimization of photonic structures.", "configspace": "", "generation": 59, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {}, "mutation_prompt": null}
{"id": "70edb4c4-b1aa-4e04-82e0-6183aefa0585", "solution": "import numpy as np\n\nclass ADESAC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F = 0.5  # initial differential weight\n        self.CR = 0.9  # initial crossover probability\n\n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def mutate(self, idx, population, F):\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        a, b, c = population[np.random.choice(indices, 3, replace=False)]\n        mutant = a + F * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant, CR):\n        crossover_mask = np.random.rand(self.dim) < CR\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, mutant, target)\n\n    def __call__(self, func):\n        self.lb, self.ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = self.initialize_population(self.lb, self.ub)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                F = 0.4 + 0.3 * np.random.rand()  # self-adaptive F\n                CR = 0.8 + 0.2 * np.random.rand()  # self-adaptive CR\n                \n                mutant = self.mutate(i, population, F)\n                trial = self.crossover(population[i], mutant, CR)\n                \n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "ADESAC", "description": "Adaptive Differential Evolution with Self-Adaptive Mutation and Crossover (ADESAC) utilizing self-adaptive mechanisms to balance exploration and exploitation for optimizing photonic structures.", "configspace": "", "generation": 60, "fitness": 0.9238806674434177, "feedback": "The algorithm ADESAC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9171746357964196, 0.9305866990904159]}, "mutation_prompt": null}
{"id": "d20c61da-53c0-4071-9ffe-fd33da7d2852", "solution": "import numpy as np\n\nclass EnhancedQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.elite_archive_size = 5\n        self.elite_archive = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            swarm.append({'position': position, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def randomized_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def update_elite_archive(self, candidate, value):\n        self.elite_archive.append((candidate.copy(), value))\n        self.elite_archive.sort(key=lambda x: x[1])\n        if len(self.elite_archive) > self.elite_archive_size:\n            self.elite_archive.pop()\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        swarm = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle in swarm:\n                value = func(particle['position'])\n                evaluations += 1\n\n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                self.update_elite_archive(particle['position'], value)\n                \n                if evaluations >= self.budget:\n                    break\n\n            beta = 0.5 + 0.5 * (1 - evaluations / self.budget) ** 2\n            for particle in swarm:\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.randomized_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "EnhancedQPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization (Enhanced QPSO) that improves global search by incorporating a dynamic adaptive beta and an elite archiving strategy for robust exploration and exploitation.", "configspace": "", "generation": 61, "fitness": 0.9598277594079079, "feedback": "The algorithm EnhancedQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9449659651250002, 0.9746895536908154]}, "mutation_prompt": null}
{"id": "c8d0a405-a226-4b2f-9886-5687e28a6966", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            swarm.append({'position': position, 'velocity': np.zeros(self.dim), 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta, learning_rate):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.pi * (r1 - 0.5)\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * learning_rate * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def randomized_mutation(self, particle, lb, ub, diversity):\n        if np.random.rand() < 0.5 * (1 - diversity):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def calculate_diversity(self, swarm):\n        positions = np.array([p['position'] for p in swarm])\n        centroid = np.mean(positions, axis=0)\n        diversity = np.mean(np.linalg.norm(positions - centroid, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        elite_fraction = 0.2\n        learning_rate = 0.1\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            diversity = self.calculate_diversity(self.swarms)\n            learning_rate = 0.5 * (1 + diversity)\n            \n            elite_particles = sorted(self.swarms, key=lambda p: p['best_value'])[:int(self.swarm_size * elite_fraction)]\n            for particle in self.swarms:\n                self.update_particle(particle, global_best, lb, ub, beta, learning_rate)\n                self.randomized_mutation(particle, lb, ub, diversity)\n                if particle in elite_particles:\n                    particle['position'] = particle['best_position'].copy()\n\n        return global_best, global_best_value", "name": "AQPSO", "description": "Introducing Adaptive Quantum-inspired Particle Swarm Optimization (AQPSO) that employs adaptive learning rates based on particle diversity and an elite strategy for improved convergence in photonic structure optimization.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {}, "mutation_prompt": null}
{"id": "b2d97428-52ab-401c-b913-fbbcb8d6cc99", "solution": "import numpy as np\n\nclass DEAM_LS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.best_solution = None\n        self.best_value = float('inf')\n    \n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n    \n    def mutate(self, population):\n        idxs = np.random.choice(self.population_size, 3, replace=False)\n        a, b, c = population[idxs]\n        return a + self.mutation_factor * (b - c)\n    \n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_probability\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n    \n    def local_search(self, candidate, lb, ub):\n        perturbation = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, lb, ub)\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = self.initialize_population(lb, ub)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            new_population = []\n            for target_idx in range(self.population_size):\n                target = population[target_idx]\n                mutant = self.mutate(population)\n                mutant = np.clip(mutant, lb, ub)\n                trial = self.crossover(target, mutant)\n                trial_value = func(trial)\n                evaluations += 1\n                \n                if trial_value < func(target):\n                    new_population.append(trial)\n                    if trial_value < self.best_value:\n                        self.best_value = trial_value\n                        self.best_solution = trial\n                else:\n                    new_population.append(target)\n                    \n                if evaluations >= self.budget:\n                    break\n                \n                if np.random.rand() < 0.1:  # Local search probability\n                    local_candidate = self.local_search(new_population[-1], lb, ub)\n                    local_value = func(local_candidate)\n                    evaluations += 1\n                    if local_value < func(new_population[-1]):\n                        new_population[-1] = local_candidate\n                        if local_value < self.best_value:\n                            self.best_value = local_value\n                            self.best_solution = local_candidate\n                \n            population = np.array(new_population)\n        \n        return self.best_solution, self.best_value", "name": "DEAM_LS", "description": "Introducing Differential Evolution with Adaptive Mutation and Local Search (DEAM-LS) which combines adaptive mutation strategies and local search intensification for efficient global optimization of photonic structures.", "configspace": "", "generation": 63, "fitness": 0.6920614389988546, "feedback": "The algorithm DEAM_LS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.03.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.7265946018334296, 0.6575282761642796]}, "mutation_prompt": null}
{"id": "5cd9f6f7-3f81-44e0-a762-b1207b299f72", "solution": "import numpy as np\n\nclass ADE_DNS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.mutation_factor = 0.5\n        self.crossover_prob = 0.9\n        self.best_solution = None\n        self.best_value = float('inf')\n\n    def initialize_population(self, lb, ub):\n        return [lb + (ub - lb) * np.random.rand(self.dim) for _ in range(self.pop_size)]\n\n    def mutate(self, population, idx, lb, ub):\n        indices = list(range(self.pop_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.mutation_factor * (population[b] - population[c])\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_prob\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_mutation(self, target_value, global_best_value):\n        return self.mutation_factor * (target_value / global_best_value)\n\n    def dynamic_neighborhood_search(self, population, idx, lb, ub):\n        distances = [np.linalg.norm(population[idx] - population[j]) for j in range(self.pop_size)]\n        sorted_indices = np.argsort(distances)\n        for j in sorted_indices[:5]:  # Consider the 5 nearest neighbors\n            if j != idx:\n                trial = self.mutate(population, j, lb, ub)\n                trial = self.crossover(population[j], trial)\n                trial_value = self.evaluate(trial)\n                if trial_value < self.best_value:\n                    self.best_value = trial_value\n                    self.best_solution = trial\n\n    def evaluate(self, solution):\n        return func(solution)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n        while evaluations < self.budget:\n            for i in range(self.pop_size):\n                target = population[i]\n                mutant = self.mutate(population, i, lb, ub)\n                trial = self.crossover(target, mutant)\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < self.evaluate(target):\n                    population[i] = trial\n                    if trial_value < self.best_value:\n                        self.best_value = trial_value\n                        self.best_solution = trial\n\n                if evaluations >= self.budget:\n                    break\n\n            for i in range(self.pop_size):\n                self.dynamic_neighborhood_search(population, i, lb, ub)\n\n        return self.best_solution, self.best_value", "name": "ADE_DNS", "description": "Introducing Adaptive Differential Evolution with Dynamic Neighborhood Search (ADE-DNS) that combines adaptive mutation strategies and dynamic neighborhood exploration for enhanced convergence in photonic structure optimization.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {}, "mutation_prompt": null}
{"id": "6e6dbcce-c37f-4930-afec-1d8b1e809ff6", "solution": "import numpy as np\n\nclass PIQSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.num_swarms = 5\n        self.swarms = []\n        self.global_bests = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            swarm.append({'position': position, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle_position(self, particle, local_best, lb, ub, exploration_factor):\n        r1 = np.random.rand(self.dim)\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        particle['position'] = local_best + exploration_factor * (r1 - 0.5) * np.abs(local_best - particle['position']) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def quantum_tunneling(self, particle, lb, ub, global_best_value):\n        if np.random.rand() < 0.1:\n            q_jump = np.random.normal(0, 1, self.dim) * (ub - lb) * 0.1\n            particle['position'] += q_jump\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        self.global_bests = [np.full(self.dim, np.inf) for _ in range(self.num_swarms)]\n        global_best_value = float('inf')\n\n        while evaluations < self.budget:\n            for swarm_index, swarm in enumerate(self.swarms):\n                for particle_index, particle in enumerate(swarm):\n                    value = func(particle['position'])\n                    evaluations += 1\n\n                    if value < particle['best_value']:\n                        particle['best_value'] = value\n                        particle['best_position'] = particle['position'].copy()\n\n                    if value < self.global_bests[swarm_index].get('value', float('inf')):\n                        self.global_bests[swarm_index] = {'position': particle['position'].copy(), 'value': value}\n\n                    if value < global_best_value:\n                        global_best_value = value\n                        self.best_solution = particle['position'].copy()\n\n                    if evaluations >= self.budget:\n                        break\n\n                exploration_factor = 1.0 - evaluations / self.budget\n                for particle_index, particle in enumerate(swarm):\n                    self.update_particle_position(particle, self.global_bests[swarm_index]['position'], lb, ub, exploration_factor)\n                    self.quantum_tunneling(particle, lb, ub, global_best_value)\n\n            if evaluations >= self.budget:\n                break\n\n        return self.best_solution, global_best_value", "name": "PIQSO", "description": "A Parallel-Inspired Quantum Swarm Optimization (PIQSO) that utilizes simultaneous multi-swarm dynamics and quantum tunneling to enhance convergence speed and global exploration in photonic structure optimization.", "configspace": "", "generation": 65, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'numpy.ndarray' object has no attribute 'get'\").", "error": "AttributeError(\"'numpy.ndarray' object has no attribute 'get'\")", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {}, "mutation_prompt": null}
{"id": "6500142a-1e1b-437e-87ca-60777c763efb", "solution": "import numpy as np\n\nclass AEFO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        return [{'position': lb + (ub - lb) * np.random.rand(self.dim),\n                 'charge': np.random.rand()} for _ in range(self.population_size)]\n\n    def update_particle(self, particle, best_position, lb, ub, inertia_factor):\n        for i in range(self.dim):\n            force = (best_position[i] - particle['position'][i]) * particle['charge']\n            direction = np.sign(force)\n            step_size = inertia_factor * force * direction\n            particle['position'][i] += step_size\n            particle['position'][i] = np.clip(particle['position'][i], lb[i], ub[i])\n\n    def adaptive_mutation(self, particle, lb, ub, eval_ratio):\n        if np.random.rand() < 0.5 * (1 - eval_ratio):\n            mutation_strength = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.05\n            particle['position'] += mutation_strength\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n        best_position = None\n        best_value = float('inf')\n\n        while evaluations < self.budget:\n            for particle in self.population:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < best_value:\n                    best_value = value\n                    best_position = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            inertia_factor = 0.5 + 0.5 * (1 - evaluations / self.budget)\n            for particle in self.population:\n                self.update_particle(particle, best_position, lb, ub, inertia_factor)\n                self.adaptive_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return best_position, best_value", "name": "AEFO", "description": "Introducing Adaptive Electromagnetic Field-based Optimization (AEFO) that mimics electromagnetic attraction-repulsion dynamics and adaptive inertia for superior exploration-exploitation balance in photonic structure optimization.", "configspace": "", "generation": 66, "fitness": 0.6581192267176195, "feedback": "The algorithm AEFO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.05.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.6056334312530303, 0.7106050221822087]}, "mutation_prompt": null}
{"id": "9720ea61-dc7e-4e8c-8b04-f404497bec6f", "solution": "import numpy as np\n\nclass QIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            individual = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append(individual)\n        return np.array(population)\n\n    def mutate(self, target_idx, lb, ub):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, lb, ub)\n\n    def quantum_mutation(self, candidate, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            phase = np.arccos(1 - 2 * np.random.rand(self.dim))\n            direction = np.sign(np.random.rand(self.dim) - 0.5)\n            quantum_movement = (ub - lb) * 0.05 * np.tan(phase) * direction\n            candidate = candidate + quantum_movement\n            candidate = np.clip(candidate, lb, ub)\n        return candidate\n\n    def crossover(self, target, mutant):\n        trial = np.copy(target)\n        j_rand = np.random.randint(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR or j == j_rand:\n                trial[j] = mutant[j]\n        return trial\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i, lb, ub)\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.quantum_mutation(trial, lb, ub, evaluations / self.budget)\n                \n                trial_value = func(trial)\n                evaluations += 1\n                \n                if trial_value < self.best_value:\n                    self.best_value = trial_value\n                    self.best_solution = trial.copy()\n                \n                if trial_value < func(self.population[i]):\n                    self.population[i] = trial\n                \n                if evaluations >= self.budget:\n                    break\n\n        return self.best_solution, self.best_value", "name": "QIDE", "description": "Introducing the Quantum-Inspired Differential Evolution (QIDE) that combines differential evolution with quantum-inspired mutation for efficient exploration and exploitation in complex photonic structure optimization.", "configspace": "", "generation": 67, "fitness": 0.8587033059823702, "feedback": "The algorithm QIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.86 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.871678289799988, 0.8457283221647525]}, "mutation_prompt": null}
{"id": "26936f63-91f7-40cb-b07c-aec5db68219d", "solution": "import numpy as np\n\nclass EnhancedQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            swarm.append({'position': position, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def levy_flight(self, lb, ub):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step * (ub - lb) * 0.01\n\n    def update_particle(self, particle, global_best, lb, ub, alpha):\n        mean_best = (particle['best_position'] + global_best) / 2\n        direction = np.random.choice([-1, 1], size=self.dim)\n        particle['position'] = mean_best + alpha * np.random.rand(self.dim) * direction * self.levy_flight(lb, ub)\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n\n        while evaluations < self.budget:\n            evaluation_ratio = evaluations / self.budget\n            alpha = 0.1 + 0.9 * evaluation_ratio  # Adaptive convergence pressure\n\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n\n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n\n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            for particle in self.swarms:\n                self.update_particle(particle, global_best, lb, ub, alpha)\n\n        return global_best, global_best_value", "name": "EnhancedQPSO", "description": "Enhance Quantum-inspired Particle Swarm Optimization (QPSO) by integrating Lévy flight for exploration and adaptive convergence pressure for balanced exploration-exploitation trade-off in photonic structure optimization.", "configspace": "", "generation": 68, "fitness": 0.8489995388828162, "feedback": "The algorithm EnhancedQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85 with standard deviation 0.02.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.8717389138863625, 0.8262601638792699]}, "mutation_prompt": null}
{"id": "f7ff4182-9f3a-4103-a82a-f46469d1e2f6", "solution": "import numpy as np\n\nclass AGB_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 20\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.best_solution = None\n        self.best_value = float('inf')\n\n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.pop_size, self.dim)\n\n    def mutate(self, population, best_idx):\n        indices = np.arange(self.pop_size)\n        np.random.shuffle(indices)\n        idxs = indices[:3]\n        while best_idx in idxs:\n            np.random.shuffle(indices)\n            idxs = indices[:3]\n        a, b, c = population[idxs]\n        mutant = a + self.f * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def gradient_based_adjustment(self, trial, lb, ub, func, step_size=0.01):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            step = np.zeros(self.dim)\n            step[i] = step_size\n            grad[i] = (func(np.clip(trial + step, lb, ub)) - func(np.clip(trial - step, lb, ub))) / (2 * step_size)\n        adjusted = trial - step_size * grad\n        return np.clip(adjusted, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations += self.pop_size\n\n        while evaluations < self.budget:\n            for i in range(self.pop_size):\n                best_idx = np.argmin(fitness)\n                mutant = self.mutate(population, best_idx)\n                trial = self.crossover(population[i], mutant)\n                trial = self.gradient_based_adjustment(trial, lb, ub, func)\n                trial_value = func(trial)\n                evaluations += 1\n                \n                if trial_value < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_value\n                \n                if trial_value < self.best_value:\n                    self.best_value = trial_value\n                    self.best_solution = trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_solution, self.best_value", "name": "AGB_DE", "description": "Adaptive Gradient-Based Differential Evolution (AGB-DE) combines differential evolution with adaptive gradient search to enhance exploration and exploitation for optimizing photonic structures.", "configspace": "", "generation": 69, "fitness": 0.652157481971193, "feedback": "The algorithm AGB_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.05.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.705458287824126, 0.5988566761182601]}, "mutation_prompt": null}
{"id": "2a8c7181-99b7-4659-b039-e28d60b1cc38", "solution": "import numpy as np\n\nclass ALDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        return [lb + (ub - lb) * np.random.rand(self.dim) for _ in range(self.population_size)]\n\n    def levy_flight(self, lam=1.5):\n        u = np.random.normal(0, 0.1, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (np.abs(v) ** (1 / lam))\n        return step\n\n    def differential_mutation(self, target, idx, lb, ub, F=0.5, CR=0.9):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + F * (self.population[b] - self.population[c])\n        mutant = np.clip(mutant, lb, ub)\n        trial = np.copy(target)\n        crossover = np.random.rand(self.dim) < CR\n        trial[crossover] = mutant[crossover]\n        return trial\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            for i, individual in enumerate(self.population):\n                trial = self.differential_mutation(individual, i, lb, ub)\n                \n                if np.random.rand() < 0.5:\n                    trial += self.levy_flight() * (ub - lb) * 0.05\n                    trial = np.clip(trial, lb, ub)\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < func(individual):\n                    self.population[i] = trial\n\n                if trial_value < self.best_value:\n                    self.best_value = trial_value\n                    self.best_solution = trial.copy()\n\n                if evaluations >= self.budget:\n                    break\n\n        return self.best_solution, self.best_value", "name": "ALDE", "description": "Introducing Adaptive Levy-Driven Differential Evolution (ALDE), a hybrid exploration-exploitation strategy leveraging Levy flights and differential mutation for robust optimization of photonic structures.", "configspace": "", "generation": 70, "fitness": 0.9000376861893669, "feedback": "The algorithm ALDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90 with standard deviation 0.03.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9279184814518834, 0.8721568909268504]}, "mutation_prompt": null}
{"id": "3ee0d1bc-f3a6-4f60-ab65-34d6b03b3b62", "solution": "import numpy as np\n\nclass HQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def harmony_search_adjustment(self, particle, global_best, lb, ub):\n        if np.random.rand() < 0.3:\n            memory_consideration = 0.7\n            perturbation_factor = 0.1\n            if np.random.rand() < memory_consideration:\n                particle['position'] = global_best + perturbation_factor * (np.random.rand(self.dim) - 0.5)\n            else:\n                particle['position'] = lb + (ub - lb) * np.random.rand(self.dim)\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.harmony_search_adjustment(particle, global_best, lb, ub)\n\n        return global_best, global_best_value", "name": "HQPSO", "description": "Introducing Harmony-enhanced Quantum Particle Swarm Optimization (HQPSO) which synergistically combines quantum superposition principles with harmony search strategies to enhance exploration and exploitation in photonic structure optimization.", "configspace": "", "generation": 71, "fitness": 0.9097566308571836, "feedback": "The algorithm HQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.00.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9059062861793876, 0.9136069755349796]}, "mutation_prompt": null}
{"id": "cb89fe8d-8b0c-4392-be60-ec29ab707152", "solution": "import numpy as np\n\nclass EQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.initial_swarm_size = 20\n        self.max_swarm_size = 50\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.initial_swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta, inertia_weight):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n        particle['velocity'] = inertia_weight * particle['velocity'] + r1 * (particle['best_position'] - particle['position']) + r2 * (global_best - particle['position'])\n        particle['position'] += particle['velocity']\n\n    def randomized_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def dynamic_swarm_size(self, evaluation_ratio):\n        return int(self.initial_swarm_size + evaluation_ratio * (self.max_swarm_size - self.initial_swarm_size))\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            current_swarm_size = self.dynamic_swarm_size(evaluations / self.budget)\n            if len(self.swarms) < current_swarm_size:\n                for _ in range(current_swarm_size - len(self.swarms)):\n                    position = lb + (ub - lb) * np.random.rand(self.dim)\n                    velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n                    self.swarms.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n\n            for particle_index, particle in enumerate(self.swarms[:current_swarm_size]):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n            for particle_index, particle in enumerate(self.swarms[:current_swarm_size]):\n                self.update_particle(particle, global_best, lb, ub, beta, inertia_weight)\n                self.randomized_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "EQPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization (EQPSO) improves convergence by introducing dynamic swarm size and adaptive inertia weight based on evaluation progress for photonic structure optimization.", "configspace": "", "generation": 72, "fitness": 0.8096264428230835, "feedback": "The algorithm EQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81 with standard deviation 0.02.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.8283133216610987, 0.7909395639850684]}, "mutation_prompt": null}
{"id": "94007001-dcb6-4996-b05c-2ac21b0c5995", "solution": "import numpy as np\n\nclass AQDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.scaling_factor = 0.8\n        self.cr_rate = 0.9\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def quantum_update(self, target, best, lb, ub):\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        return best + (target - best) * np.tan(phi) * direction\n\n    def differential_mutation(self, idx, lb, ub):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.scaling_factor * (self.population[b] - self.population[c])\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        trial = np.array([mutant[i] if np.random.rand() < self.cr_rate else target[i] for i in range(self.dim)])\n        return trial\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.population = self.initialize_population(lb, ub)\n        evaluations = 0\n        best_value = float('inf')\n        best_solution = None\n\n        while evaluations < self.budget:\n            new_population = []\n            for idx, target in enumerate(self.population):\n                mutant = self.differential_mutation(idx, lb, ub)\n                trial = self.crossover(target, mutant)\n                \n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial.copy()\n\n                if trial_value < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if evaluations >= self.budget:\n                    break\n\n            self.population = new_population\n            # Quantum-inspired update\n            for idx, target in enumerate(self.population):\n                self.population[idx] = self.quantum_update(target, best_solution, lb, ub)\n                self.population[idx] = np.clip(self.population[idx], lb, ub)\n\n        return best_solution, best_value", "name": "AQDE", "description": "Introducing Adaptive Quantum Differential Evolution (AQDE) that combines quantum-inspired position updates with differential mutation strategies to enhance exploration and exploitation in photonic structure optimization.", "configspace": "", "generation": 73, "fitness": 0.6737361910320934, "feedback": "The algorithm AQDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.07.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.6064252411138453, 0.7410471409503414]}, "mutation_prompt": null}
{"id": "51a931a8-c904-4442-b347-07ddba560594", "solution": "import numpy as np\n\nclass ADE_QL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.best_solution = None\n        self.best_value = float('inf')\n\n    def initialize_population(self, lb, ub):\n        return [lb + (ub - lb) * np.random.rand(self.dim) for _ in range(self.population_size)]\n\n    def mutate(self, target_idx, population, lb, ub):\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = population[np.random.choice(indices)], population[np.random.choice(indices)], population[np.random.choice(indices)]\n        mutated_vector = a + self.mutation_factor * (b - c)\n        quantum_leap = np.random.rand(self.dim) < 0.1\n        mutated_vector[quantum_leap] = lb[quantum_leap] + (ub[quantum_leap] - lb[quantum_leap]) * np.random.rand(np.sum(quantum_leap))\n        return np.clip(mutated_vector, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, target)\n        return crossover_vector\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = self.initialize_population(lb, ub)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            new_population = []\n            for idx, target in enumerate(population):\n                mutant = self.mutate(idx, population, lb, ub)\n                trial = self.crossover(target, mutant)\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < self.best_value:\n                    self.best_value = trial_value\n                    self.best_solution = trial.copy()\n\n                target_value = func(target)\n                if trial_value < target_value:\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if evaluations >= self.budget:\n                    break\n\n            population = new_population\n\n        return self.best_solution, self.best_value", "name": "ADE_QL", "description": "Introducing Adaptive Differential Evolution with Quantum Leap (ADE-QL), which combines adaptive mutation strategies with quantum-inspired jumps for robust exploration and exploitation in photonic structure optimization.", "configspace": "", "generation": 74, "fitness": 0.8082724094812161, "feedback": "The algorithm ADE_QL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81 with standard deviation 0.02.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.7843656038977267, 0.8321792150647055]}, "mutation_prompt": null}
{"id": "90cebb8f-0881-4c40-abea-2873a7d557d6", "solution": "import numpy as np\n\nclass AIHMO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 30\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            fitness = float('inf')\n            population.append({'position': position, 'fitness': fitness})\n        return population\n\n    def hypermutation(self, position, lb, ub, evaluation_ratio):\n        mutation_rate = np.exp(-evaluation_ratio * 5)  # Adaptive mutation rate\n        mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * mutation_rate\n        new_position = position + mutation_vector\n        return np.clip(new_position, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            for individual in self.population:\n                individual['fitness'] = func(individual['position'])\n                evaluations += 1\n\n                if individual['fitness'] < self.best_value:\n                    self.best_value = individual['fitness']\n                    self.best_solution = individual['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            # Evaluate hypermutation for new candidate solutions\n            for individual in self.population:\n                if evaluations >= self.budget:\n                    break\n                new_position = self.hypermutation(individual['position'], lb, ub, evaluations / self.budget)\n                new_fitness = func(new_position)\n                evaluations += 1\n\n                if new_fitness < self.best_value:\n                    self.best_value = new_fitness\n                    self.best_solution = new_position.copy()\n\n        return self.best_solution, self.best_value", "name": "AIHMO", "description": "Introducing Adaptive Immune-Inspired Hypermutation Optimization (AIHMO) that leverages immune system principles with adaptive hypermutation rates to efficiently explore and exploit the search space of photonic structures.", "configspace": "", "generation": 75, "fitness": 0.657771818118586, "feedback": "The algorithm AIHMO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.04.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.6964734469023023, 0.6190701893348697]}, "mutation_prompt": null}
{"id": "4370984e-d7a7-40e5-9279-b3fd72a7cab5", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.initial_swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.initial_swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            swarm.append({'position': position, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adaptive_resizing(self, evaluations):\n        ratio = evaluations / self.budget\n        new_size = max(2, int(self.initial_swarm_size * (1 - ratio / 2)))\n        if len(self.swarms) > new_size:\n            self.swarms = self.swarms[:new_size]\n\n    def quantum_tunneling(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.3 * (1 - evaluation_ratio):\n            direction = np.random.normal(size=self.dim)\n            step_size = (ub - lb) * 0.05\n            particle['position'] += step_size * direction\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            self.adaptive_resizing(evaluations)\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.quantum_tunneling(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "AQPSO", "description": "An enhanced Adaptive Quantum Particle Swarm Optimization (AQPSO) integrating dynamic swarm resizing and quantum tunneling strategies for robust exploration and exploitation in photonic structure optimization.", "configspace": "", "generation": 76, "fitness": 0.9416218350603534, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9543668743830027, 0.9288767957377041]}, "mutation_prompt": null}
{"id": "71906721-906f-41be-9564-eb63749f78bc", "solution": "import numpy as np\n\nclass QPSO_AQT:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def quantum_tunneling(self, particle, lb, ub, global_best, evaluation_ratio):\n        if np.random.rand() < 0.3 * (1 - evaluation_ratio):\n            potential_position = global_best + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n            potential_position = np.clip(potential_position, lb, ub)\n            potential_value = self.evaluate(potential_position)\n            if potential_value < particle['best_value']:\n                particle['position'] = potential_position\n                particle['best_value'] = potential_value\n                particle['best_position'] = potential_position.copy()\n\n    def randomized_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def evaluate(self, position):\n        return self.func(position)\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.quantum_tunneling(particle, lb, ub, global_best, evaluations / self.budget)\n                self.randomized_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "QPSO_AQT", "description": "Introducing Quantum-inspired Particle Swarm Optimization with Adaptive Quantum Tunneling (QPSO-AQT) that incorporates quantum tunneling effects to overcome local optima and further enhance exploration capabilities in photonic structure optimization.", "configspace": "", "generation": 77, "fitness": 0.9165208864383869, "feedback": "The algorithm QPSO_AQT got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9063919920379806, 0.9266497808387932]}, "mutation_prompt": null}
{"id": "0dc0d86b-2c54-4663-a946-aca13f86fe73", "solution": "import numpy as np\n\nclass QDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': position, 'value': float('inf')})\n        return population\n\n    def mutate(self, target_index, lb, ub):\n        indices = [i for i in range(self.population_size) if i != target_index]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        F = 0.8  # mutation factor\n        donor_vector = self.population[a]['position'] + F * (self.population[b]['position'] - self.population[c]['position'])\n        return np.clip(donor_vector, lb, ub)\n\n    def crossover(self, target_vector, donor_vector):\n        CR = 0.9  # crossover probability\n        trial_vector = np.where(np.random.rand(self.dim) < CR, donor_vector, target_vector)\n        return trial_vector\n\n    def quantum_influence(self, trial_vector, global_best, lb, ub, beta):\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        influenced_vector = trial_vector + beta * np.abs(global_best - trial_vector) * np.tan(phi) * direction\n        return np.clip(influenced_vector, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n\n        while evaluations < self.budget:\n            for i, individual in enumerate(self.population):\n                target_vector = individual['position']\n                donor_vector = self.mutate(i, lb, ub)\n                trial_vector = self.crossover(target_vector, donor_vector)\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n\n                if trial_value < individual['value']:\n                    individual['position'] = trial_vector\n                    individual['value'] = trial_value\n\n                if trial_value < global_best_value:\n                    global_best_value = trial_value\n                    global_best = trial_vector.copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            for individual in self.population:\n                individual['position'] = self.quantum_influence(individual['position'], global_best, lb, ub, beta)\n\n        return global_best, global_best_value", "name": "QDE", "description": "Introducing Quantum Differential Evolution (QDE) that combines quantum-inspired superposition principles with differential evolution strategies for robust exploration and exploitation in optimizing photonic structures.", "configspace": "", "generation": 78, "fitness": 0.6224722379886102, "feedback": "The algorithm QDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.62 with standard deviation 0.03.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.6508343764571678, 0.5941100995200526]}, "mutation_prompt": null}
{"id": "7e6d4a89-edc8-4ba3-ba62-bc5e650e9148", "solution": "import numpy as np\n\nclass ADHS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 20\n        self.harmonies = []\n        self.best_solution = None\n        self.best_value = float('inf')\n\n    def initialize_harmony_memory(self, lb, ub):\n        return [lb + (ub - lb) * np.random.rand(self.dim) for _ in range(self.harmony_memory_size)]\n\n    def differential_mutation(self, harmony, target_index, lb, ub):\n        indices = list(range(self.harmony_memory_size))\n        indices.remove(target_index)\n        r1, r2, r3 = np.random.choice(indices, 3, replace=False)\n        \n        mutation_vector = self.harmonies[r1] + 0.9 * (self.harmonies[r2] - self.harmonies[r3])\n        mutation_vector = np.clip(mutation_vector, lb, ub)\n        \n        return mutation_vector\n\n    def harmony_search_strategy(self, new_harmony, lb, ub):\n        for i in range(self.dim):\n            if np.random.rand() < 0.01:  # Harmony consideration rate\n                random_index = np.random.randint(self.harmony_memory_size)\n                new_harmony[i] = self.harmonies[random_index][i]\n            elif np.random.rand() < 0.3:  # Pitch adjustment rate\n                new_harmony[i] += (ub[i] - lb[i]) * (np.random.rand() - 0.5) * 0.2\n        new_harmony = np.clip(new_harmony, lb, ub)\n        return new_harmony\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.harmonies = self.initialize_harmony_memory(lb, ub)\n        \n        while evaluations < self.budget:\n            for harmony_index in range(self.harmony_memory_size):\n                if evaluations >= self.budget:\n                    break\n                \n                new_harmony = self.differential_mutation(self.harmonies[harmony_index], harmony_index, lb, ub)\n                new_harmony = self.harmony_search_strategy(new_harmony, lb, ub)\n                \n                value = func(new_harmony)\n                evaluations += 1\n                \n                if value < self.best_value:\n                    self.best_value = value\n                    self.best_solution = new_harmony.copy()\n\n                if value < func(self.harmonies[harmony_index]):\n                    self.harmonies[harmony_index] = new_harmony\n\n        return self.best_solution, self.best_value", "name": "ADHS", "description": "Adaptive Differential Harmony Search (ADHS) combines differential mutation strategies with harmony search dynamics for efficient exploration and exploitation in photonic structure optimization.", "configspace": "", "generation": 79, "fitness": 0.781763466851691, "feedback": "The algorithm ADHS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.78 with standard deviation 0.02.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.8052001332970928, 0.7583268004062891]}, "mutation_prompt": null}
{"id": "5b0b4352-d992-4d77-8695-453f920d4932", "solution": "import numpy as np\n\nclass ESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 20\n        self.mutation_rate = 0.1\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            fitness = float('inf')\n            population.append({'position': position, 'fitness': fitness})\n        return population\n\n    def evaluate_population(self, func):\n        for individual in self.population:\n            individual['fitness'] = func(individual['position'])\n\n    def select_best(self):\n        best = min(self.population, key=lambda ind: ind['fitness'])\n        return best['position'].copy(), best['fitness']\n\n    def mutate(self, individual, lb, ub):\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            individual['position'] += mutation_vector\n            individual['position'] = np.clip(individual['position'], lb, ub)\n\n    def anneal(self, candidate, best, lb, ub):\n        candidate_energy = func(candidate)\n        best_energy = func(best)\n        if candidate_energy < best_energy or np.random.rand() < np.exp((best_energy - candidate_energy) / self.temperature):\n            return candidate, candidate_energy\n        return best, best_energy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            self.evaluate_population(func)\n            best_position, best_fitness = self.select_best()\n\n            new_population = []\n            for individual in self.population:\n                self.mutate(individual, lb, ub)\n\n                candidate, candidate_energy = self.anneal(individual['position'], best_position, lb, ub)\n                evaluations += 1\n\n                new_population.append({'position': candidate, 'fitness': candidate_energy})\n\n                if evaluations >= self.budget:\n                    break\n\n            self.population = new_population\n            self.temperature *= self.cooling_rate\n\n            if evaluations >= self.budget:\n                break\n\n        return best_position, best_fitness", "name": "ESA", "description": "A novel Evolutionary-based Simulated Annealing (ESA) algorithm that combines the global search capabilities of evolutionary operations with the local search finesse of simulated annealing to optimize photonic structures dynamically and effectively.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {}, "mutation_prompt": null}
{"id": "4d4794b5-d672-4ec0-ae3f-5072ad8360a1", "solution": "import numpy as np\n\nclass EnhancedQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n        self.inertia_weight = 0.9\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def randomized_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adaptive_swarm_size(self, evaluations):\n        # Reduce swarm size dynamically as evaluations progress\n        return max(5, int(self.swarm_size - ((self.swarm_size - 5) * (evaluations / self.budget))))\n\n    def adaptive_inertia(self, evaluations):\n        # Update inertia weight dynamically\n        return self.inertia_weight * (1 - evaluations / self.budget)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms[:self.adaptive_swarm_size(evaluations)]):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            inertia = self.adaptive_inertia(evaluations)\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.randomized_mutation(particle, lb, ub, evaluations / self.budget)\n                particle['velocity'] *= inertia\n\n        return global_best, global_best_value", "name": "EnhancedQPSO", "description": "Enhance Quantum-inspired Particle Swarm Optimization (QPSO) by integrating a dynamic swarm adaptation strategy and adaptive inertia weight to further boost global and local search balance for photonic structure optimization.", "configspace": "", "generation": 81, "fitness": 0.9422488345950368, "feedback": "The algorithm EnhancedQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9367079623303588, 0.9477897068597148]}, "mutation_prompt": null}
{"id": "6e84e498-70ea-494b-bb5c-7923a5d0a56a", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            swarm.append({'position': position, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, evaluation_ratio):\n        r1, r2 = np.random.rand(), np.random.rand()\n        theta = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        alpha = 0.5 + 0.5 * evaluation_ratio\n        adaptive_beta = (1 - evaluation_ratio) * r1 + evaluation_ratio * r2\n        mean_best = alpha * particle['best_position'] + (1 - alpha) * global_best\n        \n        particle['position'] = mean_best + adaptive_beta * np.abs(global_best - particle['position']) * np.tan(theta) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def dynamic_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1 * (1 - evaluation_ratio)\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            evaluation_ratio = evaluations / self.budget\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, evaluation_ratio)\n                self.dynamic_mutation(particle, lb, ub, evaluation_ratio)\n\n        return global_best, global_best_value", "name": "AQPSO", "description": "Introducing Adaptive Quantum Particle Swarm Optimization (AQPSO) that leverages adaptive learning factors and dynamic swarm topology for improved exploration and exploitation in optimizing photonic structures.", "configspace": "", "generation": 82, "fitness": 0.870921098712427, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.87 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.8796427926101684, 0.8621994048146856]}, "mutation_prompt": null}
{"id": "2558cd6d-6173-4500-8a70-223dd6dd8b11", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta, alpha):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * np.exp(-alpha * r1) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def chaotic_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            chaotic_sequence = (np.sin(evaluation_ratio * np.pi / 2) * 0.5 + 0.5)\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * chaotic_sequence * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            alpha = 4.0 * evaluations / self.budget  # Adaptive learning factor\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta, alpha)\n                self.chaotic_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "AQPSO", "description": "Introducing Adaptive Quantum Particle Swarm Optimization (AQPSO) which combines dynamically adjusted learning factors and chaotic mutation strategies for improved exploration and convergence in photonic structure optimization.", "configspace": "", "generation": 83, "fitness": 0.8978392858358104, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9056791995595734, 0.8899993721120473]}, "mutation_prompt": null}
{"id": "2a80e55d-def2-4fbc-ae26-98f6950b1565", "solution": "import numpy as np\n\nclass AQDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population = []\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': position, 'value': float('inf')})\n        return population\n\n    def differential_mutation(self, target_idx, lb, ub):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant_vector = self.population[a]['position'] + self.mutation_factor * (self.population[b]['position'] - self.population[c]['position'])\n        mutant_vector = np.clip(mutant_vector, lb, ub)\n        return mutant_vector\n\n    def crossover(self, target_vector, mutant_vector, lb, ub):\n        crossover_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, target_vector)\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        quantum_adjustment = crossover_vector + np.tan(phi) * direction * (ub - lb) * 0.1\n        quantum_adjustment = np.clip(quantum_adjustment, lb, ub)\n        return quantum_adjustment\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            for target_idx, target in enumerate(self.population):\n                mutant_vector = self.differential_mutation(target_idx, lb, ub)\n                trial_vector = self.crossover(target['position'], mutant_vector, lb, ub)\n\n                trial_value = func(trial_vector)\n                evaluations += 1\n\n                if trial_value < target['value']:\n                    target['position'], target['value'] = trial_vector, trial_value\n\n                if trial_value < self.best_value:\n                    self.best_solution, self.best_value = trial_vector.copy(), trial_value\n\n                if evaluations >= self.budget:\n                    break\n\n            self.mutation_factor = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n        return self.best_solution, self.best_value", "name": "AQDE", "description": "Introducing Adaptive Quantum Differential Evolution (AQDE), which synergizes quantum-inspired exploration with differential mutation strategies for robust convergence in high-dimensional photonic structure optimization.", "configspace": "", "generation": 84, "fitness": 0.6861839075966238, "feedback": "The algorithm AQDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.6957455246699924, 0.6766222905232553]}, "mutation_prompt": null}
{"id": "ba339191-c51a-45f4-9a5c-980c66dfcd02", "solution": "import numpy as np\n\nclass ADEQT:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': position, 'value': float('inf')})\n        return population\n\n    def mutate(self, target_idx, population, lb, ub):\n        indices = [i for i in range(self.population_size) if i != target_idx]\n        a, b, c = population[np.random.choice(indices)], population[np.random.choice(indices)], population[np.random.choice(indices)]\n        mutant = a['position'] + self.mutation_factor * (b['position'] - c['position'])\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        trial = np.where(crossover_mask, mutant, target['position'])\n        return trial\n\n    def quantum_tunneling(self, best_position, lb, ub):\n        shift = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.01\n        tunneled_position = best_position + shift\n        return np.clip(tunneled_position, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n        \n        while evaluations < self.budget:\n            for idx, target in enumerate(population):\n                mutant = self.mutate(idx, population, lb, ub)\n                trial = self.crossover(target, mutant)\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < target['value']:\n                    target['position'] = trial\n                    target['value'] = trial_value\n\n                if trial_value < self.best_value:\n                    self.best_value = trial_value\n                    self.best_solution = trial\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations < self.budget:\n                tunneled_position = self.quantum_tunneling(self.best_solution, lb, ub)\n                tunneled_value = func(tunneled_position)\n                evaluations += 1\n\n                if tunneled_value < self.best_value:\n                    self.best_value = tunneled_value\n                    self.best_solution = tunneled_position\n\n        return self.best_solution, self.best_value", "name": "ADEQT", "description": "Introducing Adaptive Differential Evolution with Quantum Tunneling (ADEQT), a novel approach combining differential evolution and quantum tunneling to maintain diversity and enhance search capabilities in photonic structure optimization.", "configspace": "", "generation": 85, "fitness": 0.922185305387802, "feedback": "The algorithm ADEQT got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.92 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9154168707004117, 0.9289537400751922]}, "mutation_prompt": null}
{"id": "b731113c-c26f-4734-b509-9e8476680f9d", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.initial_swarm_size = 20\n        self.swarms = []\n        self.dynamic_swarm_size = max(5, self.initial_swarm_size - dim // 5)\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.dynamic_swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adaptive_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.3 * (1 - evaluation_ratio):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.05\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.adaptive_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "AQPSO", "description": "Introducing Adaptive Quantum-inspired Particle Swarm Optimization (AQPSO), leveraging dynamic swarm size and adaptive evaluation strategy for improved photonic structure optimization.", "configspace": "", "generation": 86, "fitness": 0.9471822452446652, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95 with standard deviation 0.01.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9362505258901802, 0.9581139645991503]}, "mutation_prompt": null}
{"id": "63669834-e869-4ef4-b90b-ef64f248f1b5", "solution": "import numpy as np\n\nclass EnhancedQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta, alpha):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n        particle['velocity'] = alpha * particle['velocity'] + r2 * (particle['best_position'] - particle['position'])\n\n    def randomized_mutation(self, particle, lb, ub, diversity_factor):\n        if np.random.rand() < 0.5 * diversity_factor:\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            alpha = np.random.uniform(0.5, 0.9)  # Adaptive learning coefficient\n            diversity_factor = np.std([p['position'] for p in self.swarms]) / (ub - lb)\n            \n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta, alpha)\n                self.randomized_mutation(particle, lb, ub, diversity_factor)\n\n        return global_best, global_best_value", "name": "EnhancedQPSO", "description": "Enhance Quantum-inspired Particle Swarm Optimization (QPSO) with adaptive learning coefficients and dynamic diversity control for improved exploration and exploitation balance in photonic structure optimization.", "configspace": "", "generation": 87, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {}, "mutation_prompt": null}
{"id": "f5f93651-8b42-4cf9-9519-af3057fff051", "solution": "import numpy as np\n\nclass EQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta, alpha):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] += alpha * (r2 - 0.5) * np.abs(particle['velocity'])\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def randomized_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            alpha = evaluations / self.budget\n            for particle in self.swarms:\n                self.update_particle(particle, global_best, lb, ub, beta, alpha)\n                self.randomized_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "EQPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization (EQPSO) introduces adaptive dimensional learning and dynamic parameter control to improve convergence efficiency and solution quality in photonic structure optimization.", "configspace": "", "generation": 88, "fitness": 0.9128074957806296, "feedback": "The algorithm EQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.00.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9122830644274617, 0.9133319271337974]}, "mutation_prompt": null}
{"id": "119f53da-3815-4144-850c-e8d94e75617c", "solution": "import numpy as np\n\nclass EQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            swarm.append({\n                'position': position,\n                'best_position': position,\n                'best_value': float('inf')\n            })\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta, gamma):\n        r1 = np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n\n        adaptive_step = (1 + gamma * np.random.rand()) * np.abs(global_best - particle['position'])\n        particle['position'] = mean_best + beta * (r1 - 0.5) * adaptive_step * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def randomized_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio**2):\n            mutation_strength = 0.1 * (1 - evaluation_ratio)\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * mutation_strength\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle in self.swarms:\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            gamma = 0.5 * (1 - evaluations / self.budget)\n            for particle in self.swarms:\n                self.update_particle(particle, global_best, lb, ub, beta, gamma)\n                self.randomized_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "EQPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization (EQPSO) incorporates dynamic adaptive strategies for position updates and mutation, further improving the exploration and exploitation balance in photonic structure optimization.", "configspace": "", "generation": 89, "fitness": 0.9368218845497509, "feedback": "The algorithm EQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94 with standard deviation 0.00.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9387182359838673, 0.9349255331156345]}, "mutation_prompt": null}
{"id": "de6ed71a-4ef8-42ae-b1bd-a1c178b6ba85", "solution": "import numpy as np\n\nclass EQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.initial_swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.initial_swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def randomized_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adaptive_swarm_size(self, evaluations):\n        return max(5, int(self.initial_swarm_size * (1 - evaluations / self.budget) + 5))\n\n    def dynamic_beta_scaling(self, evaluations):\n        return 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index in range(len(self.swarms)):\n                particle = self.swarms[particle_index]\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            swarm_size = self.adaptive_swarm_size(evaluations)\n            if len(self.swarms) > swarm_size:\n                self.swarms = self.swarms[:swarm_size]\n\n            beta = self.dynamic_beta_scaling(evaluations)\n            for particle_index in range(len(self.swarms)):\n                particle = self.swarms[particle_index]\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.randomized_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "EQPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization (EQPSO) with adaptive swarm size and dynamic beta scaling to improve convergence in photonic structure optimization.", "configspace": "", "generation": 90, "fitness": 0.9324084607617876, "feedback": "The algorithm EQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.00.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9279404765510801, 0.9368764449724951]}, "mutation_prompt": null}
{"id": "ae19bdd5-3393-47cb-bb56-b52c0e34732a", "solution": "import numpy as np\n\nclass HGDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.crossover_rate = 0.7\n        self.mutation_factor = 0.5\n\n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def select_parents(self, population):\n        return population[np.random.choice(self.population_size, 3, replace=False)]\n\n    def mutation(self, target, donors, lb, ub):\n        mutant = donors[0] + self.mutation_factor * (donors[1] - donors[2])\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        return np.where(crossover_mask, mutant, target)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_value = float('inf')\n\n        while evaluations < self.budget:\n            new_population = np.empty_like(population)\n            for i in range(self.population_size):\n                target = population[i]\n                donors = self.select_parents(population)\n                mutant = self.mutation(target, donors, lb, ub)\n                trial = self.crossover(target, mutant)\n                \n                trial_value = func(trial)\n                evaluations += 1\n                \n                if trial_value < func(target):\n                    new_population[i] = trial\n                else:\n                    new_population[i] = target\n\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial.copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            population = new_population\n\n        return best_solution, best_value", "name": "HGDE", "description": "Introducing a Hybrid Genetic Differential Evolution (HGDE) algorithm that combines genetic recombination and differential mutation strategies to enhance exploration and exploitation in photonic structure optimization.", "configspace": "", "generation": 91, "fitness": 0.8109633812056599, "feedback": "The algorithm HGDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81 with standard deviation 0.03.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.837987125669136, 0.7839396367421838]}, "mutation_prompt": null}
{"id": "7f8d2877-51e8-46dd-81d4-7dd34399befc", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta, alpha):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        adaptive_beta = beta + alpha * np.random.rand(self.dim)\n        particle['position'] = mean_best + adaptive_beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adaptive_mutation(self, particle, lb, ub, evaluation_ratio):\n        mutation_prob = 0.5 * (1 - evaluation_ratio)\n        if np.random.rand() < mutation_prob:\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1 * (1 - evaluation_ratio)\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        alpha = 0.1  # Adaptive scaling factor\n\n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta, alpha)\n                self.adaptive_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "AQPSO", "description": "Introducing Adaptive Quantum Particle Swarm Optimization (AQPSO) that integrates dynamic learning and adaptive quantum boundaries to enhance search diversity and convergence in photonic structure optimization.", "configspace": "", "generation": 92, "fitness": 0.9292058888948325, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.02.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9107342040591131, 0.9476775737305517]}, "mutation_prompt": null}
{"id": "403a0d18-6b29-4ffe-9835-db01fbffad52", "solution": "import numpy as np\n\nclass EQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 20\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            velocity = np.random.rand(self.dim) * (ub - lb) * 0.1\n            swarm.append({'position': position, 'velocity': velocity, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1, r2 = np.random.rand(), np.random.rand()\n        mean_best = (particle['best_position'] + global_best) / 2\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n\n        particle['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - particle['position']) * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def cooperative_learning(self, particle, neighbors):\n        neighbor_best = min(neighbors, key=lambda p: p['best_value'])['best_position']\n        particle['position'] = (particle['position'] + neighbor_best) / 2\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def selective_memory_decay(self, particle, decay_factor):\n        decay = np.exp(-decay_factor * np.random.rand())\n        particle['best_value'] *= decay\n        particle['best_position'] *= decay\n\n    def randomized_mutation(self, particle, lb, ub, evaluation_ratio):\n        if np.random.rand() < 0.5 * (1 - evaluation_ratio):\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            decay_factor = evaluations / self.budget\n            for particle_index, particle in enumerate(self.swarms):\n                neighbors = [self.swarms[(particle_index + i) % self.swarm_size] for i in range(-1, 2)]\n                self.cooperative_learning(particle, neighbors)\n                self.selective_memory_decay(particle, decay_factor)\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.randomized_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "EQPSO", "description": "Enhanced Quantum-inspired Particle Swarm Optimization (EQPSO) integrates cooperative learning and selective memory decay to boost exploration and convergence in photonic structure optimization.", "configspace": "", "generation": 93, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'lb' is not defined\").", "error": "NameError(\"name 'lb' is not defined\")", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {}, "mutation_prompt": null}
{"id": "7972255b-0188-4836-8e2e-ce44082693bb", "solution": "import numpy as np\n\nclass HQGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        population = []\n        for _ in range(self.population_size):\n            individual = lb + (ub - lb) * np.random.rand(self.dim)\n            population.append({'position': individual, 'best_position': individual, 'best_value': float('inf')})\n        return population\n\n    def quantum_update(self, individual, global_best, lb, ub, beta):\n        r1 = np.random.rand(self.dim)\n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        \n        mean_best = (individual['best_position'] + global_best) / 2\n        individual['position'] = mean_best + beta * (r1 - 0.5) * np.abs(global_best - individual['position']) * np.tan(phi) * direction\n        individual['position'] = np.clip(individual['position'], lb, ub)\n\n    def genetic_crossover_and_mutation(self, parent1, parent2, lb, ub):\n        crossover_point = np.random.randint(0, self.dim)\n        child = np.concatenate((parent1['position'][:crossover_point], parent2['position'][crossover_point:]))\n        \n        # Mutate with small probability\n        if np.random.rand() < 0.1:\n            mutation_vector = (ub - lb) * (np.random.rand(self.dim) - 0.5) * 0.1\n            child += mutation_vector\n        \n        return np.clip(child, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            # Evaluate fitness and update bests\n            for individual in self.population:\n                value = func(individual['position'])\n                evaluations += 1\n                \n                if value < individual['best_value']:\n                    individual['best_value'] = value\n                    individual['best_position'] = individual['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = individual['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n\n            # Update individuals with quantum-inspired approach\n            for individual in self.population:\n                self.quantum_update(individual, global_best, lb, ub, beta)\n\n            # Apply genetic operations\n            new_population = []\n            for _ in range(self.population_size // 2):\n                parent1, parent2 = np.random.choice(self.population, 2, replace=False)\n                child1_position = self.genetic_crossover_and_mutation(parent1, parent2, lb, ub)\n                new_population.append({'position': child1_position, 'best_position': child1_position, 'best_value': float('inf')})\n                \n                child2_position = self.genetic_crossover_and_mutation(parent2, parent1, lb, ub)\n                new_population.append({'position': child2_position, 'best_position': child2_position, 'best_value': float('inf')})\n            \n            self.population = new_population\n\n        return global_best, global_best_value", "name": "HQGA", "description": "Hybrid Quantum-Inspired Genetic Algorithm (HQGA) combines genetic crossover and mutation with quantum-inspired particle updates for robust global optimization in photonic designs.", "configspace": "", "generation": 94, "fitness": 0.8832032383280888, "feedback": "The algorithm HQGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88 with standard deviation 0.02.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.899953458777389, 0.8664530178787886]}, "mutation_prompt": null}
{"id": "7216a43f-bbc2-46ac-9eb4-2feaf8d31057", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.swarm_size = 25  # Increased swarm size for diversified exploration\n        self.swarms = []\n\n    def initialize_swarm(self, lb, ub):\n        swarm = []\n        for _ in range(self.swarm_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            swarm.append({'position': position, 'best_position': position, 'best_value': float('inf')})\n        return swarm\n\n    def update_particle(self, particle, global_best, lb, ub, beta):\n        r1 = np.random.rand(self.dim)\n        direction = np.sign(np.random.rand(self.dim) - 0.5)\n        mean_best = (particle['best_position'] + global_best) / 2\n        \n        phi = np.arccos(1 - 2 * np.random.rand(self.dim))\n        adaptive_factor = np.exp(-beta * np.abs(global_best - particle['position']))\n        particle['position'] = mean_best + beta * adaptive_factor * np.tan(phi) * direction\n        particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def adaptive_mutation(self, particle, lb, ub, evaluation_ratio):\n        mutation_probability = 0.5 * (1 - evaluation_ratio)\n        if np.random.rand() < mutation_probability:\n            mutation_vector = (ub - lb) * (2 * np.random.rand(self.dim) - 1) * (0.1 * (1 - evaluation_ratio))\n            particle['position'] += mutation_vector\n            particle['position'] = np.clip(particle['position'], lb, ub)\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.swarms = self.initialize_swarm(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        \n        while evaluations < self.budget:\n            for particle_index, particle in enumerate(self.swarms):\n                value = func(particle['position'])\n                evaluations += 1\n                \n                if value < particle['best_value']:\n                    particle['best_value'] = value\n                    particle['best_position'] = particle['position'].copy()\n                \n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = particle['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            beta = 1.0 - evaluations / self.budget\n            for particle_index, particle in enumerate(self.swarms):\n                self.update_particle(particle, global_best, lb, ub, beta)\n                self.adaptive_mutation(particle, lb, ub, evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "AQPSO", "description": "Introducing Adaptive Quantum-inspired Particle Swarm Optimization (AQPSO) that utilizes dynamic swarm adaptation and enhanced mutation strategies to improve search efficiency in photonic structure optimization.", "configspace": "", "generation": 95, "fitness": 0.6784705183595532, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.03.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.7121209792208145, 0.6448200574982919]}, "mutation_prompt": null}
{"id": "0f6cf502-189b-4ba4-a938-e4332c2b5cfa", "solution": "import numpy as np\n\nclass EHS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 25\n        self.harmony_memory = []\n        self.hmcr = 0.9  # Harmony Memory Consideration Rate\n        self.par = 0.3   # Pitch Adjustment Rate\n        self.freq_range = 0.1\n\n    def initialize_harmony_memory(self, lb, ub):\n        for _ in range(self.harmony_memory_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = float('inf')\n            self.harmony_memory.append({'position': position, 'value': value})\n\n    def update_harmony_memory(self, candidate):\n        worst_harmony = max(self.harmony_memory, key=lambda x: x['value'])\n        if candidate['value'] < worst_harmony['value']:\n            self.harmony_memory.remove(worst_harmony)\n            self.harmony_memory.append(candidate)\n\n    def generate_new_harmony(self, lb, ub):\n        new_harmony = np.zeros(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < self.hmcr:\n                selected_harmony = self.harmony_memory[np.random.randint(self.harmony_memory_size)]\n                new_harmony[i] = selected_harmony['position'][i]\n                if np.random.rand() < self.par:\n                    new_harmony[i] += self.freq_range * (np.random.rand() - 0.5)\n            else:\n                new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n        new_harmony = np.clip(new_harmony, lb, ub)\n        return new_harmony\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.initialize_harmony_memory(lb, ub)\n\n        while evaluations < self.budget:\n            new_position = self.generate_new_harmony(lb, ub)\n            new_value = func(new_position)\n            evaluations += 1\n\n            candidate = {'position': new_position, 'value': new_value}\n            self.update_harmony_memory(candidate)\n\n            if evaluations >= self.budget:\n                break\n\n        best_harmony = min(self.harmony_memory, key=lambda x: x['value'])\n        return best_harmony['position'], best_harmony['value']", "name": "EHS", "description": "Enhanced Harmony Search (EHS) integrates dynamic pitch adjustment and adaptive memory consideration for effective exploration and exploitation in photonic structure optimization.", "configspace": "", "generation": 96, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {}, "mutation_prompt": null}
{"id": "41dee0ed-6432-46ab-9d20-3c979214e9cd", "solution": "import numpy as np\n\nclass ADE_QT:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.population_size = 20\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = []\n\n    def initialize_population(self, lb, ub):\n        return [lb + (ub - lb) * np.random.rand(self.dim) for _ in range(self.population_size)]\n\n    def mutate(self, target_idx, lb, ub):\n        indices = np.arange(self.population_size)\n        indices = np.delete(indices, target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def quantum_tunneling(self, individual, lb, ub):\n        tunneling_prob = 0.1\n        if np.random.rand() < tunneling_prob:\n            delta = np.random.standard_normal(self.dim) * (ub - lb) * 0.1\n            individual += delta\n            individual = np.clip(individual, lb, ub)\n        return individual\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.population = self.initialize_population(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, lb, ub)\n                trial = self.crossover(target, mutant)\n                trial = self.quantum_tunneling(trial, lb, ub)\n                \n                value = func(trial)\n                evaluations += 1\n                \n                if value < func(target):\n                    self.population[i] = trial\n\n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = trial.copy()\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "ADE_QT", "description": "Introducing Adaptive Differential Evolution with Quantum Tunneling (ADE-QT) which leverages adaptive differential evolution and quantum tunneling effects to efficiently traverse complex landscapes in photonic structure optimization.", "configspace": "", "generation": 97, "fitness": 0.8737384847254879, "feedback": "The algorithm ADE_QT got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.87 with standard deviation 0.03.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.9015770913155101, 0.8458998781354655]}, "mutation_prompt": null}
{"id": "4d143e42-e937-4143-adf7-24a37337e6ab", "solution": "import numpy as np\n\nclass TDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.8\n        self.crossover_rate = 0.9\n        self.best_solution = None\n        self.best_value = float('inf')\n\n    def initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def mutate(self, population, best_idx):\n        mutants = np.zeros_like(population)\n        for i in range(self.population_size):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = np.random.choice(indices, 3, replace=False)\n\n            if np.random.rand() < 0.5:\n                best_vector = population[best_idx]\n            else:\n                best_vector = population[a]\n\n            mutants[i] = population[a] + self.scaling_factor * (population[b] - population[c])\n            mutants[i] += 0.5 * (self.best_solution - best_vector)\n        return mutants\n\n    def crossover(self, target, mutant):\n        trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = self.initialize_population(lb, ub)\n        evaluations = 0\n\n        while evaluations < self.budget:\n            values = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            best_idx = np.argmin(values)\n            if values[best_idx] < self.best_value:\n                self.best_value = values[best_idx]\n                self.best_solution = population[best_idx].copy()\n\n            mutants = self.mutate(population, best_idx)\n            mutants = np.clip(mutants, lb, ub)\n\n            new_population = []\n            for i in range(self.population_size):\n                trial = self.crossover(population[i], mutants[i])\n                trial_value = func(trial)\n                evaluations += 1\n                if trial_value < values[i]:\n                    new_population.append(trial)\n                    if trial_value < self.best_value:\n                        self.best_value = trial_value\n                        self.best_solution = trial.copy()\n                else:\n                    new_population.append(population[i])\n\n                if evaluations >= self.budget:\n                    break\n\n            population = np.array(new_population)\n        \n        return self.best_solution, self.best_value", "name": "TDE", "description": "Introducing Tunneling Differential Evolution (TDE) that employs a unique tunneling mechanism to escape local optima by dynamically adjusting search space exploration, enhancing robustness in photonic structure optimization.", "configspace": "", "generation": 98, "fitness": 0.7207295591489769, "feedback": "The algorithm TDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.03.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.7517994299548698, 0.689659688343084]}, "mutation_prompt": null}
{"id": "e1105634-835b-45a1-8f13-ed2a0e1c8ee5", "solution": "import numpy as np\n\nclass QIHS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.best_solution = None\n        self.best_value = float('inf')\n        self.harmony_size = 20\n        self.harmonies = []\n\n    def initialize_harmony_memory(self, lb, ub):\n        harmony_memory = []\n        for _ in range(self.harmony_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            harmony_memory.append({'position': position, 'value': float('inf')})\n        return harmony_memory\n\n    def update_harmony(self, harmony, global_best, lb, ub, harmony_consideration_rate, pitch_adjustment_rate):\n        new_position = harmony['position'].copy()\n        for i in range(self.dim):\n            if np.random.rand() < harmony_consideration_rate:\n                new_position[i] = np.random.choice([h['position'][i] for h in self.harmonies])\n                if np.random.rand() < pitch_adjustment_rate:\n                    phi = np.arccos(1 - 2 * np.random.rand())\n                    direction = np.sign(np.random.rand() - 0.5)\n                    new_position[i] += direction * np.tan(phi) * (global_best[i] - new_position[i])\n            else:\n                new_position[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n        new_position = np.clip(new_position, lb, ub)\n        harmony['position'] = new_position\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        evaluations = 0\n        self.harmonies = self.initialize_harmony_memory(lb, ub)\n        global_best = None\n        global_best_value = float('inf')\n        harmony_consideration_rate = 0.9\n        pitch_adjustment_rate = 0.3\n\n        while evaluations < self.budget:\n            for harmony in self.harmonies:\n                value = func(harmony['position'])\n                evaluations += 1\n\n                if value < harmony['value']:\n                    harmony['value'] = value\n\n                if value < global_best_value:\n                    global_best_value = value\n                    global_best = harmony['position'].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n            for harmony in self.harmonies:\n                self.update_harmony(harmony, global_best, lb, ub, harmony_consideration_rate, pitch_adjustment_rate)\n\n        return global_best, global_best_value", "name": "QIHS", "description": "Introducing Quantum-Inspired Harmony Search (QIHS) that innovatively combines quantum-inspired principles with harmony memory to enhance global exploration and convergence in photonic structure optimization.", "configspace": "", "generation": 99, "fitness": 0.6530212410584765, "feedback": "The algorithm QIHS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.03.", "error": "", "parent_id": "a745b223-22e8-4f66-8b89-75f519621274", "metadata": {"aucs": [0.6856042569536493, 0.6204382251633036]}, "mutation_prompt": null}

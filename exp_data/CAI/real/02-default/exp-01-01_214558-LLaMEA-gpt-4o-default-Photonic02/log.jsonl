{"id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "solution": "import numpy as np\n\nclass MAPE:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        # Initialize multiple swarms\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                # Evolutionary operations (mutation and crossover)\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n                \n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        # Simple mutation and crossover for diversity\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:  # Mutation rate\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:  # Crossover rate\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())", "name": "MAPE", "description": "Multi-Swarm Adaptive Particle Evolution (MAPE): An adaptive strategy combining multiple interacting particle swarms with evolutionary operators to efficiently explore and exploit complex search spaces.", "configspace": "", "generation": 0, "fitness": 0.8888409562203587, "feedback": "The algorithm MAPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.02.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9053701410118316, 0.8723117714288859]}, "mutation_prompt": null}
{"id": "ddf180c2-1558-4f72-99f0-4fe6168b974c", "solution": "import numpy as np\n\nclass QMAPE:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        diversity_control = 0.1\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    \n                    # Quantum-inspired position update\n                    quantum_position = position + np.random.uniform(-diversity_control, diversity_control, self.dim) * (ub - lb)\n                    position = np.clip(quantum_position, lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub, diversity_control)\n                \n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub, diversity_control):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * diversity_control * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n        # Adaptive diversity control based on evaluation progress\n        diversity_control = max(0.01, diversity_control * 0.99)", "name": "QMAPE", "description": "Hybrid Quantum-Inspired Multi-Swarm Adaptive Particle Evolution (Q-MAPE): Introduces quantum-inspired dynamics and adaptive diversity control to enhance exploration and convergence efficiency in complex optimization landscapes.", "configspace": "", "generation": 1, "fitness": 0.5809803017155596, "feedback": "The algorithm QMAPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.58 with standard deviation 0.01.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.5667254628721368, 0.5952351405589824]}, "mutation_prompt": null}
{"id": "0be05f87-9fda-487a-b5a9-de899d927acb", "solution": "import numpy as np\n\nclass QIES:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, quantum_prob=0.1, mutation_rate=0.1, crossover_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.quantum_prob = quantum_prob\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        # Initialize multiple swarms\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                if np.random.rand() < self.quantum_prob:\n                    self.quantum_inspired_update(swarms[swarm_id], lb, ub)\n                \n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                # Evolutionary operations (mutation and crossover)\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def quantum_inspired_update(self, swarm, lb, ub):\n        # Simulate quantum superposition and entanglement\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.5:\n                new_position = (np.random.rand(self.dim) > 0.5) * lb + (np.random.rand(self.dim) <= 0.5) * ub\n                swarm[i] = np.clip(new_position, lb, ub)\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < self.mutation_rate:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n        for i in range(0, self.swarm_size, 2):\n            if i + 1 < self.swarm_size and np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())", "name": "QIES", "description": "Quantum-Inspired Evolutionary Swarm (QIES): Integrates quantum-inspired superposition and entanglement principles with evolutionary strategies to enhance exploration and exploitation in high-dimensional spaces.", "configspace": "", "generation": 2, "fitness": 0.6184810691175495, "feedback": "The algorithm QIES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.62 with standard deviation 0.02.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.6019102610206475, 0.6350518772144516]}, "mutation_prompt": null}
{"id": "5617e6a7-d6cc-4b98-a183-30efac06af75", "solution": "import numpy as np\n\nclass DAPE:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia_min=0.4, inertia_max=0.9, cognitive=2, social=2):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_min = inertia_min\n        self.inertia_max = inertia_max\n        self.cognitive = cognitive\n        self.social = social\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        # Initialize multiple swarms\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            inertia = self.dynamic_inertia()\n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    velocities[swarm_id][i] = (inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                # Enhanced evolutionary operations with dynamic mutation rates\n                self.evolve_swarm(swarms[swarm_id], lb, ub, self.dynamic_mutation())\n                \n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub, mutation_rate):\n        for i in range(self.swarm_size):\n            if np.random.rand() < mutation_rate:  # Dynamic mutation rate\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:  # Crossover rate\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def dynamic_inertia(self):\n        proportion_evaluations = self.evaluations / self.budget\n        return self.inertia_max - (self.inertia_max - self.inertia_min) * proportion_evaluations\n\n    def dynamic_mutation(self):\n        proportion_evaluations = self.evaluations / self.budget\n        return 0.1 + 0.2 * (1 - proportion_evaluations)", "name": "DAPE", "description": "Dynamic Adaptive Particle Evolution (DAPE): An enhanced adaptive strategy using dynamic inertia and mutation rates to adaptively balance exploration and exploitation for improved convergence in complex search spaces.", "configspace": "", "generation": 3, "fitness": 0.7141652730194779, "feedback": "The algorithm DAPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.02.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.7347550346068724, 0.6935755114320833]}, "mutation_prompt": null}
{"id": "2f86abde-39d0-4b16-9430-9b673c6a2183", "solution": "import numpy as np\n\nclass QIDS:\n    def __init__(self, budget, dim, num_positions=10, alpha=0.9, beta=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.num_positions = num_positions\n        self.alpha = alpha\n        self.beta = beta\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n\n        # Initialize positions in a quantum-inspired superposition state\n        positions = np.random.uniform(lb, ub, (self.num_positions, self.dim))\n        amplitudes = np.random.rand(self.num_positions, self.dim)\n\n        while self.evaluations < self.budget:\n            for i in range(self.num_positions):\n                # Collapse quantum state to a real position using the amplitudes\n                position = np.where(np.random.rand(self.dim) < amplitudes[i], positions[i], \n                                    np.random.uniform(lb, ub, self.dim))\n                position = np.clip(position, lb, ub)\n                value = func(position)\n                self.evaluations += 1\n\n                if value < best_value:\n                    best_value = value\n                    best_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Dynamic sampling based on best-known position\n            for i in range(self.num_positions):\n                if np.random.rand() < self.alpha:\n                    positions[i] = best_position + self.beta * (positions[i] - best_position)\n                    positions[i] = np.clip(positions[i], lb, ub)\n                amplitudes[i] = np.clip(amplitudes[i] + np.random.uniform(-0.1, 0.1, self.dim), 0, 1)\n\n        return best_position", "name": "QIDS", "description": "Quantum-Inspired Dynamic Sampling (QIDS): Combines quantum-inspired superposition states with dynamic sampling strategies for enhanced exploration and exploitation in high-dimensional spaces.", "configspace": "", "generation": 4, "fitness": 0.7425856713121282, "feedback": "The algorithm QIDS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.02.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.7257328667184386, 0.7594384759058177]}, "mutation_prompt": null}
{"id": "f0bff4e0-c174-42c5-bfdc-5ca1b9efa586", "solution": "import numpy as np\n\nclass QIDE:\n    def __init__(self, budget, dim, population_size=30, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        # Quantum-inspired population initialization\n        population = self.initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            new_population = []\n            \n            for idx in range(self.population_size):\n                # Differential Evolution's mutation and crossover\n                a, b, c = self.select_random_indices(idx)\n                mutant = self.mutate(population[a], population[b], population[c], lb, ub)\n                trial = self.crossover(population[idx], mutant)\n                \n                # Quantum-inspired observation\n                trial_observed = self.observe(trial, lb, ub)\n                \n                # Evaluate trial solution\n                trial_value = func(trial_observed)\n                self.evaluations += 1\n                \n                # Selection\n                if trial_value < best_global_value:\n                    best_global_value = trial_value\n                    best_global_position = trial_observed\n                    \n                if trial_value < func(population[idx]):\n                    new_population.append(trial)\n                else:\n                    new_population.append(population[idx])\n                \n                if self.evaluations >= self.budget:\n                    break\n                \n            population = new_population\n            \n        return best_global_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def select_random_indices(self, exclude_idx):\n        indices = list(range(self.population_size))\n        indices.remove(exclude_idx)\n        selected = np.random.choice(indices, 3, replace=False)\n        return selected\n\n    def mutate(self, a, b, c, lb, ub):\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        trial = np.copy(target)\n        cross_points = np.random.rand(self.dim) < self.CR\n        trial[cross_points] = mutant[cross_points]\n        return trial\n\n    def observe(self, state, lb, ub):\n        # Simulate quantum observation by adding small random perturbations\n        perturbation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n        observed = np.clip(state + perturbation, lb, ub)\n        return observed", "name": "QIDE", "description": "Quantum-Inspired Differential Evolution (QIDE): A hybrid approach combining quantum-inspired representation with differential evolution to enhance exploration and exploitation in complex search spaces.", "configspace": "", "generation": 5, "fitness": 0.7451984339335671, "feedback": "The algorithm QIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.01.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.7518428406533906, 0.7385540272137435]}, "mutation_prompt": null}
{"id": "86d82d44-d979-49bf-8583-a607e097a973", "solution": "import numpy as np\n\nclass MAPE_DIAE:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia_max=0.9, inertia_min=0.4, cognitive=2, social=2):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_max = inertia_max\n        self.inertia_min = inertia_min\n        self.cognitive = cognitive\n        self.social = social\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            inertia_weight = self.inertia_max - (self.inertia_max - self.inertia_min) * (self.evaluations / self.budget)\n            \n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    velocities[swarm_id][i] = (inertia_weight * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.adaptive_evolve_swarm(swarms[swarm_id], lb, ub, best_global_value)\n                \n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def adaptive_evolve_swarm(self, swarm, lb, ub, best_value):\n        mutation_rate = 0.1 * (1 - (best_value / (1 + best_value)))\n        crossover_rate = 0.2 * (1 + (best_value / (1 + best_value)))\n\n        for i in range(self.swarm_size):\n            if np.random.rand() < mutation_rate:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())", "name": "MAPE_DIAE", "description": "Enhanced MAPE with Dynamic Inertia and Adaptive Evolution (MAPE-DIAE): Introduces dynamic inertia weights and adaptive evolutionary strategies to improve exploration-exploitation balance and convergence speed.", "configspace": "", "generation": 6, "fitness": 0.7459147913888754, "feedback": "The algorithm MAPE_DIAE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.00.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.7462981112034313, 0.7455314715743195]}, "mutation_prompt": null}
{"id": "5eee6138-3088-495d-a5d2-c2588728f2bc", "solution": "import numpy as np\n\nclass QMSPE:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, alpha=0.75, beta=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.alpha = alpha\n        self.beta = beta\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        p_best_positions = [np.copy(swarm) for swarm in swarms]\n        p_best_values = [np.full(self.swarm_size, float('inf')) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = self.q_update_position(swarms[swarm_id][i], best_global_position, lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < p_best_values[swarm_id][i]:\n                        p_best_values[swarm_id][i] = value\n                        p_best_positions[swarm_id][i] = position\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], p_best_positions[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def q_update_position(self, position, best_global_position, lb, ub):\n        if best_global_position is None:\n            return position\n        mean = self.alpha * position + (1 - self.alpha) * best_global_position\n        levy_step = self.beta * (np.random.rand(self.dim) - 0.5) * (ub - lb)\n        new_position = mean + levy_step\n        return np.clip(new_position, lb, ub)\n\n    def evolve_swarm(self, swarm, p_best_positions, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())", "name": "QMSPE", "description": "Quantum-inspired Multi-Swarm Particle Evolution (QMSPE): Combining quantum-behaved particles with adaptive multi-swarm dynamics to efficiently navigate complex search landscapes.", "configspace": "", "generation": 7, "fitness": 0.6604896442540908, "feedback": "The algorithm QMSPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.02.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.678080905583234, 0.6428983829249476]}, "mutation_prompt": null}
{"id": "502e4df5-3013-4d14-b8dd-80cc0e856b5c", "solution": "import numpy as np\n\nclass QIEO:\n    def __init__(self, budget, dim, population_size=20, alpha=0.001, beta=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.alpha = alpha\n        self.beta = beta\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n\n        # Initialize population and quantum states\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        quantum_states = np.random.uniform(0, 1, (self.population_size, self.dim))\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Quantum-inspired position update\n                theta = np.arccos(2 * quantum_states[i] - 1)\n                delta = self.alpha * (best_position - population[i]) if best_position is not None else 0\n\n                new_position = population[i] + self.beta * np.sin(theta) + delta\n                new_position = np.clip(new_position, lb, ub)\n\n                value = func(new_position)\n                self.evaluations += 1\n\n                if value < best_value:\n                    best_value = value\n                    best_position = new_position\n\n                population[i] = new_position\n                quantum_states[i] = np.random.uniform(0, 1, self.dim)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_position", "name": "QIEO", "description": "Quantum-Inspired Evolutionary Optimization (QIEO): A novel optimization algorithm leveraging quantum superposition principles for enhanced exploration and exploitation in complex search spaces.", "configspace": "", "generation": 8, "fitness": 0.5862548348590901, "feedback": "The algorithm QIEO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.59 with standard deviation 0.14.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.7214605438034569, 0.45104912591472346]}, "mutation_prompt": null}
{"id": "83da2bde-04c2-4437-b606-f4cf2a6a3681", "solution": "import numpy as np\n\nclass D_MAPE:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        # Initialize multiple swarms\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        local_best_positions = [swarm.copy() for swarm in swarms]\n        local_best_values = [np.full(self.swarm_size, float('inf')) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (local_best_positions[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < local_best_values[swarm_id][i]:\n                        local_best_values[swarm_id][i] = value\n                        local_best_positions[swarm_id][i] = position\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                # Adapt swarm parameters based on performance\n                self.adapt_parameters(swarm_id, local_best_values[swarm_id], swarms[swarm_id])\n\n                # Cross-interaction among swarms for diversity\n                self.interact_swarms(swarms, velocities, lb, ub)\n\n                # Evolutionary operations (mutation and crossover)\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n                \n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def adapt_parameters(self, swarm_id, local_best_values, swarm):\n        # Dynamic adjustment based on standard deviation of fitness values\n        fitness_std = np.std(local_best_values)\n        if fitness_std < 0.1:\n            self.inertia = max(0.3, self.inertia - 0.1)\n            self.social += 0.1\n        else:\n            self.inertia = min(0.9, self.inertia + 0.1)\n            self.cognitive += 0.1\n\n    def interact_swarms(self, swarms, velocities, lb, ub):\n        if np.random.rand() < 0.1:\n            for swarm_id in range(self.num_swarms):\n                partner_swarm_id = np.random.choice([i for i in range(self.num_swarms) if i != swarm_id])\n                partner_idx = np.random.randint(self.swarm_size)\n                for i in range(self.swarm_size):\n                    interaction = 0.1 * (swarms[partner_swarm_id][partner_idx] - swarms[swarm_id][i])\n                    velocities[swarm_id][i] += interaction\n\n    def evolve_swarm(self, swarm, lb, ub):\n        # Simple mutation and crossover for diversity\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:  # Mutation rate\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:  # Crossover rate\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())", "name": "D_MAPE", "description": "Dynamic Multi-Swarm Adaptive Particle Evolution (D-MAPE): Introduces a dynamic interaction framework among swarms with an adaptive parameter tuning based on swarm performance indicators to enhance exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.7499946514372601, "feedback": "The algorithm D_MAPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.01.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.759750173507091, 0.7402391293674292]}, "mutation_prompt": null}
{"id": "8568d414-ccf0-44be-90b7-37bdf14c4860", "solution": "import numpy as np\n\nclass QIGPO:\n    def __init__(self, budget, dim, num_particles=30, alpha=0.5, mutation_rate=0.1, crossover_rate=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.alpha = alpha\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        # Initialize particle positions using quantum-inspired approach\n        particles = self.initialize_particles(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update particle velocity and position\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + r1 * (best_global_position - particles[i] if best_global_position is not None else 0) + r2 * (ub - lb) * self.quantum_superposition()\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # Evaluate particle\n                value = func(particles[i])\n                self.evaluations += 1\n\n                # Update global best\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = particles[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Perform genetic operations\n            self.genetic_operations(particles, lb, ub)\n\n        return best_global_position\n\n    def initialize_particles(self, lb, ub):\n        # Quantum-inspired superposition for initialization\n        return lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n\n    def quantum_superposition(self):\n        # Simulate quantum superposition for additional exploration\n        return np.random.choice([-1, 1], self.dim) * np.random.rand(self.dim)\n\n    def genetic_operations(self, particles, lb, ub):\n        # Mutation and crossover for enhanced exploration\n        for i in range(self.num_particles):\n            if np.random.rand() < self.mutation_rate:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                particles[i] = np.clip(particles[i] + mutation, lb, ub)\n        \n        for i in range(0, self.num_particles - 1, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                particles[i][:crossover_point], particles[i+1][:crossover_point] = (\n                    particles[i+1][:crossover_point].copy(), particles[i][:crossover_point].copy())", "name": "QIGPO", "description": "Quantum-Inspired Genetic Particle Optimization (QIGPO): A hybrid approach integrating quantum-inspired superposition states with genetic operations to enhance exploration and exploitation in complex search spaces.", "configspace": "", "generation": 10, "fitness": 0.6158249702946639, "feedback": "The algorithm QIGPO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.62 with standard deviation 0.01.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.6217817030524475, 0.6098682375368804]}, "mutation_prompt": null}
{"id": "c7f6ad7e-1e29-4526-9a66-b81b7ce144d0", "solution": "import numpy as np\n\nclass QISE:\n    def __init__(self, budget, dim, num_agents=30, alpha=0.75, beta=0.25):\n        self.budget = budget\n        self.dim = dim\n        self.num_agents = num_agents\n        self.alpha = alpha\n        self.beta = beta\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        positions = self.initialize_agents(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.num_agents, self.dim))\n        \n        while self.evaluations < self.budget:\n            for i in range(self.num_agents):\n                personal_best_position = positions[i]\n                personal_best_value = func(personal_best_position)\n                self.evaluations += 1\n\n                # Quantum-inspired update\n                quantum_position = self.quantum_update(positions[i], best_global_position, lb, ub)\n                quantum_value = func(quantum_position)\n                self.evaluations += 1\n\n                if quantum_value < personal_best_value:\n                    personal_best_position = quantum_position\n                    personal_best_value = quantum_value\n                \n                if personal_best_value < best_global_value:\n                    best_global_position = personal_best_position\n                    best_global_value = personal_best_value\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Perform dynamic evolutionary operations\n            self.evolve_agents(positions, lb, ub)\n            \n            if self.evaluations >= self.budget:\n                break\n\n        return best_global_position\n\n    def initialize_agents(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.num_agents, self.dim))\n\n    def quantum_update(self, position, global_best, lb, ub):\n        if global_best is None:\n            direction = np.random.uniform(-1, 1, self.dim)\n        else:\n            direction = global_best - position\n\n        quantum_jump = self.alpha * direction + self.beta * np.random.uniform(-1, 1, self.dim) * (ub - lb)\n        new_position = np.clip(position + quantum_jump, lb, ub)\n        return new_position\n\n    def evolve_agents(self, agents, lb, ub):\n        for i in range(self.num_agents):\n            if np.random.rand() < 0.1:  # Mutation rate\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                agents[i] = np.clip(agents[i] + mutation, lb, ub)\n        \n        for i in range(0, self.num_agents, 2):\n            if i+1 < self.num_agents and np.random.rand() < 0.2:  # Crossover rate\n                crossover_point = np.random.randint(1, self.dim)\n                agents[i][:crossover_point], agents[i+1][:crossover_point] = (\n                    agents[i+1][:crossover_point].copy(), agents[i][:crossover_point].copy())", "name": "QISE", "description": "Quantum-Inspired Swarm Evolution (QISE): A novel approach integrating quantum principles with swarm behavior to enhance exploration and exploitation in complex search spaces.", "configspace": "", "generation": 11, "fitness": 0.6581985915736964, "feedback": "The algorithm QISE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.02.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.6827898748365732, 0.6336073083108197]}, "mutation_prompt": null}
{"id": "2a538a26-4493-4e51-acca-8172ff62baad", "solution": "import numpy as np\n\nclass QIAMSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    # Apply quantum-inspired perturbation\n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        # Quantum perturbation using superposition principle\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)", "name": "QIAMSO", "description": "Quantum-Inspired Adaptive Multi-Swarm Optimization (QIAMSO): Leverages quantum superposition principles and adaptive multi-swarm interaction for robust global exploration and local exploitation in complex search spaces.", "configspace": "", "generation": 12, "fitness": 0.891590970248189, "feedback": "The algorithm QIAMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.02.", "error": "", "parent_id": "64156fc9-3d87-47f8-bea8-cf2bc7101e94", "metadata": {"aucs": [0.8756588812079761, 0.907523059288402]}, "mutation_prompt": null}
{"id": "d377e259-13dd-4f0e-98e1-16a02dc9de3a", "solution": "import numpy as np\n\nclass QIMSO_DIA:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia_min=0.4, inertia_max=0.9, cognitive=2, social=2, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_min = inertia_min\n        self.inertia_max = inertia_max\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    # Apply quantum-inspired perturbation\n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    local_best_position = min(swarms[swarm_id], key=func)\n                    inertia = self.calculate_dynamic_inertia(swarms[swarm_id], lb, ub)\n\n                    velocities[swarm_id][i] = (inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (local_best_position - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n\n    def calculate_dynamic_inertia(self, swarm, lb, ub):\n        diversity = np.mean(np.linalg.norm(swarm - np.mean(swarm, axis=0), axis=1))\n        max_diversity = np.linalg.norm(ub - lb) / np.sqrt(self.dim)\n        inertia = self.inertia_max - (self.inertia_max - self.inertia_min) * (diversity / max_diversity)\n        return inertia", "name": "QIMSO_DIA", "description": "Quantum-Inspired Multi-Swarm Optimization with Dynamic Inertia Adjustment (QIMSO-DIA): Enhances convergence through adaptive inertia based on swarm diversity and improved quantum-inspired exploration techniques.", "configspace": "", "generation": 13, "fitness": 0.5378523191573374, "feedback": "The algorithm QIMSO_DIA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.00.", "error": "", "parent_id": "2a538a26-4493-4e51-acca-8172ff62baad", "metadata": {"aucs": [0.5416301504241127, 0.5340744878905621]}, "mutation_prompt": null}
{"id": "058aaa2e-c00f-444e-be7e-41aaa7dfde68", "solution": "import numpy as np\n\nclass HQGA:\n    def __init__(self, budget, dim, population_size=20, mutation_rate=0.1, crossover_rate=0.7, quantum_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.quantum_rate = quantum_rate\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        population = self.quantum_initialize_population(lb, ub)\n        \n        while self.evaluations < self.budget:\n            fitness_values = np.array([func(individual) for individual in population])\n            self.evaluations += self.population_size\n            \n            if np.min(fitness_values) < best_global_value:\n                best_global_value = np.min(fitness_values)\n                best_global_position = population[np.argmin(fitness_values)].copy()\n\n            if self.evaluations >= self.budget:\n                break\n\n            selected = self.selection(population, fitness_values)\n            offspring = self.crossover(selected)\n            mutated_offspring = self.mutation(offspring, lb, ub)\n            \n            population = mutated_offspring\n\n        return best_global_position\n\n    def quantum_initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def selection(self, population, fitness_values):\n        probabilities = 1 / (fitness_values + 1e-9)\n        probabilities /= probabilities.sum()\n        indices = np.random.choice(range(self.population_size), size=self.population_size, p=probabilities)\n        return population[indices]\n\n    def crossover(self, population):\n        new_population = np.copy(population)\n        for i in range(0, self.population_size - 1, 2):\n            if np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                new_population[i, :crossover_point], new_population[i+1, :crossover_point] = (\n                    new_population[i+1, :crossover_point], new_population[i, :crossover_point])\n        return new_population\n\n    def mutation(self, population, lb, ub):\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_rate:\n                mutation_vector = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                population[i] = np.clip(population[i] + mutation_vector, lb, ub)\n        return population", "name": "HQGA", "description": "Hybrid Quantum Genetic Algorithm (HQGA): Combines quantum-inspired initialization with adaptive genetic operations for enhanced exploration and exploitation in complex search domains.", "configspace": "", "generation": 14, "fitness": 0.7093657757164237, "feedback": "The algorithm HQGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.02.", "error": "", "parent_id": "2a538a26-4493-4e51-acca-8172ff62baad", "metadata": {"aucs": [0.6875504922189587, 0.7311810592138887]}, "mutation_prompt": null}
{"id": "f4579331-1d45-4176-9e84-ba228791dd2d", "solution": "import numpy as np\n\nclass GPaLO:\n    def __init__(self, budget, dim, population_size=50, alpha=0.1, beta=1.5, crossover_rate=0.8, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.alpha = alpha\n        self.beta = beta  # Levy parameter\n        self.crossover_rate = crossover_rate\n        self.mutation_rate = mutation_rate\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_global_position = None\n        best_global_value = float('inf')\n\n        while self.evaluations < self.budget:\n            # Evaluate and select the best solution in the population\n            fitness_values = np.array([func(individual) for individual in population])\n            self.evaluations += self.population_size\n\n            best_idx = np.argmin(fitness_values)\n            if fitness_values[best_idx] < best_global_value:\n                best_global_value = fitness_values[best_idx]\n                best_global_position = population[best_idx].copy()\n\n            # Perform selection, crossover, and mutation\n            selected_parents = self.tournament_selection(population, fitness_values)\n            offspring = self.crossover_and_mutate(selected_parents, lb, ub)\n\n            # Levy flight step for enhanced exploration\n            levy_offspring = self.levy_flight(offspring, lb, ub)\n\n            # Combine offspring and levy offspring, then evaluate\n            population = self.select_next_generation(offspring, levy_offspring, func)\n            self.evaluations += len(levy_offspring)\n\n            if self.evaluations >= self.budget:\n                break\n\n        return best_global_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def tournament_selection(self, population, fitness_values, tournament_size=3):\n        selected_parents = []\n        for _ in range(self.population_size):\n            tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n            winner_idx = tournament_indices[np.argmin(fitness_values[tournament_indices])]\n            selected_parents.append(population[winner_idx])\n        return np.array(selected_parents)\n\n    def crossover_and_mutate(self, parents, lb, ub):\n        offspring = []\n        for i in range(0, self.population_size, 2):\n            parent1 = parents[i]\n            if i + 1 < self.population_size:\n                parent2 = parents[i + 1]\n\n                if np.random.rand() < self.crossover_rate:\n                    crossover_point = np.random.randint(1, self.dim)\n                    child1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])\n                    child2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])\n                else:\n                    child1, child2 = parent1.copy(), parent2.copy()\n\n                offspring.extend([self.mutate(child1, lb, ub), self.mutate(child2, lb, ub)])\n                \n        return np.array(offspring)\n\n    def mutate(self, individual, lb, ub):\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = (np.random.rand(self.dim) - 0.5) * (ub - lb)\n            individual = np.clip(individual + mutation_vector, lb, ub)\n        return individual\n\n    def levy_flight(self, offspring, lb, ub):\n        levy_step = self.alpha * (np.random.normal(size=(len(offspring), self.dim)) / \n                                  np.abs(np.random.normal(size=(len(offspring), self.dim)))**(1/self.beta))\n        levy_offspring = np.clip(offspring + levy_step, lb, ub)\n        return levy_offspring\n\n    def select_next_generation(self, offspring, levy_offspring, func):\n        combined_population = np.vstack((offspring, levy_offspring))\n        fitness_values = np.array([func(individual) for individual in combined_population])\n        best_indices = np.argsort(fitness_values)[:self.population_size]\n        return combined_population[best_indices]", "name": "GPaLO", "description": "Genetic Particle Levy Optimization (GPaLO): Integrates genetic algorithm principles with particle dynamics and Levy flight for enhanced exploration and exploitation in complex landscapes. ", "configspace": "", "generation": 15, "fitness": 0.5973290217835832, "feedback": "The algorithm GPaLO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.60 with standard deviation 0.09.", "error": "", "parent_id": "2a538a26-4493-4e51-acca-8172ff62baad", "metadata": {"aucs": [0.507385792293809, 0.6872722512733574]}, "mutation_prompt": null}
{"id": "c39987df-7b10-488a-9381-c79330ab4047", "solution": "import numpy as np\n\nclass QEHMSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    # Apply quantum-inspired perturbation with enhanced probability\n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.hybrid_evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def hybrid_evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = np.random.normal(0, 0.05 * (ub - lb), self.dim)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.3:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + np.random.normal(0, 0.02 * (ub - lb), self.dim)\n        return np.clip(q_position, lb, ub)", "name": "QEHMSO", "description": "Quantum-Enhanced Hybrid Multi-Swarm Optimization (QEHMSO): Combines quantum superposition, hybrid mutation operators, and swarm synergy to enhance convergence and robustness across diverse optimization landscapes.", "configspace": "", "generation": 16, "fitness": 0.8384133915492007, "feedback": "The algorithm QEHMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84 with standard deviation 0.02.", "error": "", "parent_id": "2a538a26-4493-4e51-acca-8172ff62baad", "metadata": {"aucs": [0.8197102673774114, 0.85711651572099]}, "mutation_prompt": null}
{"id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "solution": "import numpy as np\n\nclass DQIAMSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n                \n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    # Apply dynamic quantum-inspired perturbation\n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n    \n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity", "name": "DQIAMSO", "description": "Quantum-Inspired Adaptive Multi-Swarm Optimization with Dynamic Quantum Probability (DQIAMSO): Enhances exploration-exploitation balance by dynamically adjusting quantum perturbation probability based on swarm diversity.", "configspace": "", "generation": 17, "fitness": 0.9337209077400672, "feedback": "The algorithm DQIAMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.01.", "error": "", "parent_id": "2a538a26-4493-4e51-acca-8172ff62baad", "metadata": {"aucs": [0.9441699755058421, 0.9232718399742924]}, "mutation_prompt": null}
{"id": "154bc56f-20e3-4b90-aade-84f6bab7125d", "solution": "import numpy as np\n\nclass EQIMSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        # Using chaotic map for initialization\n        swarms = [self.chaotic_initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n                \n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    # Adaptive velocity scaling\n                    velocity_scaler = 1.0 + 0.5 * np.random.rand()\n                    velocities[swarm_id][i] = (velocity_scaler * self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def chaotic_initialize_swarm(self, lb, ub):\n        # Logistic map for chaotic initialization\n        x = np.random.rand(self.swarm_size, self.dim)\n        x = 4 * x * (1 - x)\n        return lb + (ub - lb) * x\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n    \n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity", "name": "EQIMSO", "description": "Enhanced Quantum-Inspired Multi-Swarm Optimization (EQIMSO): Incorporates adaptive velocity scaling and chaotic map-based initialization to improve convergence speed and solution diversity.", "configspace": "", "generation": 18, "fitness": 0.85504716555431, "feedback": "The algorithm EQIMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.86 with standard deviation 0.00.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.8517800994226276, 0.8583142316859925]}, "mutation_prompt": null}
{"id": "264481f9-71cd-4fa1-a048-2c046d09d11c", "solution": "import numpy as np\n\nclass SOQSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2, neighbor_count=3):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.neighbor_count = neighbor_count\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                self.update_swarm_neighborhoods(swarms[swarm_id])\n\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    # Apply quantum-inspired perturbation\n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n\n                    # Calculate neighborhood best\n                    neighborhood = self.select_neighborhood(swarms[swarm_id], i)\n                    best_neighbor_position = min(neighborhood, key=lambda pos: func(pos))\n                    \n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (best_neighbor_position - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n    \n    def update_swarm_neighborhoods(self, swarm):\n        # Update neighborhood structure based on some criteria, like distance or similarity\n        pass\n\n    def select_neighborhood(self, swarm, index):\n        distances = np.linalg.norm(swarm - swarm[index], axis=1)\n        neighbors_idx = np.argsort(distances)[:self.neighbor_count + 1]\n        return [swarm[i] for i in neighbors_idx]", "name": "SOQSO", "description": "Self-Organizing Quantum Swarm Optimization (SOQSO): Integrates adaptive neighborhood topology with quantum-inspired perturbations for enhanced cooperative search efficiency.", "configspace": "", "generation": 19, "fitness": 0.6537875795898203, "feedback": "The algorithm SOQSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.04.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.6134320908541204, 0.69414306832552]}, "mutation_prompt": null}
{"id": "573cda9a-4756-4bf8-ab73-2bb8d68892d9", "solution": "import numpy as np\n\nclass QICSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2, interaction_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.interaction_prob = interaction_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        local_best_positions = [swarm.copy() for swarm in swarms]\n        local_best_values = [np.full(self.swarm_size, float('inf')) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n\n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n\n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (local_best_positions[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < local_best_values[swarm_id][i]:\n                        local_best_values[swarm_id][i] = value\n                        local_best_positions[swarm_id][i] = position\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        return best_global_position\n\n                self.coevolve_swarms(swarms, swarm_id, lb, ub)\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n\n    def coevolve_swarms(self, swarms, swarm_id, lb, ub):\n        if np.random.rand() < self.interaction_prob:\n            partner_swarm_id = np.random.choice([i for i in range(self.num_swarms) if i != swarm_id])\n            partner_swarm = swarms[partner_swarm_id]\n            for i in range(self.swarm_size):\n                if np.random.rand() < 0.5:\n                    crossover_point = np.random.randint(1, self.dim)\n                    swarms[swarm_id][i][:crossover_point], partner_swarm[i][:crossover_point] = (\n                        partner_swarm[i][:crossover_point].copy(), swarms[swarm_id][i][:crossover_point].copy())", "name": "QICSO", "description": "Quantum-Inspired Coevolutionary Swarm Optimization (QICSO): Integrates coevolutionary principles with quantum probability dynamics to improve global search through hybridized swarm interactions.", "configspace": "", "generation": 20, "fitness": 0.8039745340880975, "feedback": "The algorithm QICSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.80 with standard deviation 0.03.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.8315569209670417, 0.7763921472091534]}, "mutation_prompt": null}
{"id": "f2ccbefa-ba98-4d9d-bec2-13d45cc827f2", "solution": "import numpy as np\n\nclass QAMPDE:\n    def __init__(self, budget, dim, num_populations=5, population_size=10, F=0.5, CR=0.9, quantum_prob=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_populations = num_populations\n        self.population_size = population_size\n        self.F = F\n        self.CR = CR\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        populations = [self.initialize_population(lb, ub) for _ in range(self.num_populations)]\n\n        while self.evaluations < self.budget:\n            for pop_id in range(self.num_populations):\n                diversity = self.calculate_diversity(populations[pop_id])\n                dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n                \n                for i in range(self.population_size):\n                    target = populations[pop_id][i]\n                    \n                    # Mutation\n                    a, b, c = populations[pop_id][np.random.choice(self.population_size, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), lb, ub)\n                    \n                    # Crossover\n                    trial = np.array([mutant[j] if np.random.rand() < self.CR else target[j] for j in range(self.dim)])\n                    \n                    # Apply dynamic quantum-inspired perturbation\n                    if np.random.rand() < dynamic_quantum_prob:\n                        trial = self.quantum_perturbation(trial, lb, ub)\n                    \n                    value = func(trial)\n                    self.evaluations += 1\n\n                    if value < func(target):\n                        populations[pop_id][i] = trial\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = trial\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_population(populations[pop_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def evolve_population(self, population, lb, ub):\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                population[i] = np.clip(population[i] + mutation, lb, ub)\n        \n        for i in range(0, self.population_size, 2):\n            if i+1 < self.population_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                population[i][:crossover_point], population[i+1][:crossover_point] = (\n                    population[i+1][:crossover_point].copy(), population[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n\n    def calculate_diversity(self, population):\n        centroid = np.mean(population, axis=0)\n        diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n        return diversity", "name": "QAMPDE", "description": "Quantum-Inspired Adaptive Multi-Population Differential Evolution (QAMPDE): Combines quantum-inspired adaptive mutation strategies and a multi-population approach to enhance exploration and exploitation in high-dimensional spaces.", "configspace": "", "generation": 21, "fitness": 0.7278401659402409, "feedback": "The algorithm QAMPDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.01.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.7385721237542885, 0.7171082081261932]}, "mutation_prompt": null}
{"id": "3142a46e-a7fa-4b37-8d3f-ade8bd1f75ac", "solution": "import numpy as np\n\nclass EQIMSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia_bounds=(0.4, 0.9), cognitive=2, social=2, initial_quantum_prob=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_bounds = inertia_bounds\n        self.cognitive = cognitive\n        self.social = social\n        self.initial_quantum_prob = initial_quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        personal_best_positions = [swarm.copy() for swarm in swarms]\n        personal_best_values = [np.full(self.swarm_size, float('inf')) for _ in range(self.num_swarms)]\n        inertia_weights = np.full((self.num_swarms, self.swarm_size), self.inertia_bounds[1])\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.initial_quantum_prob * (1 + (self.diversity_threshold - diversity))\n                \n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    # Apply adaptive inertia weight\n                    inertia = self.adaptive_inertia(inertia_weights[swarm_id][i], personal_best_values[swarm_id][i], best_global_value)\n                    \n                    # Apply dynamic quantum-inspired perturbation\n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n\n                    velocities[swarm_id][i] = (inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (personal_best_positions[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < personal_best_values[swarm_id][i]:\n                        personal_best_values[swarm_id][i] = value\n                        personal_best_positions[swarm_id][i] = position\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n\n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity\n\n    def adaptive_inertia(self, current_inertia, personal_best_value, global_best_value):\n        if personal_best_value < global_best_value:\n            return max(self.inertia_bounds[0], current_inertia * 0.99)\n        else:\n            return min(self.inertia_bounds[1], current_inertia * 1.01)", "name": "EQIMSO", "description": "Enhanced Quantum-Inspired Multi-Swarm Optimization (EQIMSO): Improves convergence by integrating adaptive inertia weights and self-adaptive quantum probabilities based on individual particle performance.", "configspace": "", "generation": 22, "fitness": 0.6675446792398494, "feedback": "The algorithm EQIMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.00.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.6675517670290175, 0.6675375914506811]}, "mutation_prompt": null}
{"id": "91a8a8f2-7274-49ae-9289-67360ce86983", "solution": "import numpy as np\n\nclass QHAMSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        learning_rates = np.linspace(0.1, 0.5, self.num_swarms)\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n                \n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    # Apply dynamic quantum-inspired perturbation\n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               learning_rates[swarm_id] * self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n        \n            # Adjust learning rates based on performance\n            learning_rates = self.update_learning_rates(swarms, func)\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n    \n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity\n\n    def update_learning_rates(self, swarms, func):\n        performances = []\n        for swarm in swarms:\n            values = [func(individual) for individual in swarm]\n            performances.append(np.mean(values))\n        \n        min_perf, max_perf = min(performances), max(performances)\n        if min_perf == max_perf:\n            return np.full(self.num_swarms, 0.1)\n\n        return 0.1 + 0.4 * (1 - (performances - min_perf) / (max_perf - min_perf))", "name": "QHAMSO", "description": "Quantum-Inspired Hierarchical Adaptive Multi-Swarm Optimization (QHAMSO): Introduces a hierarchical structure for dynamic swarms, enhancing adaptability and convergence through conditional learning rates based on diversity and performance metrics.", "configspace": "", "generation": 23, "fitness": 0.8102212285640766, "feedback": "The algorithm QHAMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.81 with standard deviation 0.01.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.8217214945025839, 0.7987209626255695]}, "mutation_prompt": null}
{"id": "a63279ba-924f-40a1-ab1d-7532642a10d6", "solution": "import numpy as np\n\nclass AGQA:\n    def __init__(self, budget, dim, population_size=20, crossover_prob=0.8, mutation_prob=0.1, quantum_prob=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.crossover_prob = crossover_prob\n        self.mutation_prob = mutation_prob\n        self.quantum_prob = quantum_prob\n        self.diversity_threshold = diversity_threshold\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_global_position = None\n        best_global_value = float('inf')\n\n        while self.evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n            selected_population = self.selection(population, func)\n\n            for i in range(0, self.population_size, 2):\n                if i + 1 < self.population_size and np.random.rand() < self.crossover_prob:\n                    offspring1, offspring2 = self.crossover(selected_population[i], selected_population[i+1])\n                    selected_population[i], selected_population[i+1] = offspring1, offspring2\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_prob:\n                    selected_population[i] = self.mutation(selected_population[i], lb, ub)\n\n                if np.random.rand() < dynamic_quantum_prob:\n                    selected_population[i] = self.quantum_perturbation(selected_population[i], lb, ub)\n\n                value = func(selected_population[i])\n                self.evaluations += 1\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = selected_population[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n            population = selected_population\n\n        return best_global_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def selection(self, population, func):\n        fitness_values = np.array([func(ind) for ind in population])\n        self.evaluations += len(population)\n        sorted_indices = np.argsort(fitness_values)\n        return population[sorted_indices[:self.population_size]]\n\n    def crossover(self, parent1, parent2):\n        crossover_point = np.random.randint(1, self.dim)\n        offspring1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])\n        offspring2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])\n        return offspring1, offspring2\n\n    def mutation(self, individual, lb, ub):\n        mutation_vector = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n        return np.clip(individual + mutation_vector, lb, ub)\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n\n    def calculate_diversity(self, population):\n        centroid = np.mean(population, axis=0)\n        diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n        return diversity", "name": "AGQA", "description": "Adaptive Genetic Quantum Algorithm (AGQA): Combines adaptive genetic operations with quantum-inspired perturbations to dynamically explore diverse regions of the solution space.", "configspace": "", "generation": 24, "fitness": 0.6207314426057304, "feedback": "The algorithm AGQA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.62 with standard deviation 0.01.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.627239012223492, 0.614223872987969]}, "mutation_prompt": null}
{"id": "044421e6-b681-47b1-8507-593451d660e3", "solution": "import numpy as np\n\nclass DQIAMSO_ALR:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2, diversity_threshold=0.1, adaptive_lr=True):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n        self.adaptive_lr = adaptive_lr\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        local_best_positions = [swarm.copy() for swarm in swarms]\n        local_best_values = [np.full(self.swarm_size, float('inf')) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n                \n                # Adaptive learning rates\n                if self.adaptive_lr:\n                    inertia = max(0.4, self.inertia * (1 - 0.5 * (1 - diversity)))\n                    cognitive = max(1.5, self.cognitive * (1 + diversity))\n                    social = max(1.5, self.social * (1 + (1 - diversity)))\n                else:\n                    inertia, cognitive, social = self.inertia, self.cognitive, self.social\n\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    # Apply dynamic quantum-inspired perturbation\n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[swarm_id][i] = (inertia * velocities[swarm_id][i] +\n                                               cognitive * np.random.random(self.dim) * (local_best_positions[swarm_id][i] - position) +\n                                               social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < local_best_values[swarm_id][i]:\n                        local_best_values[swarm_id][i] = value\n                        local_best_positions[swarm_id][i] = position\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n    \n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity", "name": "DQIAMSO_ALR", "description": "Quantum-Inspired Adaptive Multi-Swarm Optimization with Dynamic Quantum Probability and Adaptive Learning Rates (DQIAMSO-ALR): Introduces adaptive learning rates based on swarm performance to enhance convergence speed while maintaining diversity.", "configspace": "", "generation": 25, "fitness": 0.4708405838457766, "feedback": "The algorithm DQIAMSO_ALR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.47 with standard deviation 0.02.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.4954231236124863, 0.4462580440790669]}, "mutation_prompt": null}
{"id": "e776bca3-4824-4106-aeae-549b7db6bb68", "solution": "import numpy as np\n\nclass EQIMSO:\n    def __init__(self, budget, dim, base_num_swarms=5, base_swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2, diversity_threshold=0.1, adaptive_rate=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.base_num_swarms = base_num_swarms\n        self.base_swarm_size = base_swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n        self.adaptive_rate = adaptive_rate\n        self.num_swarms = base_num_swarms\n        self.swarm_size = base_swarm_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n                \n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n                        self.update_adaptive_parameters(swarm_id)\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n    \n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity\n\n    def update_adaptive_parameters(self, swarm_id):\n        progress_ratio = self.evaluations / self.budget\n        self.num_swarms = max(1, int(self.base_num_swarms * (1 + progress_ratio)))\n        self.swarm_size = max(2, int(self.base_swarm_size * (1 - progress_ratio)))\n\n        # Adjust learning rates\n        self.inertia = max(0.4, self.inertia - self.adaptive_rate * progress_ratio)\n        self.cognitive = min(2.5, self.cognitive + self.adaptive_rate * progress_ratio)\n        self.social = min(2.5, self.social + self.adaptive_rate * progress_ratio)", "name": "EQIMSO", "description": "Enhanced Quantum-Inspired Multi-Swarm Optimization (EQIMSO): Improves convergence by dynamically adapting swarm size and introducing adaptive learning rates based on swarm performance feedback.", "configspace": "", "generation": 26, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {}, "mutation_prompt": null}
{"id": "23f5c020-1934-4c39-835c-76372f64843e", "solution": "import numpy as np\n\nclass EQGSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, entanglement_prob=0.2, entanglement_strength=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.entanglement_prob = entanglement_prob\n        self.entanglement_strength = entanglement_strength\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        personal_best_positions = [swarm.copy() for swarm in swarms]\n        personal_best_values = [np.full(self.swarm_size, float('inf')) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < personal_best_values[swarm_id][i]:\n                        personal_best_values[swarm_id][i] = value\n                        personal_best_positions[swarm_id][i] = position\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if np.random.rand() < self.entanglement_prob:\n                        position = self.quantum_entanglement(position, personal_best_positions[swarm_id][i], lb, ub)\n\n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (personal_best_positions[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def quantum_entanglement(self, position, personal_best_position, lb, ub):\n        entangled_position = position + self.entanglement_strength * (personal_best_position - position) * (np.random.rand(self.dim) - 0.5)\n        return np.clip(entangled_position, lb, ub)", "name": "EQGSO", "description": "Entangled Quantum-Guided Swarm Optimization (EQGSO): Integrates quantum-inspired entanglement to improve swarm coordination and enhance exploration-exploitation dynamics through adaptive entanglement strength.", "configspace": "", "generation": 27, "fitness": 0.8332719142200737, "feedback": "The algorithm EQGSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.83 with standard deviation 0.01.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.8441702240608828, 0.8223736043792648]}, "mutation_prompt": null}
{"id": "cda7308c-5e7a-4e31-aa5e-5c1d4cb1c1c6", "solution": "import numpy as np\n\nclass BIAGO:\n    def __init__(self, budget, dim, population_size=30, diffusion_rate=0.1, learning_rate=0.01, mutation_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.diffusion_rate = diffusion_rate\n        self.learning_rate = learning_rate\n        self.mutation_prob = mutation_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n\n        population = self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Apply stochastic diffusion\n                diffused_position = self.stochastic_diffusion(population[i], lb, ub)\n\n                # Evaluate the function at the new position\n                value = func(diffused_position)\n                self.evaluations += 1\n\n                if value < best_value:\n                    best_value = value\n                    best_position = diffused_position\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Evolve population using evolutionary learning\n            self.evolve_population(population, lb, ub)\n\n            if self.evaluations >= self.budget:\n                break\n\n        return best_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def stochastic_diffusion(self, position, lb, ub):\n        noise = np.random.normal(0, self.diffusion_rate, self.dim)\n        new_position = position + noise\n        return np.clip(new_position, lb, ub)\n\n    def evolve_population(self, population, lb, ub):\n        for i in range(self.population_size):\n            if np.random.rand() < self.mutation_prob:\n                mutation = (np.random.rand(self.dim) - 0.5) * self.learning_rate * (ub - lb)\n                population[i] = np.clip(population[i] + mutation, lb, ub)\n\n        # Selection step: keep only the best half of the population\n        half_size = self.population_size // 2\n        fitness = np.array([func(ind) for ind in population])\n        best_indices = np.argsort(fitness)[:half_size]\n        population[:half_size] = population[best_indices]\n        \n        # Refill the population by cloning best solutions\n        for i in range(half_size, self.population_size):\n            parent = population[np.random.choice(half_size)]\n            population[i] = self.stochastic_diffusion(parent, lb, ub)", "name": "BIAGO", "description": "Bio-Inspired Adaptive Gradient-Free Optimization using Stochastic Diffusion and Evolutionary Learning (BIAGO): Combines stochastic diffusion mechanisms with evolutionary strategies for gradient-free adaptation and dynamic learning in complex landscapes.", "configspace": "", "generation": 28, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {}, "mutation_prompt": null}
{"id": "c3d98d5b-d2bb-4d48-b12d-bb3285183fe7", "solution": "import numpy as np\n\nclass EQIAMSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n        self.learning_rate_decay = 0.99  # New parameter for adaptive learning\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n                \n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    # Apply dynamic quantum-inspired perturbation\n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n\n                    # Adaptive learning rate adjustment\n                    velocities[swarm_id][i] *= self.learning_rate_decay\n\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                # Local Search Exploitation\n                self.exploit_local_search(swarms[swarm_id], func, lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def exploit_local_search(self, swarm, func, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.2:\n                local_best = swarm[i]\n                for _ in range(3):  # Small number of local search steps\n                    candidate = local_best + (np.random.rand(self.dim) - 0.5) * 0.05 * (ub - lb)\n                    candidate = np.clip(candidate, lb, ub)\n                    if func(candidate) < func(local_best):\n                        local_best = candidate\n                swarm[i] = local_best\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n\n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity", "name": "EQIAMSO", "description": "Enhanced Quantum-Inspired Adaptive Multi-Swarm Optimization (EQIAMSO): Introduces adaptive learning rates and local search exploitation to improve convergence speed and solution precision.", "configspace": "", "generation": 29, "fitness": 0.77958124128972, "feedback": "The algorithm EQIAMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.78 with standard deviation 0.01.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.7702276890360606, 0.7889347935433793]}, "mutation_prompt": null}
{"id": "16dc35dd-c0bb-4f59-b052-349ec4dd925a", "solution": "import numpy as np\n\nclass BIMSCO:\n    def __init__(self, budget, dim, num_species=3, species_size=10, interaction_prob=0.3, mutation_rate=0.1, recombination_rate=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.num_species = num_species\n        self.species_size = species_size\n        self.interaction_prob = interaction_prob\n        self.mutation_rate = mutation_rate\n        self.recombination_rate = recombination_rate\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        species = [self.initialize_species(lb, ub) for _ in range(self.num_species)]\n\n        while self.evaluations < self.budget:\n            for species_id in range(self.num_species):\n                current_species = species[species_id]\n                other_species = [species[i] for i in range(self.num_species) if i != species_id]\n\n                for individual_id in range(self.species_size):\n                    individual = current_species[individual_id]\n\n                    # Interaction with other species\n                    if np.random.rand() < self.interaction_prob:\n                        partner_species = np.random.choice(other_species)\n                        partner = partner_species[np.random.randint(self.species_size)]\n                        interaction = self.species_interaction(individual, partner, lb, ub)\n                        current_species[individual_id] = interaction\n\n                    # Mutation\n                    if np.random.rand() < self.mutation_rate:\n                        self.species_mutation(current_species[individual_id], lb, ub)\n\n                    # Fitness evaluation\n                    value = func(current_species[individual_id])\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = current_species[individual_id].copy()\n\n                    if self.evaluations >= self.budget:\n                        return best_global_position\n\n                # Recombination within species\n                self.recombine_species(current_species, lb, ub)\n\n        return best_global_position\n\n    def initialize_species(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.species_size, self.dim))\n\n    def species_interaction(self, individual, partner, lb, ub):\n        interaction_vector = (partner - individual) * np.random.rand(self.dim) * 0.1\n        new_position = individual + interaction_vector\n        return np.clip(new_position, lb, ub)\n\n    def species_mutation(self, individual, lb, ub):\n        mutation_vector = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n        individual += mutation_vector\n        np.clip(individual, lb, ub, out=individual)\n\n    def recombine_species(self, species, lb, ub):\n        for i in range(0, self.species_size, 2):\n            if i+1 < self.species_size and np.random.rand() < self.recombination_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                species[i][:crossover_point], species[i+1][:crossover_point] = (\n                    species[i+1][:crossover_point].copy(), species[i][:crossover_point].copy())", "name": "BIMSCO", "description": "Bio-Inspired Multi-Species Coevolution Optimization (BIMSCO): Leverages cooperative interaction between diverse species-inspired subpopulations to enhance convergence and diversity.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {}, "mutation_prompt": null}
{"id": "166f57d0-7e52-42c0-b545-a797f56449d4", "solution": "import numpy as np\n\nclass AQCMSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, initial_quantum_prob=0.2, diversity_threshold=0.1, coop_factor=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.initial_quantum_prob = initial_quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n        self.coop_factor = coop_factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.initial_quantum_prob * (1 + (self.diversity_threshold - diversity))\n                \n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    # Apply adaptive quantum-inspired perturbation\n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    # Enhance cooperative behavior\n                    cooperative_position = self.cooperative_perturbation(swarms, swarm_id, lb, ub)\n                    \n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0) +\n                                               self.coop_factor * (cooperative_position - position))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n    \n    def cooperative_perturbation(self, swarms, current_swarm_id, lb, ub):\n        best_positions = [swarm[np.argmin([np.linalg.norm(position) for position in swarm])] for swarm in swarms if swarm is not swarms[current_swarm_id]]\n        if not best_positions:\n            return np.random.uniform(lb, ub, self.dim)\n        coop_position = np.mean(best_positions, axis=0)\n        return np.clip(coop_position, lb, ub)\n    \n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity", "name": "AQCMSO", "description": "Adaptive Quantum-Cooperative Multi-Swarm Optimization (AQCMSO): Combines adaptive quantum perturbation with cooperative swarm dynamics to enhance convergence and diversity control.", "configspace": "", "generation": 31, "fitness": 0.8901874384477211, "feedback": "The algorithm AQCMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.01.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.8795943088164061, 0.9007805680790362]}, "mutation_prompt": null}
{"id": "b1ad2c95-4b5d-4fbf-adae-a67b9ee23448", "solution": "import numpy as np\n\nclass MODQSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pareto_front = []\n        archive = []\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n\n                    # Apply dynamic quantum perturbation\n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n\n                    velocities[swarm_id][i] = (self.inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (self.select_pareto_leader(pareto_front) - position if pareto_front else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    archive.append((position, value))\n                    pareto_front = self.update_pareto_front(archive)\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return min(archive, key=lambda x: x[1])[0]\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n\n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity\n\n    def update_pareto_front(self, archive):\n        archive.sort(key=lambda x: x[1])\n        pareto_front = [archive[0]]\n        for point in archive[1:]:\n            if point[1] < pareto_front[-1][1]:\n                pareto_front.append(point)\n        return pareto_front\n\n    def select_pareto_leader(self, pareto_front):\n        return pareto_front[np.random.randint(len(pareto_front))][0] if pareto_front else np.zeros(self.dim)", "name": "MODQSO", "description": "Multi-Objective Dynamic Quantum Swarm Optimization (MODQSO): Integrates multi-objective handling with adaptive quantum perturbations tailored to Pareto front exploration and convergence.", "configspace": "", "generation": 33, "fitness": 0.8845128568383558, "feedback": "The algorithm MODQSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88 with standard deviation 0.01.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.8969070614876877, 0.8721186521890237]}, "mutation_prompt": null}
{"id": "493a8697-9c2a-40d9-be31-5cce1931341a", "solution": "import numpy as np\n\nclass EDQIAMSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia_min=0.3, inertia_max=0.7, cognitive=2, social=2, quantum_prob=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia_min = inertia_min\n        self.inertia_max = inertia_max\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n\n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n                inertia_weight = self.inertia_max - ((self.inertia_max - self.inertia_min) * (self.evaluations / self.budget))\n\n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n\n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub, level=1 + (diversity < self.diversity_threshold))\n\n                    velocities[swarm_id][i] = (inertia_weight * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub, level=1):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05 * level\n        return np.clip(q_position, lb, ub)\n\n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity", "name": "EDQIAMSO", "description": "Enhanced Dynamic Quantum-Inspired Multi-Swarm Optimization (EDQIAMSO): Introduces adaptive inertia and multi-level quantum perturbation for improved dynamic balance of exploration and exploitation.", "configspace": "", "generation": 34, "fitness": 0.8428336834421559, "feedback": "The algorithm EDQIAMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84 with standard deviation 0.00.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.8413828335574316, 0.8442845333268802]}, "mutation_prompt": null}
{"id": "ac17a561-39d2-4348-9e4b-02049785dd09", "solution": "import numpy as np\n\nclass DEQFL:\n    def __init__(self, budget, dim, population_size=20, mutation_factor=0.8, crossover_prob=0.9, levy_scale=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.mutation_factor = mutation_factor\n        self.crossover_prob = crossover_prob\n        self.levy_scale = levy_scale\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        fitness = np.array([func(ind) for ind in population])\n        self.evaluations += self.population_size\n\n        best_idx = np.argmin(fitness)\n        best_value = fitness[best_idx]\n        best_solution = population[best_idx]\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                trial = self.mutate(i, population, lb, ub)\n                trial = self.crossover(population[i], trial)\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_value\n                    if trial_value < best_value:\n                        best_value = trial_value\n                        best_solution = trial\n\n            population = self.quantum_levy_flight(population, lb, ub, best_solution)\n\n        return best_solution\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, target_idx, population, lb, ub):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(idxs, 3, replace=False)\n        mutant = population[a] + self.mutation_factor * (population[b] - population[c])\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        if not crossover_mask.any():\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        return np.where(crossover_mask, mutant, target)\n\n    def quantum_levy_flight(self, population, lb, ub, best_solution):\n        alpha = 1.5  # Levy exponent\n        for i in range(self.population_size):\n            step = self.levy_scale * self.levy_flight(alpha, self.dim) * (population[i] - best_solution)\n            new_position = np.clip(population[i] + step, lb, ub)\n            population[i] = new_position\n        return population\n\n    def levy_flight(self, alpha, dim):\n        sigma_u = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) /\n                   (np.gamma((1 + alpha) / 2) * alpha * 2**((alpha - 1) / 2)))**(1 / alpha)\n        u = np.random.normal(0, sigma_u, dim)\n        v = np.random.normal(0, 1, dim)\n        return u / np.abs(v)**(1 / alpha)", "name": "DEQFL", "description": "Differential Evolution with Quantum-Levy Flight (DE-QFL): Combines differential mutation with quantum-inspired Levy flights for enhanced exploration and exploitation balance in high-dimensional spaces.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {}, "mutation_prompt": null}
{"id": "efd3655b-9101-41ec-b28b-bc5b831087a5", "solution": "import numpy as np\n\nclass EQIAMSO:\n    def __init__(self, budget, dim, num_swarms=5, swarm_size=10, inertia=0.5, cognitive=2, social=2, quantum_prob=0.2, diversity_threshold=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = num_swarms\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.diversity_threshold = diversity_threshold\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        swarms = [self.initialize_swarm(lb, ub) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        inertia_max, inertia_min = 0.9, 0.4\n        \n        while self.evaluations < self.budget:\n            for swarm_id in range(self.num_swarms):\n                diversity = self.calculate_diversity(swarms[swarm_id])\n                dynamic_quantum_prob = self.quantum_prob * (1 + (self.diversity_threshold - diversity))\n                dynamic_inertia = inertia_max - (inertia_max - inertia_min) * (self.evaluations / self.budget)\n                \n                for i in range(self.swarm_size):\n                    position = swarms[swarm_id][i]\n                    \n                    if np.random.rand() < dynamic_quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[swarm_id][i] = (dynamic_inertia * velocities[swarm_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (swarms[swarm_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[swarm_id][i], lb, ub)\n                    swarms[swarm_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.evolve_swarm(swarms[swarm_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def evolve_swarm(self, swarm, lb, ub):\n        for i in range(self.swarm_size):\n            if np.random.rand() < 0.1:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.1 * (ub - lb)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n        \n        for i in range(0, self.swarm_size, 2):\n            if i+1 < self.swarm_size and np.random.rand() < 0.2:\n                crossover_point = np.random.randint(1, self.dim)\n                swarm[i][:crossover_point], swarm[i+1][:crossover_point] = (\n                    swarm[i+1][:crossover_point].copy(), swarm[i][:crossover_point].copy())\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n    \n    def calculate_diversity(self, swarm):\n        centroid = np.mean(swarm, axis=0)\n        diversity = np.mean(np.linalg.norm(swarm - centroid, axis=1))\n        return diversity", "name": "EQIAMSO", "description": "Enhanced Quantum-Inspired Adaptive Multi-Swarm Optimization (EQIAMSO): Introduces adaptive inertia and cognitive-social interaction balance to improve convergence speed and solution quality.", "configspace": "", "generation": 36, "fitness": 0.746397380177301, "feedback": "The algorithm EQIAMSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.01.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.7342927761708571, 0.7585019841837448]}, "mutation_prompt": null}
{"id": "8930c79f-8361-411a-8940-02cbdbe47ba2", "solution": "import numpy as np\n\nclass QEBIMPS:\n    def __init__(self, budget, dim, num_groups=4, group_size=10, inertia=0.4, cognitive=1.5, social=1.5, quantum_prob=0.15, phases=3):\n        self.budget = budget\n        self.dim = dim\n        self.num_groups = num_groups\n        self.group_size = group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.phases = phases\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        groups = [self.initialize_group(lb, ub) for _ in range(self.num_groups)]\n        velocities = [np.random.uniform(-1, 1, (self.group_size, self.dim)) for _ in range(self.num_groups)]\n\n        phase_counter = 0\n\n        while self.evaluations < self.budget:\n            for group_id in range(self.num_groups):\n                for i in range(self.group_size):\n                    position = groups[group_id][i]\n                    \n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[group_id][i] = (self.inertia * velocities[group_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (groups[group_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[group_id][i], lb, ub)\n                    groups[group_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                if phase_counter % self.phases == 0:\n                    self.phase_based_adaptation(groups[group_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n            \n            phase_counter += 1\n\n        return best_global_position\n\n    def initialize_group(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def phase_based_adaptation(self, group, lb, ub):\n        for i in range(self.group_size):\n            if np.random.rand() < 0.2:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.05 * (ub - lb)\n                group[i] = np.clip(group[i] + mutation, lb, ub)\n        \n        for i in range(0, self.group_size, 2):\n            if i + 1 < self.group_size and np.random.rand() < 0.25:\n                crossover_point = np.random.randint(1, self.dim)\n                group[i][:crossover_point], group[i + 1][:crossover_point] = (\n                    group[i + 1][:crossover_point].copy(), group[i][:crossover_point].copy())", "name": "QEBIMPS", "description": "Quantum-Enhanced Bio-Inspired Multi-Phase Search (QEBIMPS): Integrates quantum-inspired exploration, bio-inspired cooperation, and adaptive phase-based exploitation for efficient optimization.", "configspace": "", "generation": 37, "fitness": 0.9373491569833963, "feedback": "The algorithm QEBIMPS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94 with standard deviation 0.00.", "error": "", "parent_id": "9381578c-c5f4-4974-b1a5-6ab4fcf9b5ce", "metadata": {"aucs": [0.9401004757789886, 0.9345978381878041]}, "mutation_prompt": null}
{"id": "5aa589fe-30da-4a27-8117-d31c1134cc01", "solution": "import numpy as np\n\nclass AQHS:\n    def __init__(self, budget, dim, harmony_size=20, hmcr=0.9, par=0.3, bw=0.01, quantum_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_size = harmony_size\n        self.hmcr = hmcr\n        self.par = par\n        self.bw = bw\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = self.initialize_harmony_memory(lb, ub)\n        best_harmony = min(harmony_memory, key=func)\n        best_value = func(best_harmony)\n        self.evaluations += len(harmony_memory)\n\n        while self.evaluations < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_size)][i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += self.bw * (np.random.rand() - 0.5)\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                if np.random.rand() < self.quantum_prob:\n                    new_harmony[i] = self.quantum_perturbation(new_harmony[i], lb[i], ub[i])\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            self.evaluations += 1\n\n            if new_value < best_value:\n                best_value = new_value\n                best_harmony = new_harmony\n\n            worst_index = max(range(self.harmony_size), key=lambda idx: func(harmony_memory[idx]))\n            if new_value < func(harmony_memory[worst_index]):\n                harmony_memory[worst_index] = new_harmony\n\n            if self.evaluations >= self.budget:\n                break\n\n        return best_harmony\n\n    def initialize_harmony_memory(self, lb, ub):\n        return [np.random.uniform(lb, ub, self.dim) for _ in range(self.harmony_size)]\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand() - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)", "name": "AQHS", "description": "Adaptive Quantum Harmony Search (AQHS): Combines quantum-inspired harmony memory adaptation with adaptive pitch adjustment for efficient exploration and exploitation.", "configspace": "", "generation": 38, "fitness": 0.617151857085446, "feedback": "The algorithm AQHS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.62 with standard deviation 0.08.", "error": "", "parent_id": "8930c79f-8361-411a-8940-02cbdbe47ba2", "metadata": {"aucs": [0.5388060624126475, 0.6954976517582445]}, "mutation_prompt": null}
{"id": "0b5ca4f1-9d6e-4360-847d-0bae67dcb55c", "solution": "import numpy as np\n\nclass QICMSO:\n    def __init__(self, budget, dim, num_groups=4, group_size=10, inertia=0.4, cognitive=1.5, social=1.5, quantum_prob=0.15, phases=3, coop_ratio=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_groups = num_groups\n        self.group_size = group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.phases = phases\n        self.coop_ratio = coop_ratio\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        groups = [self.initialize_group(lb, ub) for _ in range(self.num_groups)]\n        velocities = [np.random.uniform(-1, 1, (self.group_size, self.dim)) for _ in range(self.num_groups)]\n\n        phase_counter = 0\n\n        while self.evaluations < self.budget:\n            for group_id in range(self.num_groups):\n                for i in range(self.group_size):\n                    position = groups[group_id][i]\n                    \n                    if np.random.rand() < self.quantum_prob:\n                        position = self.adaptive_quantum_perturbation(position, lb, ub, phase_counter)\n                    \n                    velocities[group_id][i] = (self.inertia * velocities[group_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (groups[group_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[group_id][i], lb, ub)\n                    groups[group_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                if phase_counter % self.phases == 0:\n                    self.phase_based_adaptation(groups[group_id], lb, ub, phase_counter)\n                    if np.random.rand() < self.coop_ratio:\n                        self.cooperative_update(groups, lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n            \n            phase_counter += 1\n\n        return best_global_position\n\n    def initialize_group(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.group_size, self.dim))\n\n    def adaptive_quantum_perturbation(self, position, lb, ub, phase_counter):\n        factor = 0.1 * (1 + phase_counter / (2 * self.phases))\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * factor\n        return np.clip(q_position, lb, ub)\n\n    def phase_based_adaptation(self, group, lb, ub, phase_counter):\n        mutation_scale = 0.05 * (1 + phase_counter / self.phases)\n        for i in range(self.group_size):\n            if np.random.rand() < 0.2:\n                mutation = (np.random.rand(self.dim) - 0.5) * mutation_scale * (ub - lb)\n                group[i] = np.clip(group[i] + mutation, lb, ub)\n        \n        for i in range(0, self.group_size, 2):\n            if i + 1 < self.group_size and np.random.rand() < 0.25:\n                crossover_point = np.random.randint(1, self.dim)\n                group[i][:crossover_point], group[i + 1][:crossover_point] = (\n                    group[i + 1][:crossover_point].copy(), group[i][:crossover_point].copy())\n\n    def cooperative_update(self, groups, lb, ub):\n        top_half = int(self.group_size / 2)\n        for group in groups:\n            best_half = np.argsort([func(position) for position in group])[:top_half]\n            for j in range(self.group_size):\n                if j not in best_half:\n                    donor = groups[np.random.randint(0, self.num_groups)][np.random.randint(0, self.group_size)]\n                    group[j] = np.clip(donor + np.random.normal(0, 0.1, self.dim), lb, ub)", "name": "QICMSO", "description": "Quantum-Inspired Cooperative Multi-Swarm Optimization (QICMSO): Enhances exploration and convergence by incorporating adaptive quantum perturbation and cooperative inter-group communication within dynamic multi-phase optimization.", "configspace": "", "generation": 39, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "8930c79f-8361-411a-8940-02cbdbe47ba2", "metadata": {}, "mutation_prompt": null}
{"id": "a4a15059-e9c1-47a4-b1f6-e4d4ae913a45", "solution": "import numpy as np\n\nclass AQC_PSO:\n    def __init__(self, budget, dim, num_particles=30, inertia=0.5, cognitive=1.5, social=1.5, quantum_prob=0.1, crossover_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = num_particles\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.crossover_prob = crossover_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        positions = self.initialize_positions(lb, ub)\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.array([float('inf')] * self.num_particles)\n\n        while self.evaluations < self.budget:\n            for i in range(self.num_particles):\n                if np.random.rand() < self.quantum_prob:\n                    positions[i] = self.quantum_perturbation(positions[i], lb, ub)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (personal_best_positions[i] - positions[i]) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - positions[i] if best_global_position is not None else 0))\n                \n                if np.random.rand() < self.crossover_prob:\n                    partner_idx = np.random.randint(self.num_particles)\n                    crossover_point = np.random.randint(1, self.dim)\n                    velocities[i][:crossover_point], velocities[partner_idx][:crossover_point] = (\n                        velocities[partner_idx][:crossover_point].copy(), velocities[i][:crossover_point].copy())\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                value = func(positions[i])\n                self.evaluations += 1\n\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = positions[i]\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = positions[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n    \n    def initialize_positions(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.num_particles, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)", "name": "AQC_PSO", "description": "Adaptive Quantum-Crossover Particle Swarm Optimization (AQC-PSO): Combines quantum perturbations with adaptive crossover-enhanced velocity updates for dynamic exploration and exploitation.", "configspace": "", "generation": 40, "fitness": 0.7169182327933572, "feedback": "The algorithm AQC_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01.", "error": "", "parent_id": "8930c79f-8361-411a-8940-02cbdbe47ba2", "metadata": {"aucs": [0.7254963997048463, 0.7083400658818682]}, "mutation_prompt": null}
{"id": "68e0eaf6-eeb7-4c68-ab68-8daffb3641a7", "solution": "import numpy as np\n\nclass AQEBIMPS:\n    def __init__(self, budget, dim, num_groups=4, group_size=10, inertia=0.4, cognitive=1.5, social=1.5, initial_quantum_prob=0.15, phases=3, quantum_adjustment=0.05):\n        self.budget = budget\n        self.dim = dim\n        self.num_groups = num_groups\n        self.group_size = group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = initial_quantum_prob\n        self.phases = phases\n        self.quantum_adjustment = quantum_adjustment\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        groups = [self.initialize_group(lb, ub) for _ in range(self.num_groups)]\n        velocities = [np.random.uniform(-1, 1, (self.group_size, self.dim)) for _ in range(self.num_groups)]\n\n        phase_counter = 0\n\n        while self.evaluations < self.budget:\n            for group_id in range(self.num_groups):\n                for i in range(self.group_size):\n                    position = groups[group_id][i]\n                    prev_position = position.copy()\n                    \n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[group_id][i] = (self.inertia * velocities[group_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (groups[group_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[group_id][i], lb, ub)\n                    groups[group_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if value < func(prev_position):\n                        self.quantum_prob = min(1.0, self.quantum_prob + self.quantum_adjustment)\n                    else:\n                        self.quantum_prob = max(0.0, self.quantum_prob - self.quantum_adjustment)\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                if phase_counter % self.phases == 0:\n                    self.phase_based_adaptation(groups[group_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n            \n            phase_counter += 1\n\n        return best_global_position\n\n    def initialize_group(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def phase_based_adaptation(self, group, lb, ub):\n        for i in range(self.group_size):\n            if np.random.rand() < 0.2:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.05 * (ub - lb)\n                group[i] = np.clip(group[i] + mutation, lb, ub)\n        \n        for i in range(0, self.group_size, 2):\n            if i + 1 < self.group_size and np.random.rand() < 0.25:\n                crossover_point = np.random.randint(1, self.dim)\n                group[i][:crossover_point], group[i + 1][:crossover_point] = (\n                    group[i + 1][:crossover_point].copy(), group[i][:crossover_point].copy())", "name": "AQEBIMPS", "description": "Quantum-Enhanced Bio-Inspired Multi-Phase Search with Adaptive Quantum Probability (AQEBIMPS): Enhances QEBIMPS by dynamically adjusting quantum perturbation probability based on exploration success, optimizing convergence efficiency.", "configspace": "", "generation": 41, "fitness": 0.7349736832572351, "feedback": "The algorithm AQEBIMPS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00.", "error": "", "parent_id": "8930c79f-8361-411a-8940-02cbdbe47ba2", "metadata": {"aucs": [0.7329618726060527, 0.7369854939084174]}, "mutation_prompt": null}
{"id": "0ef33dde-2d72-4480-a1ae-cf57936b6d43", "solution": "import numpy as np\n\nclass HQASO:\n    def __init__(self, budget, dim, harmony_memory_size=10, swarm_size=30, quantum_prob=0.2, adaptation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = harmony_memory_size\n        self.swarm_size = swarm_size\n        self.quantum_prob = quantum_prob\n        self.adaptation_rate = adaptation_rate\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = [self.initialize_solution(lb, ub) for _ in range(self.harmony_memory_size)]\n        harmony_values = [func(harmony) for harmony in harmony_memory]\n        global_best_index = np.argmin(harmony_values)\n        best_global_position = harmony_memory[global_best_index].copy()\n        best_global_value = harmony_values[global_best_index]\n\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        positions = self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.quantum_prob:\n                    positions[i] = self.quantum_perturbation(positions[i], lb, ub)\n                \n                if np.random.rand() < 0.5:\n                    harmony_choice = harmony_memory[np.random.choice(self.harmony_memory_size)]\n                    new_position = np.clip(positions[i] + self.adaptation_rate * (harmony_choice - positions[i]), lb, ub)\n                else:\n                    new_position = np.clip(positions[i] + velocities[i], lb, ub)\n\n                value = func(new_position)\n                self.evaluations += 1\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = new_position.copy()\n\n                if value < harmony_values[global_best_index]:\n                    global_best_index = np.argmin(harmony_values)\n                    harmony_memory[global_best_index] = new_position\n                    harmony_values[global_best_index] = value\n\n                velocities[i] = self.adaptive_velocity_update(positions[i], best_global_position, harmony_memory, velocities[i], lb, ub)\n                positions[i] = new_position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_solution(self, lb, ub):\n        return np.random.uniform(lb, ub, self.dim)\n\n    def initialize_swarm(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def adaptive_velocity_update(self, position, best_global_position, harmony_memory, velocity, lb, ub):\n        inertia = 0.5\n        cognitive = 1.5\n        social = 1.5\n        harmony_influence = np.random.rand() * (harmony_memory[np.random.choice(self.harmony_memory_size)] - position)\n        cognitive_component = cognitive * np.random.random(self.dim) * (position - best_global_position)\n        social_component = social * np.random.random(self.dim) * harmony_influence\n        new_velocity = inertia * velocity + cognitive_component + social_component\n        return np.clip(new_velocity, -1, 1)", "name": "HQASO", "description": "Harmony-Guided Quantum-Inspired Adaptive Swarm Optimization (HQASO): Combines harmony search principles with quantum-inspired particle updates and dynamic role adaptation for robust and efficient global optimization.", "configspace": "", "generation": 42, "fitness": 0.4292016531639964, "feedback": "The algorithm HQASO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.01.", "error": "", "parent_id": "8930c79f-8361-411a-8940-02cbdbe47ba2", "metadata": {"aucs": [0.4179342500790886, 0.4404690562489042]}, "mutation_prompt": null}
{"id": "862145c6-75a5-41ee-8e99-0ca2c317a42f", "solution": "import numpy as np\n\nclass MEQES:\n    def __init__(self, budget, dim, ensemble_size=5, pop_size=20, quantum_rate=0.2, mutation_rate=0.1, crossover_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.ensemble_size = ensemble_size\n        self.pop_size = pop_size\n        self.quantum_rate = quantum_rate\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n\n        ensembles = [self.initialize_population(lb, ub) for _ in range(self.ensemble_size)]\n        global_best_value = float('inf')\n\n        while self.evaluations < self.budget:\n            for ensemble in ensembles:\n                for individual in range(self.pop_size):\n                    if np.random.rand() < self.quantum_rate:\n                        self.quantum_perturbation(ensemble, individual, lb, ub)\n\n                    value = func(ensemble[individual])\n                    self.evaluations += 1\n\n                    if value < best_value:\n                        best_value = value\n                        best_position = ensemble[individual]\n\n                    if value < global_best_value:\n                        global_best_value = value\n                        self.adapt_strategy(ensemble, individual)\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                self.crossover(ensemble, lb, ub)\n                self.mutate(ensemble, lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def quantum_perturbation(self, ensemble, individual, lb, ub):\n        perturbation = (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        ensemble[individual] = np.clip(ensemble[individual] + perturbation, lb, ub)\n\n    def mutate(self, ensemble, lb, ub):\n        for i in range(self.pop_size):\n            if np.random.rand() < self.mutation_rate:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.05 * (ub - lb)\n                ensemble[i] = np.clip(ensemble[i] + mutation, lb, ub)\n\n    def crossover(self, ensemble, lb, ub):\n        for i in range(0, self.pop_size, 2):\n            if i + 1 < self.pop_size and np.random.rand() < self.crossover_rate:\n                crossover_point = np.random.randint(1, self.dim)\n                ensemble[i][:crossover_point], ensemble[i + 1][:crossover_point] = (\n                    ensemble[i + 1][:crossover_point].copy(), ensemble[i][:crossover_point].copy())\n\n    def adapt_strategy(self, ensemble, individual):\n        # Dynamic adaptation logic based on individual performance\n        quantum_adjustment = 0.05 * np.random.rand()\n        self.quantum_rate = max(0.05, min(0.3, self.quantum_rate + quantum_adjustment))", "name": "MEQES", "description": "Multi-Ensemble Quantum Evolutionary Search (MEQES): Leverages multiple ensembles with quantum-enhanced evolutionary strategies and dynamic adaptation to explore and exploit the search space efficiently.", "configspace": "", "generation": 43, "fitness": 0.6403546572328586, "feedback": "The algorithm MEQES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64 with standard deviation 0.04.", "error": "", "parent_id": "8930c79f-8361-411a-8940-02cbdbe47ba2", "metadata": {"aucs": [0.5994325100456201, 0.681276804420097]}, "mutation_prompt": null}
{"id": "32ef030a-adb3-4ce6-b94f-11a4fa6ab49d", "solution": "import numpy as np\n\nclass HSEA_QE:\n    def __init__(self, budget, dim, swarm_size=20, inertia=0.5, cognitive=1.5, social=1.5, mutation_rate=0.1, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.mutation_rate = mutation_rate\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_values = np.full(self.swarm_size, np.inf)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.quantum_prob:\n                    positions[i] = self.quantum_perturbation(positions[i], lb, ub)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (personal_best_positions[i] - positions[i]) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - positions[i] if best_global_position is not None else 0))\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                value = func(positions[i])\n                self.evaluations += 1\n\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = positions[i].copy()\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = positions[i].copy()\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.evolve_population(positions, lb, ub)\n\n        return best_global_position\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def evolve_population(self, positions, lb, ub):\n        for i in range(0, self.swarm_size, 2):\n            if i + 1 < self.swarm_size:\n                crossover_point = np.random.randint(1, self.dim)\n                if np.random.rand() < 0.5:\n                    positions[i][:crossover_point], positions[i + 1][:crossover_point] = (\n                        positions[i + 1][:crossover_point].copy(), positions[i][:crossover_point].copy())\n\n                if np.random.rand() < self.mutation_rate:\n                    positions[i] = self.mutate(positions[i], lb, ub)\n                    positions[i + 1] = self.mutate(positions[i + 1], lb, ub)\n\n    def mutate(self, position, lb, ub):\n        mutation = (np.random.rand(self.dim) - 0.5) * 0.05 * (ub - lb)\n        return np.clip(position + mutation, lb, ub)", "name": "HSEA_QE", "description": "Hybrid Swarm-Evolutionary Algorithm with Adaptive Quantum Exploration (HSEA-QE): Combines principles of particle swarm optimization, evolutionary strategies, and adaptive quantum-inspired exploration for robust optimization across varied landscapes.", "configspace": "", "generation": 44, "fitness": 0.8371652827026411, "feedback": "The algorithm HSEA_QE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84 with standard deviation 0.01.", "error": "", "parent_id": "8930c79f-8361-411a-8940-02cbdbe47ba2", "metadata": {"aucs": [0.8251523663515126, 0.8491781990537697]}, "mutation_prompt": null}
{"id": "af919773-17d7-4767-be74-ef99eb2683e3", "solution": "import numpy as np\n\nclass QCMAPE:\n    def __init__(self, budget, dim, num_groups=4, group_size=10, inertia=0.4, cognitive=1.5, social=1.5, quantum_prob=0.15, phases=3, cooperation_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.num_groups = num_groups\n        self.group_size = group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.phases = phases\n        self.cooperation_factor = cooperation_factor\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        groups = [self.initialize_group(lb, ub) for _ in range(self.num_groups)]\n        velocities = [np.random.uniform(-1, 1, (self.group_size, self.dim)) for _ in range(self.num_groups)]\n        phase_counter = 0\n\n        while self.evaluations < self.budget:\n            # Cooperative behavior across groups\n            if phase_counter % (self.phases * 2) == 0:\n                self.cooperative_transfer(groups)\n\n            for group_id in range(self.num_groups):\n                local_best_position = None\n                local_best_value = float('inf')\n                \n                for i in range(self.group_size):\n                    position = groups[group_id][i]\n                    \n                    # Quantum perturbation with adaptive scaling\n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub, phase_counter)\n                    \n                    velocities[group_id][i] = (self.inertia * velocities[group_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (groups[group_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[group_id][i], lb, ub)\n                    groups[group_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < local_best_value:\n                        local_best_value = value\n                        local_best_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                # Update global best if better local found\n                if local_best_value < best_global_value:\n                    best_global_value = local_best_value\n                    best_global_position = local_best_position\n\n                if phase_counter % self.phases == 0:\n                    self.phase_based_adaptation(groups[group_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n            \n            phase_counter += 1\n\n        return best_global_position\n\n    def initialize_group(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub, phase_counter):\n        scale = 0.1 * (0.9 ** (phase_counter // self.phases))\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * scale\n        return np.clip(q_position, lb, ub)\n\n    def phase_based_adaptation(self, group, lb, ub):\n        for i in range(self.group_size):\n            if np.random.rand() < 0.2:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.05 * (ub - lb)\n                group[i] = np.clip(group[i] + mutation, lb, ub)\n        \n        for i in range(0, self.group_size, 2):\n            if i + 1 < self.group_size and np.random.rand() < 0.25:\n                crossover_point = np.random.randint(1, self.dim)\n                group[i][:crossover_point], group[i + 1][:crossover_point] = (\n                    group[i + 1][:crossover_point].copy(), group[i][:crossover_point].copy())\n\n    def cooperative_transfer(self, groups):\n        for group in groups:\n            if np.random.rand() < self.cooperation_factor:\n                partner_group = groups[np.random.randint(0, len(groups))]\n                partner = partner_group[np.random.randint(0, self.group_size)]\n                recipient = group[np.random.randint(0, self.group_size)]\n                crossover_point = np.random.randint(1, self.dim)\n                recipient[:crossover_point] = partner[:crossover_point].copy()", "name": "QCMAPE", "description": "Quantum-Cooperative Multi-Phase Adaptive Exploration (QCMAPE): Enhances QEBIMPS with cooperative agents and adaptive exploration-intensification balancing for improved convergence.", "configspace": "", "generation": 45, "fitness": 0.9571328785133091, "feedback": "The algorithm QCMAPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96 with standard deviation 0.02.", "error": "", "parent_id": "8930c79f-8361-411a-8940-02cbdbe47ba2", "metadata": {"aucs": [0.9414363078127213, 0.9728294492138968]}, "mutation_prompt": null}
{"id": "250e43c8-884c-41d4-9296-7e4db9999122", "solution": "import numpy as np\n\nclass MOQPS:\n    def __init__(self, budget, dim, num_groups=4, group_size=10, inertia=0.5, cognitive=1.5, social=1.5, quantum_prob=0.2, cooperation_factor=0.6, archive_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.num_groups = num_groups\n        self.group_size = group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.cooperation_factor = cooperation_factor\n        self.archive_size = archive_size\n        self.evaluations = 0\n        self.archive = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        groups = [self.initialize_group(lb, ub) for _ in range(self.num_groups)]\n        velocities = [np.random.uniform(-1, 1, (self.group_size, self.dim)) for _ in range(self.num_groups)]\n        \n        while self.evaluations < self.budget:\n            self.update_archive(groups, func)\n            \n            for group_id in range(self.num_groups):\n                local_best_position = None\n                local_best_value = float('inf')\n                \n                for i in range(self.group_size):\n                    position = groups[group_id][i]\n                    \n                    if np.random.rand() < self.quantum_prob:\n                        position = self.adaptive_quantum_perturbation(position, lb, ub, len(self.archive))\n                    \n                    velocities[group_id][i] = (self.inertia * velocities[group_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (groups[group_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[group_id][i], lb, ub)\n                    groups[group_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < local_best_value:\n                        local_best_value = value\n                        local_best_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                if local_best_value < best_global_value:\n                    best_global_value = local_best_value\n                    best_global_position = local_best_position\n\n                if self.evaluations >= self.budget:\n                    break\n\n            if np.random.rand() < self.cooperation_factor:\n                self.cooperative_transfer(groups)\n\n        return best_global_position\n\n    def initialize_group(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.group_size, self.dim))\n\n    def adaptive_quantum_perturbation(self, position, lb, ub, archive_length):\n        if archive_length == 0:\n            scale = 0.1\n        else:\n            scale = 0.1 * (0.9 ** (archive_length / self.archive_size))\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * scale\n        return np.clip(q_position, lb, ub)\n\n    def cooperative_transfer(self, groups):\n        for group in groups:\n            if np.random.rand() < self.cooperation_factor:\n                partner_group = groups[np.random.randint(0, len(groups))]\n                partner = partner_group[np.random.randint(0, self.group_size)]\n                recipient = group[np.random.randint(0, self.group_size)]\n                crossover_point = np.random.randint(1, self.dim)\n                recipient[:crossover_point] = partner[:crossover_point].copy()\n\n    def update_archive(self, groups, func):\n        for group in groups:\n            for individual in group:\n                value = func(individual)\n                if len(self.archive) < self.archive_size:\n                    self.archive.append((individual, value))\n                else:\n                    self.archive.sort(key=lambda x: x[1])\n                    if value < self.archive[-1][1]:\n                        self.archive[-1] = (individual, value)", "name": "MOQPS", "description": "Multi-Objective Adaptive Quantum Particle Swarm (MOQPS): Integrates multi-objective optimization concepts with adaptive quantum perturbations to balance exploration and exploitation for global optimization in photonic structures.", "configspace": "", "generation": 46, "fitness": 0.8594182184715808, "feedback": "The algorithm MOQPS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.86 with standard deviation 0.03.", "error": "", "parent_id": "af919773-17d7-4767-be74-ef99eb2683e3", "metadata": {"aucs": [0.8883863292867643, 0.8304501076563973]}, "mutation_prompt": null}
{"id": "c9ea4ea9-23bb-4035-8dea-b348c0c78cae", "solution": "import numpy as np\n\nclass QCMAPE_DGI:\n    def __init__(self, budget, dim, num_groups=4, group_size=10, inertia=0.4, cognitive=1.5, social=1.5, quantum_prob=0.15, phases=3, cooperation_factor=0.5, subgroup_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.num_groups = num_groups\n        self.group_size = group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.phases = phases\n        self.cooperation_factor = cooperation_factor\n        self.subgroup_factor = subgroup_factor\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        groups = [self.initialize_group(lb, ub) for _ in range(self.num_groups)]\n        velocities = [np.random.uniform(-1, 1, (self.group_size, self.dim)) for _ in range(self.num_groups)]\n        phase_counter = 0\n\n        while self.evaluations < self.budget:\n            # Dynamic subgroup interaction\n            if phase_counter % (self.phases * 2) == 0:\n                self.dynamic_subgroup_transfer(groups)\n\n            for group_id in range(self.num_groups):\n                local_best_position = None\n                local_best_value = float('inf')\n                \n                for i in range(self.group_size):\n                    position = groups[group_id][i]\n                    \n                    # Quantum perturbation with adaptive scaling\n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub, phase_counter)\n                    \n                    velocities[group_id][i] = (self.inertia * velocities[group_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (groups[group_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[group_id][i], lb, ub)\n                    groups[group_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < local_best_value:\n                        local_best_value = value\n                        local_best_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                # Update global best if better local found\n                if local_best_value < best_global_value:\n                    best_global_value = local_best_value\n                    best_global_position = local_best_position\n\n                if phase_counter % self.phases == 0:\n                    self.phase_based_adaptation(groups[group_id], lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n            \n            phase_counter += 1\n\n        return best_global_position\n\n    def initialize_group(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub, phase_counter):\n        scale = 0.1 * (0.9 ** (phase_counter // self.phases))\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * scale\n        return np.clip(q_position, lb, ub)\n\n    def phase_based_adaptation(self, group, lb, ub):\n        for i in range(self.group_size):\n            if np.random.rand() < 0.2:\n                mutation = (np.random.rand(self.dim) - 0.5) * 0.05 * (ub - lb)\n                group[i] = np.clip(group[i] + mutation, lb, ub)\n        \n        for i in range(0, self.group_size, 2):\n            if i + 1 < self.group_size and np.random.rand() < 0.25:\n                crossover_point = np.random.randint(1, self.dim)\n                group[i][:crossover_point], group[i + 1][:crossover_point] = (\n                    group[i + 1][:crossover_point].copy(), group[i][:crossover_point].copy())\n\n    def dynamic_subgroup_transfer(self, groups):\n        for group in groups:\n            if np.random.rand() < self.cooperation_factor:\n                subgroup_size = int(self.subgroup_factor * self.group_size)\n                subgroup_indices = np.random.choice(self.group_size, size=subgroup_size, replace=False)\n                partner_group = groups[np.random.randint(0, len(groups))]\n                partner_indices = np.random.choice(self.group_size, size=subgroup_size, replace=False)\n\n                for si, pi in zip(subgroup_indices, partner_indices):\n                    recipient = group[si]\n                    partner = partner_group[pi]\n                    crossover_point = np.random.randint(1, self.dim)\n                    recipient[:crossover_point] = partner[:crossover_point].copy()", "name": "QCMAPE_DGI", "description": "Quantum-Cooperative Multi-Phase Adaptive Exploration with Dynamic Group Interaction (QCMAPE-DGI): Improves group interactions through dynamic subgrouping and adaptive cooperation to enhance convergence speed and stability in complex search spaces.", "configspace": "", "generation": 47, "fitness": 0.9291755035063943, "feedback": "The algorithm QCMAPE_DGI got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.02.", "error": "", "parent_id": "af919773-17d7-4767-be74-ef99eb2683e3", "metadata": {"aucs": [0.9116998543307032, 0.9466511526820854]}, "mutation_prompt": null}
{"id": "fe097cd7-aa98-4710-8065-118d9e4bc25f", "solution": "import numpy as np\n\nclass QEASS:\n    def __init__(self, budget, dim, num_spheres=5, points_per_sphere=8, sphere_radius=0.1, quantum_prob=0.2, cooperation_rate=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.num_spheres = num_spheres\n        self.points_per_sphere = points_per_sphere\n        self.sphere_radius = sphere_radius\n        self.quantum_prob = quantum_prob\n        self.cooperation_rate = cooperation_rate\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        spheres = [self.initialize_sphere(lb, ub) for _ in range(self.num_spheres)]\n        sphere_centers = [np.mean(sphere, axis=0) for sphere in spheres]\n\n        while self.evaluations < self.budget:\n            for sphere_id in range(self.num_spheres):\n                local_best_position = None\n                local_best_value = float('inf')\n\n                for i in range(self.points_per_sphere):\n                    position = spheres[sphere_id][i]\n\n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < local_best_value:\n                        local_best_value = value\n                        local_best_position = position\n\n                    if value < best_global_value:\n                        best_global_value = value\n                        best_global_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                if local_best_value < best_global_value:\n                    best_global_value = local_best_value\n                    best_global_position = local_best_position\n\n                # Adaptive sphere expansion and contraction\n                if local_best_value < best_global_value:\n                    self.sphere_radius *= 1.1\n                else:\n                    self.sphere_radius *= 0.9\n\n                # Cooperative adaptation\n                if np.random.rand() < self.cooperation_rate:\n                    self.cooperative_transfer(spheres, sphere_id)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_sphere(self, lb, ub):\n        center = np.random.uniform(lb, ub, self.dim)\n        return [self.random_point_in_sphere(center, lb, ub) for _ in range(self.points_per_sphere)]\n\n    def random_point_in_sphere(self, center, lb, ub):\n        direction = np.random.normal(0, 1, self.dim)\n        direction /= np.linalg.norm(direction)\n        point = center + direction * self.sphere_radius * np.random.rand()\n        return np.clip(point, lb, ub)\n\n    def quantum_perturbation(self, position, lb, ub):\n        scale = np.random.rand()\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * scale\n        return np.clip(q_position, lb, ub)\n\n    def cooperative_transfer(self, spheres, current_id):\n        target_id = np.random.choice([i for i in range(self.num_spheres) if i != current_id])\n        exchange_point = np.random.randint(self.points_per_sphere)\n        spheres[current_id][exchange_point], spheres[target_id][exchange_point] = spheres[target_id][exchange_point], spheres[current_id][exchange_point]", "name": "QEASS", "description": "Quantum-Enhanced Adaptive Spherical Search (QEASS): Combines adaptive spherical neighborhood exploration with quantum perturbation and cooperative adaptation to efficiently optimize diverse problem landscapes.", "configspace": "", "generation": 48, "fitness": 0.45280946990676774, "feedback": "The algorithm QEASS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.45 with standard deviation 0.02.", "error": "", "parent_id": "af919773-17d7-4767-be74-ef99eb2683e3", "metadata": {"aucs": [0.4349497272053503, 0.4706692126081852]}, "mutation_prompt": null}
{"id": "da52b7d2-3e1b-4f88-a004-2704dc78b450", "solution": "import numpy as np\n\nclass QCDHE:\n    def __init__(self, budget, dim, num_nodes=5, node_size=20, inertia=0.5, cognitive=1.4, social=1.4, quantum_prob=0.2, hyperedge_prob=0.3, cooperation_intensity=0.6):\n        self.budget = budget\n        self.dim = dim\n        self.num_nodes = num_nodes\n        self.node_size = node_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.hyperedge_prob = hyperedge_prob\n        self.cooperation_intensity = cooperation_intensity\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        nodes = [self.initialize_node(lb, ub) for _ in range(self.num_nodes)]\n        velocities = [np.random.uniform(-1, 1, (self.node_size, self.dim)) for _ in range(self.num_nodes)]\n\n        while self.evaluations < self.budget:\n            self.dynamic_hypergraph_adaptation(nodes)\n\n            for node_id in range(self.num_nodes):\n                local_best_position = None\n                local_best_value = float('inf')\n                \n                for i in range(self.node_size):\n                    position = nodes[node_id][i]\n                    \n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n                    \n                    velocities[node_id][i] = (self.inertia * velocities[node_id][i] +\n                                              self.cognitive * np.random.random(self.dim) * (nodes[node_id][i] - position) +\n                                              self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[node_id][i], lb, ub)\n                    nodes[node_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < local_best_value:\n                        local_best_value = value\n                        local_best_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                if local_best_value < best_global_value:\n                    best_global_value = local_best_value\n                    best_global_position = local_best_position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_node(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.node_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        scale = 0.1\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * scale\n        return np.clip(q_position, lb, ub)\n\n    def dynamic_hypergraph_adaptation(self, nodes):\n        for i in range(len(nodes)):\n            if np.random.rand() < self.hyperedge_prob:\n                hyper_edge = np.random.choice(len(nodes), size=int(self.num_nodes * self.cooperation_intensity), replace=False)\n                for h_node in hyper_edge:\n                    recipient = nodes[i][np.random.randint(0, self.node_size)]\n                    donor = nodes[h_node][np.random.randint(0, self.node_size)]\n                    crossover_point = np.random.randint(1, self.dim)\n                    recipient[:crossover_point] = donor[:crossover_point].copy()", "name": "QCDHE", "description": "Quantum-Cooperative Dynamic Hypergraph Exploration (QCDHE): Utilizes dynamic hypergraph topology for population structuring, enhancing information flow and convergence speed through quantum perturbations and cooperative hyperedge adaptations.", "configspace": "", "generation": 49, "fitness": 0.7407244932282286, "feedback": "The algorithm QCDHE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.00.", "error": "", "parent_id": "af919773-17d7-4767-be74-ef99eb2683e3", "metadata": {"aucs": [0.7443917473950551, 0.7370572390614023]}, "mutation_prompt": null}
{"id": "f605bc21-617a-4cc9-938f-afa2caf94954", "solution": "import numpy as np\n\nclass AQPS_EDG:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, quantum_prob=0.2, entropy_factor=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.entropy_factor = entropy_factor\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_count = max(2, int(self.entropy_factor * self.dim))\n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_count, group_size, lb, ub)\n        velocities = self.initialize_velocities(group_count, group_size)\n\n        while self.evaluations < self.budget:\n            entropy = self.calculate_entropy(particles)\n            adaptive_group_count = max(2, int(self.entropy_factor * entropy * self.dim))\n\n            for group_id in range(adaptive_group_count):\n                local_best_position = None\n                local_best_value = float('inf')\n                \n                for i in range(group_size):\n                    position = particles[group_id][i]\n                    \n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n\n                    velocities[group_id][i] = (self.inertia * velocities[group_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (particles[group_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[group_id][i], lb, ub)\n                    particles[group_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n\n                    if value < local_best_value:\n                        local_best_value = value\n                        local_best_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                if local_best_value < best_global_value:\n                    best_global_value = local_best_value\n                    best_global_position = local_best_position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_count, group_size, lb, ub):\n        return [np.random.uniform(lb, ub, (group_size, self.dim)) for _ in range(group_count)]\n\n    def initialize_velocities(self, group_count, group_size):\n        return [np.random.uniform(-1, 1, (group_size, self.dim)) for _ in range(group_count)]\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def calculate_entropy(self, particles):\n        flat_positions = np.concatenate(particles).flatten()\n        hist, _ = np.histogram(flat_positions, bins='auto', density=True)\n        hist = hist[hist > 0]\n        return -np.sum(hist * np.log(hist))", "name": "AQPS_EDG", "description": "Adaptive Quantum Particle Swarm with Entropy-Based Dynamic Grouping (AQPS-EDG): Introduces entropy-based dynamic grouping and adaptive quantum perturbations to enhance diversity and convergence.", "configspace": "", "generation": 50, "fitness": 0.9573996354952863, "feedback": "The algorithm AQPS_EDG got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96 with standard deviation 0.00.", "error": "", "parent_id": "af919773-17d7-4767-be74-ef99eb2683e3", "metadata": {"aucs": [0.9593598686999086, 0.955439402290664]}, "mutation_prompt": null}
{"id": "d5795863-29e5-4ec3-849d-861c4cdf86b6", "solution": "import numpy as np\n\nclass QPSTEE:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, quantum_prob=0.2, entropy_factor=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.entropy_factor = entropy_factor\n        self.evaluations = 0\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_count = max(2, int(self.entropy_factor * self.dim))\n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_count, group_size, lb, ub)\n        velocities = self.initialize_velocities(group_count, group_size)\n\n        while self.evaluations < self.budget:\n            entropy = self.calculate_entropy(particles)\n            temporal_entropy = self.calculate_temporal_entropy(entropy)\n\n            adaptive_group_count = max(2, int(self.entropy_factor * temporal_entropy * self.dim))\n\n            for group_id in range(adaptive_group_count):\n                local_best_position = None\n                local_best_value = float('inf')\n                \n                for i in range(group_size):\n                    position = particles[group_id][i]\n                    \n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n\n                    velocities[group_id][i] = (self.inertia * velocities[group_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (particles[group_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[group_id][i], lb, ub)\n                    particles[group_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n                    self.history.append(value)\n\n                    if value < local_best_value:\n                        local_best_value = value\n                        local_best_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                if local_best_value < best_global_value:\n                    best_global_value = local_best_value\n                    best_global_position = local_best_position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_count, group_size, lb, ub):\n        return [np.random.uniform(lb, ub, (group_size, self.dim)) for _ in range(group_count)]\n\n    def initialize_velocities(self, group_count, group_size):\n        return [np.random.uniform(-1, 1, (group_size, self.dim)) for _ in range(group_count)]\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def calculate_entropy(self, particles):\n        flat_positions = np.concatenate(particles).flatten()\n        hist, _ = np.histogram(flat_positions, bins='auto', density=True)\n        hist = hist[hist > 0]\n        return -np.sum(hist * np.log(hist))\n\n    def calculate_temporal_entropy(self, current_entropy):\n        if not self.history:\n            return current_entropy\n        diff_entropy = np.abs(np.diff(self.history[-min(len(self.history), 10):]))\n        mean_diff = np.mean(diff_entropy) if diff_entropy.size > 0 else 0\n        return current_entropy * (1 + mean_diff)", "name": "QPSTEE", "description": "Quantum Particle Swarm with Temporal Entropy Exploration (QPSTEE): Enhances AQPS-EDG by incorporating temporal entropy to adaptively control exploration and exploitation over time.", "configspace": "", "generation": 51, "fitness": 0.9300750810582796, "feedback": "The algorithm QPSTEE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.00.", "error": "", "parent_id": "f605bc21-617a-4cc9-938f-afa2caf94954", "metadata": {"aucs": [0.9285898725972068, 0.9315602895193523]}, "mutation_prompt": null}
{"id": "7fb4556f-2df2-4e96-8e36-a438c91def3d", "solution": "import numpy as np\n\nclass Enhanced_AQPS_EDG:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, quantum_prob=0.2, entropy_factor=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.entropy_factor = entropy_factor\n        self.evaluations = 0\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_count = max(2, int(self.entropy_factor * self.dim))\n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_count, group_size, lb, ub)\n        velocities = self.initialize_velocities(group_count, group_size)\n\n        while self.evaluations < self.budget:\n            entropy = self.calculate_entropy(particles)\n            adaptive_group_count = max(2, int(self.entropy_factor * entropy * self.dim))\n            \n            # Dynamic parameter adjustment based on historical performance\n            if self.evaluations > 0 and self.evaluations % (self.budget // 10) == 0:\n                self.adjust_parameters()\n\n            for group_id in range(adaptive_group_count):\n                local_best_position = None\n                local_best_value = float('inf')\n                \n                for i in range(group_size):\n                    position = particles[group_id][i]\n                    \n                    if np.random.rand() < self.quantum_prob:\n                        position = self.quantum_perturbation(position, lb, ub)\n\n                    velocities[group_id][i] = (self.inertia * velocities[group_id][i] +\n                                               self.cognitive * np.random.random(self.dim) * (particles[group_id][i] - position) +\n                                               self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                    position = np.clip(position + velocities[group_id][i], lb, ub)\n                    particles[group_id][i] = position\n\n                    value = func(position)\n                    self.evaluations += 1\n                    self.history.append(value)\n\n                    if value < local_best_value:\n                        local_best_value = value\n                        local_best_position = position\n\n                    if self.evaluations >= self.budget:\n                        break\n\n                if local_best_value < best_global_value:\n                    best_global_value = local_best_value\n                    best_global_position = local_best_position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_count, group_size, lb, ub):\n        return [np.random.uniform(lb, ub, (group_size, self.dim)) for _ in range(group_count)]\n\n    def initialize_velocities(self, group_count, group_size):\n        return [np.random.uniform(-1, 1, (group_size, self.dim)) for _ in range(group_count)]\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def calculate_entropy(self, particles):\n        flat_positions = np.concatenate(particles).flatten()\n        hist, _ = np.histogram(flat_positions, bins='auto', density=True)\n        hist = hist[hist > 0]\n        return -np.sum(hist * np.log(hist))\n\n    def adjust_parameters(self):\n        # Analyze history to adjust parameters\n        recent_history = self.history[-(self.budget // 10):]\n        improvement = np.mean(recent_history) - np.min(self.history)\n        \n        if improvement < 0.01:  # If there's little improvement\n            self.quantum_prob = min(0.9, self.quantum_prob + 0.1)  # Increase exploration\n            self.inertia = max(0.1, self.inertia - 0.1)  # Decrease inertia for more particle movement\n        else:\n            self.quantum_prob = max(0.1, self.quantum_prob - 0.1)  # Reduce exploration\n            self.inertia = min(0.9, self.inertia + 0.1)  # Increase inertia to stabilize particles", "name": "Enhanced_AQPS_EDG", "description": "Enhanced AQPS-EDG with Memory-Based Adaptive Control: Incorporates historical performance analysis for dynamic adaptation of algorithm parameters to improve convergence and exploration balance.", "configspace": "", "generation": 52, "fitness": 0.9338604222411135, "feedback": "The algorithm Enhanced_AQPS_EDG got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.01.", "error": "", "parent_id": "f605bc21-617a-4cc9-938f-afa2caf94954", "metadata": {"aucs": [0.9480896617695279, 0.9196311827126993]}, "mutation_prompt": null}
{"id": "3ca7bf4d-66d6-4b40-aef1-b8e6e871953e", "solution": "import numpy as np\nfrom collections import deque\n\nclass HTS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)", "name": "HTS_PSO", "description": "Hybrid TS-PSO (HTS-PSO): Integrates Tabu Search with Particle Swarm Optimization by using adaptive memory structures to exploit promising regions and enhance convergence.", "configspace": "", "generation": 53, "fitness": 0.9596513710211325, "feedback": "The algorithm HTS_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96 with standard deviation 0.00.", "error": "", "parent_id": "f605bc21-617a-4cc9-938f-afa2caf94954", "metadata": {"aucs": [0.9635555770861577, 0.9557471649561072]}, "mutation_prompt": null}
{"id": "369afa68-5b93-49da-b77c-2fb2d627f782", "solution": "import numpy as np\nfrom collections import deque\n\nclass Enhanced_HTS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2, adaptivity_factor=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.adaptivity_factor = adaptivity_factor\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            adaptive_inertia = self.inertia * (1 - self.evaluations / self.budget)\n            adaptive_social = self.social * (1 + (self.evaluations / self.budget))\n            \n            for i in range(group_size):\n                position = particles[i]\n\n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                velocities[i] = (adaptive_inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 adaptive_social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n            group_size = int(self.base_group_size * (1 + self.adaptivity_factor * (self.evaluations / self.budget)))\n            if group_size > len(particles):\n                new_particles = self.initialize_particles(group_size - len(particles), lb, ub)\n                particles = np.vstack((particles, new_particles))\n                new_velocities = self.initialize_velocities(group_size - len(velocities))\n                velocities = np.vstack((velocities, new_velocities))\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)", "name": "Enhanced_HTS_PSO", "description": "Enhanced HTS_PSO with Dynamic Group Size and Adaptive Velocity for improved convergence and exploitation of promising regions in photonic structures optimization.", "configspace": "", "generation": 54, "fitness": 0.9499090415487095, "feedback": "The algorithm Enhanced_HTS_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95 with standard deviation 0.01.", "error": "", "parent_id": "3ca7bf4d-66d6-4b40-aef1-b8e6e871953e", "metadata": {"aucs": [0.9428652990808779, 0.9569527840165409]}, "mutation_prompt": null}
{"id": "66a5a323-84a6-4a04-bfa4-ac99aa5db25b", "solution": "import numpy as np\nfrom collections import deque\n\nclass QETS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, initial_inertia=0.9, final_inertia=0.4, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.initial_inertia = initial_inertia\n        self.final_inertia = final_inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            inertia = self.compute_inertia(self.evaluations, self.budget)\n            \n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                velocities[i] = (inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.2\n        return np.clip(q_position, lb, ub)\n\n    def compute_inertia(self, current_eval, max_eval):\n        return self.initial_inertia - (self.initial_inertia - self.final_inertia) * (current_eval / max_eval)", "name": "QETS_PSO", "description": "Quantum Enhanced Tabu Search-PSO (QETS-PSO): Employs quantum perturbation in Tabu Search and adaptive parameter control in PSO to improve exploration and convergence speed.", "configspace": "", "generation": 55, "fitness": 0.7597530681714983, "feedback": "The algorithm QETS_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.76 with standard deviation 0.02.", "error": "", "parent_id": "3ca7bf4d-66d6-4b40-aef1-b8e6e871953e", "metadata": {"aucs": [0.7430793612869127, 0.7764267750560842]}, "mutation_prompt": null}
{"id": "c296fd5f-e47f-4638-930d-66ba991b932f", "solution": "import numpy as np\nfrom collections import deque\n\nclass Enhanced_HTS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                \n                # Dynamic velocity scaling\n                velocities[i] *= np.exp(-0.5 * (self.evaluations / self.budget))\n                position = np.clip(position + velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Dynamic group size adjustment\n            if self.evaluations % (self.budget // 10) == 0:\n                group_size = min(self.base_group_size + (self.evaluations // (self.budget // 10)), self.base_group_size * 2)\n                particles = self.initialize_particles(group_size, lb, ub)\n                velocities = self.initialize_velocities(group_size)\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)", "name": "Enhanced_HTS_PSO", "description": "Enhanced HTS-PSO with dynamic group size and velocity scaling for improved exploration-exploitation balance and convergence acceleration.", "configspace": "", "generation": 56, "fitness": 0.9558612599748845, "feedback": "The algorithm Enhanced_HTS_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96 with standard deviation 0.00.", "error": "", "parent_id": "3ca7bf4d-66d6-4b40-aef1-b8e6e871953e", "metadata": {"aucs": [0.9586831745333447, 0.9530393454164242]}, "mutation_prompt": null}
{"id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "solution": "import numpy as np\nfrom collections import deque\n\nclass Enhanced_HTS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate(best_global_value)\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget)))", "name": "Enhanced_HTS_PSO", "description": "Enhanced HTS_PSO with Adaptive Learning Rate: Dynamically adjusts learning rates based on convergence progress to improve exploration and exploitation balance.", "configspace": "", "generation": 57, "fitness": 0.9614579141998599, "feedback": "The algorithm Enhanced_HTS_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.96 with standard deviation 0.02.", "error": "", "parent_id": "3ca7bf4d-66d6-4b40-aef1-b8e6e871953e", "metadata": {"aucs": [0.9781451726137114, 0.9447706557860085]}, "mutation_prompt": null}
{"id": "b3201a91-1637-483f-acb0-eea741801ff4", "solution": "import numpy as np\nfrom collections import deque\n\nclass Quantum_Swarm_GA:\n    def __init__(self, budget, dim, population_size=20, crossover_prob=0.7, mutation_prob=0.1, quantum_prob=0.3, memory_size=10):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.crossover_prob = crossover_prob\n        self.mutation_prob = mutation_prob\n        self.quantum_prob = quantum_prob\n        self.memory_size = memory_size\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        population = self.initialize_population(self.population_size, lb, ub)\n        \n        while self.evaluations < self.budget:\n            new_population = []\n            \n            for _ in range(self.population_size // 2):\n                parent1, parent2 = self.select_parents(population, func)\n                offspring1, offspring2 = self.crossover(parent1, parent2)\n                \n                offspring1 = self.mutate(offspring1, lb, ub)\n                offspring2 = self.mutate(offspring2, lb, ub)\n                \n                if np.random.rand() < self.quantum_prob:\n                    offspring1 = self.quantum_perturbation(offspring1, lb, ub)\n                if np.random.rand() < self.quantum_prob:\n                    offspring2 = self.quantum_perturbation(offspring2, lb, ub)\n                \n                new_population.extend([offspring1, offspring2])\n\n            population = new_population\n\n            for individual in population:\n                if tuple(individual) in self.tabu_list:\n                    continue\n\n                value = func(individual)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(individual))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = individual\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n    \n    def initialize_population(self, population_size, lb, ub):\n        return np.random.uniform(lb, ub, (population_size, self.dim))\n\n    def select_parents(self, population, func):\n        indices = np.random.choice(range(len(population)), size=2, replace=False)\n        return population[indices[0]], population[indices[1]]\n\n    def crossover(self, parent1, parent2):\n        if np.random.rand() < self.crossover_prob:\n            point = np.random.randint(1, self.dim)\n            offspring1 = np.concatenate((parent1[:point], parent2[point:]))\n            offspring2 = np.concatenate((parent2[:point], parent1[point:]))\n        else:\n            offspring1, offspring2 = parent1, parent2\n        return offspring1, offspring2\n\n    def mutate(self, individual, lb, ub):\n        if np.random.rand() < self.mutation_prob:\n            mutation_vector = np.random.normal(0, 0.1, self.dim)\n            individual = np.clip(individual + mutation_vector, lb, ub)\n        return individual\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)", "name": "Quantum_Swarm_GA", "description": "Quantum-Swarm Genetic Algorithm (QSGA): Integrates quantum-inspired perturbations and genetic crossover operators to enhance diversification and convergence in global optimization tasks.", "configspace": "", "generation": 58, "fitness": 0.5585332289622795, "feedback": "The algorithm Quantum_Swarm_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.56 with standard deviation 0.06.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.6158098986315057, 0.5012565592930535]}, "mutation_prompt": null}
{"id": "c9013e9b-3624-4342-875d-664dd2bf732b", "solution": "import numpy as np\nfrom collections import deque\n\nclass Quantum_Enhanced_HTS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n        self.dynamic_grouping = True\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n        particle_best_positions = np.copy(particles)\n        particle_best_values = np.full(group_size, float('inf'))\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_tunneling(position, lb, ub)\n\n                self.update_learning_rate(best_global_value)\n                self.update_inertia()\n\n                neighborhood_best_position = self.get_neighborhood_best(particles, particle_best_values)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particle_best_positions[i] - position) +\n                                 self.social * np.random.random(self.dim) * (neighborhood_best_position - position))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < particle_best_values[i]:\n                    particle_best_values[i] = value\n                    particle_best_positions[i] = position\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_tunneling(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.2\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget)))\n\n    def update_inertia(self):\n        self.inertia = 0.9 - 0.7 * (self.evaluations / self.budget)\n\n    def get_neighborhood_best(self, particles, particle_best_values):\n        if self.dynamic_grouping:\n            idx = np.random.choice(len(particles))\n            return particles[np.argmin(particle_best_values)]\n        return np.mean(particles, axis=0)", "name": "Quantum_Enhanced_HTS_PSO", "description": "Quantum-Enhanced HTS_PSO with Adaptive Inertia and Dynamic Neighborhoods: Incorporates quantum tunneling and dynamic subgrouping to balance exploration and exploitation more effectively.", "configspace": "", "generation": 59, "fitness": 0.8405428161470418, "feedback": "The algorithm Quantum_Enhanced_HTS_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.84 with standard deviation 0.01.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.828311871548801, 0.8527737607452825]}, "mutation_prompt": null}
{"id": "12295252-e03e-49f4-b732-532ea7094a10", "solution": "import numpy as np\nfrom collections import deque\n\nclass Enhanced_Quantum_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate(best_global_value)\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n            # Dynamically adjust group size based on progress\n            if self.evaluations % (self.budget // 10) == 0:\n                group_size = min(len(particles) * 2, self.budget - self.evaluations + 1)\n                particles = self.initialize_particles(group_size, lb, ub)\n                velocities = self.initialize_velocities(group_size)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget)))", "name": "Enhanced_Quantum_PSO", "description": "Enhanced Quantum PSO with Adaptive Group Size and Memory-based Perturbation: Incorporates dynamic group size adjustments and memory-driven position perturbations to enhance exploration efficiency and convergence speed.", "configspace": "", "generation": 60, "fitness": 0.7806093053333942, "feedback": "The algorithm Enhanced_Quantum_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.78 with standard deviation 0.00.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.7774282760209246, 0.7837903346458639]}, "mutation_prompt": null}
{"id": "cdcd201e-f4a5-4a2e-9dd5-9091855acd14", "solution": "import numpy as np\nfrom collections import deque\n\nclass QuantumEnhancedSA:\n    def __init__(self, budget, dim, initial_temp=100, cooling_rate=0.99, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_position = self.initialize_position(lb, ub)\n        current_value = func(current_position)\n        best_position = current_position\n        best_value = current_value\n        temperature = self.initial_temp\n        \n        while self.evaluations < self.budget:\n            new_position = self.generate_neighbor(current_position, lb, ub)\n            new_value = func(new_position)\n            self.evaluations += 1\n            self.tabu_list.append(tuple(new_position))\n\n            if new_value < best_value or self.acceptance_probability(current_value, new_value, temperature) > np.random.rand():\n                current_position = new_position\n                current_value = new_value\n                if new_value < best_value:\n                    best_value = new_value\n                    best_position = new_position\n\n            temperature *= self.cooling_rate\n\n            if self.evaluations >= self.budget:\n                break\n        \n        return best_position\n\n    def initialize_position(self, lb, ub):\n        return np.random.uniform(lb, ub, self.dim)\n\n    def generate_neighbor(self, position, lb, ub):\n        if np.random.rand() < self.quantum_prob:\n            return self.quantum_perturbation(position, lb, ub)\n        return np.clip(position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1, lb, ub)\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def acceptance_probability(self, current_value, new_value, temperature):\n        if new_value < current_value:\n            return 1.0\n        return np.exp((current_value - new_value) / max(temperature, 1e-10))", "name": "QuantumEnhancedSA", "description": "Quantum-Enhanced Simulated Annealing with Memory: Integrates quantum perturbation and memory-based tabu search into simulated annealing to enhance exploration and exploitation capabilities.", "configspace": "", "generation": 61, "fitness": 0.5431733576671047, "feedback": "The algorithm QuantumEnhancedSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.54 with standard deviation 0.00.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.5453032310690211, 0.5410434842651883]}, "mutation_prompt": null}
{"id": "5aef2f68-75d5-4033-bf57-f355eb9ceaa0", "solution": "import numpy as np\n\nclass QIADE:\n    def __init__(self, budget, dim, population_size=50, crossover_rate=0.9, beta_min=0.2, beta_max=0.8, gamma=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.crossover_rate = crossover_rate\n        self.beta_min = beta_min\n        self.beta_max = beta_max\n        self.gamma = gamma\n        self.evaluations = 0\n        self.adaptive_mutation = lambda t: self.beta_min + (self.beta_max - self.beta_min) * np.exp(-self.gamma * t)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_position = None\n        best_value = float('inf')\n        mutation_factor = self.beta_max\n\n        while self.evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                x1, x2, x3 = population[np.random.choice(self.population_size, 3, replace=False)]\n                mutant_vector = x1 + mutation_factor * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, population[i])\n                trial_vector = np.clip(trial_vector, lb, ub)\n\n                trial_value = func(trial_vector)\n                self.evaluations += 1\n\n                if trial_value < func(population[i]):\n                    new_population.append(trial_vector)\n                    if trial_value < best_value:\n                        best_value = trial_value\n                        best_position = trial_vector\n                else:\n                    new_population.append(population[i])\n\n            population = np.array(new_population)\n            mutation_factor = self.adaptive_mutation(self.evaluations / self.budget)\n\n        return best_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))", "name": "QIADE", "description": "Quantum-Inspired Adaptive Differential Evolution (QIADE): Leverages quantum superposition and adaptive mutation to enhance exploration and exploitation in high-dimensional search spaces.", "configspace": "", "generation": 62, "fitness": 0.7045795399066008, "feedback": "The algorithm QIADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.06.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.6436938342246141, 0.7654652455885874]}, "mutation_prompt": null}
{"id": "036f37a7-2ff3-4368-909b-c6cafe76b0a9", "solution": "import numpy as np\n\nclass QADE:\n    def __init__(self, budget, dim, population_size=20, F_min=0.4, F_max=0.9, CR=0.9, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F_min = F_min\n        self.F_max = F_max\n        self.CR = CR\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_value = float('inf')\n        best_position = None\n        \n        while self.evaluations < self.budget:\n            new_population = []\n            F = self.adaptive_scaling_factor()\n            \n            for i in range(self.population_size):\n                x = population[i]\n                a, b, c = population[np.random.choice(self.population_size, 3, replace=False)]\n                mutant = a + F * (b - c)\n                trial = self.crossover(x, mutant, lb, ub)\n\n                if np.random.rand() < self.quantum_prob:\n                    trial = self.quantum_perturbation(trial, lb, ub)\n\n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < func(x):\n                    new_population.append(trial)\n                    if trial_value < best_value:\n                        best_value = trial_value\n                        best_position = trial\n                else:\n                    new_population.append(x)\n\n                if self.evaluations >= self.budget:\n                    break\n\n            population = new_population\n\n        return best_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def adaptive_scaling_factor(self):\n        return self.F_min + (self.F_max - self.F_min) * (1 - (self.evaluations / self.budget))\n\n    def crossover(self, target, mutant, lb, ub):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return np.clip(trial, lb, ub)\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)", "name": "QADE", "description": "Quantum-Inspired Adaptive Differential Evolution (QADE): Integrates quantum-inspired position updates with adaptive control parameters to enhance exploration and exploitation.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('only integer scalar arrays can be converted to a scalar index').", "error": "TypeError('only integer scalar arrays can be converted to a scalar index')", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {}, "mutation_prompt": null}
{"id": "1231bc7e-0bde-4557-910a-9e2f2c3b80c6", "solution": "import numpy as np\nfrom collections import deque\n\nclass Adaptive_Quantum_PSOTabu:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, initial_memory_size=5, quantum_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = initial_memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate(best_global_value)\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n                    # Dynamically adjust tabu memory size based on convergence\n                    self.memory_size = max(2, min(10, int(self.memory_size * 1.1)))\n                    self.tabu_list = deque(self.tabu_list, maxlen=self.memory_size)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget)))", "name": "Adaptive_Quantum_PSOTabu", "description": "Adaptive Quantum-Enhanced PSO with Dynamic Tabu Memory: Integrates quantum-inspired perturbations with dynamic tabu memory adjustments for enhanced exploration and convergence efficiency.", "configspace": "", "generation": 64, "fitness": 0.9338507554291273, "feedback": "The algorithm Adaptive_Quantum_PSOTabu got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.93 with standard deviation 0.02.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.9155283004472816, 0.952173210410973]}, "mutation_prompt": null}
{"id": "b169e95d-df34-451d-a915-051366489262", "solution": "import numpy as np\nfrom collections import deque\n\nclass Adaptive_Quantum_Swarm:\n    def __init__(self, budget, dim, swarm_size=15, inertia=0.7, cognitive=1.4, social=1.4, memory_size=5, quantum_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.6\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        particles = self.initialize_particles(lb, ub)\n        velocities = self.initialize_velocities()\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.adaptive_quantum_perturbation(position, lb, ub, particles)\n\n                self.update_learning_rate()\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n\n    def initialize_velocities(self):\n        return np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n\n    def adaptive_quantum_perturbation(self, position, lb, ub, particles):\n        neighbor_avg = np.mean(particles, axis=0)\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05 + (neighbor_avg - position) * 0.05\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self):\n        self.learning_rate = max(0.2, min(0.9, 0.6 * (1.0 - self.evaluations / self.budget)))", "name": "Adaptive_Quantum_Swarm", "description": "Adaptive Quantum Swarm Optimization: Integrates adaptive quantum perturbation with swarm intelligence to enhance exploration and exploitation in complex search spaces.", "configspace": "", "generation": 65, "fitness": 0.8921844423334946, "feedback": "The algorithm Adaptive_Quantum_Swarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.01.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.877804285718166, 0.9065645989488232]}, "mutation_prompt": null}
{"id": "8dc901d2-69b6-49c5-8c06-66da2e662c98", "solution": "import numpy as np\n\nclass QuantumSwarmDE:\n    def __init__(self, budget, dim, population_size=20, mutation_factor=0.8, crossover_rate=0.9, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.mutation_factor = mutation_factor\n        self.crossover_rate = crossover_rate\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        scores = np.array([func(individual) for individual in population])\n        self.evaluations += self.population_size\n        \n        while self.evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.quantum_prob:\n                    candidate = self.quantum_perturbation(population[i], lb, ub)\n                else:\n                    candidate = self.mutate_and_crossover(i, population, scores, lb, ub)\n                candidate_score = func(candidate)\n                self.evaluations += 1\n\n                if candidate_score < scores[i]:\n                    new_population.append(candidate)\n                    scores[i] = candidate_score\n                else:\n                    new_population.append(population[i])\n\n                if self.evaluations >= self.budget:\n                    break\n\n            population = new_population\n\n        best_idx = np.argmin(scores)\n        return population[best_idx]\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate_and_crossover(self, idx, population, scores, lb, ub):\n        candidates = list(range(self.population_size))\n        candidates.remove(idx)\n        a, b, c = np.random.choice(candidates, 3, replace=False)\n        mutant = np.clip(population[a] + self.mutation_factor * (population[b] - population[c]), lb, ub)\n        crossover = np.random.rand(self.dim) < self.crossover_rate\n        trial = np.where(crossover, mutant, population[idx])\n        return trial\n\n    def quantum_perturbation(self, individual, lb, ub):\n        q_individual = individual + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_individual, lb, ub)", "name": "QuantumSwarmDE", "description": "Quantum-Swarm Differential Evolution (QSDE): Combines quantum perturbations with differential evolution for dynamic balance between exploration and exploitation.", "configspace": "", "generation": 66, "fitness": 0.881574096398321, "feedback": "The algorithm QuantumSwarmDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.88 with standard deviation 0.00.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.8830925049440326, 0.8800556878526092]}, "mutation_prompt": null}
{"id": "29ea8665-a493-401a-8cfb-bd81f927bf6a", "solution": "import numpy as np\nfrom collections import deque\n\nclass Hybrid_QPS_APG:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            adaptive_group_size = self.adjust_group_size(group_size)\n            for i in range(adaptive_group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub, func, best_global_position)\n\n                self.update_learning_rate(best_global_value)\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub, func, best_position):\n        scale = (func(bounds=best_position) - func(bounds=position)) / max(func(bounds=position), 1e-9)\n        q_position = position + (np.random.rand(self.dim) - 0.5) * scale * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget)))\n\n    def adjust_group_size(self, base_size):\n        factor = 0.5 + 0.5 * (1 - self.evaluations / self.budget)\n        return max(2, int(base_size * factor))", "name": "Hybrid_QPS_APG", "description": "Hybrid Quantum Perturbation Strategy with Adaptive Particle Grouping: Integrates quantum-inspired perturbations and dynamic group size adjustments to enhance exploration and exploitation across varying solution landscapes.", "configspace": "", "generation": 67, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('__call__(): incompatible function arguments. The following argument types are supported:\\n    1. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[float]) -> float\\n    2. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[List[float]]) -> List[float]\\n\\nInvoked with: <RealSingleObjectiveProblem 1121. ellipsometry (iid=1 dim=2)>; kwargs: bounds=array([  2.25834754, 109.31263671])').", "error": "TypeError('__call__(): incompatible function arguments. The following argument types are supported:\\n    1. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[float]) -> float\\n    2. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[List[float]]) -> List[float]\\n\\nInvoked with: <RealSingleObjectiveProblem 1121. ellipsometry (iid=1 dim=2)>; kwargs: bounds=array([  2.25834754, 109.31263671])')", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {}, "mutation_prompt": null}
{"id": "bc696e86-1a1d-4c9b-8e49-da17349ba6f4", "solution": "import numpy as np\n\nclass Quantum_Dynamic_Hypercube:\n    def __init__(self, budget, dim, base_group_size=10, quantum_prob=0.2, exploration_factor=0.5):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.exploration_factor = exploration_factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = np.random.uniform(lb, ub, self.dim)\n        best_global_value = func(best_global_position)\n        self.evaluations += 1\n\n        hypercubes = self.initialize_hypercubes(self.base_group_size, lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.base_group_size):\n                center = hypercubes[i]['center']\n                size = hypercubes[i]['size']\n\n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(center, size, lb, ub)\n                else:\n                    position = np.random.uniform(center - size / 2, center + size / 2)\n\n                position = np.clip(position, lb, ub)\n                value = func(position)\n                self.evaluations += 1\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.adapt_hypercubes(hypercubes, best_global_position, lb, ub)\n\n        return best_global_position\n\n    def initialize_hypercubes(self, group_size, lb, ub):\n        hypercubes = []\n        for _ in range(group_size):\n            center = np.random.uniform(lb, ub, self.dim)\n            size = (ub - lb) * self.exploration_factor\n            hypercubes.append({'center': center, 'size': size})\n        return hypercubes\n\n    def quantum_perturbation(self, center, size, lb, ub):\n        q_position = center + np.random.uniform(-size / 2, size / 2)\n        return np.clip(q_position, lb, ub)\n\n    def adapt_hypercubes(self, hypercubes, best_global_position, lb, ub):\n        for hypercube in hypercubes:\n            center = hypercube['center']\n            direction = best_global_position - center\n            hypercube['center'] = center + direction * self.exploration_factor\n            hypercube['center'] = np.clip(hypercube['center'], lb, ub)", "name": "Quantum_Dynamic_Hypercube", "description": "Quantum-Inspired Dynamic Hypercube Optimization - Utilizes dynamic hypercube regions for adaptive search space partitioning and quantum-inspired principles for exploration.", "configspace": "", "generation": 68, "fitness": 0.663362418340711, "feedback": "The algorithm Quantum_Dynamic_Hypercube got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.03.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.6979790608224766, 0.6287457758589452]}, "mutation_prompt": null}
{"id": "55ed3d68-b040-4c6d-a72a-9ee88c75bcab", "solution": "import numpy as np\n\nclass QuantumAnnealed_APSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, quantum_prob=0.2, initial_temp=100, cooling_rate=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.initial_temp = initial_temp\n        self.cooling_rate = cooling_rate\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        particles = self.initialize_particles(self.base_group_size, lb, ub)\n        velocities = self.initialize_velocities(self.base_group_size)\n        temperatures = np.full(self.base_group_size, self.initial_temp)\n\n        while self.evaluations < self.budget:\n            for i in range(self.base_group_size):\n                position = particles[i]\n\n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * np.subtract(particles[i], position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                \n                new_position = np.clip(position + velocities[i], lb, ub)\n\n                if self.acceptance_probability(func(position), func(new_position), temperatures[i]) > np.random.rand():\n                    position = new_position\n                    particles[i] = position\n\n                value = func(position)\n                self.evaluations += 1\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                temperatures[i] *= self.cooling_rate\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def acceptance_probability(self, old_cost, new_cost, temperature):\n        if new_cost < old_cost:\n            return 1.0\n        return np.exp((old_cost - new_cost) / temperature)", "name": "QuantumAnnealed_APSO", "description": "Quantum-Annealed Adaptive Particle Swarm Optimization (QA-APSO): Integrates quantum perturbation and simulated annealing to enhance exploration and convergence in dynamic environments.", "configspace": "", "generation": 69, "fitness": 0.8972104717728915, "feedback": "The algorithm QuantumAnnealed_APSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.90 with standard deviation 0.00.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.8942040439023876, 0.9002168996433952]}, "mutation_prompt": null}
{"id": "fc439cf0-bc59-474c-aeaf-854426674af7", "solution": "import numpy as np\nfrom collections import deque\n\nclass Hybrid_Quantum_Adaptive_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2, annealing_rate=0.95):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.annealing_rate = annealing_rate\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n        self.temperature = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate(best_global_value)\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n                elif np.random.rand() < self.simulated_annealing(value, best_global_value):\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.temperature *= self.annealing_rate\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget)))\n\n    def simulated_annealing(self, candidate_value, current_best_value):\n        return np.exp((current_best_value - candidate_value) / self.temperature)", "name": "Hybrid_Quantum_Adaptive_PSO", "description": "Hybrid Quantum Adaptive PSO: Integrates simulated annealing for escape from local minima, dynamically adjusts learning rates, and employs quantum perturbation for enhanced exploration.", "configspace": "", "generation": 70, "fitness": 0.5566190427379136, "feedback": "The algorithm Hybrid_Quantum_Adaptive_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.56 with standard deviation 0.10.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.46127258674054683, 0.6519654987352805]}, "mutation_prompt": null}
{"id": "c8215a87-6c9c-40b5-846a-133087ffc9ac", "solution": "import numpy as np\n\nclass AQIFA:\n    def __init__(self, budget, dim, num_fireflies=20, absorption=1.0, attractiveness=0.5, beta_min=0.2, quantum_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.num_fireflies = num_fireflies\n        self.absorption = absorption\n        self.attractiveness = attractiveness\n        self.beta_min = beta_min\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        fireflies = self.initialize_fireflies(lb, ub)\n        intensities = np.array([func(firefly) for firefly in fireflies])\n        self.evaluations += self.num_fireflies\n        \n        while self.evaluations < self.budget:\n            for i in range(self.num_fireflies):\n                for j in range(self.num_fireflies):\n                    if intensities[i] > intensities[j]:\n                        distance = np.linalg.norm(fireflies[i] - fireflies[j])\n                        beta = self.beta_min + (self.attractiveness - self.beta_min) * np.exp(-self.absorption * distance**2)\n                        fireflies[i] += beta * (fireflies[j] - fireflies[i]) + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n                        fireflies[i] = np.clip(fireflies[i], lb, ub)\n                        \n                        if np.random.rand() < self.quantum_prob:\n                            fireflies[i] = self.quantum_perturbation(fireflies[i], lb, ub)\n                        \n                        new_intensity = func(fireflies[i])\n                        self.evaluations += 1\n                        \n                        if new_intensity < intensities[i]:\n                            intensities[i] = new_intensity\n\n                        if self.evaluations >= self.budget:\n                            break\n\n        best_index = np.argmin(intensities)\n        return fireflies[best_index]\n\n    def initialize_fireflies(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.num_fireflies, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)", "name": "AQIFA", "description": "Adaptive Quantum-Inspired Firefly Algorithm (AQIFA): Enhances exploration and exploitation by combining quantum perturbations and adaptive attractiveness based on convergence progress.", "configspace": "", "generation": 71, "fitness": 0.7525470359115227, "feedback": "The algorithm AQIFA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.02.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.7766341741560986, 0.728459897666947]}, "mutation_prompt": null}
{"id": "b833a41b-e485-40c7-a2d2-af445fe42b8a", "solution": "import numpy as np\nfrom collections import deque\n\nclass Quantum_Adaptive_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia_min=0.4, inertia_max=0.9, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia_min = inertia_min\n        self.inertia_max = inertia_max\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.inertia = self.inertia_max\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_inertia()\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_inertia(self):\n        self.inertia = self.inertia_max - ((self.inertia_max - self.inertia_min) * (self.evaluations / self.budget))", "name": "Quantum_Adaptive_PSO", "description": "Quantum-Inspired Adaptive PSO: Integrates quantum perturbation and dynamic inertia adjustment to enhance exploitation and exploration in high-dimensional spaces.", "configspace": "", "generation": 72, "fitness": 0.7908815614243965, "feedback": "The algorithm Quantum_Adaptive_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.79 with standard deviation 0.07.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.7185226102834414, 0.8632405125653515]}, "mutation_prompt": null}
{"id": "150cae6d-211f-4215-b52b-d34ce8bbd677", "solution": "import numpy as np\nfrom collections import deque\n\nclass QEM_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.7, cognitive=1.4, social=1.4, momentum_factor=0.9, quantum_prob=0.15):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.momentum_factor = momentum_factor\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=5)\n        self.momentum = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n        self.momentum = np.zeros((group_size, self.dim))\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_tunneling(position, lb, ub)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                \n                self.momentum[i] = self.momentum_factor * self.momentum[i] + (1 - self.momentum_factor) * velocities[i]\n                position = np.clip(position + self.momentum[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_tunneling(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.2\n        return np.clip(q_position, lb, ub)", "name": "QEM_PSO", "description": "Quantum-Enhanced Momentum Particle Swarm Optimizer (QEM-PSO): Integrates momentum and quantum tunneling for enhanced global search capabilities in dynamic environments.", "configspace": "", "generation": 73, "fitness": 0.5590605251417599, "feedback": "The algorithm QEM_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.56 with standard deviation 0.01.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.5503790396977977, 0.567742010585722]}, "mutation_prompt": null}
{"id": "aa39c494-f22b-4b67-a91a-193380c8e3e3", "solution": "import numpy as np\n\nclass AQIDE:\n    def __init__(self, budget, dim, population_size=20, F=0.5, CR=0.9, quantum_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F\n        self.CR = CR\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_global_value = float('inf')\n        best_global_position = None\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                # Crossover\n                trial = np.copy(population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n\n                # Quantum-inspired perturbation\n                if np.random.rand() < self.quantum_prob:\n                    trial = self.quantum_perturbation(trial, lb, ub)\n\n                # Selection\n                f_trial = func(trial)\n                self.evaluations += 1\n                f_target = func(population[i])\n                if f_trial < f_target:\n                    population[i] = trial\n                    if f_trial < best_global_value:\n                        best_global_value = f_trial\n                        best_global_position = trial\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        perturbation = (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        q_position = position + perturbation\n        return np.clip(q_position, lb, ub)", "name": "AQIDE", "description": "Adaptive Quantum-Inspired Differential Evolution (AQIDE): Combines differential evolution with adaptive quantum perturbation to enhance exploration and convergence in complex landscapes.", "configspace": "", "generation": 74, "fitness": 0.8927495598643742, "feedback": "The algorithm AQIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.89 with standard deviation 0.03.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.919133321974802, 0.8663657977539465]}, "mutation_prompt": null}
{"id": "3c697f57-7484-4ad6-805b-74e5ea658947", "solution": "import numpy as np\n\nclass Hybrid_PSO_DE:\n    def __init__(self, budget, dim, swarm_size=20, inertia=0.5, cognitive=1.5, social=1.5, F=0.5, CR=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = swarm_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.F = F  # Differential weight\n        self.CR = CR  # Crossover probability\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = self.initialize_particles(self.swarm_size, lb, ub)\n        velocities = self.initialize_velocities(self.swarm_size)\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(self.swarm_size, np.inf)\n        global_best_position = None\n        global_best_value = np.inf\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                value = func(particles[i])\n                self.evaluations += 1\n                \n                # Update personal best\n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = np.copy(particles[i])\n\n                # Update global best\n                if value < global_best_value:\n                    global_best_value = value\n                    global_best_position = np.copy(particles[i])\n\n                # PSO update\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social * r2 * (global_best_position - particles[i] if global_best_position is not None else 0))\n                particles[i] = np.clip(particles[i] + velocities[i], lb, ub)\n\n                # DE mutation and crossover\n                if np.random.rand() < self.CR:\n                    indices = np.random.choice(self.swarm_size, 3, replace=False)\n                    donor_vector = particles[indices[0]] + self.F * (particles[indices[1]] - particles[indices[2]])\n                    mutant_vector = np.where(np.random.rand(self.dim) < self.CR, donor_vector, particles[i])\n                    particles[i] = np.clip(mutant_vector, lb, ub)\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return global_best_position\n\n    def initialize_particles(self, swarm_size, lb, ub):\n        return np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n    def initialize_velocities(self, swarm_size):\n        return np.random.uniform(-1, 1, (swarm_size, self.dim))", "name": "Hybrid_PSO_DE", "description": "Hybrid Particle-Swarm and Differential-Evolution Optimization: Combines swarm intelligence with differential mutation to enhance global exploration and local exploitation in high-dimensional spaces.", "configspace": "", "generation": 75, "fitness": 0.610955417195284, "feedback": "The algorithm Hybrid_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.61 with standard deviation 0.03.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.6426671657519958, 0.5792436686385722]}, "mutation_prompt": null}
{"id": "dacaf81a-cf6e-49b0-bb21-f352e8bfa218", "solution": "import numpy as np\nfrom collections import deque\n\nclass Quantum_Adaptive_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.7, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n        neighborhood_radius = np.linalg.norm(ub - lb) / 4\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n\n                # Quantum-inspired perturbation\n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_superposition(position, lb, ub, neighborhood_radius)\n\n                self.update_learning_rate(best_global_value)\n                \n                for j in range(group_size):\n                    if i != j and np.linalg.norm(particles[j] - position) < neighborhood_radius:\n                        velocities[i] += self.social * np.random.random(self.dim) * (particles[j] - position)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                \n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_superposition(self, position, lb, ub, neighborhood_radius):\n        perturbation = (np.random.rand(self.dim) - 0.5) * neighborhood_radius * 0.1\n        q_position = position + perturbation\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget)))", "name": "Quantum_Adaptive_PSO", "description": "Quantum-Inspired Adaptive Particle Swarm: Integrates quantum superposition principles with dynamic neighborhood adaptation and convergence-driven parameter tuning for enhanced exploration and exploitation.", "configspace": "", "generation": 76, "fitness": 0.4426528885597031, "feedback": "The algorithm Quantum_Adaptive_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.00.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.4410159019378508, 0.4442898751815554]}, "mutation_prompt": null}
{"id": "e571242e-0835-41b8-9191-508e1d8e7e41", "solution": "import numpy as np\nfrom scipy.optimize import rosen\n\nclass Quantum_Chaotic_ES:\n    def __init__(self, budget, dim, population_size=50, omega=0.5, alpha=1.5, beta=1.5, quantum_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.omega = omega\n        self.alpha = alpha\n        self.beta = beta\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        population = self.initialize_population(lb, ub)\n        velocities = self.initialize_velocities()\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if np.random.rand() < self.quantum_prob:\n                    population[i] = self.quantum_perturbation(population[i], lb, ub)\n\n                chaotic_factor = self.chaotic_map(i)\n                velocities[i] = (self.omega * velocities[i] +\n                                 self.alpha * chaotic_factor * (best_global_position - population[i]) +\n                                 self.beta * np.random.random(self.dim) * (population[np.random.randint(self.population_size)] - population[i]))\n\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                value = func(population[i])\n                self.evaluations += 1\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = population[i]\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def initialize_velocities(self):\n        return np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n\n    def chaotic_map(self, index):\n        x = np.sin(np.pi * index / self.population_size)\n        return (2 * x * (1 - x)) * (np.sin(self.evaluations / self.budget * np.pi) ** 2)", "name": "Quantum_Chaotic_ES", "description": "Quantum Chaotic Evolutionary Strategy (QCES): Integrates quantum-inspired perturbations with chaotic maps to enhance diversity and convergence in high-dimensional spaces.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {}, "mutation_prompt": null}
{"id": "e5e09d49-7ced-474b-bf5d-e52dc5b2b5b3", "solution": "import numpy as np\nfrom collections import deque\n\nclass Enhanced_Fuzzy_HTS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n        self.inertia = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate(best_global_value)\n                self.update_inertia(best_global_value)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget)))\n\n    def update_inertia(self, best_value):\n        progress = self.evaluations / self.budget\n        if progress < 0.5:\n            self.inertia = 0.9 - 0.4 * progress\n        else:\n            self.inertia = 0.5 * (1 - progress)", "name": "Enhanced_Fuzzy_HTS_PSO", "description": "Enhanced Quantum PSO with Adaptive Fuzzy Inertia: Introduces adaptive fuzzy logic to dynamically adjust inertia for better control over exploration and exploitation.", "configspace": "", "generation": 78, "fitness": 0.8637745999023707, "feedback": "The algorithm Enhanced_Fuzzy_HTS_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.86 with standard deviation 0.02.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.8450603149459714, 0.88248888485877]}, "mutation_prompt": null}
{"id": "b9848d6d-cb6c-4e10-be6c-ac725f1c4978", "solution": "import numpy as np\nfrom collections import deque\nfrom scipy.spatial import Voronoi\n\nclass AVPSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, voronoi_threshold=0.6):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.voronoi_threshold = voronoi_threshold\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.best_global_value = float('inf')\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            voronoi = Voronoi(particles)\n            for i in range(group_size):\n                position = particles[i]\n                if self.evaluations / self.budget > self.voronoi_threshold:\n                    region_index = voronoi.point_region[i]\n                    region = voronoi.regions[region_index]\n                    if region:  # Ensure the region is not empty or a point\n                        rand_vertex = np.random.choice(region)\n                        position = voronoi.vertices[rand_vertex]\n                        position = np.clip(position, lb, ub)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < self.best_global_value:\n                    self.best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))", "name": "AVPSO", "description": "Adaptive Voronoi Particle Swarm Optimization (AVPSO): Integrates Voronoi partitioning to improve exploration and identify diverse high-potential regions, enhancing convergence in complex landscapes.", "configspace": "", "generation": 79, "fitness": -Infinity, "feedback": "An exception occurred: QhullError(\"QH6154 Qhull precision error: Initial simplex is flat (facet 3 is coplanar with the interior point)\\n\\nWhile executing:  | qhull v Qbb Qz Qc\\nOptions selected for Qhull 2019.1.r 2019/06/21:\\n  run-id 1692694782  voronoi  Qbbound-last  Qz-infinity-point  Qcoplanar-keep\\n  _pre-merge  _zero-centrum  Qinterior-keep  Pgood  _max-width 7.8e-12\\n  Error-roundoff 1.3e-13  _one-merge 9.1e-13  Visible-distance 2.6e-13\\n  U-max-coplanar 2.6e-13  Width-outside 5.2e-13  _wide-facet 1.6e-12\\n  _maxoutside 1e-12\\n\\nThe input to qhull appears to be less than 3 dimensional, or a\\ncomputation has overflowed.\\n\\nQhull could not construct a clearly convex simplex from points:\\n- p10(v4):   2.2    93    93\\n- p7(v3):   2.2    93     0\\n- p5(v2):   2.2    93 1.4e-10\\n- p8(v1):   2.2    93 1.6e-10\\n\\nThe center point is coplanar with a facet, or a vertex is coplanar\\nwith a neighboring facet.  The maximum round off error for\\ncomputing distances is 1.3e-13.  The center point, facets and distances\\nto the center point are as follows:\\n\\ncenter point    2.216    93.29    23.32\\n\\nfacet p7 p5 p8 distance= -1.2\\nfacet p10 p5 p8 distance= -4.8e-13\\nfacet p10 p7 p8 distance= -4.8e-14\\nfacet p10 p7 p5 distance= -5.1e-14\\n\\nThese points either have a maximum or minimum x-coordinate, or\\nthey maximize the determinant for k coordinates.  Trial points\\nare first selected from points that maximize a coordinate.\\n\\nThe min and max coordinates for each dimension are:\\n  0:     2.216     2.216  difference= 2.052e-13\\n  1:     93.29     93.29  difference= 7.844e-12\\n  2:         0     93.29  difference= 93.29\\n\\nIf the input should be full dimensional, you have several options that\\nmay determine an initial simplex:\\n  - use 'QJ'  to joggle the input and make it full dimensional\\n  - use 'QbB' to scale the points to the unit cube\\n  - use 'QR0' to randomly rotate the input for different maximum points\\n  - use 'Qs'  to search all points for the initial simplex\\n  - use 'En'  to specify a maximum roundoff error less than 1.3e-13.\\n  - trace execution with 'T3' to see the determinant for each point.\\n\\nIf the input is lower dimensional:\\n  - use 'QJ' to joggle the input and make it full dimensional\\n  - use 'Qbk:0Bk:0' to delete coordinate k from the input.  You should\\n    pick the coordinate with the least range.  The hull will have the\\n    correct topology.\\n  - determine the flat containing the points, rotate the points\\n    into a coordinate plane, and delete the other coordinates.\\n  - add one or more points to make the input full dimensional.\\n\").", "error": "QhullError(\"QH6154 Qhull precision error: Initial simplex is flat (facet 3 is coplanar with the interior point)\\n\\nWhile executing:  | qhull v Qbb Qz Qc\\nOptions selected for Qhull 2019.1.r 2019/06/21:\\n  run-id 1692694782  voronoi  Qbbound-last  Qz-infinity-point  Qcoplanar-keep\\n  _pre-merge  _zero-centrum  Qinterior-keep  Pgood  _max-width 7.8e-12\\n  Error-roundoff 1.3e-13  _one-merge 9.1e-13  Visible-distance 2.6e-13\\n  U-max-coplanar 2.6e-13  Width-outside 5.2e-13  _wide-facet 1.6e-12\\n  _maxoutside 1e-12\\n\\nThe input to qhull appears to be less than 3 dimensional, or a\\ncomputation has overflowed.\\n\\nQhull could not construct a clearly convex simplex from points:\\n- p10(v4):   2.2    93    93\\n- p7(v3):   2.2    93     0\\n- p5(v2):   2.2    93 1.4e-10\\n- p8(v1):   2.2    93 1.6e-10\\n\\nThe center point is coplanar with a facet, or a vertex is coplanar\\nwith a neighboring facet.  The maximum round off error for\\ncomputing distances is 1.3e-13.  The center point, facets and distances\\nto the center point are as follows:\\n\\ncenter point    2.216    93.29    23.32\\n\\nfacet p7 p5 p8 distance= -1.2\\nfacet p10 p5 p8 distance= -4.8e-13\\nfacet p10 p7 p8 distance= -4.8e-14\\nfacet p10 p7 p5 distance= -5.1e-14\\n\\nThese points either have a maximum or minimum x-coordinate, or\\nthey maximize the determinant for k coordinates.  Trial points\\nare first selected from points that maximize a coordinate.\\n\\nThe min and max coordinates for each dimension are:\\n  0:     2.216     2.216  difference= 2.052e-13\\n  1:     93.29     93.29  difference= 7.844e-12\\n  2:         0     93.29  difference= 93.29\\n\\nIf the input should be full dimensional, you have several options that\\nmay determine an initial simplex:\\n  - use 'QJ'  to joggle the input and make it full dimensional\\n  - use 'QbB' to scale the points to the unit cube\\n  - use 'QR0' to randomly rotate the input for different maximum points\\n  - use 'Qs'  to search all points for the initial simplex\\n  - use 'En'  to specify a maximum roundoff error less than 1.3e-13.\\n  - trace execution with 'T3' to see the determinant for each point.\\n\\nIf the input is lower dimensional:\\n  - use 'QJ' to joggle the input and make it full dimensional\\n  - use 'Qbk:0Bk:0' to delete coordinate k from the input.  You should\\n    pick the coordinate with the least range.  The hull will have the\\n    correct topology.\\n  - determine the flat containing the points, rotate the points\\n    into a coordinate plane, and delete the other coordinates.\\n  - add one or more points to make the input full dimensional.\\n\")", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {}, "mutation_prompt": null}
{"id": "d3d7a349-6898-428d-949b-531129a4e771", "solution": "import numpy as np\nfrom collections import deque\n\nclass AGQPSO:\n    def __init__(self, budget, dim, population_size=20, crossover_prob=0.8, mutation_prob=0.1, inertia=0.5, cognitive=1.5, social=1.5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.crossover_prob = crossover_prob\n        self.mutation_prob = mutation_prob\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        particles = self.initialize_particles(lb, ub)\n        velocities = self.initialize_velocities()\n\n        while self.evaluations < self.budget:\n            new_particles = []\n            for i in range(self.population_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                new_particles.append(position)\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Apply crossover and mutation\n            for i in range(0, self.population_size, 2):\n                if i + 1 < self.population_size and np.random.rand() < self.crossover_prob:\n                    new_particles[i], new_particles[i+1] = self.crossover(new_particles[i], new_particles[i+1], lb, ub)\n                if np.random.rand() < self.mutation_prob:\n                    new_particles[i] = self.mutate(new_particles[i], lb, ub)\n            particles = new_particles\n\n        return best_global_position\n\n    def initialize_particles(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def initialize_velocities(self):\n        return np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def crossover(self, parent1, parent2, lb, ub):\n        alpha = np.random.rand(self.dim)\n        offspring1 = np.clip(alpha * parent1 + (1 - alpha) * parent2, lb, ub)\n        offspring2 = np.clip(alpha * parent2 + (1 - alpha) * parent1, lb, ub)\n        return offspring1, offspring2\n\n    def mutate(self, individual, lb, ub):\n        mutation_vector = (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(individual + mutation_vector, lb, ub)", "name": "AGQPSO", "description": "Adaptive Genetic Quantum Particle Swarm Optimization (AGQPSO): Integrates genetic algorithm operations with quantum-inspired perturbations to enhance diversity and convergence in high-dimensional spaces.", "configspace": "", "generation": 80, "fitness": 0.954678728701086, "feedback": "The algorithm AGQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95 with standard deviation 0.00.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.9589498450924224, 0.9504076123097497]}, "mutation_prompt": null}
{"id": "37d25bde-d58c-4f9e-9587-a325b075dae8", "solution": "import numpy as np\nfrom collections import deque\n\nclass Enhanced_QLearning_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n        self.q_table = np.ones((base_group_size, 2)) * 0.5\n        self.epsilon = 0.1\n        self.discount_factor = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate(i, best_global_value)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                # Q-Learning-like update\n                reward = -value\n                self.q_table[i, 1] = ((1 - self.learning_rate) * self.q_table[i, 1] + \n                                      self.learning_rate * (reward + self.discount_factor * np.max(self.q_table[i])))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, particle_index, best_value):\n        exploit_prob = self.q_table[particle_index, 1] / np.sum(self.q_table[particle_index])\n        if np.random.rand() < self.epsilon:\n            self.learning_rate = np.random.choice([0.1, 1.0])\n        else:\n            self.learning_rate = 0.1 if exploit_prob < 0.5 else 1.0", "name": "Enhanced_QLearning_PSO", "description": "Enhanced Q-Learning PSO: Integrates a Q-learning-like mechanism to adaptively adjust exploration-exploitation balance based on feedback from solution quality.", "configspace": "", "generation": 81, "fitness": 0.6652295234307194, "feedback": "The algorithm Enhanced_QLearning_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.09.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.5794310615009377, 0.7510279853605011]}, "mutation_prompt": null}
{"id": "fc0d7451-a2b5-4321-b7c8-e6eda512b8d3", "solution": "import numpy as np\nfrom collections import deque\n\nclass Enhanced_HTS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            current_group_size = self.dynamic_group_size(group_size)\n            for i in range(current_group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate(best_global_value)\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        improvement = (self.budget - self.evaluations) / self.budget\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - improvement)))\n\n    def dynamic_group_size(self, base_group_size):\n        progress_ratio = self.evaluations / self.budget\n        return max(2, int(base_group_size * (1 + 0.5 * np.sin(np.pi * progress_ratio))))", "name": "Enhanced_HTS_PSO", "description": "Enhanced_HTS_PSO with Adaptive Resource Allocation: Dynamically adjusts group sizes and learning rates based on optimization progress for improved convergence.", "configspace": "", "generation": 82, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {}, "mutation_prompt": null}
{"id": "948d1de9-34db-4863-b1ee-98e84b250bbb", "solution": "import numpy as np\nfrom collections import deque\n\nclass Hybrid_Memory_Driven_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n        self.memory_archive = []\n        self.memory_threshold = 1e-5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate(best_global_value)\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n                self.update_memory_archive(position, value)\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.dynamic_group_adjustment()\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget)))\n\n    def update_memory_archive(self, position, value):\n        # Add to memory archive if significant improvement\n        if not self.memory_archive or (self.memory_archive and value < min(v for _, v in self.memory_archive) - self.memory_threshold):\n            self.memory_archive.append((position, value))\n            self.memory_archive = sorted(self.memory_archive, key=lambda x: x[1])[:self.memory_size]\n\n    def dynamic_group_adjustment(self):\n        # Adjust group size based on diversity in memory archive\n        diversity = np.std([v for _, v in self.memory_archive]) if self.memory_archive else 0\n        if diversity < self.memory_threshold and len(self.memory_archive) >= self.memory_size:\n            self.base_group_size = max(5, self.base_group_size - 1)\n        else:\n            self.base_group_size = min(20, self.base_group_size + 1)", "name": "Hybrid_Memory_Driven_PSO", "description": "Hybrid Memory-Driven PSO: Integrates adaptive memory archive for dynamic exploration and exploitation balance with enhanced convergence precision.", "configspace": "", "generation": 83, "fitness": 0.9078396067073018, "feedback": "The algorithm Hybrid_Memory_Driven_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.91 with standard deviation 0.05.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.9596934957767769, 0.8559857176378267]}, "mutation_prompt": null}
{"id": "868de7fb-d638-4a0f-914b-c89ffb860b41", "solution": "import numpy as np\nfrom collections import deque\n\nclass Quantum_Adaptive_Grouping_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n        subgroup_size = max(2, group_size // 2)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                subgroup_best_position, subgroup_best_value = self.evaluate_subgroup(particles, func, i, subgroup_size, lb, ub)\n                \n                self.update_learning_rate(best_global_value)\n                \n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (subgroup_best_position - position))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, best_value):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget)))\n\n    def evaluate_subgroup(self, particles, func, index, subgroup_size, lb, ub):\n        subgroup_indices = np.random.choice(range(len(particles)), size=subgroup_size, replace=False)\n        subgroup_best_position = particles[subgroup_indices[0]]\n        subgroup_best_value = func(subgroup_best_position)\n        \n        for idx in subgroup_indices:\n            if idx == index:\n                continue\n            position = particles[idx]\n            if tuple(position) in self.tabu_list:\n                continue\n            value = func(position)\n            if value < subgroup_best_value:\n                subgroup_best_value = value\n                subgroup_best_position = position\n        \n        return subgroup_best_position, subgroup_best_value", "name": "Quantum_Adaptive_Grouping_PSO", "description": "Quantum Adaptive Grouping PSO: Integrates dynamic subgroup adaptation with quantum perturbation to enhance exploration and maintain diversity.", "configspace": "", "generation": 84, "fitness": 0.6641823080442999, "feedback": "The algorithm Quantum_Adaptive_Grouping_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.10.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.7641708471724864, 0.5641937689161134]}, "mutation_prompt": null}
{"id": "63061f91-ef58-4cc8-8e9f-47b4c39ced20", "solution": "import numpy as np\n\nclass QGDE:\n    def __init__(self, budget, dim, population_size=20, F=0.5, CR=0.7, quantum_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F\n        self.CR = CR\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = self.initialize_population(lb, ub)\n        best_individual = None\n        best_value = float('inf')\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                a, b, c = self.select_three_others(i)\n                mutant = np.clip(pop[a] + self.F * (pop[b] - pop[c]), lb, ub)\n                trial = self.crossover(pop[i], mutant)\n\n                if np.random.rand() < self.quantum_prob:\n                    trial = self.quantum_perturbation(trial, lb, ub)\n                \n                trial_value = func(trial)\n                self.evaluations += 1\n\n                if trial_value < self.gradient_guided_update(trial, trial_value, func):\n                    pop[i] = trial\n                    if trial_value < best_value:\n                        best_value = trial_value\n                        best_individual = trial\n\n                if self.evaluations >= self.budget:\n                    break\n        \n        return best_individual\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def select_three_others(self, current_index):\n        indices = np.array([i for i in range(self.population_size) if i != current_index])\n        return np.random.choice(indices, 3, replace=False)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.05\n        return np.clip(q_position, lb, ub)\n\n    def gradient_guided_update(self, position, value, func):\n        grad = self.estimate_gradient(position, func)\n        new_position = position - 0.01 * grad\n        new_value = func(new_position)\n        self.evaluations += 1\n        return new_value if new_value < value else value\n\n    def estimate_gradient(self, position, func, epsilon=1e-4):\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            delta = np.zeros(self.dim)\n            delta[i] = epsilon\n            grad[i] = (func(position + delta) - func(position - delta)) / (2 * epsilon)\n            self.evaluations += 2  # Two evaluations for each dimension\n        return grad", "name": "QGDE", "description": "Quantum-inspired Gradient-guided Differential Evolution: Combines quantum-inspired perturbations with gradient guidance to enhance local search and escape local minima efficiently.", "configspace": "", "generation": 85, "fitness": 0.6321377110238536, "feedback": "The algorithm QGDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.63 with standard deviation 0.03.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.6067449507894531, 0.6575304712582541]}, "mutation_prompt": null}
{"id": "89050114-6a69-4b21-ac4d-f4cb29ffbbc7", "solution": "import numpy as np\n\nclass Quantum_DE:\n    def __init__(self, budget, dim, population_size=20, F=0.5, CR=0.9, quantum_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.F = F\n        self.CR = CR\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        while self.evaluations < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                if np.random.rand() < self.quantum_prob:\n                    mutant = self.quantum_mutation(population[i], lb, ub)\n                else:\n                    mutant = self.mutation(population, i, lb, ub)\n                \n                trial = self.crossover(population[i], mutant, lb, ub)\n                value = func(trial)\n                self.evaluations += 1\n                \n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = trial\n                \n                if value < func(population[i]):\n                    new_population.append(trial)\n                else:\n                    new_population.append(population[i])\n                \n                if self.evaluations >= self.budget:\n                    break\n            \n            population = new_population\n        \n        return best_global_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def mutation(self, population, index, lb, ub):\n        indices = list(range(self.population_size))\n        indices.remove(index)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.F * (population[b] - population[c])\n        return np.clip(mutant, lb, ub)\n    \n    def crossover(self, target, mutant, lb, ub):\n        trial = np.copy(target)\n        for j in range(self.dim):\n            if np.random.rand() < self.CR:\n                trial[j] = mutant[j]\n        return np.clip(trial, lb, ub)\n    \n    def quantum_mutation(self, position, lb, ub):\n        step_size = np.random.rand(self.dim) * (ub - lb) * 0.1\n        q_position = position + step_size * np.where(np.random.rand(self.dim) < 0.5, 1, -1)\n        return np.clip(q_position, lb, ub)", "name": "Quantum_DE", "description": "Quantum-Inspired Differential Evolution with Adaptive Mutation: Combines differential evolution with quantum-inspired mechanisms to enhance exploration and adaptively adjusts mutation rates based on convergence.", "configspace": "", "generation": 86, "fitness": 0.7778404821806459, "feedback": "The algorithm Quantum_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.78 with standard deviation 0.04.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.7402855396753054, 0.8153954246859866]}, "mutation_prompt": null}
{"id": "59d0bf93-9643-4e12-99a3-1d410c12b04e", "solution": "import numpy as np\nfrom collections import deque\n\nclass Adaptive_Quantum_Boosted_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia_start=0.9, inertia_end=0.4, cognitive=1.5, social=1.5, memory_size=5, initial_quantum_prob=0.2, final_quantum_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia_start = inertia_start\n        self.inertia_end = inertia_end\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.initial_quantum_prob = initial_quantum_prob\n        self.final_quantum_prob = final_quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            inertia_weight = self.adaptive_inertia()\n            quantum_prob = self.adaptive_quantum_prob()\n            \n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def adaptive_inertia(self):\n        return self.inertia_start - (self.inertia_start - self.inertia_end) * (self.evaluations / self.budget)\n\n    def adaptive_quantum_prob(self):\n        return self.initial_quantum_prob - (self.initial_quantum_prob - self.final_quantum_prob) * (self.evaluations / self.budget)", "name": "Adaptive_Quantum_Boosted_PSO", "description": "Adaptive Quantum-Boosted PSO: Incorporates adaptive quantum-based exploration with evolving inertia and perturbation functions to enhance convergence dynamics.", "configspace": "", "generation": 87, "fitness": 0.8487859973990968, "feedback": "The algorithm Adaptive_Quantum_Boosted_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.85 with standard deviation 0.05.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.8995486357597117, 0.7980233590384819]}, "mutation_prompt": null}
{"id": "56996559-c41c-4d40-8985-557c85828827", "solution": "import numpy as np\n\nclass Adaptive_Quantum_GA:\n    def __init__(self, budget, dim, population_size=20, crossover_prob=0.7, mutation_prob=0.1, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.crossover_prob = crossover_prob\n        self.mutation_prob = mutation_prob\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution, best_value = None, float('inf')\n\n        while self.evaluations < self.budget:\n            new_population = []\n\n            for i in range(0, self.population_size, 2):\n                # Selection\n                parent1, parent2 = self.tournament_selection(population, func), self.tournament_selection(population, func)\n\n                # Crossover\n                if np.random.rand() < self.crossover_prob:\n                    offspring1, offspring2 = self.quantum_crossover(parent1, parent2, lb, ub)\n                else:\n                    offspring1, offspring2 = parent1, parent2\n\n                # Mutation\n                if np.random.rand() < self.mutation_prob:\n                    offspring1 = self.quantum_mutation(offspring1, lb, ub)\n                    offspring2 = self.quantum_mutation(offspring2, lb, ub)\n\n                if np.random.rand() < self.quantum_prob:\n                    offspring1 = self.quantum_perturbation(offspring1, lb, ub)\n                    offspring2 = self.quantum_perturbation(offspring2, lb, ub)\n\n                new_population.extend([offspring1, offspring2])\n\n            population = new_population\n\n            # Evaluate new population\n            for individual in population:\n                value = func(individual)\n                self.evaluations += 1\n\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_solution\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def tournament_selection(self, population, func):\n        tournament_size = 3\n        selected = np.random.choice(population, tournament_size)\n        best = min(selected, key=func)\n        return best\n\n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha = np.random.rand(self.dim)\n        offspring1 = alpha * parent1 + (1 - alpha) * parent2\n        offspring2 = alpha * parent2 + (1 - alpha) * parent1\n        return np.clip(offspring1, lb, ub), np.clip(offspring2, lb, ub)\n\n    def quantum_mutation(self, individual, lb, ub):\n        mutation_vector = (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(individual + mutation_vector, lb, ub)\n\n    def quantum_perturbation(self, individual, lb, ub):\n        perturbation = (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(individual + perturbation, lb, ub)", "name": "Adaptive_Quantum_GA", "description": "Adaptive Quantum Genetic Algorithm (AQGA): Introduces quantum-inspired crossover and mutation with adaptive exploration for efficient search in high-dimensional spaces.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {}, "mutation_prompt": null}
{"id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "solution": "import numpy as np\nfrom collections import deque\n\nclass Quantum_Enhanced_HTS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate()\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self):\n        diversity = np.std([np.linalg.norm(p) for p in self.tabu_list])\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget * np.tanh(diversity))))", "name": "Quantum_Enhanced_HTS_PSO", "description": "Quantum-Inspired HTS_PSO with Adaptive Dynamic Learning Rate: Integrates a dynamic learning rate and quantum perturbation to intensify global and local search efficiency.", "configspace": "", "generation": 89, "fitness": 0.9690212336162098, "feedback": "The algorithm Quantum_Enhanced_HTS_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.97 with standard deviation 0.00.", "error": "", "parent_id": "b5eb72b8-c6dc-4acc-8397-3bcf0597a40b", "metadata": {"aucs": [0.9655630402035769, 0.9724794270288429]}, "mutation_prompt": null}
{"id": "6d9731bf-2706-4444-8743-cc9f050c14f6", "solution": "import numpy as np\nfrom collections import deque\n\nclass Quantum_Enhanced_Subgroup_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n        self.phase_switch = budget // 3  # Divide the budget into three phases\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate()\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n            if self.evaluations % self.phase_switch == 0:\n                self.adapt_strategy()\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self):\n        diversity = np.std([np.linalg.norm(p) for p in self.tabu_list])\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget * np.tanh(diversity))))\n\n    def adapt_strategy(self):\n        # Switch between exploration and exploitation phases\n        if self.evaluations < self.phase_switch:\n            self.inertia = 0.7\n            self.cognitive = 1.7\n            self.social = 1.3\n        elif self.evaluations < 2 * self.phase_switch:\n            self.inertia = 0.5\n            self.cognitive = 1.5\n            self.social = 1.5\n        else:\n            self.inertia = 0.3\n            self.cognitive = 1.3\n            self.social = 1.7", "name": "Quantum_Enhanced_Subgroup_PSO", "description": "Quantum-Inspired Dynamic Subgroup PSO with Adaptive Multi-Phase Learning: Utilizes dynamic subgrouping and multi-phase learning to enhance convergence speed and exploration-exploitation balance.", "configspace": "", "generation": 90, "fitness": 0.9660460112255391, "feedback": "The algorithm Quantum_Enhanced_Subgroup_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.97 with standard deviation 0.00.", "error": "", "parent_id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "metadata": {"aucs": [0.9633534295467756, 0.9687385929043026]}, "mutation_prompt": null}
{"id": "81f64985-d52c-4bb5-82ea-d67f926dc1f1", "solution": "import numpy as np\nfrom collections import deque\n\nclass Quantum_Enhanced_DG_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2, max_group_size=20):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.max_group_size = max_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            diversity = self.calculate_diversity(particles)\n            group_size = min(self.max_group_size, self.base_group_size + int(diversity * 10))\n            particles, velocities = self.adjust_group_size(particles, velocities, group_size, lb, ub)\n\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.adaptive_perturbation(position, lb, ub, diversity)\n\n                self.update_learning_rate(diversity)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def adaptive_perturbation(self, position, lb, ub, diversity):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1 * diversity\n        return np.clip(q_position, lb, ub)\n\n    def calculate_diversity(self, particles):\n        mean_position = np.mean(particles, axis=0)\n        return np.mean([np.linalg.norm(p - mean_position) for p in particles])\n\n    def update_learning_rate(self, diversity):\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget * np.tanh(diversity))))\n\n    def adjust_group_size(self, particles, velocities, group_size, lb, ub):\n        current_size = len(particles)\n        if group_size > current_size:\n            new_particles = np.random.uniform(lb, ub, (group_size - current_size, self.dim))\n            new_velocities = np.random.uniform(-1, 1, (group_size - current_size, self.dim))\n            particles = np.vstack((particles, new_particles))\n            velocities = np.vstack((velocities, new_velocities))\n        elif group_size < current_size:\n            particles = particles[:group_size]\n            velocities = velocities[:group_size]\n        return particles, velocities", "name": "Quantum_Enhanced_DG_PSO", "description": "Quantum-Inspired Dynamic Grouping PSO with Adaptive Disturbance: Enhances convergence by dynamically adjusting group size and introducing adaptive disturbances based on diversity measures.", "configspace": "", "generation": 91, "fitness": 0.9453019734683785, "feedback": "The algorithm Quantum_Enhanced_DG_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.95 with standard deviation 0.01.", "error": "", "parent_id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "metadata": {"aucs": [0.939779239310191, 0.9508247076265661]}, "mutation_prompt": null}
{"id": "dd5cf473-a141-4d7a-adcc-903e4527116a", "solution": "import numpy as np\nfrom collections import deque\n\nclass Quantum_Enhanced_HTS_PSO_Advanced:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2, mutation_factor=0.8, min_group_size=5):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.mutation_factor = mutation_factor\n        self.min_group_size = min_group_size\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            self.adjust_group_size()\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate()\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = self.differential_mutation(position, lb, ub, particles, best_global_position)\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self):\n        diversity = np.std([np.linalg.norm(p) for p in self.tabu_list])\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget * np.tanh(diversity))))\n\n    def adjust_group_size(self):\n        if self.evaluations < self.budget / 2:\n            self.base_group_size = max(self.min_group_size, int(self.base_group_size * (1 + 0.1 * np.sin(2 * np.pi * self.evaluations / self.budget))))\n        else:\n            self.base_group_size = max(self.min_group_size, int(self.base_group_size * (1 - 0.05)))\n\n    def differential_mutation(self, position, lb, ub, particles, best_global_position):\n        idxs = np.random.choice(len(particles), 3, replace=False)\n        a, b, c = particles[idxs]\n        mutant = a + self.mutation_factor * (b - c)\n        trial = np.clip(mutant + self.mutation_factor * (best_global_position - position), lb, ub)\n        return np.where(np.random.rand(self.dim) < 0.5, trial, position)", "name": "Quantum_Enhanced_HTS_PSO_Advanced", "description": "Quantum-Enhanced HTS_PSO with Adaptive Swarm Diversity Control: Enhances convergence by dynamically adjusting swarm size and incorporating differential mutation for improved exploration.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "metadata": {}, "mutation_prompt": null}
{"id": "480aab52-b63f-4eff-9bdd-571cdce461fc", "solution": "import numpy as np\nfrom collections import deque\n\nclass Enhanced_Quantum_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2, mutation_prob=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.mutation_prob = mutation_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n\n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n\n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    position = self.adaptive_mutation(position, lb, ub)\n\n                self.update_learning_rate_and_inertia()\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def adaptive_mutation(self, position, lb, ub):\n        mutation_strength = np.random.rand(self.dim) * (ub - lb) * 0.05\n        return np.clip(position + mutation_strength * (np.random.rand(self.dim) - 0.5), lb, ub)\n\n    def update_learning_rate_and_inertia(self):\n        diversity = np.std([np.linalg.norm(p) for p in self.tabu_list]) if len(self.tabu_list) > 1 else 0\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget * np.tanh(diversity))))\n        self.inertia = 0.9 - 0.5 * (self.evaluations / self.budget * np.tanh(diversity))", "name": "Enhanced_Quantum_PSO", "description": "Enhanced Quantum PSO with Adaptive Mutation and Dynamic Diversity Control: Introduces adaptive mutation based on diversity and dynamic inertia to balance exploration and exploitation across the search space.", "configspace": "", "generation": 93, "fitness": 0.8688561143964592, "feedback": "The algorithm Enhanced_Quantum_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.87 with standard deviation 0.02.", "error": "", "parent_id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "metadata": {"aucs": [0.8503454766744826, 0.8873667521184357]}, "mutation_prompt": null}
{"id": "339b39e2-0a76-4d6c-9c6d-9bf1a589a02f", "solution": "import numpy as np\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom collections import deque\n\nclass Surrogate_Assisted_Quantum_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n        self.gpr = GaussianProcessRegressor()\n        self.surrogate_training_interval = 10\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            if self.evaluations % self.surrogate_training_interval == 0 and len(self.tabu_list) >= self.memory_size:\n                self.train_surrogate(func)\n\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate()\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = self.estimate_or_evaluate(func, position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self):\n        diversity = np.std([np.linalg.norm(p) for p in self.tabu_list])\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget * np.tanh(diversity))))\n\n    def train_surrogate(self, func):\n        X = np.array([list(p) for p in self.tabu_list])\n        y = np.array([func(p) for p in X])\n        self.gpr.fit(X, y)\n\n    def estimate_or_evaluate(self, func, position):\n        if self.evaluations % self.surrogate_training_interval < self.memory_size and len(self.tabu_list) >= self.memory_size:\n            return self.gpr.predict([position])[0]\n        else:\n            return func(position)", "name": "Surrogate_Assisted_Quantum_PSO", "description": "Adaptive Surrogate-Assisted HTS_PSO with Quantum Perturbation: Employs surrogate models to estimate objective function, reducing evaluations while enhancing exploration with quantum perturbation.", "configspace": "", "generation": 94, "fitness": 0.45698429713691724, "feedback": "The algorithm Surrogate_Assisted_Quantum_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.01.", "error": "", "parent_id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "metadata": {"aucs": [0.44431664702015217, 0.4696519472536823]}, "mutation_prompt": null}
{"id": "8a9e6a0b-fb3f-4aed-aa6d-2dad4efd6350", "solution": "import numpy as np\n\nclass Adaptive_Quantum_Genetic_Algorithm:\n    def __init__(self, budget, dim, population_size=20, crossover_prob=0.7, mutation_prob=0.1, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.crossover_prob = crossover_prob\n        self.mutation_prob = mutation_prob\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(self.population_size, lb, ub)\n        best_position = None\n        best_value = float('inf')\n        \n        while self.evaluations < self.budget:\n            fitness = self.evaluate_population(population, func)\n            if self.evaluations >= self.budget:\n                break\n\n            if min(fitness) < best_value:\n                best_value = min(fitness)\n                best_position = population[np.argmin(fitness)]\n\n            new_population = self.selection(population, fitness)\n            self.crossover(new_population, lb, ub)\n            self.mutation(new_population, lb, ub)\n            self.quantum_perturbation(new_population, lb, ub)\n\n            population = np.array(new_population)\n\n        return best_position\n\n    def initialize_population(self, size, lb, ub):\n        return np.random.uniform(lb, ub, (size, self.dim))\n\n    def evaluate_population(self, population, func):\n        fitness = []\n        for individual in population:\n            value = func(individual)\n            self.evaluations += 1\n            fitness.append(value)\n            if self.evaluations >= self.budget:\n                break\n        return fitness\n\n    def selection(self, population, fitness):\n        selected_indices = np.argsort(fitness)[:self.population_size // 2]\n        return [population[i] for i in selected_indices]\n\n    def crossover(self, population, lb, ub):\n        for i in range(0, len(population), 2):\n            if np.random.rand() < self.crossover_prob and i + 1 < len(population):\n                parent1, parent2 = population[i], population[i + 1]\n                point = np.random.randint(1, self.dim)\n                child1 = np.concatenate((parent1[:point], parent2[point:]))\n                child2 = np.concatenate((parent2[:point], parent1[point:]))\n                population[i], population[i + 1] = np.clip(child1, lb, ub), np.clip(child2, lb, ub)\n\n    def mutation(self, population, lb, ub):\n        for i in range(len(population)):\n            if np.random.rand() < self.mutation_prob:\n                mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n                population[i] = np.clip(population[i] + mutation_vector, lb, ub)\n\n    def quantum_perturbation(self, population, lb, ub):\n        for i in range(len(population)):\n            if np.random.rand() < self.quantum_prob:\n                q_position = population[i] + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n                population[i] = np.clip(q_position, lb, ub)", "name": "Adaptive_Quantum_Genetic_Algorithm", "description": "Adaptive Quantum Genetic Algorithm (AQGA): Combines genetic operations with adaptive quantum perturbation to achieve enhanced exploration and exploitation balance.", "configspace": "", "generation": 95, "fitness": 0.5971365891169604, "feedback": "The algorithm Adaptive_Quantum_Genetic_Algorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.60 with standard deviation 0.06.", "error": "", "parent_id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "metadata": {"aucs": [0.6595200774849099, 0.5347531007490108]}, "mutation_prompt": null}
{"id": "cfaec393-56a0-49e3-9fd3-28f5a69d31a9", "solution": "import numpy as np\nfrom collections import deque\n\nclass Adaptive_Quantum_HTS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n        self.convergence_speed = 0.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            last_best_value = best_global_value\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate()\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n            self.convergence_speed = abs(best_global_value - last_best_value)\n            if self.convergence_speed < 1e-5:  # Regroup particles if convergence is too slow\n                particles = self.initialize_particles(group_size, lb, ub)\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self):\n        diversity = np.std([np.linalg.norm(p) for p in self.tabu_list])\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget * np.tanh(diversity))))", "name": "Adaptive_Quantum_HTS_PSO", "description": "Self-Adaptive Quantum-Enhanced HTS_PSO with Progressive Learning Rate Tuning: Enhances solution quality by dynamically adjusting learning rates based on convergence speed and diversity measures with strategic particle regrouping.", "configspace": "", "generation": 96, "fitness": 0.6521063338219439, "feedback": "The algorithm Adaptive_Quantum_HTS_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.02.", "error": "", "parent_id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "metadata": {"aucs": [0.6348234932667359, 0.669389174377152]}, "mutation_prompt": null}
{"id": "62c17cd1-9511-4c09-b2ee-c061594fc420", "solution": "import numpy as np\nfrom collections import deque\n\nclass Adaptive_Quantum_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n\n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate(particles)\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (particles[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self, particles):\n        diversity = np.mean([np.linalg.norm(p - np.mean(particles, axis=0)) for p in particles])\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget * np.tanh(diversity))))", "name": "Adaptive_Quantum_PSO", "description": "Adaptive Quantum-Inspired PSO with Dynamic Particle Swarm Diversity Control: Enhances exploration and exploitation by adaptively controlling swarm diversity and learning rates using dispersion metrics.", "configspace": "", "generation": 97, "fitness": 0.9689180302190955, "feedback": "The algorithm Adaptive_Quantum_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.97 with standard deviation 0.01.", "error": "", "parent_id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "metadata": {"aucs": [0.9615124334642239, 0.9763236269739671]}, "mutation_prompt": null}
{"id": "60ba9cfc-f106-45ff-9e27-cc84b25f7bb3", "solution": "import numpy as np\nfrom collections import deque\n\nclass Hierarchical_Quantum_Enhanced_HTS_PSO:\n    def __init__(self, budget, dim, base_group_size=10, inertia=0.5, cognitive=1.5, social=1.5, memory_size=5, quantum_prob=0.2, mutation_rate=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.base_group_size = base_group_size\n        self.inertia = inertia\n        self.cognitive = cognitive\n        self.social = social\n        self.memory_size = memory_size\n        self.quantum_prob = quantum_prob\n        self.mutation_rate = mutation_rate\n        self.evaluations = 0\n        self.tabu_list = deque(maxlen=self.memory_size)\n        self.learning_rate = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        group_size = self.base_group_size\n        particles = self.initialize_particles(group_size, lb, ub)\n        velocities = self.initialize_velocities(group_size)\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.full(group_size, float('inf'))\n\n        while self.evaluations < self.budget:\n            for i in range(group_size):\n                position = particles[i]\n                \n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                self.update_learning_rate()\n\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.cognitive * np.random.random(self.dim) * (personal_best_positions[i] - position) +\n                                 self.social * np.random.random(self.dim) * (best_global_position - position if best_global_position is not None else 0))\n                position = np.clip(position + self.learning_rate * velocities[i], lb, ub)\n                particles[i] = position\n\n                if tuple(position) in self.tabu_list:\n                    continue\n\n                value = func(position)\n                self.evaluations += 1\n                self.tabu_list.append(tuple(position))\n                \n                if value < personal_best_values[i]:\n                    personal_best_values[i] = value\n                    personal_best_positions[i] = position\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = position\n\n                if self.evaluations >= self.budget:\n                    break\n\n                # Apply adaptive mutation based on diversity\n                if np.random.rand() < self.mutation_rate:\n                    particles[i] = self.adaptive_mutation(particles[i], lb, ub)\n\n        return best_global_position\n\n    def initialize_particles(self, group_size, lb, ub):\n        return np.random.uniform(lb, ub, (group_size, self.dim))\n\n    def initialize_velocities(self, group_size):\n        return np.random.uniform(-1, 1, (group_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + (np.random.rand(self.dim) - 0.5) * (ub - lb) * 0.1\n        return np.clip(q_position, lb, ub)\n\n    def update_learning_rate(self):\n        diversity = np.std([np.linalg.norm(p) for p in self.tabu_list]) if len(self.tabu_list) > 0 else 0\n        self.learning_rate = max(0.1, min(1.0, 0.5 * (1.0 - self.evaluations / self.budget * np.tanh(diversity))))\n\n    def adaptive_mutation(self, position, lb, ub):\n        mutation_strength = (1 - (self.evaluations / self.budget)) * 0.1\n        mutated_position = position + np.random.normal(0, mutation_strength, size=self.dim)\n        return np.clip(mutated_position, lb, ub)", "name": "Hierarchical_Quantum_Enhanced_HTS_PSO", "description": "Hierarchical Quantum-Enhanced HTS_PSO with Adaptive Mutation Strategy: Integrates hierarchical learning and adaptive mutation for enhanced exploration and exploitation.", "configspace": "", "generation": 98, "fitness": 0.935955694315311, "feedback": "The algorithm Hierarchical_Quantum_Enhanced_HTS_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.94 with standard deviation 0.01.", "error": "", "parent_id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "metadata": {"aucs": [0.9306283878230432, 0.9412830008075788]}, "mutation_prompt": null}
{"id": "1e6c3669-fc8d-4343-af6b-bbc387e20ab0", "solution": "import numpy as np\n\nclass Quantum_Enhanced_SOS:\n    def __init__(self, budget, dim, population_size=10, quantum_prob=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = population_size\n        self.quantum_prob = quantum_prob\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_global_position = None\n        best_global_value = float('inf')\n        \n        population = self.initialize_population(lb, ub)\n        partner_indices = np.random.randint(0, self.population_size, self.population_size)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                position = population[i]\n\n                if np.random.rand() < self.quantum_prob:\n                    position = self.quantum_perturbation(position, lb, ub)\n\n                partner = population[partner_indices[i]]\n                symbiotic_partner = self.symbiotic_interaction(position, partner, lb, ub)\n                \n                value = func(symbiotic_partner)\n                self.evaluations += 1\n\n                if value < best_global_value:\n                    best_global_value = value\n                    best_global_position = symbiotic_partner\n\n                population[i] = symbiotic_partner\n\n                if self.evaluations >= self.budget:\n                    break\n\n            partner_indices = np.random.randint(0, self.population_size, self.population_size)\n\n        return best_global_position\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def quantum_perturbation(self, position, lb, ub):\n        q_position = position + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n        return np.clip(q_position, lb, ub)\n\n    def symbiotic_interaction(self, individual, partner, lb, ub):\n        alpha = np.random.rand()\n        new_position = alpha * individual + (1 - alpha) * partner\n        return np.clip(new_position, lb, ub)", "name": "Quantum_Enhanced_SOS", "description": "Quantum-Enhanced Adaptive Symbiotic Organisms Search (QEASOS): Combines quantum perturbation, adaptive learning, and symbiotic strategies to enhance exploration and exploitation in complex landscapes.", "configspace": "", "generation": 99, "fitness": 0.5677084293507767, "feedback": "The algorithm Quantum_Enhanced_SOS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.57 with standard deviation 0.06.", "error": "", "parent_id": "ee66bad1-440d-4b36-a0b0-811bba4b670a", "metadata": {"aucs": [0.5116167528758379, 0.6238001058257155]}, "mutation_prompt": null}

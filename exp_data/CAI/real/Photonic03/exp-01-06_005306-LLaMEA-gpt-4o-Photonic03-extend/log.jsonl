{"id": "8c7ce1a3-8a50-48a2-9b34-d89e1599de65", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Hybrid DE/PSO iteration\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * 0.5\n            self.Cr = 0.5 + np.random.rand() * 0.5\n            self.w = 0.4 + np.random.rand() * 0.5\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Hybrid Differential Evolution and Particle Swarm Optimization with Adaptive Parameter tuning for efficient exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.13265629333976467, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.1341048844058631, 0.13205360972417524, 0.13181038588925564]}, "mutation_prompt": null}
{"id": "56d2a086-14b7-41b0-afd4-4967393afbc2", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.no_improvement_iters = 0  # Track no improvement iterations\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Hybrid DE/PSO iteration\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n                        self.no_improvement_iters = 0  # Reset no improvement counter\n                else:\n                    self.no_improvement_iters += 1  # Increment no improvement counter\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * 0.5\n            self.Cr = 0.5 + np.random.rand() * 0.5\n            self.w = 0.4 + np.random.rand() * 0.5\n\n            if self.no_improvement_iters > 100:  # Early stopping if no improvement for many iterations\n                break\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhanced convergence by introducing a random early stopping mechanism when no improvement is detected.", "configspace": "", "generation": 1, "fitness": 0.12969947130237527, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "8c7ce1a3-8a50-48a2-9b34-d89e1599de65", "metadata": {"aucs": [0.13281903809768048, 0.12945236170895424, 0.12682701410049113]}, "mutation_prompt": null}
{"id": "65ce9b8b-6ccd-4094-9d63-edf476e3957b", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Hybrid DE/PSO iteration\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_position - pop[i]) + 0.1 * (ub - lb) * np.random.rand(self.dim)\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * 0.5\n            self.Cr = 0.5 + np.random.rand() * 0.5\n            self.w = 0.4 + np.random.rand() * 0.5\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Hybrid DEPSO with modified velocity update to enhance convergence speed.", "configspace": "", "generation": 2, "fitness": 0.13217146781713, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "8c7ce1a3-8a50-48a2-9b34-d89e1599de65", "metadata": {"aucs": [0.13204582572761436, 0.13171203293091638, 0.13275654479285925]}, "mutation_prompt": null}
{"id": "319d5084-0105-48af-8fa2-9ea814883903", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Hybrid DE/PSO iteration\n            if evaluations > self.budget // 2:  # Dynamic population size adjustment\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * 0.5\n            self.Cr = 0.5 + np.random.rand() * 0.5\n            self.w = 0.4 + np.random.rand() * 0.5\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhanced HybridDEPSO with dynamic population size adjustment for improved exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.1329562772950639, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "8c7ce1a3-8a50-48a2-9b34-d89e1599de65", "metadata": {"aucs": [0.1346868412752773, 0.13211693336442898, 0.13206505724548545]}, "mutation_prompt": null}
{"id": "6cc5e542-cf60-45af-b775-13f603508a8c", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * 0.5\n            self.Cr = 0.5 + np.random.rand() * 0.5\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduced a time-based decay for the inertia weight in PSO to enhance convergence speed.", "configspace": "", "generation": 4, "fitness": 0.1338487597250512, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "319d5084-0105-48af-8fa2-9ea814883903", "metadata": {"aucs": [0.1349186892731069, 0.13272926828843845, 0.13389832161360826]}, "mutation_prompt": null}
{"id": "22cfbab6-e938-443c-b7e8-e7c99155d40a", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * (1 - evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + (0.5 * (self.budget - evaluations) / self.budget)\n            self.Cr = 0.5 + np.random.rand() * 0.5\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhanced convergence by introducing a linearly decreasing mutation factor in DE and a time-adaptive social coefficient for PSO.", "configspace": "", "generation": 5, "fitness": 0.13338044821802378, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "6cc5e542-cf60-45af-b775-13f603508a8c", "metadata": {"aucs": [0.1347613631940352, 0.13340103383993107, 0.1319789476201051]}, "mutation_prompt": null}
{"id": "a3781f04-38aa-4c1c-8c7e-454323a022f5", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * 0.5\n            self.Cr = 0.5 + np.random.rand() * 0.5\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhanced mutation vector scaling factor in DE with a constant value to improve exploration efficiency.", "configspace": "", "generation": 6, "fitness": 0.1342701782222784, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "6cc5e542-cf60-45af-b775-13f603508a8c", "metadata": {"aucs": [0.13424391370849886, 0.13505202370440617, 0.13351459725393022]}, "mutation_prompt": null}
{"id": "ad5f9654-75b5-49b7-bdf7-f0a7f33f7358", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * 0.5\n            self.Cr = 0.5 + np.random.rand() * 0.5\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a dynamic adjustment to the cognitive and social coefficients in PSO for enhanced convergence by adapting them based on evaluation progress.", "configspace": "", "generation": 7, "fitness": 0.13448507607640023, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "a3781f04-38aa-4c1c-8c7e-454323a022f5", "metadata": {"aucs": [0.13540146745681658, 0.13340685830238186, 0.13464690247000222]}, "mutation_prompt": null}
{"id": "0958a7a9-2d20-4087-9850-90fb6437085e", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            improvement_ratio = np.sum(personal_best_values < self.global_best_value) / self.population_size\n            self.F = 0.5 + np.random.rand() * 0.5 * improvement_ratio\n            self.Cr = 0.5 + np.random.rand() * 0.5 * (1 - improvement_ratio)\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a feedback mechanism to adjust DE's F and Cr based on recent improvement trends.", "configspace": "", "generation": 8, "fitness": 0.13436565892751448, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "ad5f9654-75b5-49b7-bdf7-f0a7f33f7358", "metadata": {"aucs": [0.1355181126174424, 0.13241782649183897, 0.13516103767326204]}, "mutation_prompt": null}
{"id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by introducing adaptive learning rates for DE parameters and increasing PSO's cognitive impact as budget decreases.", "configspace": "", "generation": 9, "fitness": 0.13491697834534547, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "ad5f9654-75b5-49b7-bdf7-f0a7f33f7358", "metadata": {"aucs": [0.13487344805771906, 0.13485467581933075, 0.13502281115898662]}, "mutation_prompt": null}
{"id": "7c0fa312-3800-427c-8f63-71032f3a45aa", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                temporal_rand = np.random.uniform(-1, 1, self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i]) + \\\n                                temporal_rand * (1 - evaluations / self.budget)\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by adding a temporal randomization factor to the velocities for improved exploration.", "configspace": "", "generation": 10, "fitness": 0.13348100842935529, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13365896389813647, 0.13182271108085908, 0.1349613503090703]}, "mutation_prompt": null}
{"id": "89854a2b-06d2-4e5c-9908-febdf0a084e5", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                adaptive_F = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive F decrease\n                mutant = pop[a] + adaptive_F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 + 0.3 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (self.c2 + 0.4 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                # Boundary perturbation\n                perturb = 0.1 * np.random.randn(self.dim) * (ub - lb) * (1 - evaluations / self.budget)\n                pop[i] = np.clip(pop[i] + velocities[i] + perturb, lb, ub)\n\n            # Adaptive parameter tuning\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce adaptive mutation scaling in DE and dynamic boundary perturbation in PSO to improve search space exploration and exploitation balance.  ", "configspace": "", "generation": 11, "fitness": 0.13189569634863166, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1337735665105244, 0.1294679086976671, 0.13244561383770348]}, "mutation_prompt": null}
{"id": "de4649e5-7b01-4143-b906-51ab16c32019", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.5 * (1 - evaluations / self.budget)) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve HybridDEPSO by introducing adaptive social coefficient based on remaining budget to enhance exploration.", "configspace": "", "generation": 12, "fitness": 0.13460593111970576, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13504281076547553, 0.1335764411916428, 0.13519854140199894]}, "mutation_prompt": null}
{"id": "89536675-6c6c-4b8b-9a19-6a21ab3646e2", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + 0.6 * evaluations / self.budget  # Dynamic cognitive coefficient\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a dynamic adjustment to the cognitive coefficient and inertia weight to improve convergence speed in later stages.", "configspace": "", "generation": 13, "fitness": 0.13360330474301776, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.134239001314421, 0.13328655828491875, 0.13328435462971355]}, "mutation_prompt": null}
{"id": "55f9d91a-a285-4059-ac96-e4e77c334710", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr or j == np.random.randint(self.dim):\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.8 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by introducing minor adjustments to PSO coefficients and improving DE's trial selection mechanism.", "configspace": "", "generation": 14, "fitness": 0.1342704584432732, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13501774952177392, 0.1329977164506171, 0.13479590935742858]}, "mutation_prompt": null}
{"id": "8efb0f63-bc19-4287-98fd-26a2ad02a968", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4 * (self.budget - evaluations) / self.budget  # Dynamic Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by introducing a dynamic crossover probability that decreases linearly as evaluations increase.", "configspace": "", "generation": 15, "fitness": 0.13420990284865586, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1346097292262023, 0.13305332435517525, 0.13496665496459004]}, "mutation_prompt": null}
{"id": "8f282cb8-8ed1-4b22-82a1-1ce64ee74098", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.6 * (1 - evaluations / self.budget)  # Adjusted inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Refine HybridDEPSO by adjusting PSO inertia weight decay to accelerate convergence and improve diversity maintenance.", "configspace": "", "generation": 16, "fitness": 0.1343024427168694, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13517256568495029, 0.13309522998435375, 0.13463953248130411]}, "mutation_prompt": null}
{"id": "96f0eb18-12ca-45e2-b5e8-c86ec1f83fad", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6 * (1 - evaluations / self.budget)  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Fine-tune DE's scaling factor to dynamically increase diversity when evaluations are near budget to improve convergence.", "configspace": "", "generation": 17, "fitness": 0.13448820871793998, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13495934308988222, 0.13346725320530017, 0.13503802985863755]}, "mutation_prompt": null}
{"id": "46b6f0e7-b468-4603-9549-272d25d9a962", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Dynamic Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - np.sqrt(evaluations / self.budget))  # Adjusted inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve HybridDEPSO by adjusting the inertia weight decay and implementing a dynamic crossover probability based on evaluation progress.", "configspace": "", "generation": 18, "fitness": 0.13442569971558715, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13500234516067555, 0.1332511156967573, 0.13502363828932862]}, "mutation_prompt": null}
{"id": "b28d8bc0-9e36-4ceb-9434-e54134d889a8", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6 * (1 - (evaluations/self.budget)**2)  # Nonlinear decay\n            self.Cr = 0.6 + np.random.rand() * 0.4\n            if evaluations % (self.budget // 10) == 0:  # Diversity preservation\n                pop[np.random.randint(self.population_size)] = np.random.uniform(lb, ub, self.dim)\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance adaptive behavior by using nonlinear decay for the DE scaling factor and introducing diversity preservation with random reinitialization.", "configspace": "", "generation": 19, "fitness": 0.1347849416736849, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1347448498259246, 0.13458641887810063, 0.13502355631702945]}, "mutation_prompt": null}
{"id": "4f07446d-f5ea-4139-98cb-1e30f5f45419", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget**1.5)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by dynamically adjusting PSO's inertia weight to balance exploration and exploitation as the budget progresses.", "configspace": "", "generation": 20, "fitness": 0.13412893598907538, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1345512932034808, 0.1330343752032377, 0.13480113956050765]}, "mutation_prompt": null}
{"id": "7806ae90-12fd-474d-8919-45ce4b8fdbc0", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * ((1 - evaluations / self.budget) * (pop[b] - pop[c]))  # Enhanced mutation\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + (0.8 + 0.6 * evaluations / self.budget)) * r2 * (self.global_best_position - pop[i])  # Dynamic social coefficient\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Refine HybridDEPSO by introducing a dynamic adjustment for PSO's social coefficient and enhancing the mutation strategy in DE.", "configspace": "", "generation": 21, "fitness": 0.13361906578145832, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1334032661677763, 0.1345062902480857, 0.13294764092851297]}, "mutation_prompt": null}
{"id": "9a710e0c-b84b-4c3e-bbce-ac486253b6b5", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + 0.6 * (1 - evaluations / self.budget)  # Adjusted cognitive coefficient\n                self.c2 = 1.2 + 0.6 * evaluations / self.budget  # Adjusted social coefficient\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Fine-tune PSO's cognitive and social coefficients to dynamically adjust based on progress, enhancing solution exploration and exploitation balance.", "configspace": "", "generation": 22, "fitness": 0.13228884962878196, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13304314595149735, 0.1318788428595532, 0.13194456007529531]}, "mutation_prompt": null}
{"id": "421b987b-5c61-4aae-bb36-e3965d697484", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[self.global_best_position] - pop[b])  # Modified mutation strategy\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                velocities[i] = np.clip(velocities[i], -0.1*(ub-lb), 0.1*(ub-lb))  # Constrain velocities\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve convergence by adjusting the mutation strategy in DE and introducing adaptive velocity constraints in PSO.", "configspace": "", "generation": 23, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('arrays used as indices must be of integer (or boolean) type').", "error": "IndexError('arrays used as indices must be of integer (or boolean) type')", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {}, "mutation_prompt": null}
{"id": "357d630c-ae27-4694-a7cc-ce31fa0cb91f", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6 * (1 + 0.5 * evaluations / self.budget)  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a dynamic scaling factor to increase DE's exploration potential as evaluations approach budget limit.", "configspace": "", "generation": 24, "fitness": 0.1347314516878271, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13487689083650067, 0.13458416592482048, 0.1347332983021602]}, "mutation_prompt": null}
{"id": "75ce7a2d-420e-41d5-a2a9-16dc35ca01c4", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 3)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 - 0.5 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by introducing adaptive cognitive coefficients and dynamically scaling the population size based on budget usage.", "configspace": "", "generation": 25, "fitness": 0.13385632987794235, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13378229029633393, 0.13431977174925347, 0.13346692758823964]}, "mutation_prompt": null}
{"id": "31792524-0259-4bc5-9994-1f853ed9dcb2", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 0.5 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])  # Adjusted social coefficient\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce an adaptive mechanism for updating the social coefficient (c2) to enhance convergence control as evaluations progress.", "configspace": "", "generation": 26, "fitness": 0.1343077840649499, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13465559867805, 0.13320991062898913, 0.13505784288781053]}, "mutation_prompt": null}
{"id": "3427fe5b-cb76-4e1b-a7bd-7a576361b3d8", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (self.c2 + 0.5 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.5  # Adjusted range for F\n            self.Cr = 0.7 + np.random.rand() * 0.3  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce self-adaptive strategies for DE parameters and fine-tune PSO coefficients for enhanced convergence.", "configspace": "", "generation": 27, "fitness": 0.13372212690541585, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13427286784460513, 0.13404109345168413, 0.1328524194199583]}, "mutation_prompt": null}
{"id": "6c40db1d-2ab8-4e3a-905c-5346ae761090", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (self.global_best_position - pop[i])  # Improved mutation\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i]) * (0.5 + 0.5 * evaluations / self.budget)  # Dynamic learning rate\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Focus on enhancing exploration by improving the mutation strategy and adding a dynamic learning rate to velocity updates in PSO.", "configspace": "", "generation": 28, "fitness": 0.13431715880503317, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13438658432869732, 0.13393205268044772, 0.1346328394059545]}, "mutation_prompt": null}
{"id": "0bb672f9-7276-4816-ae8c-22bdda0973f6", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 4:  # Change population size adjustment to earlier\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c]) + np.random.rand(self.dim) * 0.1  # Add noise to mutation\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by dynamically adjusting population size based on convergence and improving mutation diversity for DE.", "configspace": "", "generation": 29, "fitness": 0.1344291546856882, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1356978669581802, 0.1330941858856306, 0.1344954112132538]}, "mutation_prompt": null}
{"id": "8884323b-3a4f-4aee-a986-9faa1305f5bd", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.6 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Refine HybridDEPSO by dynamically adjusting the PSO inertia weight to enhance convergence rate.", "configspace": "", "generation": 30, "fitness": 0.13341007095637603, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13443050440022797, 0.13241033533370405, 0.13338937313519605]}, "mutation_prompt": null}
{"id": "2dacda2a-c018-4348-b602-8ac32216a934", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (1.3 - 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce adaptive inertia calculation and enhance exploitation by adjusting the cognitive coefficient in PSO.", "configspace": "", "generation": 31, "fitness": 0.13289731463538623, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13408498352910558, 0.13219599399242798, 0.13241096638462513]}, "mutation_prompt": null}
{"id": "a82cd4f6-11a4-45c1-a982-40b74e1ba69c", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                # Change line: Adapt F based on evaluations\n                self.F = 0.4 + 0.6 * (1 - evaluations / self.budget)  # Adaptive mutation rate\n\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce an adaptive parameter for mutation rate to enhance exploration in later stages of the budget.", "configspace": "", "generation": 32, "fitness": 0.13410448013053597, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13435158149409698, 0.13411893378363526, 0.13384292511387563]}, "mutation_prompt": null}
{"id": "f9f87cbf-f6eb-4b6b-a95d-ccd39f41a5d0", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6 * (1 - evaluations / self.budget)  # Adjusted range for F at budget end\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by incorporating a dynamic population resizing approach and adaptive F parameter adjustment towards the end of the budget.", "configspace": "", "generation": 33, "fitness": 0.13448820871793998, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13495934308988222, 0.13346725320530017, 0.13503802985863755]}, "mutation_prompt": null}
{"id": "266256d4-df6a-47d6-8f47-ee4ca3fa9676", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n            self.c1 = 1.0 + 1.0 * evaluations / self.budget  # Adaptive cognitive coefficient\n            self.c2 = 2.0 - 1.0 * evaluations / self.budget  # Adaptive social coefficient\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce adaptive cognitive and social coefficients for PSO based on the evaluation budget to enhance exploration and exploitation balance.", "configspace": "", "generation": 34, "fitness": 0.13491697834534547, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13487344805771906, 0.13485467581933075, 0.13502281115898662]}, "mutation_prompt": null}
{"id": "19496b66-5467-4f0c-9795-d8a9caaadd1f", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 * (1 - evaluations / self.budget)) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.9 * (1 - evaluations / self.budget)  # Dynamic inversion for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by introducing decay to the cognitive coefficient and dynamic inversion for DE's crossover probability as budget decreases.", "configspace": "", "generation": 35, "fitness": 0.13327840451201892, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13458736092060386, 0.1313993246862366, 0.1338485279292163]}, "mutation_prompt": null}
{"id": "4ec28a02-12d1-48e1-b0a9-1a227cc491ae", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - 0.5 * (1 + np.sin(2 * np.pi * evaluations / self.budget)))  # Sinusoidal inertia\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a dynamic adjustment to PSO's inertia weight based on a sinusoidal function for improved exploration and exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.1346890322920964, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13565605005886072, 0.13313861787934578, 0.13527242893808267]}, "mutation_prompt": null}
{"id": "059183d5-79c3-43b0-99da-1610720e8fc0", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            diversity = np.mean(np.std(pop, axis=0))  # Calculate population diversity\n            self.F = 0.4 + 0.6 * (1 - diversity)  # Adjust F based on diversity\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget) * diversity  # Inertia decay with diversity\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a diversity-preserving mechanism by dynamically adjusting the mutation factor F and inertia weight w based on population diversity.", "configspace": "", "generation": 37, "fitness": 0.12674986491090776, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.12949207422096154, 0.12656595172985652, 0.12419156878190518]}, "mutation_prompt": null}
{"id": "75d20a68-e922-4ae3-b62d-2ff8990410b9", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                diversity = np.std(pop, axis=0).mean()\n                self.c1 = 1.0 + 0.5 * (1 - diversity / (ub - lb).mean())\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by incorporating dynamic scaling for the cognitive coefficient based on population diversity.", "configspace": "", "generation": 38, "fitness": 0.13491697834534547, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13487344805771906, 0.13485467581933075, 0.13502281115898662]}, "mutation_prompt": null}
{"id": "06d43d67-d1b8-46de-b010-68b232615687", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 + 0.4 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (self.c2 - 0.4 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce dynamic adjustment of the cognitive and social coefficients based on current evaluations to enhance convergence in HybridDEPSO.", "configspace": "", "generation": 39, "fitness": 0.13286685897956704, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1338341104972004, 0.13232258902212846, 0.13244387741937225]}, "mutation_prompt": null}
{"id": "353019a3-1855-4851-bc84-7f1e9d80acb8", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6 * (1 - evaluations / self.budget)  # Adjusted range for F\n            self.c1 = 1.2 + np.random.rand() * 0.6  # Dynamic cognitive coefficient for PSO\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by leveraging an adaptive global scaling factor and dynamic cognitive coefficient for PSO to better balance exploration and exploitation.", "configspace": "", "generation": 40, "fitness": 0.1342125911316976, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.135202332676023, 0.13316129991296066, 0.1342741408061091]}, "mutation_prompt": null}
{"id": "23d97eaa-280d-4a19-be57-728274291712", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive population size scaling\n            self.population_size = max(5, int(10 * self.dim * (1 - evaluations / self.budget)))\n\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce adaptive population size scaling based on evaluation progress to enhance exploration and exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.1348135185238322, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13541255947036734, 0.13515766925946493, 0.13387032684166433]}, "mutation_prompt": null}
{"id": "9632bb45-74f6-4334-88ab-0338f9ceee23", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1_initial = 1.5  # Initial cognitive coefficient for PSO\n        self.c2_initial = 1.5  # Initial social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            \n            # Update cognitive and social coefficients\n            self.c1 = self.c1_initial * (1 - evaluations / self.budget)\n            self.c2 = self.c2_initial * (evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve HybridDEPSO by dynamically altering the cognitive and social coefficients based on evaluations to enhance exploration-exploitation balance.", "configspace": "", "generation": 42, "fitness": 0.1325270565575739, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13226266122655317, 0.1330161453997254, 0.13230236304644316]}, "mutation_prompt": null}
{"id": "1f00edb4-2dff-4fe6-8af8-219eaeb2fdad", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + np.log1p(self.budget - evaluations)) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.3 + np.log1p(self.budget - evaluations) * 0.5  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by introducing a dynamic mutation factor F and a learning rate for PSO's cognitive component as a logarithmic function of the remaining budget.", "configspace": "", "generation": 43, "fitness": 0.12732247651464337, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.12949207422096154, 0.12656595172985652, 0.1259094035931121]}, "mutation_prompt": null}
{"id": "435ef788-3f5f-4608-9fae-0dcd32e8c6ee", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 + 0.1 * (1 - trial_value / self.global_best_value)) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (self.c2 + 0.1 * (1 - trial_value / self.global_best_value)) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by dynamically updating the cognitive and social coefficients of PSO based on the current best value to improve convergence.", "configspace": "", "generation": 44, "fitness": 0.1328664097806382, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1348333247483604, 0.13252888904862292, 0.13123701554493128]}, "mutation_prompt": null}
{"id": "fa4a1ea4-8c4a-4f09-afe2-4782b9b05b2e", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - (evaluations + 0.1) / self.budget)  # Enhanced inertia decay\n            diversity = np.mean(np.std(pop, axis=0))  # Maintain diversity\n            if diversity < 0.05 * (ub - lb).mean():\n                pop += np.random.uniform(-0.1, 0.1, pop.shape) * (ub - lb)\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve HybridDEPSO by introducing population diversity maintenance and enhancing the decay rate of PSO's inertia weight.", "configspace": "", "generation": 45, "fitness": 0.13490526771236344, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13488007702670757, 0.1348409858203944, 0.13499474028998837]}, "mutation_prompt": null}
{"id": "73ec6da2-805f-4fd0-ae2c-16540bf5e68f", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 + 0.5 * (1 - evaluations / self.budget)) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (self.c2 + 0.5 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by dynamically adjusting both social and cognitive components based on evaluation progress to balance exploration and exploitation.", "configspace": "", "generation": 46, "fitness": 0.13303774102532404, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13375809439284758, 0.13291385701220815, 0.13244127167091635]}, "mutation_prompt": null}
{"id": "f09d542d-d3ae-4dc2-a2cf-1e3257341649", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n        mid_best_position = None\n\n        while evaluations < self.budget:\n            if evaluations == self.budget // 2:\n                mid_best_position = self.global_best_position  # Elite selection\n\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                \n                # Use elite selection as an additional reference point\n                if mid_best_position is not None:\n                    mutant = mutant + 0.1 * (mid_best_position - mutant)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance population diversity by introducing elite selection, utilizing the best solution found halfway through as an extra reference point for mutation.", "configspace": "", "generation": 47, "fitness": 0.13488782223748844, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13483312813686066, 0.1348620046159097, 0.13496833395969499]}, "mutation_prompt": null}
{"id": "25a13c9b-4228-4375-8744-14be0d6805b3", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - np.tanh(evaluations / self.budget))  # Non-linear inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a non-linear decay for PSO's inertia weight to enhance convergence speed.", "configspace": "", "generation": 48, "fitness": 0.13491090965592442, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13487149195107817, 0.13484667268112072, 0.13501456433557435]}, "mutation_prompt": null}
{"id": "7bd5850c-50e5-46d1-984e-938a08a1cc4d", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n            self.c1 = 1.5 + 0.5 * (1 - evaluations / self.budget)  # Cognitive coefficient decay\n            self.c2 = 1.5 + 0.5 * evaluations / self.budget  # Social coefficient increase\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve HybridDEPSO by dynamically adjusting the cognitive and social coefficients as evaluations progress to enhance exploration and exploitation balance.", "configspace": "", "generation": 49, "fitness": 0.13491697834534547, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13487344805771906, 0.13485467581933075, 0.13502281115898662]}, "mutation_prompt": null}
{"id": "fd40c6ad-c914-4433-a082-815ebde379df", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                proximity_factor = 1 - (self.global_best_value - np.min(func.bounds.lb)) / (np.max(func.bounds.ub) - np.min(func.bounds.lb))\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 * proximity_factor) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (self.c2 * proximity_factor) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve HybridDEPSO by introducing dynamic scaling of PSO's cognitive and social coefficients based on the current best solution's proximity to the target.", "configspace": "", "generation": 50, "fitness": 0.13327545484658718, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13342128937928643, 0.13306230422690368, 0.1333427709335714]}, "mutation_prompt": null}
{"id": "62142ea9-1f88-4a66-b7be-dc373d50cc73", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c] + pop[a] - pop[i])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce dynamic scaling for PSO's inertia and update the mutation strategy in DE to enhance convergence efficiency.", "configspace": "", "generation": 51, "fitness": 0.1332474594610857, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13347597470263983, 0.1332850139539764, 0.13298138972664086]}, "mutation_prompt": null}
{"id": "960da28a-7fe6-475c-bf90-b9f99315df09", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (1.0 - 0.5 * (evaluations / self.budget)**2) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * 0.5  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve HybridDEPSO by modifying the PSO velocity update to incorporate nonlinear inertia decay and increase DE's adaptive mutation effectiveness.", "configspace": "", "generation": 52, "fitness": 0.1339109228879788, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1340725669621452, 0.13382946230741288, 0.13383073939437828]}, "mutation_prompt": null}
{"id": "e93fa469-c4b4-48fd-8d74-1e57558e264e", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.8 + 0.7 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * 0.5  # Adjusted range for F\n            self.Cr = 0.7 + np.random.rand() * 0.3  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by fine-tuning F and Cr ranges and adjusting PSO's cognitive impact.", "configspace": "", "generation": 53, "fitness": 0.13347889968250745, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13424365247755154, 0.13140061431342398, 0.1347924322565468]}, "mutation_prompt": null}
{"id": "dc618b2f-9504-42ff-93f3-c77b41442c22", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])) * \\\n                                ((self.budget - evaluations) / self.budget)\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by incorporating adaptive velocity scaling for improved exploration-exploitation balance.", "configspace": "", "generation": 54, "fitness": 0.13460205887927926, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13521522163831312, 0.13339129505893588, 0.1351996599405888]}, "mutation_prompt": null}
{"id": "160d4c69-0c5c-4985-9519-9ef64934d22f", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 3)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.2 + np.random.rand() * 0.8  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Refine HybridDEPSO by enhancing diversity with dynamic population reduction and improved exploration through a wider DE scaling factor range.", "configspace": "", "generation": 55, "fitness": 0.13456575577536814, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13510365667975988, 0.1332729411437864, 0.13532066950255817]}, "mutation_prompt": null}
{"id": "1b9492f9-6130-4734-8ab3-064561494673", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n            self.c1 = 1.5 + 0.5 * evaluations / self.budget  # Dynamic increase of cognitive coefficient\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance adaptive learning by modifying the cognitive coefficient for PSO, increasing it dynamically as evaluations approach the budget limit.", "configspace": "", "generation": 56, "fitness": 0.13491697834534547, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13487344805771906, 0.13485467581933075, 0.13502281115898662]}, "mutation_prompt": null}
{"id": "95adaaa4-42fd-4fd4-bf8f-6c240fc0eba0", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.5 + 0.5 * (1 - evaluations / self.budget) # Dynamic adjustment of c1\n                self.c2 = 1.5 + 0.5 * evaluations / self.budget       # Dynamic adjustment of c2\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve HybridDEPSO by dynamically adjusting PSO's cognitive and social coefficients based on iteration count for better exploration and exploitation balance.", "configspace": "", "generation": 57, "fitness": 0.13303774102532404, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13375809439284758, 0.13291385701220815, 0.13244127167091635]}, "mutation_prompt": null}
{"id": "9336df0d-0172-4743-a401-b7fbefe5c0ca", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(3, self.population_size // 2)  # Reduced minimum population size to 3\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (self.c2 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO with an adaptive reduction in population size and improved velocity update for convergence acceleration.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {}, "mutation_prompt": null}
{"id": "4743b53c-ebf7-45ff-a15b-42aebf5d34d8", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def crowding_distance(self, pop, values):\n        sorted_indices = np.argsort(values)\n        distances = np.zeros(self.population_size)\n        distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n        for i in range(1, self.population_size - 1):\n            distances[sorted_indices[i]] = (values[sorted_indices[i+1]] - values[sorted_indices[i-1]])\n        return distances\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            distances = self.crowding_distance(pop, personal_best_values)\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                w_dynamic = 0.4 + 0.5 * (1 - evaluations / self.budget)\n                c1_dynamic = 1.5 + distances[i] * 0.5\n                velocities[i] = w_dynamic * velocities[i] + \\\n                                c1_dynamic * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce crowding distance and adaptive cognitive weights for PSO to enhance exploration and maintain diversity.", "configspace": "", "generation": 59, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 55 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 55 is out of bounds for axis 0 with size 30')", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {}, "mutation_prompt": null}
{"id": "b5704c01-cea0-48e1-a33a-88686546905a", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.population_size = max(5, int(10 * self.dim * (1 - evaluations / self.budget)))  # Dynamic adjustment\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a dynamic population size adjustment strategy based on the remaining budget to maintain diversity and balance exploration-exploitation.", "configspace": "", "generation": 60, "fitness": 0.1348135185238322, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13541255947036734, 0.13515766925946493, 0.13387032684166433]}, "mutation_prompt": null}
{"id": "a7ea07e7-2e64-4b13-8ae1-165176f48291", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.5 + 1.0 * ((self.budget - evaluations) / self.budget)) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * ((self.budget - evaluations) / self.budget)) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - (evaluations / self.budget)**2)  # Non-linear inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a non-linear decay for the inertia weight and dynamically adapt the cognitive and social coefficients based on progress.", "configspace": "", "generation": 61, "fitness": 0.13391501416971252, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13480983951997794, 0.13308844723601987, 0.13384675575313976]}, "mutation_prompt": null}
{"id": "0fdeb176-48ee-4aaa-8471-0d0a7cf7de0b", "solution": "# Description: Improve HybridDEPSO by dynamically adjusting the cognitive coefficient for PSO based on function evaluations and enhancing exploration with a dynamic scaling factor.\n# Code:\nimport numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (self.c2 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])  # Adjusted line\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6 * (1 - evaluations / self.budget)  # Adjusted line\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve HybridDEPSO by dynamically adjusting the cognitive coefficient for PSO based on function evaluations and enhancing exploration with a dynamic scaling factor.", "configspace": "", "generation": 62, "fitness": 0.13379440274526508, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13422958012041197, 0.13369596205484902, 0.13345766606053422]}, "mutation_prompt": null}
{"id": "dd7e116a-8c8a-4655-8bf7-2d1960717362", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            success_rate = np.mean(personal_best_values < self.global_best_value)\n            self.F = 0.4 + success_rate * 0.6  # Adjusted range for F based on success rate\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget * 0.5)  # Inertia slower decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce dynamic scaling for DE parameters based on success rate and increase PSO's inertia weight when close to the budget limit.", "configspace": "", "generation": 63, "fitness": 0.1347332915269496, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1356809269177015, 0.13329784934582845, 0.13522109831731888]}, "mutation_prompt": null}
{"id": "d6e4fdd2-34e4-4051-bfb7-899810d278b7", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.5 * (1 - evaluations / self.budget)) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by dynamically adjusting the PSO social factor based on the ratio of current budget used. ", "configspace": "", "generation": 64, "fitness": 0.13460593111970576, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13504281076547553, 0.1335764411916428, 0.13519854140199894]}, "mutation_prompt": null}
{"id": "4e5ba9ae-93a6-4210-8638-5e70f7e73527", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update with momentum\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                momentum = 0.9  # Adding momentum term\n                velocities[i] = momentum * velocities[i] + self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce momentum-based velocity update in PSO to improve convergence stability and performance.", "configspace": "", "generation": 65, "fitness": 0.12931388918784573, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1303421034608505, 0.1275153158297756, 0.1300842482729111]}, "mutation_prompt": null}
{"id": "887377f1-1450-424e-b895-8de697bffd93", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 * (1 - evaluations / self.budget) + 0.5) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce dynamic scaling of the cognitive coefficient `c1` as the budget progresses to enhance individual learning and convergence speed.", "configspace": "", "generation": 66, "fitness": 0.13273114539028763, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13338208168828658, 0.13246395488791818, 0.13234739959465813]}, "mutation_prompt": null}
{"id": "73e3cee8-bd98-4519-b354-e3f3c9cbbde6", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * (1 - evaluations / self.budget)) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * (0.4 + 0.5 * evaluations / self.budget)  # Adjust scaling factor range\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve convergence by increasing the DE scaling factor adaptively based on the evaluations and shifting cognitive influence towards the end of the budget.", "configspace": "", "generation": 67, "fitness": 0.13335417276629927, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1350180643015465, 0.13238905221799424, 0.13265540177935708]}, "mutation_prompt": null}
{"id": "49f94c20-abda-4dd7-ace1-05e14e118182", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.5 + 0.5 * (1 - np.exp(-0.1 * np.min(personal_best_values))) # Adjusted Cr based on current best\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve convergence by dynamically adjusting PSO's inertia and DE's crossover probability based on current best value.", "configspace": "", "generation": 68, "fitness": 0.13464313923482787, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13562329561611342, 0.13355143813948778, 0.13475468394888246]}, "mutation_prompt": null}
{"id": "b8abfa59-213a-4f9d-8982-418b1200fe40", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2) + np.random.randint(-1, 2)  # Dynamic adjustment\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by introducing a dynamic population size based on convergence speed to improve efficiency.", "configspace": "", "generation": 69, "fitness": 0.13490920593263686, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13486117990058955, 0.13485467477586655, 0.13501176312145446]}, "mutation_prompt": null}
{"id": "fbc9dd0e-5364-4f0f-ab6e-79f047dd74cd", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Local search phase\n            if evaluations < self.budget * 0.75:  # Trigger local search in the early phase\n                indices = np.argsort(personal_best_values)[:3]  # Select top 3 individuals\n                for index in indices:\n                    local_search = personal_best_positions[index] + np.random.normal(0, 0.1, self.dim)  # Small perturbation\n                    local_search = np.clip(local_search, lb, ub)\n                    local_value = func(local_search)\n                    evaluations += 1\n\n                    if local_value < personal_best_values[index]:\n                        personal_best_values[index] = local_value\n                        personal_best_positions[index] = local_search\n\n                        if local_value < self.global_best_value:\n                            self.global_best_value = local_value\n                            self.global_best_position = local_search\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by leveraging a dynamic local search phase based on selected individuals' proximity to improve local exploration and convergence speed.", "configspace": "", "generation": 70, "fitness": 0.13460763096966233, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13438557152069763, 0.13445468127173987, 0.13498264011654948]}, "mutation_prompt": null}
{"id": "107836e0-0cdb-47ed-93c3-6f77a3bc0cdd", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.6 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by tuning the adaptive inertia weight to improve exploration-exploitation balance.", "configspace": "", "generation": 71, "fitness": 0.1335172867179454, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13429816439765851, 0.1325420829663, 0.13371161278987775]}, "mutation_prompt": null}
{"id": "540a3f92-6ac6-4f93-85c4-29da7881c314", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity_scale = (0.4 + 0.6 * (1 - evaluations / self.budget))  # Adaptive velocity scaling\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                self.c2 * r2 * (self.global_best_position - pop[i])\n                velocities[i] *= velocity_scale  # Apply adaptive scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by incorporating adaptive velocity scaling in PSO based on iteration progress to balance exploration and exploitation.", "configspace": "", "generation": 72, "fitness": 0.13365053382355072, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13461387709177997, 0.1320720598401698, 0.13426566453870237]}, "mutation_prompt": null}
{"id": "709d7cc8-6682-4ad2-834c-d7795f3356d6", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 * (1 - evaluations / self.budget)) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (self.c2 * (1 - evaluations / self.budget)) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by implementing decay for the cognitive and social coefficients to balance exploration and exploitation.", "configspace": "", "generation": 73, "fitness": 0.13372816441723315, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13429354709572938, 0.13311595465843795, 0.13377499149753214]}, "mutation_prompt": null}
{"id": "0f2c3298-c3c2-4fc8-ae6f-9cae6baa652e", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            # Modified line for adaptive inertia weight adjustment\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget) * (1 - min(personal_best_values) / self.global_best_value)\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce adaptive inertia adjustment for PSO to improve convergence speed in HybridDEPSO.", "configspace": "", "generation": 74, "fitness": 0.13477673082848696, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.1358134181233278, 0.13332197897551834, 0.13519479538661472]}, "mutation_prompt": null}
{"id": "6af0ae19-c83b-4b5c-ab07-1eb06f4cbc88", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c]) + 0.1 * (pop[a] - pop[i])  # Enhanced trial mutation\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                diversity_factor = np.std(pop, axis=0)  # Calculate diversity\n                velocities[i] = self.w * velocities[i] * (1 + 0.5 * diversity_factor / self.dim) + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Refine HybridDEPSO by dynamically adjusting velocities based on diversity and enhance trial mutation for better exploration.", "configspace": "", "generation": 75, "fitness": 0.12674986491090776, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.12949207422096154, 0.12656595172985652, 0.12419156878190518]}, "mutation_prompt": null}
{"id": "c8ef638d-e319-45e8-b163-665e8b615fe6", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                self.F = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Dynamically adjust F based on evaluations\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance HybridDEPSO by adapting mutation strategy with a dynamic scaling factor tied to the iteration progress.", "configspace": "", "generation": 76, "fitness": 0.13334302568834897, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13430398689879564, 0.13230532356008018, 0.13341976660617105]}, "mutation_prompt": null}
{"id": "91871b95-807f-4d02-a0ff-2b0e1f35f349", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Refine the inertia weight decay strategy to enhance exploration and exploitation balance in HybridDEPSO.", "configspace": "", "generation": 77, "fitness": 0.13498772219521157, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "38f69767-9ebc-4965-9db2-e686465bcf5d", "metadata": {"aucs": [0.13519750771723682, 0.13461962967819785, 0.13514602919020002]}, "mutation_prompt": null}
{"id": "df64b169-8523-4941-b112-d7adb6206e4f", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + ((0.5 + 0.4 * evaluations / self.budget) * (pop[b] - pop[c]))  # Adaptive F\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Apply an adaptive mutation strategy by adjusting the scale factor based on evaluation progress to improve solution diversity in HybridDEPSO.", "configspace": "", "generation": 78, "fitness": 0.13492898309108406, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "91871b95-807f-4d02-a0ff-2b0e1f35f349", "metadata": {"aucs": [0.135554987591066, 0.1346208550281358, 0.1346111066540504]}, "mutation_prompt": null}
{"id": "39408faf-0ef9-4ac4-9413-aea3a546cc2c", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.5 + np.random.rand() * 0.5  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Slightly adjust the scaling factor range to enhance exploration and exploitation in HybridDEPSO.", "configspace": "", "generation": 79, "fitness": 0.13430613859187043, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "91871b95-807f-4d02-a0ff-2b0e1f35f349", "metadata": {"aucs": [0.13513508625116855, 0.13252752752108332, 0.1352558020033594]}, "mutation_prompt": null}
{"id": "887dcd28-428d-4022-ae10-74a09720c979", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 + 0.5 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance convergence by introducing a dynamic update to the cognitive coefficient in PSO.", "configspace": "", "generation": 80, "fitness": 0.1326386659557244, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "91871b95-807f-4d02-a0ff-2b0e1f35f349", "metadata": {"aucs": [0.13328279424142042, 0.13169394658861755, 0.13293925703713527]}, "mutation_prompt": null}
{"id": "75f53404-15e5-4fe3-b12d-dba0688c837d", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = 0.4 + np.random.rand() * 0.6 * (1 - evaluations / self.budget)  # Adjusted range for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance global exploration by adjusting DE scaling factor and PSO social coefficient adaptively.", "configspace": "", "generation": 81, "fitness": 0.13463730061328794, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "91871b95-807f-4d02-a0ff-2b0e1f35f349", "metadata": {"aucs": [0.13524110896866215, 0.13354406635425053, 0.13512672651695112]}, "mutation_prompt": null}
{"id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance adaptive parameter tuning by allowing self-adaptive mutation scale factor updates.", "configspace": "", "generation": 82, "fitness": 0.13505424997929685, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "91871b95-807f-4d02-a0ff-2b0e1f35f349", "metadata": {"aucs": [0.1358571136690716, 0.13477042300397946, 0.13453521326483953]}, "mutation_prompt": null}
{"id": "fe92cec7-70f1-42ff-b3f9-c003723921f2", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, 0.4 + 0.5 * (0.5 * (1 + np.cos(np.pi * evaluations / self.budget)))))  # Cosine adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce cosine adaptation to the mutation scale factor for smoother parameter transitions.", "configspace": "", "generation": 83, "fitness": 0.13371081907547197, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.13483801990096833, 0.13268183570356162, 0.13361260162188593]}, "mutation_prompt": null}
{"id": "6c14b912-e7ad-4c73-8a0e-0aff4adaf4b3", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 - 0.5 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce an additional dynamic adjustment to the cognitive coefficient `c1` over time for better balance between exploration and exploitation.", "configspace": "", "generation": 84, "fitness": 0.13397751303228544, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.13465463692998603, 0.13357508341514346, 0.13370281875172685]}, "mutation_prompt": null}
{"id": "8c018f57-ae97-4bdd-b0d5-ccd4fdef741b", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * (0.4 + 0.5 * (self.global_best_value / np.min(personal_best_values)))  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce dynamic crossover probability adjustment by linking it to the current fitness improvement rate.", "configspace": "", "generation": 85, "fitness": 0.13436525163246701, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.13523993162096715, 0.13336330780547845, 0.13449251547095542]}, "mutation_prompt": null}
{"id": "fba2c114-80e6-44c3-b3eb-f2254aea8060", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            diversity = np.mean(np.std(pop, axis=0))  # Calculate diversity of population\n            self.F = max(0.4, min(0.9, diversity))  # Self-adaptive F based on diversity\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce adaptive scaling factor dynamics by leveraging population diversity to enhance convergence.", "configspace": "", "generation": 86, "fitness": 0.13420083294902993, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.13480110921513366, 0.1339265783583402, 0.1338748112736159]}, "mutation_prompt": null}
{"id": "2b1397e3-94be-4128-ba46-b8aebdd1a725", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - (evaluations / self.budget) ** 2)))  # Non-linear decay for F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a non-linear decay function for the scaling factor F to enhance exploitation-exploration balance.", "configspace": "", "generation": 87, "fitness": 0.13354839277680364, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.13508822239345109, 0.13163919912909083, 0.133917756807869]}, "mutation_prompt": null}
{"id": "8d18240c-f8cc-419b-8295-8f700c96a361", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.c1 = 1.2 + 0.6 * (1 - evaluations / self.budget)  # Dynamic cognitive coefficient\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce dynamic scaling for the cognitive coefficient to enhance exploration and convergence dynamics.", "configspace": "", "generation": 88, "fitness": 0.13505424997929685, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.1358571136690716, 0.13477042300397946, 0.13453521326483953]}, "mutation_prompt": null}
{"id": "5917529d-1f70-4c2f-aa80-68895538bfcb", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j] + np.random.normal(0, 0.1)  # Mutation step added\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce diversity by adding a mutation step to the DE's crossover process.", "configspace": "", "generation": 89, "fitness": 0.13429639170378846, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.1351207423095202, 0.13247970120240327, 0.13528873159944188]}, "mutation_prompt": null}
{"id": "38f951db-f82d-4e63-aefd-e486eb372d46", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.5 + 0.5 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.8 + 0.7 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Enhance convergence by dynamically adjusting cognitive and social coefficients in PSO.", "configspace": "", "generation": 90, "fitness": 0.13476314871350784, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.1357659659792071, 0.1332820643816135, 0.13524141577970294]}, "mutation_prompt": null}
{"id": "382c0278-93c3-4662-90a4-fde8ef2899ee", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * (0.3 + 0.1 * evaluations / self.budget)  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Incorporate a self-adaptive crossover probability to enhance exploration capabilities.", "configspace": "", "generation": 91, "fitness": 0.13487380406454552, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.1353758687771709, 0.13477345883782665, 0.13447208457863902]}, "mutation_prompt": null}
{"id": "c81b15d1-300e-4113-a505-20b704ee971e", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n            self.c2 = 1.0 + 1.5 * (evaluations / self.budget)  # Dynamic social coefficient\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Strengthen social learning by dynamically adjusting the social coefficient in PSO.", "configspace": "", "generation": 92, "fitness": 0.13505424997929685, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.1358571136690716, 0.13477042300397946, 0.13453521326483953]}, "mutation_prompt": null}
{"id": "6bd7d2fe-03d5-47c5-854b-8e2b2c3b5903", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * (1 - evaluations / self.budget)) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a dynamic adjustment to the social coefficient `c2` to enhance convergence speed and stability.", "configspace": "", "generation": 93, "fitness": 0.13434623067023754, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.1336264131532685, 0.13478858666082627, 0.13462369219661785]}, "mutation_prompt": null}
{"id": "0b5ce71b-7eb8-44d5-bac5-02ad5daadda5", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.std(pop) / (ub - lb)  # Adjusted to reflect diversity\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Improve exploration by dynamically adjusting the crossover probability based on the diversity of the population.", "configspace": "", "generation": 94, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {}, "mutation_prompt": null}
{"id": "6be7530e-24fc-467a-9d19-f2292a96b0ce", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.c1 = 1.0 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Dynamic cognitive coefficient\n            self.c2 = 1.5 + np.random.rand() * 0.5 * (1 - evaluations / self.budget)  # Dynamic social coefficient\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a dynamic adjustment of the cognitive and social coefficients in PSO, improving convergence speed and precision.", "configspace": "", "generation": 95, "fitness": 0.13450546343391248, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.13554119391475117, 0.1331047651854349, 0.1348704312015514]}, "mutation_prompt": null}
{"id": "1c19943c-fdee-4a3c-bfd3-3c95fa6276cd", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4 * evaluations / self.budget  # Dynamic Cr adjustment\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Incorporate dynamic crossover probability adjustment for enhanced exploration in later stages of optimization.", "configspace": "", "generation": 96, "fitness": 0.13451083064763292, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.13548884583225163, 0.13515316720547876, 0.13289047890516836]}, "mutation_prompt": null}
{"id": "7fc2bcc5-52ec-4dd8-861e-4d0eb375ade8", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (self.c1 * (0.5 + 0.5 * evaluations / self.budget)) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (self.c2 * (0.5 + 0.5 * evaluations / self.budget)) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce dynamic adjustment for cognitive and social coefficients in PSO, enhancing exploration-exploitation balance.", "configspace": "", "generation": 97, "fitness": 0.13452122631167132, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.13522798176161477, 0.13315996481606907, 0.13517573235733016]}, "mutation_prompt": null}
{"id": "86ab82ce-94d0-43ab-9c5b-c3090f4ba68c", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n            self.c1 = 1.5 + 0.5 * (evaluations / self.budget)  # Dynamic c1\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a dynamic scaling factor for PSO's cognitive coefficient to enhance exploration and exploitation balance.", "configspace": "", "generation": 98, "fitness": 0.13505424997929685, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.1358571136690716, 0.13477042300397946, 0.13453521326483953]}, "mutation_prompt": null}
{"id": "2470dc63-6b53-4454-a763-bc3a48b6276b", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Scaling factor for DE\n        self.Cr = 0.9  # Crossover probability for DE\n        self.w = 0.5  # Inertia weight for PSO\n        self.c1 = 1.5  # Cognitive coefficient for PSO\n        self.c2 = 1.5  # Social coefficient for PSO\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_values = np.array([func(ind) for ind in pop])\n\n        if np.min(personal_best_values) < self.global_best_value:\n            self.global_best_value = np.min(personal_best_values)\n            self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size // 2)\n            for i in range(self.population_size):\n                a, b, c = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.copy(pop[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.Cr:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                evaluations += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best_values[i] = trial_value\n                    personal_best_positions[i] = trial\n\n                    if trial_value < self.global_best_value:\n                        self.global_best_value = trial_value\n                        self.global_best_position = trial\n\n                # PSO Update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                (0.7 + 0.8 * evaluations / self.budget) * r1 * (personal_best_positions[i] - pop[i]) + \\\n                                (0.5 + 1.0 * evaluations / self.budget) * r2 * (self.global_best_position - pop[i])\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive parameter tuning\n            self.F = max(0.4, min(0.9, self.F * (1 - evaluations / self.budget)))  # Self-adaptive F\n            self.Cr = 0.6 + np.random.rand() * 0.4  # Adjusted range for Cr\n            self.c1 = 1.0 + 0.5 * (1 - evaluations / self.budget)  # Dynamic c1 adjustment\n            self.w = 0.4 + np.random.rand() * 0.4 * (1 - evaluations / self.budget)  # Inertia decay\n\n        return self.global_best_position, self.global_best_value", "name": "HybridDEPSO", "description": "Introduce a dynamic scaling of the cognitive coefficient in PSO to enhance convergence adaptability.", "configspace": "", "generation": 99, "fitness": 0.13505424997929685, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "683ac55e-4a8c-46d9-9674-00aa2b41d6a9", "metadata": {"aucs": [0.1358571136690716, 0.13477042300397946, 0.13453521326483953]}, "mutation_prompt": null}

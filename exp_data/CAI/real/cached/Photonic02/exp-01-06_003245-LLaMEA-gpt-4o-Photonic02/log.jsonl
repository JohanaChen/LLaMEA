{"id": "f8c586b4-b75f-4f85-8968-2d1fc61357db", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    # Scale position within bounds\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    # Update personal best\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    # Update global best\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                # Update velocities and positions (with inertia weight adjustment)\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], self.min_vel, self.max_vel)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        # Return best solution found\n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Adaptive Multi-Population Particle Swarm Optimization (AMP-PSO) with dynamic parameter tuning for diverse global exploration and local exploitation.", "configspace": "", "generation": 0, "fitness": 0.34011368973374406, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.01.", "error": "", "parent_id": null, "metadata": {"aucs": [0.3472883227378606, 0.340617169678999, 0.33243557678437263]}, "mutation_prompt": null}
{"id": "3b83e3dc-8b4f-4aeb-9f8d-c6e56f12da0d", "solution": "import numpy as np\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight\n        self.cognitive_coeff = 1.7  # Adjusted cognitive coefficient\n        self.social_coeff = 1.7  # Adjusted social coefficient\n        self.max_vel = 0.3  # Adjusted max velocity\n        self.min_vel = -0.3  # Adjusted min velocity\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    # Scale position within bounds\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    # Update personal best\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    # Update global best\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                inertia_adjustment = self.inertia_weight - (0.5 * eval_count / self.budget)  # Dynamic inertia adjustment\n                for i in range(self.population_size):\n                    r1, r2 = np.random.rand(2)\n                    selected_idx = np.random.choice(range(self.population_size))  # Competition-based selection\n                    population['velocities'][i] = inertia_adjustment * population['velocities'][i] + \\\n                                                  self.cognitive_coeff * r1 * (population['personal_best_positions'][i] - population['positions'][i]) + \\\n                                                  self.social_coeff * r2 * (population['personal_best_positions'][selected_idx] - population['positions'][i])  # Use selected competitor\n                    \n                    population['velocities'][i] = np.clip(population['velocities'][i], self.min_vel, self.max_vel)\n                    population['positions'][i] += population['velocities'][i]\n                    population['positions'][i] = np.clip(population['positions'][i], 0.0, 1.0)\n                \n        # Return best solution found\n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Enhanced_AMP_PSO", "description": "Enhanced Adaptive Multi-Population Particle Swarm Optimization (Enhanced AMP-PSO) with adaptive inertia and competition-based selection for improved exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.2604260059379284, "feedback": "The algorithm Enhanced_AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "f8c586b4-b75f-4f85-8968-2d1fc61357db", "metadata": {"aucs": [0.25081086086215354, 0.2619259951445654, 0.26854116180706633]}, "mutation_prompt": null}
{"id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced AMP-PSO with adaptive velocity limits for improved balance between exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.39924654702822976, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.04.", "error": "", "parent_id": "f8c586b4-b75f-4f85-8968-2d1fc61357db", "metadata": {"aucs": [0.3664341653005544, 0.36882198676903144, 0.4624834890151035]}, "mutation_prompt": null}
{"id": "dad5139c-84c1-4f01-be6c-e7b9e620ce71", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for pop_idx, population in enumerate(self.populations):\n                if eval_count > self.budget // 2 and pop_idx == 1:  # Dynamic population adjustment\n                    population['positions'] = population['positions'][:self.population_size // 2]\n                    population['velocities'] = population['velocities'][:self.population_size // 2]\n                    population['personal_best_positions'] = population['personal_best_positions'][:self.population_size // 2]\n                    population['personal_best_values'] = population['personal_best_values'][:self.population_size // 2]\n                    \n                for i in range(len(population['positions'])):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                # Interaction between populations\n                inter_pop_effect = np.mean([p['positions'] for p in self.populations], axis=0)\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions']) + \\\n                                           0.1 * (inter_pop_effect - population['positions'])  # Added multi-population interaction\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduced dynamic population size adjustment and multi-population interaction to enhance global search capabilities.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.').", "error": "ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.')", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {}, "mutation_prompt": null}
{"id": "e95eda47-a23b-41bb-b4ff-cd13244fa44a", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                dynamic_cognitive_coeff = self.cognitive_coeff * (1 + 0.5 * (eval_count / self.budget))\n                dynamic_social_coeff = self.social_coeff * (1 + 0.5 * (eval_count / self.budget))\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           dynamic_cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           dynamic_social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Improved AMP-PSO using dynamic cognitive and social coefficients for enhanced adaptation.", "configspace": "", "generation": 4, "fitness": 0.3343039055829722, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.01.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.34311342968012204, 0.32141736556135103, 0.3383809215074435]}, "mutation_prompt": null}
{"id": "3abda9b9-1176-4131-bfb5-bd1f9e3b6909", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                local_best_values = np.full(self.population_size, float('inf'))\n                local_best_positions = np.zeros((self.population_size, self.dim))\n                \n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                    # Dynamic neighborhood selection\n                    neighborhood_indices = np.random.choice(self.population_size, size=3, replace=False)\n                    for index in neighborhood_indices:\n                        if population['personal_best_values'][index] < local_best_values[i]:\n                            local_best_values[i] = population['personal_best_values'][index]\n                            local_best_positions[i] = population['personal_best_positions'][index]\n                \n                r1, r2, r3 = np.random.rand(3)\n                inertia_adjustment = 0.5 + r3 * 0.4  # Stochastic inertia weight\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (local_best_positions - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Improved AMP-PSO with dynamic neighborhood selection and stochastic inertia for enhanced convergence and diversity.", "configspace": "", "generation": 5, "fitness": 0.2888421096026079, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.2713642843940257, 0.27418218275099715, 0.3209798616628009]}, "mutation_prompt": null}
{"id": "582c844b-80dc-4630-85d0-74808ed55f83", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.6  # Changed from 1.5\n        self.social_coeff = 1.6  # Changed from 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Slightly increase cognitive and social coefficients to boost exploration and exploitation synergy.", "configspace": "", "generation": 6, "fitness": 0.30063599705768956, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.03.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.2792826176724632, 0.28585993457249614, 0.3367654389281094]}, "mutation_prompt": null}
{"id": "68ccdbe0-aa2c-480d-b6a4-78e855c26a19", "solution": "import numpy as np\n\nclass AMP_PSO_GM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.mutation_rate = 0.1  # Added mutation rate\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def _mutate(self, position):  # Genetic mutation operation\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = np.random.uniform(-0.1, 0.1, size=position.shape)\n            position += mutation_vector\n        return np.clip(position, 0.0, 1.0)\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = self._mutate(population['positions'])  # Apply mutation\n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO_GM", "description": "Introducing Genetic Mutation to AMP-PSO for enhanced diversity and convergence.", "configspace": "", "generation": 7, "fitness": 0.2931561591009401, "feedback": "The algorithm AMP_PSO_GM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.04.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.34080405797956637, 0.2566991806434994, 0.28196523867975454]}, "mutation_prompt": null}
{"id": "96daae1c-7356-49c9-aec6-444ace952352", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - 0.5 * (eval_count / self.budget)**2  # Nonlinear inertia adjustment\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) * (eval_count / self.budget) + \\  # Dynamic coefficient\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Adaptive Multi-Population PSO with Nonlinear Inertia and Dynamic Cognitive Coefficients for Enhanced Convergence.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: SyntaxError('unexpected character after line continuation character', ('<string>', 48, 286, \"                population['velocities'] = inertia_adjustment * population['velocities'] + \\\\\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) * (eval_count / self.budget) + \\\\  # Dynamic coefficient\\n\")).", "error": "SyntaxError('unexpected character after line continuation character', ('<string>', 48, 286, \"                population['velocities'] = inertia_adjustment * population['velocities'] + \\\\\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) * (eval_count / self.budget) + \\\\  # Dynamic coefficient\\n\"))", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {}, "mutation_prompt": null}
{"id": "666cbbfa-9cdf-4c8b-8dd3-db1fd26bc5bb", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                adaptive_cognitive_coeff = self.cognitive_coeff * (1 + 0.5 * eval_count / self.budget)\n                adaptive_social_coeff = self.social_coeff * (1 - 0.5 * eval_count / self.budget)\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           adaptive_cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           adaptive_social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduced dynamic cognitive and social coefficients to enhance the exploration-exploitation balance over iterations.", "configspace": "", "generation": 9, "fitness": 0.36179945023243665, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.03.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.3288423502804829, 0.4025790413903184, 0.3539769590265086]}, "mutation_prompt": null}
{"id": "db66d055-6463-445b-8c26-c56fad56a915", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.neighborhood_size = max(3, dim // 2)\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 * (1 - eval_count / self.budget)  # Self-adaptive inertia\n                local_best_position = self._get_local_best(population['positions'], population['personal_best_values'], i)\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (local_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], self.min_vel, self.max_vel)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)\n    \n    def _get_local_best(self, positions, personal_best_values, index):\n        neighborhood_indices = (np.arange(index - self.neighborhood_size, index + self.neighborhood_size + 1) % self.population_size)\n        local_best_index = neighborhood_indices[np.argmin(personal_best_values[neighborhood_indices])]\n        return positions[local_best_index]", "name": "AMP_PSO", "description": "Improved AMP-PSO with dynamic neighborhood and self-adaptive inertia for enhanced exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.277236974063753, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.02.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.29833050194688193, 0.25443751004134507, 0.27894291020303197]}, "mutation_prompt": null}
{"id": "38e0d9fb-098b-4adb-a95e-055dab073149", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(10, 5 * dim)\n        self.min_population_size = 5  # New parameter for minimum population size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population(self.initial_population_size) for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self, size):  # Adjusted to take dynamic size\n        return {\n            'positions': np.random.uniform(size=(size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(size, self.dim)),\n            'personal_best_positions': np.zeros((size, self.dim)),\n            'personal_best_values': np.full(size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        population_size = self.initial_population_size\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n                    \n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = self.max_vel * (1 - eval_count / self.budget)  # Simplified adaptive velocity limit\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n            if eval_count % (self.budget // 10) == 0:  # Dynamic population resizing\n                population_size = max(self.min_population_size, int(population_size * 0.9))\n                self.populations = [self._initialize_population(population_size) for _ in range(3)]\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Improved AMP_PSO with dynamic population resizing and diversity preservation for enhanced exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.30340586809100306, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.02.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.32460294371229415, 0.2906870849180643, 0.2949275756426507]}, "mutation_prompt": null}
{"id": "4c59caab-7662-4e7c-814a-e77347a33174", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                population['velocities'] = (inertia_adjustment * self.inertia_weight) * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introducing a decay factor to the inertia weight for improved exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.34364441221554154, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.01.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.3340374782517599, 0.3474412906130736, 0.349454467781791]}, "mutation_prompt": null}
{"id": "83ba8146-8dd1-43d1-be57-da5fcbe62f19", "solution": "import numpy as np\n\nclass AMP_PSO_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                ranks = np.argsort(population['personal_best_values'])\n                stochastic_factor = np.random.rand(self.population_size, self.dim)\n                population['positions'] += stochastic_factor * (population['positions'][ranks[0]] - population['positions'])\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO_Hybrid", "description": "A hybrid AMP-PSO with stochastic rank-based selection for enhanced diversity and convergence.", "configspace": "", "generation": 13, "fitness": 0.2986617420020076, "feedback": "The algorithm AMP_PSO_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.2979321840467428, 0.2940978245837642, 0.3039552173755159]}, "mutation_prompt": null}
{"id": "ecfad652-7238-4bd2-8b91-ed6119d32ba9", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                cognitive_dynamic = self.cognitive_coeff * (1 - eval_count / self.budget)  # Dynamic adjustment\n                social_dynamic = self.social_coeff * (eval_count / self.budget)  # Dynamic adjustment\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_dynamic * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_dynamic * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduced dynamic cognitive and social coefficients to enhance exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.39070837068477954, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.03.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.35678397243826454, 0.3908350059645409, 0.4245061336515331]}, "mutation_prompt": null}
{"id": "78ea5065-739f-423a-b640-ad15324c57fd", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                \n                # Adaptive coefficients based on current progress\n                cognitive_coeff_adaptive = self.cognitive_coeff * (1 - eval_count / self.budget)\n                social_coeff_adaptive = self.social_coeff * (1 - eval_count / self.budget)\n                \n                local_best_position = np.mean([pop['personal_best_positions'] for pop in self.populations], axis=0)\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adaptive * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adaptive * r2 * (self.global_best_position - local_best_position)\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce adaptive learning coefficients and local best sharing among populations to enhance convergence in AMP-PSO.", "configspace": "", "generation": 15, "fitness": 0.2792480914060355, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.01.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.27116992051074607, 0.2946942365688343, 0.2718801171385261]}, "mutation_prompt": null}
{"id": "373de7c0-1e75-4421-8996-d24e6694bb96", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Self-adaptive inertia weight\n                self.inertia_weight = 0.9 - (0.5 * eval_count / self.budget)\n                # Mutation strategy to escape local optima\n                if eval_count > self.budget * 0.5:\n                    mutation_rate = 0.1\n                    mutation_mask = np.random.rand(self.population_size, self.dim) < mutation_rate\n                    population['positions'] = np.where(mutation_mask, np.random.uniform(size=(self.population_size, self.dim)), population['positions'])\n                \n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                population['velocities'] = self.inertia_weight * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Integrate self-adaptive parameter control and mutation strategy into AMP_PSO for enhanced exploration and convergence speed.", "configspace": "", "generation": 16, "fitness": 0.2880035563832796, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.30745289987000024, 0.26613846376000727, 0.2904193055198314]}, "mutation_prompt": null}
{"id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                # Changed line: Adjust social coefficient with budget usage\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Improved exploration by adjusting social coefficient decay with budget usage.", "configspace": "", "generation": 17, "fitness": 0.4153494947786392, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.03.", "error": "", "parent_id": "c18f7c07-2dbc-4ad6-8bf6-e65b57e8fecb", "metadata": {"aucs": [0.3986288225789315, 0.3896800667648047, 0.45773959499218153]}, "mutation_prompt": null}
{"id": "1f4404a8-86b5-4ed1-b7f7-da8f23760cd3", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.diversity_boost = 0.1  # Added line: diversity boost factor\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                adaptive_cognitive_coeff = self.cognitive_coeff * (0.5 + 0.5 * np.random.rand())  # Adaptive cognitive coefficient\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Adjusted line: Combined adaptive cognitive coefficient and diversity boost factor\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           adaptive_cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions']) + \\\n                                           self.diversity_boost * np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim))\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced particle swarm optimization with adaptive cognitive and diversity-boost mechanisms.", "configspace": "", "generation": 18, "fitness": 0.30060761736835945, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.03.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3150421598147991, 0.25770369580120134, 0.32907699648907796]}, "mutation_prompt": null}
{"id": "4c45fdd3-af2e-4ece-8cd6-86ac0d49366d", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                # Changed line: Enhanced adaptive velocity range\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                # Changed line: Adjusted social coefficient strategy\n                social_coeff_adjusted = self.social_coeff * (1 - 0.5 * eval_count / self.budget)\n\n                # Changed line: Enhanced dynamic velocity adjustment\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                # Changed line: Improved boundary control\n                population['positions'] = np.clip(population['positions'], 0.1, 0.9)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced velocity adjustment and dynamic population interaction for improved convergence.", "configspace": "", "generation": 19, "fitness": 0.3392872374072368, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3399545167502045, 0.32751017993917286, 0.35039701553233293]}, "mutation_prompt": null}
{"id": "1626798e-90b8-4e9b-b434-6cbe3ef397ae", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        adaptive_inertia_weight = self.inertia_weight\n        diversity_threshold = self.budget // 4  # Trigger diversity bonus\n        \n        while eval_count < self.budget:\n            for idx, population in enumerate(self.populations):\n                if eval_count > diversity_threshold * (idx + 1) and len(self.populations) < 5:\n                    self.populations.append(self._initialize_population())  # Dynamic subdivision\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = adaptive_inertia_weight - (0.5 * eval_count / self.budget)  # Adaptive inertia\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                \n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced diversity and convergence using adaptive inertia and dynamic subdivision of populations.", "configspace": "", "generation": 20, "fitness": 0.29120699178268505, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3190573279127652, 0.2728446212694825, 0.28171902616580746]}, "mutation_prompt": null}
{"id": "de3a810a-517c-4304-9a33-a717a1ae5a0b", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                # Changed line: Adjust cognitive coefficient with budget usage\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced exploration by dynamically adjusting cognitive coefficient based on budget usage.", "configspace": "", "generation": 21, "fitness": 0.3671606741082512, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3531873633326926, 0.35635525165992954, 0.3919394073321315]}, "mutation_prompt": null}
{"id": "0c8079bd-dca1-4a9a-a64b-dea07441eff6", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        # Changed line: Introduce dynamic population count based on budget\n        self.populations = [self._initialize_population(int(self.population_size * (1 + 0.5 * i / (self.budget // self.population_size)))) for i in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self, size):\n        return {\n            'positions': np.random.uniform(size=(size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(size, self.dim)),\n            'personal_best_positions': np.zeros((size, self.dim)),\n            'personal_best_values': np.full(size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        # Changed line: Add dynamic inertia weight calculation\n        inertia_dynamic_start = 0.9\n        inertia_dynamic_end = 0.4\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(len(population['positions'])):  # Changed line: Use dynamic population size\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Changed line: Dynamic inertia weight for better exploration-exploitation balance\n                inertia_adjustment = inertia_dynamic_start - (inertia_dynamic_start - inertia_dynamic_end) * (eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced PSO with adaptive population and dynamic inertia weight to improve convergence and exploration balance.", "configspace": "", "generation": 22, "fitness": 0.298476899858241, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3237947778848247, 0.2876833694817449, 0.2839525522081534]}, "mutation_prompt": null}
{"id": "fc668d53-710f-44b8-a2af-d7094fbf3ea5", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.7 * eval_count / self.budget)  # Fine-tuned inertia decay\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced convergence by fine-tuning the inertia weight decay based on evaluation count.", "configspace": "", "generation": 23, "fitness": 0.39109414356994665, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.36704052514486196, 0.39371110745711135, 0.41253079810786664]}, "mutation_prompt": null}
{"id": "4e2332f9-3f58-4506-97fe-6531c9bbbc51", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                local_best_index = np.argmin(population['personal_best_values'])\n                local_best_position = population['personal_best_positions'][local_best_index]\n\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2, r3 = np.random.rand(3)\n                inertia_adjustment = 0.4 + 0.5 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions']) + \\\n                                           0.5 * r3 * (local_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced AMP_PSO with adaptive inertia and hierarchical information sharing for diverse exploration.", "configspace": "", "generation": 24, "fitness": 0.2866925181613141, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3006358962400032, 0.2681997301135166, 0.2912419281304225]}, "mutation_prompt": null}
{"id": "58b56774-364e-44e0-8928-0729aa4ce185", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.95 - (0.8 * eval_count / self.budget)  # Fine-tuned line\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Fine-tune inertia adjustment for enhanced convergence speed and stability.", "configspace": "", "generation": 25, "fitness": 0.40857914125659506, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.42975221342778724, 0.3971854389139533, 0.39879977142804457]}, "mutation_prompt": null}
{"id": "08d9f3e1-4264-4460-a722-2a4a3c4250ca", "solution": "import numpy as np\n\nclass AMP_PSO_RW:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Introduce random walk component for enhanced exploration\n                random_walk = np.random.uniform(low=-0.05, high=0.05, size=(self.population_size, self.dim))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions']) + \\\n                                           random_walk\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO_RW", "description": "Adaptive hybrid strategy combining PSO with random walks to enhance exploration and exploitation balance.", "configspace": "", "generation": 26, "fitness": 0.28177417126900034, "feedback": "The algorithm AMP_PSO_RW got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.2859053823764409, 0.2738011109770625, 0.28561602045349754]}, "mutation_prompt": null}
{"id": "0240a7b6-ecaf-4924-8a14-5f7b642a5b92", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.7  # Changed line: Increased cognitive coefficient from 1.5 to 1.7\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Slightly increase the cognitive coefficient to enhance individual exploration while adhering to the adjustment constraints.", "configspace": "", "generation": 27, "fitness": 0.40030398002063056, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.4012196141504958, 0.37024831225610055, 0.4294440136552954]}, "mutation_prompt": null}
{"id": "a3ccc0e0-f22f-43cc-8824-1c5186c4f472", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.5 * eval_count / self.budget)\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 + eval_count / (2 * self.budget))\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], self.min_vel, self.max_vel)  # Removed adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced exploitation via dynamic learning parameters adjusting inertia weight and cognitive coefficients over iterations.", "configspace": "", "generation": 28, "fitness": 0.30683491009446967, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3375193022915379, 0.2858852062633418, 0.29710022172852923]}, "mutation_prompt": null}
{"id": "458a3e87-e2cb-4b56-a343-76682d006a0f", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight_max = 0.9  # Changed line: Adaptive inertia weight\n        self.inertia_weight_min = 0.4  # Changed line: Adaptive inertia weight\n        self.cognitive_coeff_max = 2.5  # Changed line: Dynamic cognitive coefficient\n        self.cognitive_coeff_min = 1.0  # Changed line: Dynamic cognitive coefficient\n        self.social_coeff_max = 2.5  # Changed line: Dynamic social coefficient\n        self.social_coeff_min = 1.0  # Changed line: Dynamic social coefficient\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                \n                # Changed lines: Adaptive inertia, cognitive and social coefficients\n                progress = eval_count / self.budget\n                inertia_weight = self.inertia_weight_max - (self.inertia_weight_max - self.inertia_weight_min) * progress\n                cognitive_coeff = self.cognitive_coeff_max - (self.cognitive_coeff_max - self.cognitive_coeff_min) * progress\n                social_coeff = self.social_coeff_max - (self.social_coeff_max - self.social_coeff_min) * progress\n                \n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_weight * population['velocities'] + \\\n                                           cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced AMP_PSO via adaptive inertia weight and dynamic cognitive/social coefficients for improved convergence.", "configspace": "", "generation": 29, "fitness": 0.28923354650628924, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.03.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3016917891230392, 0.2539512972102945, 0.31205755318553396]}, "mutation_prompt": null}
{"id": "89e54457-4c67-47c4-a54b-3bb9d9878475", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.5  # Changed line: Adjusted inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = 0.2 * (1 - eval_count / self.budget)  # Changed line: Simplified adaptive velocity calculation\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (eval_count / self.budget))  # Changed line: Adaptive cognitive coefficient\n                # Changed line: Adjust social coefficient with budget usage\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n\n                # Added line: Restart strategy\n                if eval_count % (self.budget // 3) == 0:\n                    self._restart_population(population)\n\n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)\n\n    def _restart_population(self, population):  # Added method: Restart population strategy\n        worst_indices = np.argsort(population['personal_best_values'])[-self.population_size//5:]\n        for i in worst_indices:\n            population['positions'][i] = np.random.uniform(size=self.dim)\n            population['velocities'][i] = np.random.uniform(low=self.min_vel, high=self.max_vel, size=self.dim)\n            population['personal_best_positions'][i] = np.zeros(self.dim)\n            population['personal_best_values'][i] = float('inf')", "name": "AMP_PSO", "description": "Enhanced AMP_PSO with adaptive cognitive coefficient and restart strategy for better convergence.", "configspace": "", "generation": 30, "fitness": 0.3112305759325334, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.04.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.35694741389777507, 0.2640129923820492, 0.31273132151777583]}, "mutation_prompt": null}
{"id": "06e1b4fb-5cab-47e4-9020-ca2f42700e53", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        # Line 1: Added mutation to enhance exploration\n                        population['personal_best_positions'][i] = population['positions'][i] + np.random.normal(0, 0.1, size=self.dim)\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced exploration by adding mutation to personal best positions, maintaining the balance of exploration and exploitation.", "configspace": "", "generation": 31, "fitness": 0.3360109093648906, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3357359020153138, 0.3261117140994284, 0.3461851119799295]}, "mutation_prompt": null}
{"id": "11c5aa25-0359-4e03-8071-5c416e75a646", "solution": "import numpy as np\n\nclass AMP_PSO_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  \n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Changed line: Introduce dynamic cognitive coefficient adjustment\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 - 0.5 * eval_count / self.budget)  \n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                # Changed line: Hybrid exploration mechanism\n                if eval_count < 0.5 * self.budget:  \n                    population['positions'] = np.clip(population['positions'] + np.tanh(population['velocities']), 0.0, 1.0)\n                else:\n                    population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO_Improved", "description": "Introduce dynamic cognitive coefficient adjustment and hybrid exploration mechanisms to enhance convergence and exploration balance.", "configspace": "", "generation": 32, "fitness": 0.3347731458833177, "feedback": "The algorithm AMP_PSO_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.05.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.37820871284943336, 0.3562704797100338, 0.269840245090486]}, "mutation_prompt": null}
{"id": "b8247e3c-7f1a-4d2e-953a-1c2d70591627", "solution": "import numpy as np\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_weight = self.initial_inertia_weight - ((self.initial_inertia_weight - self.final_inertia_weight) * (eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  \n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_weight * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  \n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n            \n            # Collaboration step to share global best position among populations\n            for population in self.populations:\n                population['positions'] += 0.1 * (self.global_best_position - population['positions'])\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Enhanced_AMP_PSO", "description": "Enhanced exploration by dynamically adjusting inertia and introducing multi-population collaboration.", "configspace": "", "generation": 33, "fitness": 0.296941281527547, "feedback": "The algorithm Enhanced_AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3223554413133699, 0.26378878478221557, 0.3046796184870556]}, "mutation_prompt": null}
{"id": "d74ddf51-35df-43a9-8239-1ad90934f57e", "solution": "import numpy as np\n\nclass Hybrid_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.mutation_probability = 0.1\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.5 * eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                # Mutation mechanism\n                if np.random.rand() < self.mutation_probability:\n                    mutation_vector = np.random.uniform(low=-0.1, high=0.1, size=population['positions'].shape)\n                    population['positions'] += mutation_vector\n                \n                population['velocities'] = np.clip(population['velocities'], self.min_vel, self.max_vel)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Hybrid_PSO", "description": "Hybrid PSO with dynamic inertia and mutation for enhanced exploration and exploitation balance.", "configspace": "", "generation": 34, "fitness": 0.2967838279050926, "feedback": "The algorithm Hybrid_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.04.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3456890560487871, 0.25263736444113294, 0.2920250632253578]}, "mutation_prompt": null}
{"id": "37bab6c2-52bb-4cfa-8853-67b58623fc7a", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Differential evolution-inspired mutation\n                F = 0.5\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                X_r1, X_r2, X_r3 = population['positions'][indices]\n                mutant_vector = X_r1 + F * (X_r2 - X_r3)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (mutant_vector - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced diversity and convergence by incorporating differential evolution-based mutation in velocity update.", "configspace": "", "generation": 35, "fitness": 0.2627551797478303, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.2627707311850689, 0.24875673140892363, 0.27673807664949845]}, "mutation_prompt": null}
{"id": "b49de5ee-7953-4520-9e7b-3f6b53ec101b", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                # Changed lines: Adjust cognitive coefficient and inertia weight\n                cognitive_coeff_adjusted = self.cognitive_coeff + 0.5 * (eval_count / self.budget)\n                inertia_weight_adjusted = self.inertia_weight * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_weight_adjusted * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced social and cognitive adaptation by varying coefficients based on function evaluations, improving search balance.", "configspace": "", "generation": 36, "fitness": 0.32328809569651057, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.04.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3527251203573766, 0.35422630593954574, 0.26291286079260945]}, "mutation_prompt": null}
{"id": "82c2c55a-73a1-4f7c-b737-2cb9a1324ccf", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * np.sin(np.pi * eval_count / self.budget))  # Nonlinear inertia\n                cognitive_coeff_adjusted = self.cognitive_coeff * np.random.uniform(0.5, 1.5)  # Stochastic cognitive coefficient\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced adaptive PSO with nonlinear inertia and stochastic cognitive coefficient.", "configspace": "", "generation": 37, "fitness": 0.293386517024603, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.03.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.32484023856816513, 0.2615623336078088, 0.29375697889783503]}, "mutation_prompt": null}
{"id": "64bdbb66-2d37-4a90-896e-b54cd1cc0fd2", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                # Changed line: Adjust cognitive coefficient with budget usage\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced exploration by dynamically adapting the cognitive coefficient based on function evaluation progress.", "configspace": "", "generation": 38, "fitness": 0.4047772284510965, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.41180148030171704, 0.3980218044492627, 0.40450840060230975]}, "mutation_prompt": null}
{"id": "971abb0c-b21e-4797-aec2-a6500d782621", "solution": "import numpy as np\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                diversity = np.mean(np.std(population['positions'], axis=0))  # Calculate diversity\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n\n                # Dynamic adjustment of cognitive coefficient based on diversity\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 + diversity)\n\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Enhanced_AMP_PSO", "description": "Enhanced AMP_PSO by introducing dynamic population diversity control and adaptive cognitive coefficient.", "configspace": "", "generation": 39, "fitness": 0.2854142727553608, "feedback": "The algorithm Enhanced_AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3122884134001054, 0.2576881753304231, 0.2862662295355539]}, "mutation_prompt": null}
{"id": "4a6f6e80-2dd5-4ac2-a8b9-afa5a98b769f", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 + 0.5 * eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - 0.5 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Adaptive multi-population PSO with dynamic cognitive and social coefficient adjustments for enhanced exploration and exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.2916125626807923, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.03.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.31917219383789697, 0.25703230389180076, 0.2986331903126791]}, "mutation_prompt": null}
{"id": "3a6f8e04-3dc8-411b-9898-95143f9dd82a", "solution": "import numpy as np\n\nclass Hybrid_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Differential Evolution mutation and crossover\n                a, b, c = population['positions'][np.random.choice(self.population_size, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), 0, 1)\n                crossover = np.random.rand(self.dim) < 0.9\n                trial_position = np.where(crossover, mutant, population['positions'][i])\n                \n                trial_value = func(bounds.lb + trial_position * (bounds.ub - bounds.lb))\n                eval_count += 1\n                if trial_value < population['personal_best_values'][i]:\n                    population['positions'][i] = trial_position\n                    population['personal_best_positions'][i] = trial_position\n                    population['personal_best_values'][i] = trial_value\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Hybrid_PSO_DE", "description": "Hybrid strategy combining adaptive PSO with differential evolution for enhanced convergence.", "configspace": "", "generation": 41, "fitness": 0.28608786861175733, "feedback": "The algorithm Hybrid_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.31098835940270575, 0.265235694392312, 0.2820395520402542]}, "mutation_prompt": null}
{"id": "a1b23a32-3085-4bbe-853f-05975a41a1aa", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Changed line: Dynamic inertia weight decay further towards the end of the budget\n                inertia_adjustment = 0.9 - (0.85 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced velocity adjustment through dynamic inertia weight decay for improved convergence.", "configspace": "", "generation": 42, "fitness": 0.39628857261138933, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3993027947611567, 0.37079393179741527, 0.4187689912755961]}, "mutation_prompt": null}
{"id": "261c2b1f-e1ea-473e-9864-146be6e2b9a2", "solution": "import numpy as np\n\nclass Adaptive_MultiSwarm_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(4)]  # Increased number of swarms\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                # Introducing learning mechanism among swarms\n                if eval_count % (self.budget // 4) == 0:\n                    for swarm in self.populations:\n                        for pos in swarm['positions']:\n                            if np.random.rand() < 0.1:\n                                pos[:] = np.random.choice(self.populations)['global_best_position']\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Adaptive_MultiSwarm_PSO", "description": "Incorporate multi-swarm adaptive particle learning to maintain diversity and improve performance.", "configspace": "", "generation": 43, "fitness": -Infinity, "feedback": "An exception occurred: KeyError('global_best_position').", "error": "KeyError('global_best_position')", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {}, "mutation_prompt": null}
{"id": "6ad918ba-6e63-4a23-8e9e-ea2a28435f74", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Changed line: Adjust inertia weight with budget usage for better exploration\n                inertia_adjustment = 0.9 - (0.5 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                # Changed line: Further adjust social coefficient to enhance convergence towards the end\n                social_coeff_adjusted = self.social_coeff * (0.5 + 0.5 * eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced exploration with adaptive inertia weight adjustment based on budget usage.", "configspace": "", "generation": 44, "fitness": 0.36602431435965116, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.03.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.41171872793632336, 0.33024082401123944, 0.35611339113139073]}, "mutation_prompt": null}
{"id": "8f5dca02-8ca8-4119-b5bb-cf98de56c81e", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                # Changed line: Introduce adaptive cognitive coefficient\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * eval_count / self.budget) \n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                # Changed line: Adjust social coefficient with budget usage\n                social_coeff_adjusted = self.social_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                # Changed line: Use adjusted cognitive and social coefficients\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced exploration-exploitation balance with adaptive cognitive and social coefficients based on evaluation progress.", "configspace": "", "generation": 45, "fitness": 0.2888226947276982, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3091118995897695, 0.2600992177310385, 0.29725696686228664]}, "mutation_prompt": null}
{"id": "03288953-0a39-407c-a918-9d379198327a", "solution": "import numpy as np\n\nclass AMP_PSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.cognitive_coeff = 2.0  # Increased cognitive coefficient\n        self.social_coeff = 1.5\n        self.max_vel = 0.3  # Expanded velocity range\n        self.min_vel = -0.3\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                diversity_factor = np.std(population['positions'], axis=0)\n                adaptive_inertia = self.inertia_weight * (1 - diversity_factor) + 0.5\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = adaptive_inertia * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], self.min_vel, self.max_vel)  # Maintain expanded range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO_Enhanced", "description": "Enhanced diversity and convergence through adaptive population diversity and momentum strategies.", "configspace": "", "generation": 46, "fitness": 0.2996829031918931, "feedback": "The algorithm AMP_PSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.03.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3012121784169691, 0.2599761404122911, 0.33786039074641916]}, "mutation_prompt": null}
{"id": "19aa82f2-ac1b-4b9a-b5d7-2740a4190cb5", "solution": "import numpy as np\n\nclass AMP_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.f = 0.5  # Differential weight\n        self.cr = 0.7  # Crossover probability\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    pos = population['positions'][i]\n                    scaled_position = bounds.lb + pos * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = pos\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = pos\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.6 + 0.3 * np.cos(np.pi * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                \n                # Differential Evolution Mutation\n                for j in range(self.population_size):\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    x1, x2, x3 = population['positions'][idxs]\n                    mutant = x1 + self.f * (x2 - x3)\n                    trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population['positions'][j])\n                    population['positions'][j] = np.clip(trial, 0.0, 1.0)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO_DE", "description": "Enhancing local and global search balance by dynamic inertia and hybridization with differential evolution (DE).", "configspace": "", "generation": 47, "fitness": 0.3029029078757213, "feedback": "The algorithm AMP_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.2780078548018823, 0.2965454723368175, 0.33415539648846404]}, "mutation_prompt": null}
{"id": "51b403f2-38b4-43d6-a3e9-ce162a272a15", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Changed line: Reduce inertia weight linearly over time\n                inertia_adjustment = 0.9 - (0.5 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Reduce inertia weight linearly over time to enhance exploration and exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.3577316381819317, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.03.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3526685744800301, 0.3299545830984545, 0.3905717569673106]}, "mutation_prompt": null}
{"id": "2a353b22-3578-49bd-88e7-4b46051b3b77", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9  # Changed: Adjusted initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.3  # Changed: Increased maximum velocity for better exploration\n        self.min_vel = -0.3  # Changed: Increased minimum velocity for symmetry\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight - (0.4 * eval_count / self.budget)  # Changed: Dynamic inertia adjustment\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                \n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Changed: Added momentum term for velocity update\n                momentum = 0.1 * np.random.randn(self.population_size, self.dim)\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions']) + \\\n                                           momentum\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n\n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced multi-population PSO with dynamic inertia and velocity adaptation for improved optimization.", "configspace": "", "generation": 49, "fitness": 0.2895170735573868, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.30034084603368394, 0.2795371696079245, 0.28867320503055194]}, "mutation_prompt": null}
{"id": "6fcc5d85-2a48-4bdd-8ce2-ff9e5f47266d", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                # Changed line: Adjust cognitive coefficient with budget usage\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced convergence speed by introducing time-varying cognitive coefficient adjustment.", "configspace": "", "generation": 50, "fitness": 0.4112865018164289, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.41766808661942156, 0.3854854640484424, 0.4307059547814226]}, "mutation_prompt": null}
{"id": "16fb83d7-810c-44b0-a9b9-1db56887a942", "solution": "import numpy as np\n\nclass AMP_PSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9  # Increased initial inertia\n        self.cognitive_coeff = 2.0  # Increased cognitive coefficient\n        self.social_coeff = 1.5\n        self.max_vel = 0.3  # Increased max velocity\n        self.min_vel = -0.3  # Increased min velocity\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight - (0.5 * eval_count / self.budget)  # More gradual decrease\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (0.5 + 0.5 * (1 - eval_count / self.budget))  # Adjusted adaptive velocity\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO_Enhanced", "description": "Enhanced dynamic adaptation of inertia and velocity constraints for better convergence in varying landscapes.", "configspace": "", "generation": 51, "fitness": 0.2865794081464131, "feedback": "The algorithm AMP_PSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.30619619398112685, 0.2625619559218133, 0.29098007453629904]}, "mutation_prompt": null}
{"id": "fb945cbd-0164-4f9c-a9c3-3ce03a3ebd2b", "solution": "import numpy as np\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9  # Changed line: Starting higher inertia for better exploration\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.7  # Changed line: Increased social coefficient for enhanced global search\n        self.max_vel = 0.3  # Changed line: Increased maximum velocity\n        self.min_vel = -0.3  # Changed line: Increased minimum velocity\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.7 * eval_count / self.budget)  # Changed line: Modified decay rate\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (0.5 + 0.5 * (1 - eval_count / self.budget))  # Changed line: Dynamic velocity limit\n                social_coeff_adjusted = self.social_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))  # Changed line: Dynamic social coefficient\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Enhanced_AMP_PSO", "description": "Enhanced global exploration and exploitation using adaptive inertia and velocity clamping based on convergence rate.", "configspace": "", "generation": 52, "fitness": 0.2921142159104214, "feedback": "The algorithm Enhanced_AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.2912036164510332, 0.2839952446411439, 0.30114378663908714]}, "mutation_prompt": null}
{"id": "58b160e2-45ea-427f-8dbc-68daeabee578", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9  # Adjusted inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            neighborhood_best_positions = []\n            for population in self.populations:\n                local_best_value = float('inf')\n                local_best_position = None\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n                    \n                    if current_value < local_best_value:\n                        local_best_value = current_value\n                        local_best_position = population['positions'][i]\n                \n                neighborhood_best_positions.append(local_best_position)\n                \n                r1, r2, r3 = np.random.rand(3)\n                inertia_adjustment = self.inertia_weight * (1 - eval_count / self.budget)  # Dynamic inertia\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions']) + \\\n                                           0.5 * r3 * (local_best_position - population['positions'])  # New neighborhood influence\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Adaptive multi-population PSO with dynamic inertia and neighborhood influence for enhanced exploration and exploitation balance.", "configspace": "", "generation": 53, "fitness": 0.29723460379901234, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.04.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.34319206575670047, 0.25582106297359786, 0.2926906826667387]}, "mutation_prompt": null}
{"id": "2448f6d1-55cd-4b8a-9536-bf1d6da99e52", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Changed line: Adjust inertia weight with budget usage\n                inertia_adjustment = 0.9 - (0.6 * eval_count / self.budget)  # Slightly reduce the range of inertia adjustment\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced convergence by dynamically adjusting the inertia weight based on budget usage.", "configspace": "", "generation": 54, "fitness": 0.4079734984050301, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.4158298411912078, 0.4007013479941812, 0.40738930602970147]}, "mutation_prompt": null}
{"id": "57cbf53d-a065-450c-bce6-7acf801e7ee3", "solution": "import numpy as np\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf')),\n            'diversity_factor': np.random.uniform(0.8, 1.2, self.population_size)  # Add diversity factor\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget) \n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                # Enhance: Adjust velocities with diversity factor\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) * population['diversity_factor'].reshape(-1, 1) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n                # Update diversity factor to maintain exploration\n                population['diversity_factor'] = np.random.uniform(0.8, 1.2, self.population_size)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Enhanced_AMP_PSO", "description": "Adaptive momentum-based swarm optimization with enhanced diversity control and adaptive velocity adjustments for robust convergence.", "configspace": "", "generation": 55, "fitness": 0.2895434878383701, "feedback": "The algorithm Enhanced_AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3129700985862025, 0.27728272269136345, 0.27837764223754424]}, "mutation_prompt": null}
{"id": "e133cb14-81f9-4095-97c0-3ed63ba0516f", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.7  # Increased initial social coefficient\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                # Changed line: Adjust social coefficient with budget usage\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Refined social coefficient decay for better convergence by slightly increasing the initial social influence.", "configspace": "", "generation": 56, "fitness": 0.3712736951412663, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3786075099488696, 0.37825383744025887, 0.3569597380346705]}, "mutation_prompt": null}
{"id": "9c917948-e310-4874-a4ee-768526bd94e2", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n\n    def _opposition_based_learning(self, positions, bounds):\n        opposite_positions = bounds.ub + bounds.lb - positions\n        return opposite_positions\n\n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n\n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight - (0.5 * eval_count / self.budget)  # Dynamic inertia\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n\n                if eval_count % (self.budget // 10) == 0:  # Use elite OBL periodically\n                    opp_positions = self._opposition_based_learning(population['positions'], bounds)\n                    for j in range(self.population_size):\n                        opp_scaled_position = bounds.lb + opp_positions[j] * (bounds.ub - bounds.lb)\n                        opp_value = func(opp_scaled_position)\n                        eval_count += 1\n                        if opp_value < population['personal_best_values'][j]:\n                            population['personal_best_positions'][j] = opp_positions[j]\n                            population['personal_best_values'][j] = opp_value\n\n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced AMP_PSO by introducing dynamic inertia and introducing elite opposition-based learning to refine exploration and exploitation.", "configspace": "", "generation": 57, "fitness": 0.27286596760277476, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.2981905720488175, 0.25524977541306515, 0.2651575553464417]}, "mutation_prompt": null}
{"id": "90f0c247-ea90-40fd-ae6a-c8810a5f6574", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + eval_count / (2 * self.budget))  # New line: Adaptive cognitive coefficient\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced AMP_PSO by introducing adaptive cognitive coefficient scaling to improve balance between exploration and exploitation.", "configspace": "", "generation": 58, "fitness": 0.410256408458606, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.04.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.45151323623926876, 0.3631921278409026, 0.41606386129564654]}, "mutation_prompt": null}
{"id": "5f765191-d4e6-4ddd-81f3-d80aeadcbe22", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.5 * eval_count / self.budget)  # Adjusted inertia weight range\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 + np.sin(np.pi * eval_count / self.budget))  # New learning rate strategy\n                social_coeff_adjusted = self.social_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))  # Increased influence of diversity\n                \n                # Adjust velocities with new learning rates\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced diversified search with adaptive learning rates and population diversity strategies.", "configspace": "", "generation": 59, "fitness": 0.2913461362894848, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.30990883253691526, 0.2569710021533793, 0.30715857417815984]}, "mutation_prompt": null}
{"id": "bdb37d7e-b2bb-4a65-9a25-527236053e1f", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        phase_switch = self.budget // 2\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                \n                # Dual-phase adjustment of coefficients\n                if eval_count < phase_switch:\n                    cognitive_coeff_adjusted = self.cognitive_coeff * (eval_count / phase_switch)\n                    social_coeff_adjusted = self.social_coeff * (1 - eval_count / phase_switch)\n                else:\n                    cognitive_coeff_adjusted = self.cognitive_coeff * (1 - (eval_count - phase_switch) / phase_switch)\n                    social_coeff_adjusted = self.social_coeff * ((eval_count - phase_switch) / phase_switch)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced Particle Swarm Optimization with dual-phase dynamic learning coefficients to balance exploration and exploitation.", "configspace": "", "generation": 60, "fitness": 0.29058696163377457, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.31208872239061136, 0.2674791201964055, 0.29219304231430687]}, "mutation_prompt": null}
{"id": "a65b0340-fc04-4ea2-81a6-edb54373aaee", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Start of change: Adjust inertia weight dynamically for better exploration/exploitation balance\n                inertia_adjustment = 0.9 - 0.5 * (eval_count / self.budget)\n                # New line: Introduce mutation effect\n                mutation_probability = 0.05 * (1 - eval_count / self.budget)\n                mutation_vector = np.random.uniform(-mutation_probability, mutation_probability, (self.population_size, self.dim))\n                \n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - 0.6 * eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                # Apply mutation to positions\n                population['positions'] += population['velocities'] + mutation_vector\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced convergence by introducing dynamic inertia and adaptive mutation for position updates.", "configspace": "", "generation": 61, "fitness": 0.28021811497120713, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.2887882733857199, 0.26913714849342785, 0.2827289230344736]}, "mutation_prompt": null}
{"id": "b5fe1705-38d6-4401-87a0-bbf38cf8a767", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Changed line: Adaptive inertia weight based on evaluation progression\n                inertia_adjustment = 0.9 - (0.5 * eval_count / self.budget)\n                \n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce adaptive inertia weight decay based on the evaluation progression to balance exploration and exploitation.", "configspace": "", "generation": 62, "fitness": 0.3939357911653549, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3970809113474769, 0.3752891448687987, 0.40943731727978894]}, "mutation_prompt": null}
{"id": "9f06df9d-2d8d-41c5-93e8-db5fed8c28cb", "solution": "import numpy as np\n\nclass Improved_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.stagnation_threshold = 0.05  # New stagnation threshold\n        self.last_best_value = float('inf')\n\n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Detect stagnation and introduce mutation\n                if self.global_best_value == self.last_best_value:\n                    mutation = np.random.normal(scale=0.1, size=(self.population_size, self.dim))  # Added mutation\n                    population['positions'] += mutation\n                self.last_best_value = self.global_best_value\n\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n\n                # Introduce collaboration between sub-populations\n                for k, other_population in enumerate(self.populations):\n                    if k != self.populations.index(population):\n                        crossover_mask = np.random.rand(self.population_size, self.dim) < 0.1\n                        population['positions'] = np.where(crossover_mask, other_population['positions'], population['positions'])\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Improved_AMP_PSO", "description": "Enhanced diversity by introducing dynamic sub-population collaboration and adaptive mutation based on stagnation detection.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {}, "mutation_prompt": null}
{"id": "b2b82548-d239-4173-b105-041c823ab7ae", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = 0.9 - (0.8 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                # Changed line: Adjust social coefficient with budget usage\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Modified dynamic inertia weight for better exploration\n                dynamic_inertia = 0.5 + (0.4 * (1 - eval_count / self.budget))  \n                # Modified velocities calculation with dynamic inertia\n                population['velocities'] = dynamic_inertia * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced diversity and convergence by introducing dynamic inertia and velocity scaling based on evaluation progress.", "configspace": "", "generation": 64, "fitness": 0.39409760315865716, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.00.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.39115549130339666, 0.3969240317220569, 0.394213286450518]}, "mutation_prompt": null}
{"id": "92a23827-fbee-4025-b04b-f14af8095eb5", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.init_population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.init_population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.init_population_size, self.dim)),\n            'personal_best_values': np.full(self.init_population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                # Dynamic population size scaling\n                current_pop_size = max(5, int(self.init_population_size * (1 - eval_count / self.budget)))\n                population['positions'] = population['positions'][:current_pop_size]\n                population['velocities'] = population['velocities'][:current_pop_size]\n                \n                for i in range(current_pop_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight - (0.5 * eval_count / self.budget)  # Adaptive inertia weight\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n\n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced AMP_PSO by introducing dynamic population scaling and adaptive inertia weight for improved convergence.", "configspace": "", "generation": 65, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (30,6) (28,6) ').", "error": "ValueError('operands could not be broadcast together with shapes (30,6) (28,6) ')", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {}, "mutation_prompt": null}
{"id": "b5ab6890-6e27-4613-ad38-a26de5dccfb2", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Changed line: Introduce a dynamic inertia weight\n                inertia_adjustment = 0.9 - (0.7 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                # Changed line: Introduce an adaptive cognitive coefficient\n                cognitive_coeff_adjusted = self.cognitive_coeff * (eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced convergence by introducing a dynamic inertia weight and adaptive cognitive coefficient based on budget usage.", "configspace": "", "generation": 66, "fitness": 0.3178548261353495, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.03.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3154064567343333, 0.2818841416175416, 0.3562738800541735]}, "mutation_prompt": null}
{"id": "c273e6e9-b6fa-49ee-aa8a-c0bce8e7ebb5", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.min_inertia = 0.4\n        self.max_inertia = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.subpopulations = 4\n        self.populations = [self._initialize_population() for _ in range(self.subpopulations)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for idx, population in enumerate(self.populations):\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_weight = self.max_inertia - ((self.max_inertia - self.min_inertia) * eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                if idx % 2 == 0:\n                    cognitive_coeff_adjusted = self.cognitive_coeff * 1.2\n                else:\n                    cognitive_coeff_adjusted = self.cognitive_coeff * 0.8\n                    \n                population['velocities'] = inertia_weight * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], self.min_vel, self.max_vel)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced particle swarm optimization with dynamic inertia weight and clustered subpopulations for improved local and global exploration.", "configspace": "", "generation": 67, "fitness": 0.27771668874022787, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.01.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.270615222901178, 0.26995692078051514, 0.2925779225389904]}, "mutation_prompt": null}
{"id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Changed line: Adjust inertia weight based on budget usage\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced global exploration by modifying inertia weight dynamically based on evaluation progress.", "configspace": "", "generation": 68, "fitness": 0.42288822766700657, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.42 with standard deviation 0.02.", "error": "", "parent_id": "1ea42d50-7618-45d8-beff-2e1a1079b0b2", "metadata": {"aucs": [0.3951165854055553, 0.44140276561554237, 0.4321453319799221]}, "mutation_prompt": null}
{"id": "67fc294a-46ac-4ece-bb01-960e07ce467d", "solution": "import numpy as np\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment_phase = (0.5 + (0.5 * np.cos(np.pi * eval_count / self.budget)))  # Phased inertia weight\n                adaptive_vel_range = (self.max_vel - self.min_vel) * np.exp(-2 * eval_count / self.budget)  # Exponential decay\n                social_coeff_adjusted = self.social_coeff * (1 - np.cos(np.pi * eval_count / self.budget))\n                # Adaptive population size step\n                self.population_size = max(10, int(self.population_size * (1 + np.sin(np.pi * eval_count / self.budget) / 10)))\n                \n                population['velocities'] = inertia_adjustment_phase * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Enhanced_AMP_PSO", "description": "A multi-phase adaptive PSO with dynamic population adjustment for improved convergence.", "configspace": "", "generation": 69, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {}, "mutation_prompt": null}
{"id": "4f3b1006-6cfe-45b6-b83d-9b615d1ffb13", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Changed line: Adjust cognitive coefficient based on budget usage\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 + 0.5 * eval_count / self.budget)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced exploration by dynamically adjusting the cognitive coefficient based on evaluation progress.", "configspace": "", "generation": 70, "fitness": 0.3906474808246367, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.02.", "error": "", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {"aucs": [0.386268051304674, 0.36714750552761477, 0.4185268856416213]}, "mutation_prompt": null}
{"id": "adcb8624-6670-4c3f-86ec-f53a1a76dfcc", "solution": "import numpy as np\n\nclass AMP_PSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.num_subgroups = 3  # Number of dynamic subgroups\n        self.mutation_rate = 0.1  # Introducing mutation\n        self.populations = [self._initialize_population() for _ in range(self.num_subgroups)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def _mutate(self, position):\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = np.random.uniform(-0.1, 0.1, size=self.dim)\n            position += mutation_vector\n        return position\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    population['positions'][i] = self._mutate(population['positions'][i])\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO_Enhanced", "description": "Introducing dynamic subgrouping and mutation to explore diverse regions effectively and enhance convergence.", "configspace": "", "generation": 71, "fitness": 0.29718080271195313, "feedback": "The algorithm AMP_PSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.03.", "error": "", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {"aucs": [0.33576564308676127, 0.2667917702224054, 0.2889849948266927]}, "mutation_prompt": null}
{"id": "f794eb31-ddef-4619-b9b9-6f63025382df", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Change 1: Incorporate best-performing population's best position in velocity update\n                best_population_position = min(self.populations, key=lambda pop: min(pop['personal_best_values']))['personal_best_positions']\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (best_population_position - population['positions'])  # Adjusted line\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Refine particle update by incorporating a dynamic social component influenced by the best-performing population.", "configspace": "", "generation": 72, "fitness": 0.35771507998930646, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.04.", "error": "", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {"aucs": [0.4143944218749922, 0.34599914161659584, 0.3127516764763313]}, "mutation_prompt": null}
{"id": "d2336283-c831-4317-9516-e1a349646af7", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Adaptive inertia and velocity ranges\n                inertia_adjustment = self.inertia_weight * (0.5 + 0.4 * np.cos(eval_count / self.budget * np.pi))\n                social_coeff_adjusted = self.social_coeff * (np.sin(eval_count / self.budget * np.pi) + 0.5)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                # Introduce random perturbations occasionally to escape local optima\n                if np.random.rand() < 0.1:\n                    random_perturbation = np.random.uniform(-0.1, 0.1, population['velocities'].shape)\n                    population['velocities'] += random_perturbation\n                \n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce a multi-swarm collaboration strategy with adaptive learning rates to enhance convergence and avoid local optima.", "configspace": "", "generation": 73, "fitness": 0.30883409605431233, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.03.", "error": "", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {"aucs": [0.3386456117091481, 0.2718492890909222, 0.3160073873628667]}, "mutation_prompt": null}
{"id": "918d6721-d133-4ddd-b5d1-d344a534d16b", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.mutation_rate = 0.1  # Added line: Mutation rate for position perturbation\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n                # Added line: Introduce mutation to perturb positions\n                mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_rate\n                population['positions'] = np.where(mutation_mask, np.random.uniform(size=(self.population_size, self.dim)), population['positions'])\n\n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce diversity by incorporating a mutation operator to perturb particle positions.", "configspace": "", "generation": 74, "fitness": 0.328942067057393, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.02.", "error": "", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {"aucs": [0.33269133260495776, 0.34545283598758647, 0.30868203257963467]}, "mutation_prompt": null}
{"id": "b7262ee3-2bd2-4fd6-9094-73a3b9a37a48", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                # Changed line: Adjust cognitive coefficient based on budget usage\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 + 0.5 * eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Improved exploration by dynamically adjusting the cognitive coefficient based on evaluation progress.", "configspace": "", "generation": 75, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'social_coeff_adjusted' is not defined\").", "error": "NameError(\"name 'social_coeff_adjusted' is not defined\")", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {}, "mutation_prompt": null}
{"id": "45dd873e-9d07-4cff-8789-4b101abf0615", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                # Changed line: Introduce adaptive cognitive coefficient\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + eval_count / (2 * self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce an adaptive cognitive coefficient to improve convergence speed while maintaining exploration.", "configspace": "", "generation": 76, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'social_coeff_adjusted' is not defined\").", "error": "NameError(\"name 'social_coeff_adjusted' is not defined\")", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {}, "mutation_prompt": null}
{"id": "6922357a-ddf7-4d96-85ab-51f0bab22c77", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Changed line: Apply nonlinear decay to inertia weight\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * (eval_count / self.budget)**2))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)  # Adaptive velocity limit\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)  # Apply adaptive range\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Optimize inertia weight dynamically with a nonlinear decay function based on budget evaluation progress.", "configspace": "", "generation": 77, "fitness": 0.2855938003698973, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {"aucs": [0.2818437761142669, 0.2663609239504924, 0.3085767010449325]}, "mutation_prompt": null}
{"id": "14fa612e-7bae-4104-bed2-c1c14a72f8a7", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 + 0.5 * (eval_count / self.budget))\n                social_coeff_adjusted = self.social_coeff * (1 - 0.5 * eval_count / self.budget)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n                # Boundary handling: re-evaluate boundary instances\n                boundary_idx = np.where((population['positions'] == 0.0) | (population['positions'] == 1.0))\n                for idx in zip(*boundary_idx):\n                    boundary_position = bounds.lb + population['positions'][idx] * (bounds.ub - bounds.lb)\n                    boundary_value = func(boundary_position)\n                    eval_count += 1\n                    if boundary_value < population['personal_best_values'][idx[0]]:\n                        population['personal_best_positions'][idx[0]] = population['positions'][idx]\n                        population['personal_best_values'][idx[0]] = boundary_value\n\n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Adaptive Multi-population PSO (AMP-PSO) with dynamic learning coefficients and boundary handling for improved convergence.", "configspace": "", "generation": 78, "fitness": 0.2967081682068195, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.03.", "error": "", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {"aucs": [0.3316189206184089, 0.26747624826852845, 0.2910293357335211]}, "mutation_prompt": null}
{"id": "8df7d7d2-a193-487b-aeda-2a766e6d712a", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Changed line: Adjust cognitive coefficient based on budget usage\n                cognitive_coeff_adjusted = self.cognitive_coeff * (1 - eval_count / (2 * self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Improve convergence by introducing dynamic cognitive coefficients based on evaluation progress.", "configspace": "", "generation": 79, "fitness": 0.3289168014000254, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.00.", "error": "", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {"aucs": [0.3298745694523971, 0.3240428469929041, 0.332832987754775]}, "mutation_prompt": null}
{"id": "4a3fda9f-e007-42b3-ac11-89c38aae5ba9", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        subgroup_count = max(2, self.population_size // 5)  # New: subdivide population\n\n        while eval_count < self.budget:\n            for population in self.populations:\n                # New: Split population into subgroups for diverse exploration\n                np.random.shuffle(population['positions'])\n                subgroups = np.array_split(population['positions'], subgroup_count)\n                \n                for subgroup in subgroups:\n                    for i in range(subgroup.shape[0]):\n                        scaled_position = bounds.lb + subgroup[i] * (bounds.ub - bounds.lb)\n                        current_value = func(scaled_position)\n                        eval_count += 1\n\n                        if current_value < population['personal_best_values'][i]:\n                            population['personal_best_positions'][i] = subgroup[i]\n                            population['personal_best_values'][i] = current_value\n\n                        if current_value < self.global_best_value:\n                            self.global_best_position = subgroup[i]\n                            self.global_best_value = current_value\n\n                    r1, r2 = np.random.rand(2)\n                    inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                    adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                    # New: Introduce diversity measure to adjust social coefficient\n                    diversity_factor = np.std(subgroup, axis=0).mean()\n                    social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget) * diversity_factor\n                    \n                    population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                               self.cognitive_coeff * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                               social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                    \n                    population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                    population['positions'] += population['velocities']\n                    population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced global exploration using adaptive subgroup learning and diversity-based population update.", "configspace": "", "generation": 80, "fitness": 0.21208952301312145, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.01.", "error": "", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {"aucs": [0.22143427242390923, 0.2008707640162175, 0.21396353259923762]}, "mutation_prompt": null}
{"id": "e3d34136-5eaa-45f9-8ad0-efa096da2925", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Changed line: Introduce decay in cognitive coefficient\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce decay in the cognitive coefficient to balance exploration and exploitation dynamically.", "configspace": "", "generation": 81, "fitness": 0.4254500607673311, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.06.", "error": "", "parent_id": "de9dc484-8cda-4f2d-ac3a-5bc15773c2f4", "metadata": {"aucs": [0.4148810756471162, 0.3555840618871313, 0.5058850447677458]}, "mutation_prompt": null}
{"id": "69c87cb5-e41d-4a25-bcb3-5a74e28a8fa7", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9  # Updated for smoother transition\n        self.cognitive_coeff = 2.0  # Slightly increased to enhance local search initially\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                # Dual cosine inertia weights\n                inertia_adjustment = self.inertia_weight * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))\n                # Adaptive velocity range based on cosine function\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget))\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                \n                # Updated line: Adaptive cognitive coefficient\n                cognitive_coeff_adjusted = self.cognitive_coeff * np.cos(np.pi * eval_count / (2 * self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce adaptive learning rates and dual cosine inertia weights for enhanced global convergence.", "configspace": "", "generation": 82, "fitness": 0.29186671157369837, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.03.", "error": "", "parent_id": "e3d34136-5eaa-45f9-8ad0-efa096da2925", "metadata": {"aucs": [0.3015551199712271, 0.25483565675655306, 0.31920935799331496]}, "mutation_prompt": null}
{"id": "b0f1f579-c8ea-4d04-90ea-62fb1b95f0c0", "solution": "import numpy as np\n\nclass Hybrid_PSO_AM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n        \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        while eval_count < self.budget:\n            for population in self.populations:\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                mutation_prob = 0.1 * (1 - eval_count / self.budget)\n                mutation_mask = np.random.rand(*population['positions'].shape) < mutation_prob\n                mutation_vals = np.random.uniform(0, 1, population['positions'].shape)\n                population['positions'] = np.where(mutation_mask, mutation_vals, population['positions'])\n\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Hybrid_PSO_AM", "description": "Hybrid Approach with Adaptive Mutation to Enhance Global Exploration and Local Exploitation Balance.", "configspace": "", "generation": 83, "fitness": 0.30116624039271456, "feedback": "The algorithm Hybrid_PSO_AM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.01.", "error": "", "parent_id": "e3d34136-5eaa-45f9-8ad0-efa096da2925", "metadata": {"aucs": [0.31406589366604376, 0.28841667657159054, 0.3010161509405094]}, "mutation_prompt": null}
{"id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    # Randomly reset 10% of the particles\n                    reset_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce diversity maintenance by randomly resetting 10% of the particles' positions when no improvement occurs for 20% of the budget.", "configspace": "", "generation": 84, "fitness": 0.4312948806953993, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.02.", "error": "", "parent_id": "e3d34136-5eaa-45f9-8ad0-efa096da2925", "metadata": {"aucs": [0.4590446667831428, 0.42773583051650943, 0.40710414478654566]}, "mutation_prompt": null}
{"id": "17b6cdf2-0d8a-46d9-9432-10805577d398", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                reset_prob = min(0.1 + 0.1 * (no_improvement_count / (0.2 * self.budget)), 0.3)\n                if no_improvement_count >= 0.1 * self.budget:\n                    reset_indices = np.random.choice(self.population_size, size=int(reset_prob * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           self.social_coeff * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhance particle diversity through adaptive inertia and dynamic reset probability based on stagnation length.", "configspace": "", "generation": 85, "fitness": 0.2756396974924153, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.02.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.29342245919798904, 0.2553073090579343, 0.2781893242213225]}, "mutation_prompt": null}
{"id": "8efe35f4-66a7-417f-8567-d653d5033570", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 2.0\n        self.social_coeff = 2.0\n        self.max_vel = 0.3\n        self.min_vel = -0.3\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    reset_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                \n                mutation_factor = np.random.normal(0, 0.1, population['velocities'].shape)\n                population['velocities'] = inertia_adjustment * (population['velocities'] + mutation_factor) + \\\n                                           1.5 * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           1.5 * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhanced diversity and adaptive parameters by integrating mutation and dynamic learning coefficients within PSO.", "configspace": "", "generation": 86, "fitness": 0.26688691504009293, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.2557684998484494, 0.2597410517286274, 0.28515119354320206]}, "mutation_prompt": null}
{"id": "dc6f446e-60fb-4921-8c70-70eb37b7b970", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    # Randomly reset 10% of the particles\n                    reset_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget) * 0.8  # Changed line\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce adaptive velocity scaling by dynamically reducing the range of velocities based on the evaluation count to enhance convergence.", "configspace": "", "generation": 87, "fitness": 0.4127795908468849, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.01.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.42561066379715884, 0.40237339517676185, 0.4103547135667339]}, "mutation_prompt": null}
{"id": "0ebe8243-cc8c-4616-bd05-03b74d14a6be", "solution": "import numpy as np\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n\n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n\n        while eval_count < self.budget:\n            for population_index, population in enumerate(self.populations):\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n\n                if no_improvement_count >= 0.2 * self.budget:\n                    reset_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n\n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                mutation_strength = 0.1 * (1 - eval_count / self.budget)\n                mutation_indices = np.random.choice(self.population_size, size=int(0.05 * self.population_size), replace=False)\n                population['positions'][mutation_indices] += np.random.normal(0, mutation_strength, (len(mutation_indices), self.dim))\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Enhanced_AMP_PSO", "description": "Introduce adaptive mutation and hierarchical population structures to enhance exploration and exploitation balance.", "configspace": "", "generation": 88, "fitness": 0.28664857735130417, "feedback": "The algorithm Enhanced_AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.30826207228022406, 0.2592736594257249, 0.2924100003479635]}, "mutation_prompt": null}
{"id": "72bc1863-fe9e-4639-b53b-7aae403f3bec", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.3  # Adjusted for improved exploration\n        self.min_vel = -0.3 # Adjusted for improved exploration\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    # Randomly reset 15% of the particles with new strategy\n                    reset_indices = np.random.choice(self.population_size, size=int(0.15 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    population['velocities'][reset_indices] = np.random.uniform(low=self.min_vel, high=self.max_vel, size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce stochastic reinitialization of particles with adaptive velocity clamping to enhance exploration.", "configspace": "", "generation": 89, "fitness": 0.38042970846248486, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.02.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.36363133072365084, 0.36424694928264834, 0.4134108453811556]}, "mutation_prompt": null}
{"id": "ff6b4730-951b-41bb-9b1b-536e6d7a658c", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.15 * self.budget:  # Adjusted threshold\n                    # Adaptive mutation for diversity\n                    mutation_strength = 0.05 * (1 - eval_count / self.budget)\n                    for i in range(self.population_size):\n                        if np.random.rand() < 0.1:\n                            population['positions'][i] += np.random.normal(0, mutation_strength, size=self.dim)\n                    population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce adaptive mutation and dynamic velocity adjustment for improved diversity and convergence.", "configspace": "", "generation": 90, "fitness": 0.30091904906282557, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.04.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.3566007250051171, 0.2555087089842054, 0.2906477131991543]}, "mutation_prompt": null}
{"id": "3d476bbb-57ed-4d13-8901-9ec31bd36b39", "solution": "import numpy as np\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.initial_population_size = self.population_size\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.tournament_size = max(2, int(0.1 * self.population_size))\n\n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    reset_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                if not improved:\n                    no_improvement_count += 1\n                    if no_improvement_count >= 0.1 * self.budget:\n                        self.population_size = max(10, self.population_size // 2)\n                        population['positions'] = population['positions'][:self.population_size]\n                        population['velocities'] = population['velocities'][:self.population_size]\n                        population['personal_best_positions'] = population['personal_best_positions'][:self.population_size]\n                        population['personal_best_values'] = population['personal_best_values'][:self.population_size]\n                else:\n                    no_improvement_count = 0\n                    if self.population_size < self.initial_population_size:\n                        self.population_size = min(self.initial_population_size, self.population_size + 1)\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                tournament_indices = np.random.choice(self.population_size, self.tournament_size, replace=False)\n                tournament_best_index = np.argmin(population['personal_best_values'][tournament_indices])\n                tournament_best_position = population['personal_best_positions'][tournament_indices][tournament_best_index]\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (tournament_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Enhanced_AMP_PSO", "description": "Enhance AMP_PSO by introducing a dynamic resizing of the population based on performance and using tournament selection for better exploration.", "configspace": "", "generation": 91, "fitness": 0.27463773613897996, "feedback": "The algorithm Enhanced_AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.28396072472366884, 0.2557501564273663, 0.28420232726590466]}, "mutation_prompt": null}
{"id": "f53c01dd-000a-47cd-ac4e-8d1cc7a70a27", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    reset_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                non_linear_decay = 1 - np.tanh(eval_count / self.budget)\n\n                social_coeff_adjusted = self.social_coeff * non_linear_decay\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * non_linear_decay)\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce adaptive learning factors that vary non-linearly with the number of evaluations to enhance convergence and diversity.", "configspace": "", "generation": 92, "fitness": 0.32381747542754036, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.04.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.35255114052243997, 0.34896071023378894, 0.26994057552639217]}, "mutation_prompt": null}
{"id": "a167e816-6faf-4733-80a4-0c02861e60af", "solution": "import numpy as np\n\nclass AMP_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    reset_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                    for index in reset_indices:\n                        indices = np.random.choice(self.population_size, 3, replace=False)\n                        a, b, c = population['positions'][indices]\n                        population['positions'][index] = np.clip(a + 0.8 * (b - c), 0.0, 1.0)\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO_DE", "description": "Enhance diversity and convergence by incorporating differential evolution-inspired mutation and optional elitism to preserve top solutions, providing a more robust particle swarm optimization approach.", "configspace": "", "generation": 93, "fitness": 0.30091904906282557, "feedback": "The algorithm AMP_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.04.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.3566007250051171, 0.2555087089842054, 0.2906477131991543]}, "mutation_prompt": null}
{"id": "35e609d0-b5e7-4de2-84b0-fac53b551931", "solution": "import numpy as np\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        speculative_phase_triggered = False\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    reset_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                if not speculative_phase_triggered and eval_count > 0.5 * self.budget:\n                    speculative_phase_triggered = True\n                    self.augment_population(population)\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)\n\n    def augment_population(self, population):\n        # Increase population size for speculative exploration\n        extra_positions = np.random.uniform(size=(int(0.2 * self.population_size), self.dim))\n        population['positions'] = np.vstack((population['positions'], extra_positions))\n        extra_velocities = np.random.uniform(low=self.min_vel, high=self.max_vel, size=(extra_positions.shape[0], self.dim))\n        population['velocities'] = np.vstack((population['velocities'], extra_velocities))\n        extra_best_values = np.full(extra_positions.shape[0], float('inf'))\n        population['personal_best_positions'] = np.vstack((population['personal_best_positions'], extra_positions))\n        population['personal_best_values'] = np.concatenate((population['personal_best_values'], extra_best_values))", "name": "Enhanced_AMP_PSO", "description": "Enhance convergence by dynamically adjusting population size and introducing a speculative exploration stage using a global search distribution.", "configspace": "", "generation": 94, "fitness": 0.3004407288421977, "feedback": "The algorithm Enhanced_AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.04.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.3557150308018818, 0.2551405304343132, 0.29046662529039813]}, "mutation_prompt": null}
{"id": "c9facda9-5492-4f70-b797-83e82e5a3685", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.15 * self.budget:\n                    # Randomly reset 20% of the particles\n                    reset_indices = np.random.choice(self.population_size, size=int(0.2 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    population['velocities'][reset_indices] = np.random.uniform(low=self.min_vel, high=self.max_vel, size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Enhance diversity by resetting 20% of particles' velocities and positions when no improvement occurs for 15% of the budget to potentially increase exploration.", "configspace": "", "generation": 95, "fitness": 0.34998729956015745, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.02.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.3734061424503664, 0.3262916521793542, 0.3502641040507519]}, "mutation_prompt": null}
{"id": "ce3bb337-edc5-4bfd-9e62-19aeae7c60a5", "solution": "import numpy as np\n\nclass AMP_PSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n\n                # Dynamically adjust reset percentage based on stagnation\n                reset_percentage = min(0.1 + 0.05 * (no_improvement_count / (0.2 * self.budget)), 0.5)\n                if no_improvement_count >= 0.1 * self.budget:\n                    reset_indices = np.random.choice(self.population_size, size=int(reset_percentage * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    population['velocities'][reset_indices] = np.random.uniform(low=self.min_vel, high=self.max_vel, size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO_Enhanced", "description": "Adaptive diversity enhancement by dynamically adjusting particle reset percentage based on stagnation.", "configspace": "", "generation": 96, "fitness": 0.30091904906282557, "feedback": "The algorithm AMP_PSO_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.04.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.3566007250051171, 0.2555087089842054, 0.2906477131991543]}, "mutation_prompt": null}
{"id": "24177a7b-ee9b-48ab-bb8f-cca897e03447", "solution": "import numpy as np\nfrom minisom import MiniSom\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.9\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.som = MiniSom(3, 3, dim, sigma=0.3, learning_rate=0.5)\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        self.som.random_weights_init(np.random.uniform(bounds.lb, bounds.ub, (100, self.dim)))\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    reset_indices = np.random.choice(self.population_size, size=int(0.1 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                self.inertia_weight = 0.9 - (0.5 * eval_count / self.budget)\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = self.inertia_weight * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                self.som.train_random(population['positions'], 10)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Enhanced_AMP_PSO", "description": "Enhanced AMP_PSO with adaptive inertia and self-organizing maps for diverse exploration and efficient optimization.", "configspace": "", "generation": 97, "fitness": -Infinity, "feedback": "An exception occurred: ModuleNotFoundError(\"No module named 'minisom'\").", "error": "ModuleNotFoundError(\"No module named 'minisom'\")", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {}, "mutation_prompt": null}
{"id": "f815de42-6f8b-4398-b68b-73db1653fc8c", "solution": "import numpy as np\n\nclass Enhanced_AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    reset_indices = np.random.choice(self.population_size, size=int(0.15 * self.population_size), replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.7 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions']) + \\\n                                           np.random.uniform(-0.02, 0.02, population['positions'].shape)  # Local search\n\n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "Enhanced_AMP_PSO", "description": "Enhanced diversity and adaptive mechanism in PSO by introducing local search and dynamic influence of personal best positions.", "configspace": "", "generation": 98, "fitness": 0.3014253235906548, "feedback": "The algorithm Enhanced_AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.01.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.3120862428551102, 0.30285992289009556, 0.28932980502675865]}, "mutation_prompt": null}
{"id": "d7643fe6-aa69-4cef-987e-8bc25fb1d97b", "solution": "import numpy as np\n\nclass AMP_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.max_vel = 0.2\n        self.min_vel = -0.2\n        self.populations = [self._initialize_population() for _ in range(3)]\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        \n    def _initialize_population(self):\n        return {\n            'positions': np.random.uniform(size=(self.population_size, self.dim)),\n            'velocities': np.random.uniform(low=self.min_vel, high=self.max_vel, size=(self.population_size, self.dim)),\n            'personal_best_positions': np.zeros((self.population_size, self.dim)),\n            'personal_best_values': np.full(self.population_size, float('inf'))\n        }\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        eval_count = 0\n        no_improvement_count = 0\n        \n        while eval_count < self.budget:\n            for population in self.populations:\n                improved = False\n                for i in range(self.population_size):\n                    scaled_position = bounds.lb + population['positions'][i] * (bounds.ub - bounds.lb)\n                    current_value = func(scaled_position)\n                    eval_count += 1\n\n                    if current_value < population['personal_best_values'][i]:\n                        population['personal_best_positions'][i] = population['positions'][i]\n                        population['personal_best_values'][i] = current_value\n                        improved = True\n\n                    if current_value < self.global_best_value:\n                        self.global_best_position = population['positions'][i]\n                        self.global_best_value = current_value\n\n                if not improved:\n                    no_improvement_count += 1\n                else:\n                    no_improvement_count = 0\n\n                # Change 1: Decreasing reset threshold over time\n                reset_threshold = int(0.1 * (self.population_size * (1 - eval_count / self.budget)))\n                \n                if no_improvement_count >= 0.2 * self.budget:\n                    # Change 2: Use dynamic reset threshold\n                    reset_indices = np.random.choice(self.population_size, size=reset_threshold, replace=False)\n                    population['positions'][reset_indices] = np.random.uniform(size=(len(reset_indices), self.dim))\n                    no_improvement_count = 0\n\n                r1, r2 = np.random.rand(2)\n                inertia_adjustment = self.inertia_weight * (0.9 - (0.8 * eval_count / self.budget))\n                adaptive_vel_range = (self.max_vel - self.min_vel) * (1 - eval_count / self.budget)\n                social_coeff_adjusted = self.social_coeff * (1 - eval_count / self.budget)\n\n                cognitive_coeff_adjusted = self.cognitive_coeff * (0.5 + 0.5 * (1 - eval_count / self.budget))\n                \n                population['velocities'] = inertia_adjustment * population['velocities'] + \\\n                                           cognitive_coeff_adjusted * r1 * (population['personal_best_positions'] - population['positions']) + \\\n                                           social_coeff_adjusted * r2 * (self.global_best_position - population['positions'])\n                \n                population['velocities'] = np.clip(population['velocities'], -adaptive_vel_range, adaptive_vel_range)\n                population['positions'] += population['velocities']\n                population['positions'] = np.clip(population['positions'], 0.0, 1.0)\n                \n        return bounds.lb + self.global_best_position * (bounds.ub - bounds.lb)", "name": "AMP_PSO", "description": "Introduce a dynamic reset threshold that progressively decreases as evaluations increase, enhancing exploration in later stages.", "configspace": "", "generation": 99, "fitness": 0.40825990558301317, "feedback": "The algorithm AMP_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.41 with standard deviation 0.04.", "error": "", "parent_id": "c2cb429f-d32a-45e4-92bc-35c69ce3c2ae", "metadata": {"aucs": [0.40958296948158324, 0.36036046056981785, 0.4548362866976383]}, "mutation_prompt": null}

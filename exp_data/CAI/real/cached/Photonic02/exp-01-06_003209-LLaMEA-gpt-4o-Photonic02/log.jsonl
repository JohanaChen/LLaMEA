{"id": "95726359-8856-4c55-9b80-d9804f26bf7d", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.8  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "A hybrid metaheuristic algorithm combining differential evolution and simulated annealing for efficient global optimization of complex photonic structures within constrained evaluation budgets.", "configspace": "", "generation": 0, "fitness": 0.33053308002543574, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.01.", "error": "", "parent_id": null, "metadata": {"aucs": [0.3207848863048961, 0.3308149323333688, 0.3399994214380424]}, "mutation_prompt": null}
{"id": "a6192563-6283-42b3-a977-917d46e05039", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.8  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "A hybrid metaheuristic algorithm enhanced with adaptive cooling in simulated annealing for improved global optimization of photonic structures within constrained evaluation budgets.", "configspace": "", "generation": 1, "fitness": 0.35826379985498397, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.03.", "error": "", "parent_id": "95726359-8856-4c55-9b80-d9804f26bf7d", "metadata": {"aucs": [0.3167639137852254, 0.3924838235639502, 0.3655436622157763]}, "mutation_prompt": null}
{"id": "c44daa91-ebd0-4c4b-865a-cff362dd4faf", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Slightly adjust the differential weight to provide more exploration capability in the search space.", "configspace": "", "generation": 2, "fitness": 0.3644649458545273, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.01.", "error": "", "parent_id": "a6192563-6283-42b3-a977-917d46e05039", "metadata": {"aucs": [0.37449089559545456, 0.36957377088589116, 0.3493301710822362]}, "mutation_prompt": null}
{"id": "4da236d9-adba-4f00-adf1-8e735bd3237c", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Adaptive adjustment of F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Incorporate adaptive differential weight adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.3752469236095175, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.02.", "error": "", "parent_id": "c44daa91-ebd0-4c4b-865a-cff362dd4faf", "metadata": {"aucs": [0.40442812544346507, 0.3761234742437438, 0.34518917114134373]}, "mutation_prompt": null}
{"id": "6f9667f7-e98a-4ebc-b353-ce8e3b6c1149", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Adaptive adjustment of F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Enhanced Adaptive Crossover\n                CR_adaptive = CR + 0.1 * (best_fitness - pop_fitness[i]) / (abs(best_fitness) + 1e-10)\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Enhanced Adaptive Cooling\n            temp_initial *= cooling_rate * (1 - evaluations / (self.budget + 1e-10))  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance adaptive cooling and crossover mechanisms to improve convergence speed and solution quality.", "configspace": "", "generation": 4, "fitness": 0.3601930493732021, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.01.", "error": "", "parent_id": "4da236d9-adba-4f00-adf1-8e735bd3237c", "metadata": {"aucs": [0.3785691907279535, 0.3558549339304766, 0.3461550234611762]}, "mutation_prompt": null}
{"id": "e82ed65d-d91e-4df8-aaa9-5c6e747aea9f", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            diversity_factor = np.std(pop_fitness) / np.abs(np.mean(pop_fitness))  # Added line\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Adaptive adjustment of F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * diversity_factor  # Modified line to use diversity_factor\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate adaptive cooling rate based on population diversity to enhance convergence.", "configspace": "", "generation": 5, "fitness": 0.2520888576752796, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.01.", "error": "", "parent_id": "4da236d9-adba-4f00-adf1-8e735bd3237c", "metadata": {"aucs": [0.2524267558361655, 0.2625107673056316, 0.2413290498840418]}, "mutation_prompt": null}
{"id": "de1c862c-3c8a-4540-a8d1-beb8bf5befaf", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Adaptive adjustment of F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.5 + 0.4 * (evaluations / self.budget)  # Adaptive adjustment of CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive crossover probability adjustment to enhance exploration in later stages.", "configspace": "", "generation": 6, "fitness": 0.34738067498390085, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.02.", "error": "", "parent_id": "4da236d9-adba-4f00-adf1-8e735bd3237c", "metadata": {"aucs": [0.37449089559545456, 0.3409597689164161, 0.3266913604398318]}, "mutation_prompt": null}
{"id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce randomness in differential weight F for improved adaptability in diverse landscapes.", "configspace": "", "generation": 7, "fitness": 0.38729347069401704, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.02.", "error": "", "parent_id": "4da236d9-adba-4f00-adf1-8e735bd3237c", "metadata": {"aucs": [0.38423872535791115, 0.36158449637381207, 0.41605719035032784]}, "mutation_prompt": null}
{"id": "26fd1e19-df6e-4624-a05d-852f32e74b7f", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, int(self.budget / 8))  # adaptive population size\n        F = 0.85  # differential weight\n        CR = 0.8 + 0.2 * np.random.rand()  # dynamic crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce dynamic crossover probability CR and adaptive population size to enhance exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.3395966036320986, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.03.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.3154480078022438, 0.37974402267291363, 0.3235977804211383]}, "mutation_prompt": null}
{"id": "2e9266bf-f87e-4b1a-b73e-019c17a4ced8", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR_initial = 0.9  # initial crossover probability\n        CR_min = 0.1  # minimum crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Adaptive Crossover\n                CR = CR_initial - (CR_initial - CR_min) * (evaluations / self.budget)  # Adaptive CR\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive crossover probability CR for enhanced exploration in early stages and exploitation in later stages.", "configspace": "", "generation": 9, "fitness": 0.35487120030328595, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.01.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.3382082702535235, 0.374397836630309, 0.3520074940260254]}, "mutation_prompt": null}
{"id": "ba7046e5-9eb3-4af0-9d42-a0d2b44f3aee", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n            F = 0.8 + 0.2 * np.cos(np.pi * evaluations / self.budget)  # Slightly modified F adaptation strategy\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Improve dynamic adaptation of the differential weight F for enhanced convergence properties.", "configspace": "", "generation": 10, "fitness": 0.2996504324365155, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.02.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.2985837435136265, 0.3227390547650786, 0.2776284990308414]}, "mutation_prompt": null}
{"id": "0451cbc7-2682-4d23-ad44-89f2f66bac10", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Adaptive Crossover\n                CR_adaptive = 0.7 + 0.3 * (best_fitness - pop_fitness[i]) / (best_fitness + 1e-9)  # Adaptive crossover\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive  # Updated line\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate adaptive crossover probability for enhanced exploration-exploitation balance in diverse landscapes.", "configspace": "", "generation": 11, "fitness": 0.32959483199380085, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.03.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.3413921292564023, 0.3539416954562882, 0.29345067126871205]}, "mutation_prompt": null}
{"id": "c1641966-69da-471e-ab78-2fee5f3c5b81", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)\n        F_base = 0.85\n        CR = 0.9\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n        reinit_counter = 0\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = F_base * (0.5 + 0.5 * np.random.rand())\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n            reinit_counter += 1\n            if reinit_counter % 10 == 0:  # Periodic reinitialization\n                new_points = np.random.uniform(lb, ub, (pop_size // 5, self.dim))\n                for point in new_points:\n                    if evaluations >= self.budget:\n                        break\n                    fitness = func(point)\n                    evaluations += 1\n                    worst_idx = np.argmax(pop_fitness)\n                    if fitness < pop_fitness[worst_idx]:\n                        pop[worst_idx] = point\n                        pop_fitness[worst_idx] = fitness\n                        if fitness < best_fitness:\n                            best_solution = point\n                            best_fitness = fitness\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate adaptive mutation control and periodic reinitialization to enhance exploration and convergence balance.", "configspace": "", "generation": 12, "fitness": 0.32993604186678843, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.02.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.36021296692058946, 0.3114686220940899, 0.3181265365856859]}, "mutation_prompt": null}
{"id": "5eb59f92-9983-4528-a3cb-f38a831d89b4", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(60, self.budget // 10)  # Adjusted population size\n        F_initial = 0.9  # initial differential weight\n        CR_initial = 0.8  # initial crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.9  # Slightly adjusted cooling rate\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            F = F_initial * (1 - evaluations / self.budget)  # Adaptive F\n            CR = CR_initial * (1 - evaluations / self.budget)  # Adaptive CR\n\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive DE Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on modified acceptance criteria\n                acceptance_probability = np.exp((pop_fitness[i] - trial_fitness) / temp_initial)\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < acceptance_probability):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Boltzmann-inspired temperature update\n            temp_initial *= cooling_rate / (1 + np.log(1 + evaluations))  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enrich the exploration-exploitation balance using adaptive F and CR, coupled with a Boltzmann-inspired temperature schedule.", "configspace": "", "generation": 13, "fitness": 0.3362563111474179, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.01.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.3495402073349144, 0.3263486340006454, 0.33288009210669367]}, "mutation_prompt": null}
{"id": "22c8cfe5-75f3-4c1c-85e0-2bb04c5b638f", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.92  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Slightly increased crossover probability to enhance exploration.", "configspace": "", "generation": 14, "fitness": 0.29350383571802013, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.27206410973087203, 0.3021069528143384, 0.30634044460885]}, "mutation_prompt": null}
{"id": "e1c6274e-76e9-4160-8287-1787d0c59093", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + (0.5 * (1 - evaluations / self.budget) * np.random.rand()) * (1 - evaluations / self.budget)  # Decrease F over iterations\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Decrease mutation rate F over iterations for better local exploitation in later stages.", "configspace": "", "generation": 15, "fitness": 0.2954942295893317, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.01.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.2905693690865837, 0.31259882565891095, 0.2833144940225004]}, "mutation_prompt": null}
{"id": "a92e6876-0d57-42a4-aefe-c4751ceff50c", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.9 * (1 - evaluations / self.budget)  # Adjust CR based on budget consumption\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Adjust crossover probability CR based on budget consumption for enhanced exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.37185987477898824, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.03.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.4069171073092621, 0.36099367169911256, 0.3476688453285899]}, "mutation_prompt": null}
{"id": "cfebc30a-4816-4777-a348-520ff526cee8", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Local search step\n            local_candidate = best_solution + np.random.normal(0, 0.1, self.dim) * (ub - lb)\n            local_candidate = np.clip(local_candidate, lb, ub)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n            if local_fitness < best_fitness:\n                best_solution = local_candidate\n                best_fitness = local_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce local search step for enhancement of exploitation in promising regions.", "configspace": "", "generation": 17, "fitness": 0.21429151499669186, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.01.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.1993822837103162, 0.22009324781552553, 0.22339901346423385]}, "mutation_prompt": null}
{"id": "8f638633-1b08-4680-a296-4d993d398c57", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = CR * (1 - evaluations / self.budget)  # Adaptive crossover probability\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive crossover probability CR for enhanced exploration capabilities.", "configspace": "", "generation": 18, "fitness": 0.03144121619215334, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.03 with standard deviation 0.01.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.021479659460084677, 0.04521349925231655, 0.027630489864058805]}, "mutation_prompt": null}
{"id": "96fbd078-f1bf-475d-ab64-7217a77c51df", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.98  # More aggressive cooling\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Apply a more aggressive cooling schedule for faster convergence.", "configspace": "", "generation": 19, "fitness": 0.3389114305737569, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.01.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.35812769085741414, 0.3351845276131822, 0.3234220732506745]}, "mutation_prompt": null}
{"id": "4dda82ed-a917-49d4-9f73-9b396e1c68c0", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.9  # More aggressive cooling rate\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Adjust the cooling rate to be more aggressive early on to escape local optima faster.", "configspace": "", "generation": 20, "fitness": 0.2818110560209296, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.02.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.31100781361891716, 0.27432908557268365, 0.260096268871188]}, "mutation_prompt": null}
{"id": "cb36a2cc-eef4-4e41-af47-b95f8b547380", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Dynamic Crossover\n                CR_dynamic = 0.5 + 0.5 * np.random.rand()  # Change 1: Make CR dynamic\n                crossover_mask = np.random.rand(self.dim) < CR_dynamic  # Change 2: Use CR_dynamic instead of CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce dynamic crossover probability CR to enhance exploration and exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.3281853687554389, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.02.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.32015619545982765, 0.3539416954562882, 0.3104582153502009]}, "mutation_prompt": null}
{"id": "b19bde96-bb29-4491-9d0d-00e76c37645a", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            diversity_factor = np.mean(np.std(pop, axis=0))\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget) * (1 + diversity_factor)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive cooling by modifying the cooling rate based on diversity.", "configspace": "", "generation": 22, "fitness": 0.30295768774257514, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.01.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.3098493037850777, 0.31107273703906557, 0.28795102240358217]}, "mutation_prompt": null}
{"id": "473810cd-fb4e-4ca4-b8eb-676a58a3bde7", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_dynamic = 0.9 * (1 - evaluations / self.budget)  # Introduce dynamic CR\n                crossover_mask = np.random.rand(self.dim) < CR_dynamic\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a dynamic crossover probability CR for improved exploration-exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.30934637281775285, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.02.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.31471967475655493, 0.28256485343621984, 0.3307545902604837]}, "mutation_prompt": null}
{"id": "90d80755-0758-472f-8d74-f1570371396a", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover with decaying probability\n                crossover_mask = np.random.rand(self.dim) < (CR * (1 - evaluations / self.budget))  # Changed line\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Use a decaying crossover probability for enhanced exploration-exploitation balance.", "configspace": "", "generation": 24, "fitness": 0.34223561816466946, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.02.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.35812769085741414, 0.3178754655546818, 0.3507036980819124]}, "mutation_prompt": null}
{"id": "45d78db0-6799-4c9c-bbe0-8ef35629db85", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = CR * (1 - evaluations / self.budget)  # Increase CR adaptively\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance local exploitation by increasing crossover probability CR adaptively based on iterations.", "configspace": "", "generation": 25, "fitness": 0.30934637281775285, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.02.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.31471967475655493, 0.28256485343621984, 0.3307545902604837]}, "mutation_prompt": null}
{"id": "6bcde738-0d81-4ba9-ac4a-4c9984fc771e", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.8  # crossover probability  # Adjusted CR\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Adjusted crossover probability CR for enhanced exploration in diverse landscapes.", "configspace": "", "generation": 26, "fitness": 0.34096883330008204, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.02.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.35812769085741414, 0.3178754655546818, 0.3469033434881502]}, "mutation_prompt": null}
{"id": "c126b563-b499-4730-ad92-3a887830c46e", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover with adaptive probability\n                CR_adaptive = 0.8 + 0.2 * (best_fitness / (np.min(pop_fitness) + 1e-10))\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive crossover probability for enhanced exploration and exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.34464600522803096, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.01.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.33460696313044835, 0.3601373799161802, 0.33919367263746436]}, "mutation_prompt": null}
{"id": "3dcc95a4-0d86-4cff-93e0-f3f145426876", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            # Dynamically adjust population size\n            pop_size = max(10, int((self.budget - evaluations) / 10) + 1)\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(min(50, evaluations // 10)) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Boost exploration by dynamically adjusting population size based on evaluations.", "configspace": "", "generation": 28, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {}, "mutation_prompt": null}
{"id": "51c37905-fad4-47b2-ba84-5d37b8cbd920", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c) + 0.1 * F_adaptive * (best_solution - a), lb, ub)  # Modified line\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < CR\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Improve mutation strategy by adding weighted influence of the best solution for better convergence.", "configspace": "", "generation": 29, "fitness": 0.3274615227579998, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.03.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.34133662101113216, 0.35942010057965834, 0.28162784668320884]}, "mutation_prompt": null}
{"id": "981487b6-987e-4245-b6ae-259758fe9d01", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover with adaptive CR\n                CR_adaptive = CR * (0.5 + 0.5 * evaluations / self.budget)\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate adaptive crossover probability for better exploration-exploitation balance.", "configspace": "", "generation": 30, "fitness": 0.31256344305808076, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.03.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.27000426423155666, 0.329728988276512, 0.3379570766661737]}, "mutation_prompt": null}
{"id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive crossover rate CR for improved exploration-exploitation balance in diverse landscapes.", "configspace": "", "generation": 31, "fitness": 0.40043497750789786, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.01.", "error": "", "parent_id": "6328f49f-2317-4c9c-9e1a-2afae2da416d", "metadata": {"aucs": [0.4036803476131826, 0.41410041630179284, 0.3835241686087181]}, "mutation_prompt": null}
{"id": "b6d7c891-81ea-46bd-a584-56afbbc5a66e", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        \n            # Dynamic population resizing\n            if evaluations % (self.budget // 10) == 0:\n                pop_size = min(pop_size + 1, self.budget // 5)  # Adjust population size\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate adaptive mutation scaling and dynamic population resizing for enhanced convergence efficiency.", "configspace": "", "generation": 32, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {}, "mutation_prompt": null}
{"id": "f8dde91d-2c2c-4bbd-8404-bbe6a9d1fed5", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        inertia_weight = 0.9  # dynamic inertia weight\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.9  # altered cooling rate\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation with inertia weight\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = inertia_weight * (0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand())\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n            \n            # Adjust inertia weight dynamically\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n            \n            # Adaptive cooling\n            temp_initial *= cooling_rate * (1 - evaluations / (self.budget * 1.5))\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by integrating a dynamic inertia weight with the DE strategy and adaptive temperature schedule.", "configspace": "", "generation": 33, "fitness": 0.30163428301397577, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.31546191953364555, 0.30324063110255184, 0.2862002984057299]}, "mutation_prompt": null}
{"id": "97da5f69-189f-4314-b234-873261a159c9", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.6 * (1 - evaluations / self.budget) * np.random.rand()  # Adjusted randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.2 * np.random.rand() * (pop_fitness[i] > best_fitness)  # Adaptive CR based on improvement\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a dynamic mutation strategy and adaptive CR tuning based on feedback from the fitness improvement.", "configspace": "", "generation": 34, "fitness": 0.31452494022915484, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.31300340516161695, 0.30368059937407077, 0.32689081615177673]}, "mutation_prompt": null}
{"id": "6b748779-b9cc-4136-90cd-8c420f788b44", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50 + int(0.1 * self.budget), self.budget // 10)  # adaptive population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive population size for better convergence across diverse problem landscapes.", "configspace": "", "generation": 35, "fitness": 0.3193850325380256, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.05.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3820193346267666, 0.3124197773044326, 0.26371598568287746]}, "mutation_prompt": null}
{"id": "32a439f6-c3b6-4079-a10d-253611baa689", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget) * (1 + np.std(pop_fitness) / 100.0)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance adaptive cooling by including a dynamic factor based on the standard deviation of population fitness.", "configspace": "", "generation": 36, "fitness": 0.30045360007398314, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3180412075836335, 0.284188722230007, 0.2991308704083089]}, "mutation_prompt": null}
{"id": "6696c75b-34a7-46ca-8c14-53b777dea7c2", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand() * (1 - temp_initial / 1000.0)  # Enhanced adaptive F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget) * 0.99  # Enhanced adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate adaptive mutation scaling and enhanced cooling dynamics for robust global search efficiency.", "configspace": "", "generation": 37, "fitness": 0.2938270426991518, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2776278680775043, 0.3058181753618291, 0.298035084658122]}, "mutation_prompt": null}
{"id": "9a1b0fa0-7a2e-4a43-b22b-3cc86cc8b001", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                F_adaptive *= (best_fitness / (pop_fitness[i] + 1e-8))  # Dynamically scaled F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance mutation strategy by introducing dynamic scaling factor F based on current best fitness, promoting convergence.", "configspace": "", "generation": 38, "fitness": 0.24587109656754857, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.24244504715985704, 0.25296898127962464, 0.24219926126316405]}, "mutation_prompt": null}
{"id": "5f95835b-5994-40fa-bb22-7cb40aa53802", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Lévy flight perturbation\n                levy_step = 0.01 * np.random.normal(size=self.dim) * (1 / np.abs(np.random.normal(size=self.dim))**(1/3))\n                trial_levy = np.clip(trial + levy_step, lb, ub)\n\n                # Evaluate trial vector\n                trial_fitness = func(trial_levy)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial_levy\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial_levy\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate Lévy flight-based perturbation to enhance exploration and avoid local optima.", "configspace": "", "generation": 39, "fitness": 0.26337030330188865, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.23358664503723847, 0.26868139131387325, 0.2878428735545543]}, "mutation_prompt": null}
{"id": "7e9f9e73-d776-4dab-b376-af06371823dc", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c) + 0.01 * np.random.randn(self.dim), lb, ub)  # Added perturbation\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a small perturbation in the population update to enhance exploration capabilities.", "configspace": "", "generation": 40, "fitness": 0.3287445305892673, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.30935947626298743, 0.33494318954233193, 0.34193092596248253]}, "mutation_prompt": null}
{"id": "e0b87fe2-f56a-4eb3-964d-2433d6fb7573", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            # Adaptive reduction in population size\n            pop_size = max(5, int(pop_size * (1 - evaluations / self.budget)))\n\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(len(pop)) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Incorporate adaptive population size reduction to enhance exploitation in later stages of search.", "configspace": "", "generation": 41, "fitness": 0.24990501508799043, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.00.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2541716610809366, 0.252000248235589, 0.2435431359474457]}, "mutation_prompt": null}
{"id": "9f983c3d-e6a5-4fa0-b64c-f8906f663780", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            diversity = np.std(pop, axis=0).mean()  # Calculate population diversity\n            pop_size = int(min(50, max(10, diversity * 10)))  # Adjust population size\n\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance convergence by integrating dynamic population size adjustment based on diversity.", "configspace": "", "generation": 42, "fitness": 0.28992175925495545, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.28511329414641495, 0.29435085529983473, 0.29030112831861665]}, "mutation_prompt": null}
{"id": "fa00e150-7b6b-46b0-a7c8-39933fa1d746", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget) * (1 + np.std(pop_fitness) / 100)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Improve adaptive cooling strategy by adding dynamic factor based on standard deviation of population fitness.", "configspace": "", "generation": 43, "fitness": 0.3342971778278237, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.368283266208865, 0.3284587503531138, 0.3061495169214925]}, "mutation_prompt": null}
{"id": "b71d3a27-5c47-4abe-bb5a-4ce8777e548f", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  \n        F = 0.85  \n        CR = 0.9  \n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            diversity_factor = np.var(pop, axis=0).mean()  # Calculate diversity\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand() * diversity_factor  # Adjust with diversity\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand() * diversity_factor  # Adjust with diversity\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget) \n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate self-adapting mutation and crossover strategies with improved diversity management for enhanced convergence in diverse landscapes.", "configspace": "", "generation": 44, "fitness": 0.30783406766925775, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.04.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3616841046463709, 0.3043716442870742, 0.2574464540743281]}, "mutation_prompt": null}
{"id": "6e4996c2-7d01-42ea-a1ea-754c3bf4b3fb", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c) + 0.2 * (best_solution - pop[i]), lb, ub)  # Add influence of the best solution\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by introducing a dynamic directional search influenced by the best global solution to improve convergence speed.", "configspace": "", "generation": 45, "fitness": 0.25533377882929253, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2823263167206663, 0.23059666410922097, 0.2530783556579903]}, "mutation_prompt": null}
{"id": "ee1e2bf4-1858-4cd2-a003-3dc9fd8f5a49", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # Initial population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            # Adaptive population size\n            pop_size = max(5, int(min(50, pop_size * (1 - evaluations / self.budget))))\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive population size based on budget usage for enhanced convergence.", "configspace": "", "generation": 46, "fitness": 0.29832939737118064, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.28509160207636763, 0.27156661089388734, 0.338329979143287]}, "mutation_prompt": null}
{"id": "494e7b24-c9cf-4074-87db-571ea15ee0a6", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                F_adaptive *= 1 - (evaluations / (2 * self.budget))  # Dynamic F scaling\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance adaptive strategy by incorporating dynamic F scaling for accelerated convergence.", "configspace": "", "generation": 47, "fitness": 0.3303830451273599, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3693753095790048, 0.31939004402993343, 0.3023837817731414]}, "mutation_prompt": null}
{"id": "1045398e-c32e-4652-a297-a043f162e530", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            # Calculate diversity of the population\n            diversity = np.mean(np.std(pop, axis=0))\n\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                F_adaptive *= (1 + diversity)  # Adjust F based on diversity\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by dynamically adjusting mutation strategy based on current diversity.", "configspace": "", "generation": 48, "fitness": 0.36253529418790925, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.00.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.35941541645744846, 0.3653174159240854, 0.36287305018219385]}, "mutation_prompt": null}
{"id": "fc188c80-67cb-4725-b9c4-59bf6fcc5980", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.93  # Adjusted cooling rate\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance adaptive cooling by reducing the cooling rate to improve convergence precision.", "configspace": "", "generation": 49, "fitness": 0.29165415507975495, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.29277646220859777, 0.2857339332745099, 0.29645206975615723]}, "mutation_prompt": null}
{"id": "125b632a-090d-4474-8ea1-4a7caff0401d", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.7 + 0.3 * np.random.rand()  # Shifted randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive mutation scale F for enhanced diversity control in dynamic adaptation.", "configspace": "", "generation": 50, "fitness": 0.263585043957498, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2807339352468682, 0.22317248536937084, 0.286848711256255]}, "mutation_prompt": null}
{"id": "4883bc42-6fbc-4cb9-9e68-0c980e51f5c5", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.4 + 0.6 * (1 - evaluations / self.budget) * np.random.rand()  # More dynamic F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n            # Dynamically adjust population size within limits\n            if evaluations < self.budget * 0.5:\n                pop_size = min(pop_size + 1, self.budget // 5)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by introducing dynamic population size and adaptive mutation strategy.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {}, "mutation_prompt": null}
{"id": "63ca19eb-3445-46ff-94ab-e888b6f63102", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand() * (best_fitness / pop_fitness[i])  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n            # Dynamic population resizing\n            pop_size = max(5, int(pop_size * (1 - evaluations / self.budget)))  # Adjust population size\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive mutation scaling and dynamic population resizing for enhanced optimization efficiency.", "configspace": "", "generation": 52, "fitness": 0.3601540459695011, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.00.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3580622956545009, 0.3566199809523366, 0.36577986130166584]}, "mutation_prompt": null}
{"id": "048f80f5-ff7f-4ff8-8736-575ec696aaba", "solution": "import numpy as np\n\nclass HybridDELevyAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        def levy_flight(Lambda):\n            sigma = (np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) / \n                    (np.math.gamma((1 + Lambda) / 2) * Lambda * 2**((Lambda - 1) / 2)))**(1 / Lambda)\n            u = np.random.normal(0, sigma, self.dim)\n            v = np.random.normal(0, 1, self.dim)\n            return u / np.abs(v)**(1 / Lambda)\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation with Levy flights\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                mutant = np.clip(a + F_adaptive * (b - c) + levy_flight(1.5), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n        return best_solution, best_fitness", "name": "HybridDELevyAnnealingOptimizer", "description": "Integrate Levy Flights to enhance exploration and escape local optima efficiently.", "configspace": "", "generation": 53, "fitness": 0.32630502555584867, "feedback": "The algorithm HybridDELevyAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.31687175541735724, 0.3216848091446596, 0.34035851210552914]}, "mutation_prompt": null}
{"id": "5764191d-4b47-4ae8-b39e-2ca90193ca5b", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.normal()  # Modified randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Increase mutation diversity by modifying the adaptive F calculation.", "configspace": "", "generation": 54, "fitness": 0.3117978936482231, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.31363077772616943, 0.3034440084908584, 0.3183188947276414]}, "mutation_prompt": null}
{"id": "c246a468-27b0-4944-a6e7-871f4abd04db", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 8)  # population size adjustment\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance global search by adjusting the population size based on the budget dynamically.", "configspace": "", "generation": 55, "fitness": 0.26441798077615747, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2934023297823516, 0.24570221938839054, 0.25414939315773033]}, "mutation_prompt": null}
{"id": "4118f4f7-14c6-4aca-8afb-fc20c1e56ff4", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb - 0.1*(ub-lb), ub + 0.1*(ub-lb), (pop_size, self.dim))  # Introduce diversity\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce diversity by varying population initialization scale.", "configspace": "", "generation": 56, "fitness": 0.33356315322452906, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.36970136446898794, 0.3150153698638959, 0.3159727253407034]}, "mutation_prompt": null}
{"id": "4e911fad-24a6-4ce4-870c-578fe0e0332a", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation with Lévy flight\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                levy_step = np.random.standard_normal() * (np.abs(a - b)) ** 1.5  # Lévy flight\n                mutant = np.clip(a + levy_step * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by including Lévy flight for dynamic mutation step sizes in diverse landscapes.", "configspace": "", "generation": 57, "fitness": 0.3658883107162785, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.05.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.41757334002091373, 0.38796201408254116, 0.29212957804538053]}, "mutation_prompt": null}
{"id": "39ffe072-2483-47d5-add7-2f4eceb501e4", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n            # Dynamic population adjustment\n            pop_size = max(20, int((1 - evaluations / self.budget) * 50))  # Dynamically adjust population size\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a dynamic population size to enhance exploration and exploitation throughout the optimization process.", "configspace": "", "generation": 58, "fitness": 0.2802757538851462, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2818004080741182, 0.270148067764707, 0.2888787858166133]}, "mutation_prompt": null}
{"id": "8e2b1574-28db-46d0-b962-198317f4b2cd", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.75 + 0.25 * np.random.rand()  # Adjusted randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Fine-tune crossover probability by adjusting its randomness range for better exploration.", "configspace": "", "generation": 59, "fitness": 0.3083083502764753, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3167999598596991, 0.2913905670640661, 0.3167345239056607]}, "mutation_prompt": null}
{"id": "3c059656-2cf2-463f-bf81-e86d2fbcd0e3", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n        \n        # Dynamic population size\n        min_pop_size = 10\n        max_pop_size = pop_size\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            # Adjust population size based on progress\n            pop_size = int(min_pop_size + (max_pop_size - min_pop_size) * (1 - evaluations / self.budget))\n            pop_size = max(min_pop_size, min(pop_size, max_pop_size))\n            pop = pop[:pop_size]\n            pop_fitness = pop_fitness[:pop_size]\n\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate a dynamic population size adjustment to enhance adaptability across varying optimization landscapes.", "configspace": "", "generation": 60, "fitness": 0.2827125645471362, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.31048240097742397, 0.2639163069843158, 0.2737389856796689]}, "mutation_prompt": null}
{"id": "89559ecd-66ca-48dd-bd85-f029846c7713", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        initial_pop_size = min(50, self.budget // 10)  # initial population size\n        F = 0.85  # differential weight\n        CR_base = 0.9  # base crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (initial_pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = initial_pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            pop_size = max(5, initial_pop_size - (evaluations // 100))  # Adaptive population size\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = CR_base * (0.7 + 0.3 * np.random.rand())  # Adjusted CR scaling\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive population size scaling and diversity preservation techniques for enhanced exploration-exploitation trade-off.", "configspace": "", "generation": 61, "fitness": 0.36189697415353245, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.34184934611212014, 0.3851377368206452, 0.3587038395278319]}, "mutation_prompt": null}
{"id": "a5760e6a-4edd-4343-930e-25d353fd7495", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 15)  # Adjusted population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce dynamic population size adjustment for better convergence across varying problem complexities.", "configspace": "", "generation": 62, "fitness": 0.2998278369944683, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3051686837920564, 0.29506192341463366, 0.2992529037767149]}, "mutation_prompt": null}
{"id": "daf00c0a-4243-44ac-8b08-ec2a2daeca4e", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Chaotic Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)  # Chaotic adaptation of F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Chaotic Crossover\n                CR_adaptive = 0.7 + 0.3 * np.cos(evaluations / self.budget * np.pi)  # Chaotic adaptation of CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce chaotic dynamics in parameter adaptation for enhanced convergence and diversity.", "configspace": "", "generation": 63, "fitness": 0.31462126006134356, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3422405281661314, 0.27622902225889046, 0.3253942297590089]}, "mutation_prompt": null}
{"id": "ae82d2ae-f157-4597-bc6b-81e251d01421", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F_base = 0.85  # differential weight base\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F = F_base * (1 + 0.3 * np.sin(np.pi * evaluations / self.budget))  # Dynamic scaling of F\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Adjust mutation strategy by dynamically scaling differential weight F to enhance convergence rate.", "configspace": "", "generation": 64, "fitness": 0.32519402717118256, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3355409113439477, 0.33602043655527924, 0.3040207336143207]}, "mutation_prompt": null}
{"id": "c837a45b-0cac-427f-a51b-c7ab8b801c6b", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        stagnation_counter = 0  # Added line\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n                        stagnation_counter = 0  # Added line\n                    else:\n                        stagnation_counter += 1  # Added line\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n            # Random restart mechanism\n            if stagnation_counter > 10:  # Added logic line\n                pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n                pop_fitness = np.array([func(ind) for ind in pop])\n                stagnation_counter = 0  # Reset counter after restart\n                evaluations += pop_size\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate random restarts to escape local minima and enhance global search dynamics.", "configspace": "", "generation": 65, "fitness": 0.2589199944719955, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2439646383885241, 0.22718011105288027, 0.3056152339745821]}, "mutation_prompt": null}
{"id": "a81a9b22-19bd-4ef0-b845-d06cbe3986d8", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.6 * (1 - evaluations / self.budget) * np.random.rand()  # Adjusted mutation scaling\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.6 + 0.4 * np.random.rand()  # Adjusted crossover randomness\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance adaptive mechanism by introducing dynamic mutation scaling and multinomial parameter adjustments.", "configspace": "", "generation": 66, "fitness": 0.3293880062708369, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.33470140521677927, 0.33226288549482375, 0.3211997281009078]}, "mutation_prompt": null}
{"id": "1847581c-ad9b-40b1-84f6-97aefb4fb809", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            fitness_ranks = np.argsort(pop_fitness)  # New line: Calculate fitness ranks\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  \n                if fitness_ranks[i] < pop_size / 2:  # New line: Dynamic mutation strategy\n                    F_adaptive *= 1.2  # Adjust mutation factor for better solutions\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance adaptive DE by incorporating dynamic mutation strategy based on fitness ranking for better diversity and convergence.", "configspace": "", "generation": 67, "fitness": 0.2582457831858844, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.22298888285158847, 0.2609156245970905, 0.2908328421089743]}, "mutation_prompt": null}
{"id": "c1aaeb9d-2aae-4616-90a5-b3e99d84320f", "solution": "import numpy as np\nimport math\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + (1 - evaluations / self.budget) * np.random.rand()  # Adaptive F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n            # Chaos-based local search\n            if np.random.rand() < 0.05:\n                chaos = 0.5 * (np.sin(10 * evaluations / self.budget))**2\n                perturbed = best_solution + chaos * np.random.uniform(-1, 1, self.dim)\n                perturbed = np.clip(perturbed, lb, ub)\n                perturbed_fitness = func(perturbed)\n                evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_solution = perturbed\n                    best_fitness = perturbed_fitness\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Improve HybridDEAnnealing by introducing chaos-based local search and adaptive differential weight F.", "configspace": "", "generation": 68, "fitness": 0.34012870501583475, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.33844860556885525, 0.3591303541790981, 0.32280715529955095]}, "mutation_prompt": null}
{"id": "06e77f05-2580-437a-b9d5-de368f2d167c", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            # Adaptive population size\n            if evaluations % (self.budget // 5) == 0 and pop_size < 100:\n                pop_size += 2\n                new_individuals = np.random.uniform(lb, ub, (2, self.dim))\n                new_fitness = np.array([func(ind) for ind in new_individuals])\n                evaluations += 2\n                pop = np.vstack((pop, new_individuals))\n                pop_fitness = np.hstack((pop_fitness, new_fitness))\n\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Incorporate adaptive population size and enhance diversity to improve solution quality and convergence speed.", "configspace": "", "generation": 69, "fitness": 0.3347600452472204, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3063972591423231, 0.3728267712042962, 0.32505610539504204]}, "mutation_prompt": null}
{"id": "121323c0-e24a-4e62-b64e-fe54b932b839", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            pop_size = int(min(50, self.budget // 10) * (1 - evaluations / self.budget)) + 1  # Dynamic population size\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a dynamic population size to enhance adaptive exploration-exploitation over the optimization process.", "configspace": "", "generation": 70, "fitness": 0.33028862773074147, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3519585459193172, 0.3299471008516851, 0.30896023642122217]}, "mutation_prompt": null}
{"id": "16876a2e-2c1e-4757-a42e-30f4f38e92c8", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n        previous_best_fitness = best_fitness  # Track previous best fitness\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            improvement_rate = (previous_best_fitness - best_fitness) / previous_best_fitness if previous_best_fitness else 0\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget) * (1 + improvement_rate)  # Dynamic cooling\n            previous_best_fitness = best_fitness  # Update previous best fitness\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a more dynamic cooling rate that adapts based on the fitness improvement rate.", "configspace": "", "generation": 71, "fitness": 0.26672378748085596, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.04.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.31968393351996294, 0.24412121007236798, 0.236366218850237]}, "mutation_prompt": null}
{"id": "09cfe08e-bb40-4501-93ff-a33837fda848", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.5 + 0.5 * np.random.rand()  # Adjust CR range for better diversity\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= 0.9 * (1 - evaluations / self.budget)  # Dynamic cooling adjustment\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Refine adaptive CR for better diversity control and replace fixed cooling with dynamic cooling.", "configspace": "", "generation": 72, "fitness": 0.33309227500909094, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3251727875847069, 0.327543614626146, 0.34656042281641986]}, "mutation_prompt": null}
{"id": "0ac57255-0110-4040-9889-c04024b8aa3a", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                F_alternate = np.random.rand() * (ub - lb)  # New alternate mutation strategy\n                mutant = np.clip(a + F_adaptive * (b - c) + F_alternate, lb, ub)  # Line modified\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance solution diversity by introducing an additional mutation strategy with adaptive scaling.", "configspace": "", "generation": 73, "fitness": 0.3192815087138477, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3427627785230807, 0.3138189527245939, 0.30126279489386854]}, "mutation_prompt": null}
{"id": "c2a2b07b-9244-494b-978e-5303f3ead516", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 8)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Optimize exploration by using adaptive cooling and a varied population size to balance exploitation.", "configspace": "", "generation": 74, "fitness": 0.3246630206870194, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.29627277517675454, 0.3258620634255214, 0.35185422345878237]}, "mutation_prompt": null}
{"id": "d6501ae4-90c1-4583-832a-3346aa280ad2", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        # Initialize chaotic map for randomness\n        chaos_sequence = np.random.rand(self.budget // 2)\n        chaotic_factor = 0.1  # Example value for chaos scaling\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * chaos_sequence[evaluations % len(chaos_sequence)]  # Chaotic F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover with chaotic influence\n                CR_adaptive = 0.7 + 0.3 * chaos_sequence[evaluations % len(chaos_sequence)]  # Chaotic CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by introducing chaotic maps and a self-adaptive crossover for improved convergence.", "configspace": "", "generation": 75, "fitness": 0.3301475467767135, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3484873662880025, 0.35255238196193417, 0.28940289208020376]}, "mutation_prompt": null}
{"id": "aea5811c-ba8e-43b9-b7c2-5424381cf62a", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / (2 * self.budget))  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a dynamic factor in the cooling rate to enhance convergence speed.", "configspace": "", "generation": 76, "fitness": 0.3689904547941492, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3694342578457982, 0.3529329526697641, 0.3846041538668854]}, "mutation_prompt": null}
{"id": "6cbdb5f7-fede-4350-83c2-01ceb6bb6d84", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.3 * (1 - evaluations / self.budget) * np.random.rand()  # Updated randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive mutation factor F for improved convergence and exploration balance.", "configspace": "", "generation": 77, "fitness": 0.246556993137531, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2397064555133247, 0.22461941932777973, 0.27534510457148853]}, "mutation_prompt": null}
{"id": "57f3f3e3-dbd6-4106-b014-3354a29e42ea", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  \n        F = 0.85  \n        CR = 0.9  \n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                levy = np.random.standard_cauchy(self.dim)  # Levy flight\n                F_dynamic = 0.5 + 0.5 * np.random.rand()  # Dynamic scale factor\n                mutant = np.clip(a + F_dynamic * (b - c) + 0.01 * levy, lb, ub)\n\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  \n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  \n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration and convergence by integrating Levy flight and dynamic scale factor adjustment in DE mutation.", "configspace": "", "generation": 78, "fitness": 0.3219865839301294, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.35545107247642926, 0.288975925665822, 0.32153275364813705]}, "mutation_prompt": null}
{"id": "79e24987-e8a9-4bf5-8390-da7f30b46dcc", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                adaptive_mutation_factor = 1 + np.log(1 + evaluations) / np.log(self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n            # Dynamic population resizing\n            if evaluations % (self.budget // 5) == 0 and pop_size > 10:\n                pop_size = max(10, pop_size - 1)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce dynamic population resizing and adaptive mutation strategies for enhanced convergence and solution quality.", "configspace": "", "generation": 79, "fitness": 0.3377242448660979, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3253427574667245, 0.34895480747636265, 0.3388751696552065]}, "mutation_prompt": null}
{"id": "12a0cc98-59ff-4b40-ad52-aa5d10f0f669", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n            \n            # Dynamic population size adaptation\n            pop_size = max(20, int(pop_size * (1 - evaluations / self.budget)))  # Adjust pop_size\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce dynamic population size adaptation to improve convergence rate.", "configspace": "", "generation": 80, "fitness": 0.25619944864577016, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2501099995596574, 0.2731171862661711, 0.24537116011148197]}, "mutation_prompt": null}
{"id": "17c064cf-bdd1-42e1-a0bf-539778d63dd8", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand() * np.exp((best_fitness - pop_fitness[i]) / best_fitness)  # Dynamic CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a dynamic update for the crossover probability that considers both the current and best solutions to enhance convergence.", "configspace": "", "generation": 81, "fitness": 0.30754952952807524, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3160287373001759, 0.3113495905025774, 0.29527026078147245]}, "mutation_prompt": null}
{"id": "061392b3-7a0e-45a8-8ffc-582b831fe633", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand() * (ub - lb).mean()  # Dynamic scaling\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Incorporate dynamic scaling of differential weight F for better adaptability across diverse landscapes.", "configspace": "", "generation": 82, "fitness": 0.24967465362796662, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2423800517416943, 0.22737404837157282, 0.27926986077063276]}, "mutation_prompt": null}
{"id": "025544dc-4d9b-46da-941c-94da022a525a", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # initial population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            # Adjust population size dynamically\n            pop_size = int(pop_size * (0.8 + 0.4 * np.random.rand()))\n            pop_size = min(max(4, pop_size), self.budget - evaluations + pop_size)\n\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria and stochastic ranking\n                acceptance_prob = np.exp((pop_fitness[i] - trial_fitness) / temp_initial)\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < acceptance_prob):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a dynamic population size adjustment and stochastic ranking for enhanced exploration-exploitation trade-off.", "configspace": "", "generation": 83, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 55 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 55 is out of bounds for axis 0 with size 50')", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {}, "mutation_prompt": null}
{"id": "75073c0e-0cd7-46c8-bbd4-5ab14942f447", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - best_fitness / max(pop_fitness))  # Adaptive cooling based on best fitness\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a dynamic cooling rate influenced by the best fitness found to improve convergence speed.", "configspace": "", "generation": 84, "fitness": 0.3064955508579352, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.32394295428457875, 0.28244053472476827, 0.31310316356445855]}, "mutation_prompt": null}
{"id": "f4f61303-435f-4840-b54a-e42446f7ab62", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand() * (1 - temp_initial / 1000.0)  # Dynamic mutation scaling\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce dynamic mutation scaling factor to enhance convergence speed and solution diversity.", "configspace": "", "generation": 85, "fitness": 0.3311914616248269, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2975065566572287, 0.37530087285751745, 0.32076695535973443]}, "mutation_prompt": null}
{"id": "1f36209d-b821-4dee-aa09-e4b0e611f5d0", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n            # Adaptive population size and reinitialization\n            if evaluations % 100 == 0:\n                pop_size = min(pop_size + 5, self.budget // 5)\n                pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n                pop_fitness = np.array([func(ind) for ind in pop])\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce adaptive population size and periodic reinitialization to maintain diversity and prevent premature convergence.", "configspace": "", "generation": 86, "fitness": 0.3183791621354651, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.32359736275672535, 0.28758444910736847, 0.34395567454230147]}, "mutation_prompt": null}
{"id": "34eb0a2d-0264-4d1a-a118-f0ccb337cdf9", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            pop_size = min(pop_size, max(5, self.budget // 20 + evaluations // 100))  # Dynamic pop_size adjustment\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance adaptive variation by introducing a dynamic pop_size adjustment based on evaluation progress.", "configspace": "", "generation": 87, "fitness": 0.3445796917957759, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3391741032906207, 0.367213643929027, 0.32735132816767987]}, "mutation_prompt": null}
{"id": "bb1072b0-f115-49fa-8ea8-b3c841ae91c9", "solution": "import numpy as np\n\nclass ImprovedDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        max_pop_size = min(50, self.budget // 10)  # initial population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (max_pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = max_pop_size\n        pop_size = max_pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n\n                # Opposition-based learning\n                opposite = lb + ub - mutant\n                trial = np.where(crossover_mask, mutant, pop[i])\n                trial_opp = np.where(crossover_mask, opposite, pop[i])\n\n                # Evaluate trial vectors\n                trial_fitness = func(trial)\n                evaluations += 1\n                trial_opp_fitness = func(trial_opp)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n                elif (trial_opp_fitness < pop_fitness[i]):\n                    pop[i] = trial_opp\n                    pop_fitness[i] = trial_opp_fitness\n\n                # Update global best\n                if pop_fitness[i] < best_fitness:\n                    best_solution = pop[i]\n                    best_fitness = pop_fitness[i]\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n            # Adaptive population size reduction\n            if evaluations > self.budget * 0.7:\n                pop_size = max(5, pop_size // 2)\n\n        return best_solution, best_fitness", "name": "ImprovedDEAnnealingOptimizer", "description": "Employ adaptive population size reduction and opposition-based learning for enhanced convergence efficiency in diverse landscapes.", "configspace": "", "generation": 88, "fitness": 0.282824446339288, "feedback": "The algorithm ImprovedDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.283048015160806, 0.27480814053004654, 0.2906171833270115]}, "mutation_prompt": null}
{"id": "c2acb0b3-d06a-43dc-8376-e50f26417dff", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget + np.std(pop_fitness) / np.mean(pop_fitness)) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by introducing a dynamic mutation strategy based on population diversity.", "configspace": "", "generation": 89, "fitness": 0.23182125016205743, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.03.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2679736549135404, 0.19938347405411316, 0.22810662151851868]}, "mutation_prompt": null}
{"id": "1e41e39c-fc03-4027-8fb2-9ed2173eb948", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation with Lévy Flights\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                beta = 1.5\n                sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                         (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n                u = np.random.normal(0, sigma, self.dim)\n                v = np.random.normal(0, 1, self.dim)\n                step = u / abs(v)**(1 / beta)\n                levy = step * (a - b)\n                mutant = np.clip(a + F * levy, lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by integrating Lévy flights for generating mutant vectors in the DE process.", "configspace": "", "generation": 90, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {}, "mutation_prompt": null}
{"id": "0314fcff-ea8a-4399-b7a0-cef368f7dc15", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation with Lévy Flight\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                levy_step = np.random.standard_cauchy(self.dim) * (ub - lb) * 0.01  # Lévy flight step\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                mutant = np.clip(a + F_adaptive * (b - c) + levy_step, lb, ub)  # Include Lévy flight in mutation\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by incorporating a Lévy flight mechanism in the mutation step to sample new candidate solutions.", "configspace": "", "generation": 91, "fitness": 0.28767704993052495, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3082445483969045, 0.2819446767112538, 0.2728419246834165]}, "mutation_prompt": null}
{"id": "3e89ede0-0727-4912-9727-09602e21c18b", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def levy_flight(self, size, alpha=1.5):\n        sigma = (np.gamma(1 + alpha) * np.sin(np.pi * alpha / 2) / \n                 (np.gamma((1 + alpha) / 2) * alpha * 2**((alpha - 1) / 2)))**(1 / alpha)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        return u / np.abs(v)**(1/alpha)\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation with Lévy flights\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                levy = self.levy_flight(self.dim) * (b - c)\n                mutant = np.clip(a + F_adaptive * levy, lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Dynamic cooling rate adjustment\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget) * (best_fitness / np.min(pop_fitness + 1e-8))\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by introducing Lévy flights in the mutation step and adjust cooling dynamically based on performance.", "configspace": "", "generation": 92, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {}, "mutation_prompt": null}
{"id": "236d8223-b3d5-4a48-a801-2bc2b426ffaf", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n            # Dynamic population size adjustment\n            if evaluations % (self.budget // 5) == 0:\n                pop_size = int(pop_size * (1 + 0.1 * np.random.rand()))  # Adjust population size\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a dynamic population size adjustment to enhance diversity and convergence speed.", "configspace": "", "generation": 93, "fitness": 0.3521256986561492, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.04.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.39988075550818747, 0.35408016283346755, 0.3024161776267925]}, "mutation_prompt": null}
{"id": "3b53768d-ea78-4f8e-8a3f-bda0fcf46a4b", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.5 + 0.5 * np.random.rand()  # Changed lower bound from 0.7 to 0.5\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance exploration by introducing a dynamic lower bound limit for the adaptive crossover rate CR.", "configspace": "", "generation": 94, "fitness": 0.31005937364254693, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3409109378983134, 0.29437416522540993, 0.2948930178039175]}, "mutation_prompt": null}
{"id": "41fa889e-1d39-485d-9eab-03580bec038a", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()  # Introduce randomness in F\n                F_adaptive *= (1.5 - evaluations / self.budget)  # Dynamic mutation scaling\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Integrate dynamic mutation scaling in HybridDEAnnealingOptimizer for enhanced exploration in early stages.", "configspace": "", "generation": 95, "fitness": 0.3307778978287719, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.34311853367642864, 0.3269514204452496, 0.3222637393646376]}, "mutation_prompt": null}
{"id": "2b0306c9-f168-4214-978e-990c79ce67ce", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n        swap_interval = 10  # New: interval for swapping individuals\n        num_subpops = 5  # New: number of subpopulations\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        subpop_size = pop_size // num_subpops  # New: size of each subpopulation\n        populations = [np.random.uniform(lb, ub, (subpop_size, self.dim)) for _ in range(num_subpops)]\n        pop_fitness = [np.array([func(ind) for ind in pop]) for pop in populations]\n\n        # Initialize best solution\n        best_solution = None\n        best_fitness = np.inf\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for p_index, pop in enumerate(populations):  # New: iterate over subpopulations\n                for i in range(subpop_size):\n                    if evaluations >= self.budget:\n                        break\n\n                    # Adaptive Differential Evolution Mutation\n                    idxs = [idx for idx in range(subpop_size) if idx != i]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                    mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                    # Crossover\n                    CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                    crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                    trial = np.where(crossover_mask, mutant, pop[i])\n\n                    # Evaluate trial vector\n                    trial_fitness = func(trial)\n                    evaluations += 1\n\n                    # Selection based on Simulated Annealing acceptance criteria\n                    if (trial_fitness < pop_fitness[p_index][i]) or (np.random.rand() < np.exp((pop_fitness[p_index][i] - trial_fitness) / temp_initial)):\n                        pop[i] = trial\n                        pop_fitness[p_index][i] = trial_fitness\n\n                        # Update global best\n                        if trial_fitness < best_fitness:\n                            best_solution = trial\n                            best_fitness = trial_fitness\n\n            # New: Swap individuals between subpopulations\n            if evaluations % swap_interval == 0:\n                for j in range(num_subpops - 1):\n                    swap_idx = np.random.choice(subpop_size, 2, replace=False)\n                    populations[j][swap_idx[0]], populations[j+1][swap_idx[1]] = populations[j+1][swap_idx[1]], populations[j][swap_idx[0]]\n                    pop_fitness[j][swap_idx[0]], pop_fitness[j+1][swap_idx[1]] = pop_fitness[j+1][swap_idx[1]], pop_fitness[j][swap_idx[0]]\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a diversity-enhancing mechanism by periodically swapping individuals between multiple subpopulations.", "configspace": "", "generation": 96, "fitness": 0.3291134120824846, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.34186839766922505, 0.3328226862663374, 0.3126491523118914]}, "mutation_prompt": null}
{"id": "d3c687a4-5f67-478e-bb7e-655f962d03b6", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - (evaluations / self.budget)**2) * np.random.rand()  # Time-varying scale factor\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Enhance the adaptive mutation strategy by incorporating a time-varying scale factor for better convergence.", "configspace": "", "generation": 97, "fitness": 0.3517380191176021, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.05.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.4151420003421127, 0.33940584602847235, 0.30066621098222124]}, "mutation_prompt": null}
{"id": "3d89cf84-ff28-4c69-88f4-89549ed8a986", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                (np.math.gamma((1 + beta) / 2) * beta * \n                2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.randn(size) * sigma\n        v = np.random.randn(size)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def __call__(self, func):\n        pop_size = min(30 + int(20 * np.random.rand()), self.budget // 10)  # Dynamic population size\n        F = 0.85\n        CR = 0.9\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget) * np.random.rand()\n                mutant = np.clip(a + F_adaptive * (b - c) + self.levy_flight(self.dim), lb, ub)  # Apply Lévy flight\n\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Introduce a dynamic population size strategy and Lévy flight for enhanced global exploration and local exploitation.", "configspace": "", "generation": 98, "fitness": 0.26814570308359964, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.2780702496920847, 0.24829934233060125, 0.27806751722811296]}, "mutation_prompt": null}
{"id": "84767a4b-58b8-4ae7-82c3-89f12f857b71", "solution": "import numpy as np\n\nclass HybridDEAnnealingOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        pop_size = min(50, self.budget // 10)  # population size\n        F = 0.85  # differential weight\n        CR = 0.9  # crossover probability\n        temp_initial = 1000.0\n        temp_min = 1e-5\n        cooling_rate = 0.95\n\n        # Initialize population\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        pop = np.random.uniform(lb, ub, (pop_size, self.dim))\n        pop_fitness = np.array([func(ind) for ind in pop])\n\n        # Initialize best solution\n        best_idx = np.argmin(pop_fitness)\n        best_solution = pop[best_idx]\n        best_fitness = pop_fitness[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget and temp_initial > temp_min:\n            for i in range(pop_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Adaptive Differential Evolution Mutation\n                idxs = [idx for idx in range(pop_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Improved without randomness in F\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n\n                # Crossover\n                CR_adaptive = 0.7 + 0.3 * np.random.rand()  # Introduce randomness in CR\n                crossover_mask = np.random.rand(self.dim) < CR_adaptive\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection based on Simulated Annealing acceptance criteria\n                if (trial_fitness < pop_fitness[i]) or (np.random.rand() < np.exp((pop_fitness[i] - trial_fitness) / temp_initial)):\n                    pop[i] = trial\n                    pop_fitness[i] = trial_fitness\n\n                    # Update global best\n                    if trial_fitness < best_fitness:\n                        best_solution = trial\n                        best_fitness = trial_fitness\n\n            # Simulated Annealing temperature update\n            temp_initial *= cooling_rate * (1 - evaluations / self.budget)  # Adaptive cooling\n\n        return best_solution, best_fitness", "name": "HybridDEAnnealingOptimizer", "description": "Refine exploration with adaptive mutation scaling to enhance search efficiency.", "configspace": "", "generation": 99, "fitness": 0.35429158984993253, "feedback": "The algorithm HybridDEAnnealingOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.02.", "error": "", "parent_id": "88345e1d-3f61-4d68-a6f7-2f83b09a82f6", "metadata": {"aucs": [0.3354642865046751, 0.38256578307817524, 0.34484469996694733]}, "mutation_prompt": null}

{"id": "7cf97625-6cb6-42a0-a370-c6f347f7273d", "solution": "import numpy as np\n\nclass HS_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.HMCR = 0.9  # Harmony Memory Consideration Rate\n        self.PAR = 0.3   # Pitch Adjustment Rate\n        self.memory_size = 10\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.memory = None\n        self.best_solution = None\n        self.best_fitness = float('inf')\n\n    def initialize_memory(self, lb, ub):\n        self.memory = np.random.uniform(lb, ub, (self.memory_size, self.dim))\n        for i in range(self.memory_size):\n            fitness = self.evaluate(self.memory[i])\n            if fitness < self.best_fitness:\n                self.best_fitness = fitness\n                self.best_solution = self.memory[i].copy()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n    \n    def harmony_search(self):\n        new_harmony = np.zeros(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < self.HMCR:\n                idx = np.random.randint(self.memory_size)\n                new_harmony[i] = self.memory[idx, i]\n                if np.random.rand() < self.PAR:\n                    new_harmony[i] += np.random.uniform(-0.1, 0.1)  # Small adjustment\n            else:\n                new_harmony[i] = np.random.uniform(self.lb[i], self.ub[i])\n        return new_harmony\n\n    def differential_evolution(self):\n        idxs = np.random.choice(self.memory_size, 3, replace=False)\n        a, b, c = self.memory[idxs]\n        mutant_vector = np.clip(a + self.mutation_factor * (b - c), self.lb, self.ub)\n        trial_vector = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant_vector, a)\n        return trial_vector\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        evaluations = 0\n\n        # Initialize memory\n        self.initialize_memory(self.lb, self.ub)\n\n        while evaluations < self.budget:\n            # Hybrid step: Use Harmony Search and Differential Evolution\n            if np.random.rand() < 0.5:\n                candidate = self.harmony_search()\n            else:\n                candidate = self.differential_evolution()\n\n            # Evaluate candidate solution\n            candidate_fitness = self.evaluate(candidate)\n            evaluations += 1\n            \n            # Update best solution and memory\n            if candidate_fitness < self.best_fitness:\n                self.best_fitness = candidate_fitness\n                self.best_solution = candidate.copy()\n\n            # Replace worst harmony in memory if better\n            worst_idx = np.argmax([self.evaluate(h) for h in self.memory])\n            if candidate_fitness < self.evaluate(self.memory[worst_idx]):\n                self.memory[worst_idx] = candidate\n\n        return {'solution': self.best_solution, 'fitness': self.best_fitness}", "name": "HS_DE_Optimizer", "description": "A hybrid Harmony Search and Differential Evolution (HS-DE) algorithm using adaptive parameter tuning for balancing exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.2687622348406051, "feedback": "The algorithm HS_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.26271257470302223, 0.2723818844654926, 0.27119224535330044]}, "mutation_prompt": null}
{"id": "0dfbb480-11b9-4691-bb3c-63b2eb89a7d3", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.9  # Rotation angle multiplier\n        self.population = None\n        self.best_solution = None\n        self.best_fitness = float('inf')\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            fitness = self.evaluate(self.population[i])\n            if fitness < self.best_fitness:\n                self.best_fitness = fitness\n                self.best_solution = self.population[i].copy()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def quantum_bit_representation(self, solution):\n        return np.greater(solution, (self.lb + self.ub) / 2).astype(float)\n\n    def quantum_rotation_gate(self, q_bit, target):\n        delta_theta = self.alpha * (target - q_bit)\n        return (q_bit + delta_theta) % 1.0\n\n    def evolve_population(self):\n        q_population = np.array([self.quantum_bit_representation(ind) for ind in self.population])\n        target = self.quantum_bit_representation(self.best_solution)\n\n        for i in range(self.population_size):\n            q_population[i] = self.quantum_rotation_gate(q_population[i], target)\n\n        new_population = self.lb + (self.ub - self.lb) * q_population\n        for i in range(self.population_size):\n            fitness = self.evaluate(new_population[i])\n            if fitness < self.best_fitness:\n                self.best_fitness = fitness\n                self.best_solution = new_population[i].copy()\n\n        self.population = new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        evaluations = 0\n\n        # Initialize population\n        self.initialize_population(self.lb, self.ub)\n\n        while evaluations < self.budget:\n            self.evolve_population()\n            evaluations += self.population_size  # Assuming a full evaluation per generation\n\n        return {'solution': self.best_solution, 'fitness': self.best_fitness}", "name": "QuantumInspiredEA", "description": "A Quantum-Inspired Evolutionary Algorithm (QEA) using quantum bit representation and rotation gates for diverse exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.23108900154374665, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.00.", "error": "", "parent_id": "7cf97625-6cb6-42a0-a370-c6f347f7273d", "metadata": {"aucs": [0.2314505654564758, 0.22850361337613967, 0.23331282579862445]}, "mutation_prompt": null}
{"id": "f89847ed-c1e1-4aab-b523-0063c543c043", "solution": "import numpy as np\n\nclass APSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.velocities = None\n        self.positions = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_particles(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.array([self.evaluate(p) for p in self.positions])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.positions[i]))\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n            score = self.evaluate(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n    def update_inertia_weight(self, evaluations):\n        self.inertia_weight = (self.inertia_weight_max - \n                               (self.inertia_weight_max - self.inertia_weight_min) \n                               * (evaluations / self.budget))\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        evaluations = 0\n\n        self.inertia_weight_max = self.inertia_weight\n        self.initialize_particles(self.lb, self.ub)\n\n        while evaluations < self.budget:\n            self.update_particles(self.lb, self.ub)\n            evaluations += self.num_particles\n            self.update_inertia_weight(evaluations)\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "APSO_Optimizer", "description": "An Adaptive Particle Swarm Optimization (APSO) with dynamic neighborhood topology and inertia weight tuning for improved global search capabilities.", "configspace": "", "generation": 2, "fitness": 0.27586773576191387, "feedback": "The algorithm APSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "7cf97625-6cb6-42a0-a370-c6f347f7273d", "metadata": {"aucs": [0.27768143255218525, 0.2731365290557599, 0.2767852456777965]}, "mutation_prompt": null}
{"id": "bd48a095-07b0-4a9a-b4b0-b018ac650893", "solution": "import numpy as np\n\nclass HDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F = 0.8  # mutation factor\n        self.CR = 0.9  # crossover probability\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.global_best_position = self.population[best_idx].copy()\n        self.global_best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, idx):\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant_vector = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant_vector, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        crossover_vector = np.array([mutant[i] if np.random.rand() < self.CR else target[i] for i in range(self.dim)])\n        return crossover_vector\n\n    def local_search(self, candidate):\n        perturbation = np.random.normal(0, 0.1, self.dim)\n        perturbed_candidate = candidate + perturbation\n        return np.clip(perturbed_candidate, self.lb, self.ub)\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        evaluations = 0\n\n        self.initialize_population(self.lb, self.ub)\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_search(trial)  # Dynamic local search\n                trial_score = self.evaluate(trial)\n                evaluations += 1\n\n                if trial_score < self.scores[i]:\n                    self.population[i] = trial\n                    self.scores[i] = trial_score\n                    if trial_score < self.global_best_score:\n                        self.global_best_score = trial_score\n                        self.global_best_position = trial\n\n                if evaluations >= self.budget:\n                    break\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "HDE_Optimizer", "description": "Hybrid Differential Evolution (HDE) with Self-Adaptive Control Parameters and Dynamic Local Search for Enhanced Exploration and Exploitation.", "configspace": "", "generation": 3, "fitness": 0.27101818648386694, "feedback": "The algorithm HDE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "f89847ed-c1e1-4aab-b523-0063c543c043", "metadata": {"aucs": [0.2708988653713248, 0.27252190167028645, 0.26963379240998964]}, "mutation_prompt": null}
{"id": "69abe2e4-3359-485e-90dc-03aad9c7fb58", "solution": "import numpy as np\n\nclass HPSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.velocities = None\n        self.positions = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_particles(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.array([self.evaluate(p) for p in self.positions])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.positions[i]))\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n            self.apply_simulated_annealing(i, lb, ub)\n            score = self.evaluate(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n    def apply_simulated_annealing(self, idx, lb, ub):\n        temp = self.current_temp()\n        neighbour = self.positions[idx] + np.random.normal(0, 1, self.dim) * temp\n        neighbour = np.clip(neighbour, lb, ub)\n        neighbour_score = self.evaluate(neighbour)\n        if neighbour_score < self.personal_best_scores[idx] or np.random.rand() < np.exp((self.personal_best_scores[idx] - neighbour_score) / temp):\n            self.positions[idx] = neighbour\n            self.personal_best_scores[idx] = neighbour_score\n\n    def current_temp(self):\n        return 1.0 - (self.evaluations / self.budget)\n\n    def update_inertia_weight(self):\n        self.inertia_weight = (self.inertia_weight_max - \n                               (self.inertia_weight_max - self.inertia_weight_min) * \n                               (self.evaluations / self.budget))\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        self.evaluations = 0\n\n        self.inertia_weight_max = self.inertia_weight\n        self.initialize_particles(self.lb, self.ub)\n\n        while self.evaluations < self.budget:\n            self.update_particles(self.lb, self.ub)\n            self.evaluations += self.num_particles\n            self.update_inertia_weight()\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "HPSO_Optimizer", "description": "A Hybrid Particle Swarm Optimization (HPSO) integrating Simulated Annealing to enhance exploration and convergence balance in global optimization.", "configspace": "", "generation": 4, "fitness": 0.2603200216152625, "feedback": "The algorithm HPSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "f89847ed-c1e1-4aab-b523-0063c543c043", "metadata": {"aucs": [0.2646204695272135, 0.26160539731843846, 0.25473419800013564]}, "mutation_prompt": null}
{"id": "aded73a9-e58c-44a0-a7b6-d6ad63a7e05a", "solution": "import numpy as np\n\nclass HybridPSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.F = 0.5  # DE mutation factor\n        self.CR = 0.7  # DE crossover probability\n        self.velocities = None\n        self.positions = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_particles(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.array([self.evaluate(p) for p in self.positions])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.positions[i]))\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n            score = self.evaluate(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n    def differential_evolution(self, lb, ub):\n        for i in range(self.num_particles):\n            indices = np.random.choice(self.num_particles, 3, replace=False)\n            x1, x2, x3 = self.positions[indices]\n            trial = x1 + self.F * (x2 - x3)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, trial, self.positions[i])\n            trial = np.clip(trial, lb, ub)\n            score = self.evaluate(trial)\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = trial.copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = trial.copy()\n\n    def update_inertia_weight(self, evaluations):\n        self.inertia_weight = (self.inertia_weight_max - \n                               (self.inertia_weight_max - self.inertia_weight_min) \n                               * (evaluations / self.budget))\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        evaluations = 0\n\n        self.inertia_weight_max = self.inertia_weight\n        self.initialize_particles(self.lb, self.ub)\n\n        while evaluations < self.budget:\n            self.update_particles(self.lb, self.ub)\n            self.differential_evolution(self.lb, self.ub)\n            evaluations += self.num_particles\n            self.update_inertia_weight(evaluations)\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "HybridPSO_DE_Optimizer", "description": "A Hybrid Particle Swarm Optimization with Adaptive Differential Evolution to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.2743549613323492, "feedback": "The algorithm HybridPSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "f89847ed-c1e1-4aab-b523-0063c543c043", "metadata": {"aucs": [0.2769185500615323, 0.27139289840267955, 0.2747534355328357]}, "mutation_prompt": null}
{"id": "b5b42f5e-57bb-446b-a99d-ec104eb9c40e", "solution": "import numpy as np\n\nclass Enhanced_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.velocities = None\n        self.positions = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.opposition_probability = 0.3  # probability of opposition learning\n\n    def initialize_particles(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.array([self.evaluate(p) for p in self.positions])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def opposition_based_learning(self, lb, ub):\n        for i in range(self.num_particles):\n            if np.random.rand() < self.opposition_probability:\n                opposite_position = lb + ub - self.positions[i]\n                opposite_score = self.evaluate(opposite_position)\n                if opposite_score < self.personal_best_scores[i]:\n                    self.personal_best_positions[i] = opposite_position\n                    self.personal_best_scores[i] = opposite_score\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_position\n\n    def update_particles(self, lb, ub):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.positions[i]))\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n            score = self.evaluate(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n    def update_inertia_weight(self, evaluations):\n        self.inertia_weight = (self.inertia_weight_max - \n                               (self.inertia_weight_max - self.inertia_weight_min) \n                               * (evaluations / self.budget))\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        evaluations = 0\n\n        self.inertia_weight_max = self.inertia_weight\n        self.initialize_particles(self.lb, self.ub)\n\n        while evaluations < self.budget:\n            self.update_particles(self.lb, self.ub)\n            self.opposition_based_learning(self.lb, self.ub)\n            evaluations += self.num_particles\n            self.update_inertia_weight(evaluations)\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "Enhanced_PSO_Optimizer", "description": "Enhanced Particle Swarm Optimization with Adaptive Topology and Velocity Control Incorporating Opposition-Based Learning for Improved Exploration and Exploitation.", "configspace": "", "generation": 6, "fitness": 0.2753494608093146, "feedback": "The algorithm Enhanced_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "f89847ed-c1e1-4aab-b523-0063c543c043", "metadata": {"aucs": [0.27694557593795777, 0.272014528315611, 0.277088278174375]}, "mutation_prompt": null}
{"id": "a897c99b-a47c-423a-9d0e-c0c5d2875f9e", "solution": "import numpy as np\n\nclass APSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.F = 0.8  # differential weight\n        self.CR = 0.9  # crossover probability\n        self.velocities = None\n        self.positions = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_particles(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.array([self.evaluate(p) for p in self.positions])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.positions[i]))\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            # Differential Evolution mutation and crossover\n            candidates = [idx for idx in range(self.num_particles) if idx != i]\n            a, b, c = np.random.choice(candidates, 3, replace=False)\n            mutant_vector = self.positions[a] + self.F * (self.positions[b] - self.positions[c])\n            mutant_vector = np.clip(mutant_vector, lb, ub)\n            crossover_vector = np.where(np.random.rand(self.dim) < self.CR, mutant_vector, self.positions[i])\n\n            score = self.evaluate(crossover_vector)\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = crossover_vector.copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = crossover_vector.copy()\n\n    def update_inertia_weight(self, evaluations):\n        self.inertia_weight = (self.inertia_weight_max - \n                               (self.inertia_weight_max - self.inertia_weight_min) \n                               * (evaluations / self.budget))\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        evaluations = 0\n\n        self.inertia_weight_max = self.inertia_weight\n        self.initialize_particles(self.lb, self.ub)\n\n        while evaluations < self.budget:\n            self.update_particles(self.lb, self.ub)\n            evaluations += self.num_particles\n            self.update_inertia_weight(evaluations)\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "APSO_DE_Optimizer", "description": "A hybrid approach combining Adaptive Particle Swarm Optimization with Differential Evolution (APSO-DE) for enhanced exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.2633271966629087, "feedback": "The algorithm APSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "f89847ed-c1e1-4aab-b523-0063c543c043", "metadata": {"aucs": [0.26186782131492214, 0.26071658613775395, 0.26739718253605005]}, "mutation_prompt": null}
{"id": "d0d9368d-1e85-477b-862a-00c43ff0a0f2", "solution": "import numpy as np\n\nclass PSO_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.9\n        self.inertia_weight_min = 0.4\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.f = 0.5  # differential weight\n        self.cr = 0.9  # crossover probability\n        self.velocities = None\n        self.positions = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_particles(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.array([self.evaluate(p) for p in self.positions])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.num_particles):\n            r1, r2 = np.random.rand(), np.random.rand()\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n                                  self.c2 * r2 * (self.global_best_position - self.positions[i]))\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n            score = self.evaluate(self.positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.positions[i].copy()\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n        \n        self.apply_differential_evolution(lb, ub)\n\n    def apply_differential_evolution(self, lb, ub):\n        for i in range(self.num_particles):\n            a, b, c = np.random.choice(np.delete(np.arange(self.num_particles), i), 3, replace=False)\n            mutant_vector = self.positions[a] + self.f * (self.positions[b] - self.positions[c])\n            trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, self.positions[i])\n            trial_vector = np.clip(trial_vector, lb, ub)\n            trial_score = self.evaluate(trial_vector)\n            if trial_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = trial_score\n                self.personal_best_positions[i] = trial_vector.copy()\n                if trial_score < self.global_best_score:\n                    self.global_best_score = trial_score\n                    self.global_best_position = trial_vector.copy()\n\n    def update_inertia_weight(self, evaluations):\n        self.inertia_weight = (self.inertia_weight_max - \n                               (self.inertia_weight_max - self.inertia_weight_min) \n                               * (evaluations / self.budget))\n\n    def __call__(self, func):\n        self.func = func\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n        evaluations = 0\n\n        self.inertia_weight_max = self.inertia_weight\n        self.initialize_particles(self.lb, self.ub)\n\n        while evaluations < self.budget:\n            self.update_particles(self.lb, self.ub)\n            evaluations += self.num_particles\n            self.update_inertia_weight(evaluations)\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "PSO_DE_Optimizer", "description": "Hybrid Particle Swarm Optimization with Differential Evolution (PSO-DE) to enhance global exploration and convergence by integrating mutation and crossover strategies.", "configspace": "", "generation": 8, "fitness": 0.2693465499961967, "feedback": "The algorithm PSO_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "f89847ed-c1e1-4aab-b523-0063c543c043", "metadata": {"aucs": [0.2769622740370533, 0.27265806330646614, 0.2584193126450708]}, "mutation_prompt": null}
{"id": "478d1f15-5e35-4fa2-8972-35b509a4260f", "solution": "import numpy as np\n\nclass HADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evaluations = 0\n\n        self.initialize_population(lb, ub)\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "HADE_Optimizer", "description": "Hierarchical Adaptive Differential Evolution (HADE) enhances exploration and exploitation by using adaptive mutation and crossover strategies in a hierarchical population structure.", "configspace": "", "generation": 9, "fitness": 0.2768845160700782, "feedback": "The algorithm HADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "f89847ed-c1e1-4aab-b523-0063c543c043", "metadata": {"aucs": [0.2770129263972536, 0.27637991514532967, 0.27726070666765135]}, "mutation_prompt": null}
{"id": "084c1b67-700a-4749-9101-911f9e6dc190", "solution": "import numpy as np\n\nclass QIGA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.05  # Quantum rotation angle step size\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n\n    def initialize_population(self, lb, ub):\n        # Use quantum superposition to initialize population in [0, 1]\n        self.population = np.random.rand(self.population_size, self.dim)\n        self.scores = np.full(self.population_size, float('inf'))\n    \n    def evaluate(self, solution):\n        # Transform [0, 1] to [lb, ub] before evaluation\n        scaled_solution = self.lb + (solution * (self.ub - self.lb))\n        return self.func(scaled_solution)\n\n    def quantum_rotation(self, individual, best_individual):\n        # Rotate each individual's qubits towards the best solution\n        for i in range(self.dim):\n            if np.random.rand() < 0.5:\n                if individual[i] < best_individual[i]:\n                    individual[i] += self.alpha * (best_individual[i] - individual[i])\n                else:\n                    individual[i] -= self.alpha * (individual[i] - best_individual[i])\n            individual[i] = np.clip(individual[i], 0, 1)\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evaluations = 0\n\n        self.initialize_population(self.lb, self.ub)\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                self.scores[i] = self.evaluate(self.population[i])\n                if self.scores[i] < self.best_score:\n                    self.best_score = self.scores[i]\n                    self.best_solution = self.population[i].copy()\n            evaluations += self.population_size\n\n            # Apply quantum rotation towards the best individual\n            for i in range(self.population_size):\n                self.quantum_rotation(self.population[i], self.best_solution)\n\n        # Transform best solution back to original bounds\n        final_solution = self.lb + (self.best_solution * (self.ub - self.lb))\n        return {'solution': final_solution, 'fitness': self.best_score}", "name": "QIGA_Optimizer", "description": "Quantum-Inspired Genetic Algorithm (QIGA) utilizes quantum superposition principles to enhance diversity and convergence speed in optimizing solutions.", "configspace": "", "generation": 10, "fitness": 0.272876984036946, "feedback": "The algorithm QIGA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "478d1f15-5e35-4fa2-8972-35b509a4260f", "metadata": {"aucs": [0.2720849196042543, 0.2752322221840333, 0.2713138103225503]}, "mutation_prompt": null}
{"id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "solution": "import numpy as np\n\nclass EHADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        # Adapt mutation factor based on current evaluation ratio\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        # Dynamically resize the population\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "EHADE_Optimizer", "description": "Enhanced Hierarchical Adaptive Differential Evolution (EHADE) introduces dynamic population resizing and variable mutation strategies to improve convergence and diversity.", "configspace": "", "generation": 11, "fitness": 0.27689568450349494, "feedback": "The algorithm EHADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "478d1f15-5e35-4fa2-8972-35b509a4260f", "metadata": {"aucs": [0.2770190935808763, 0.2763157834873501, 0.2773521764422585]}, "mutation_prompt": null}
{"id": "ac5c73c0-9f81-42fe-b6c2-e6b92f6ae23a", "solution": "import numpy as np\n\nclass ECHADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR_base = 0.9  # Base crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        # Adaptive mutation factor based on competitive selection\n        mutation_factor = self.F_base + np.random.rand() * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def adaptive_crossover_rate(self):\n        # Adaptive crossover probability\n        return self.CR_base * (1 - self.best_score / (self.best_score + 1))\n\n    def crossover(self, target, mutant):\n        crossover_rate = self.adaptive_crossover_rate()\n        crossover_mask = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        # Dynamically resize the population\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(self.lb, self.ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "ECHADE_Optimizer", "description": "Enhanced Competitive Hierarchical Adaptive Differential Evolution (ECHADE) integrates competitive selection and adaptive learning rates to balance exploration and exploitation for improved convergence.", "configspace": "", "generation": 12, "fitness": 0.2704379678283065, "feedback": "The algorithm ECHADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.2699911839650958, 0.2723703057197794, 0.2689524138000443]}, "mutation_prompt": null}
{"id": "5fd6fdcf-47c0-4c8f-bbcb-92e1ccfb125d", "solution": "import numpy as np\n\nclass EHADEPlusPlus_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR_base = 0.9  # Base crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def adaptive_mutation(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        if self.evaluations < self.budget * 0.5:\n            mutation_factor *= 1.5  # Increase exploration in early phases\n        elif self.evaluations > self.budget * 0.75:\n            mutation_factor *= 0.5  # Focus on exploitation in later phases\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def adaptive_crossover(self, target, mutant):\n        CR = self.CR_base * (1 + 0.1 * np.sin(2 * np.pi * (self.evaluations / self.budget)))\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.adaptive_mutation(i)\n                trial = self.adaptive_crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "EHADEPlusPlus_Optimizer", "description": "EHADE++ uses multi-phase mutation strategies and dynamic crossover probabilities to enhance exploration and exploitation in differential evolution.", "configspace": "", "generation": 13, "fitness": 0.2722948119666084, "feedback": "The algorithm EHADEPlusPlus_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.2755089657053199, 0.27143738833767217, 0.2699380818568331]}, "mutation_prompt": null}
{"id": "881c8f28-1922-424a-8dfb-8a7d2c42f9ab", "solution": "import numpy as np\n\nclass AQIGA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.q_population = None  # Quantum population\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.theta = np.pi / 4  # Rotation angle for quantum bits\n\n    def initialize_population(self):\n        self.q_population = np.random.uniform(0, np.pi / 2, (self.population_size, self.dim))\n        self.scores = np.full(self.population_size, float('inf'))\n\n    def decode(self, q_individual):\n        return np.cos(q_individual) ** 2  # Decoding quantum bits to classical bits\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def measure(self, q_individual):\n        return np.array([1 if np.random.rand() < np.cos(theta) ** 2 else 0 for theta in q_individual])\n\n    def quantum_rotation(self, q_individual, classical_individual, best_classical):\n        return q_individual + self.theta * (2 * best_classical - classical_individual - 1)\n\n    def select(self, classical_population):\n        indices = np.argsort(self.scores)\n        return classical_population[indices[:self.population_size // 2]]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population()\n\n        classical_population = np.zeros((self.population_size, self.dim))\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                classical_population[i] = self.decode(self.q_population[i]) * (ub - lb) + lb\n                self.scores[i] = self.evaluate(classical_population[i])\n                if self.scores[i] < self.best_score:\n                    self.best_score = self.scores[i]\n                    self.best_solution = classical_population[i].copy()\n\n            best_classical = self.decode(self.q_population[np.argmin(self.scores)])\n            selected = self.select(classical_population)\n\n            for i in range(self.population_size):\n                measured = self.measure(self.q_population[i])\n                self.q_population[i] = self.quantum_rotation(self.q_population[i], measured, best_classical)\n                self.q_population[i] = np.clip(self.q_population[i], 0, np.pi / 2)\n            \n            self.evaluations += self.population_size\n            if self.evaluations >= self.budget:\n                break\n        \n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "AQIGA_Optimizer", "description": "Adaptive Quantum-Inspired Genetic Algorithm (AQIGA) leverages quantum bit representation and dynamic parameter adjustment to enhance global search capabilities and maintain diversity.", "configspace": "", "generation": 14, "fitness": 0.2327342246639518, "feedback": "The algorithm AQIGA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.23241996201084258, 0.23324930324296556, 0.2325334087380473]}, "mutation_prompt": null}
{"id": "e007a416-3df9-4c15-9c6a-87ddb256b040", "solution": "import numpy as np\n\nclass QDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.Q = 0.1  # Quantum probability factor\n        self.F_max = 0.9  # Maximum mutation factor\n        self.F_min = 0.5  # Minimum mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutation_factor = self.F_min + (self.F_max - self.F_min) * np.random.rand()\n        mutant = a + mutation_factor * (b - c)\n        # Quantum-inspired mutation\n        if np.random.rand() < self.Q:\n            quantum_mutation = np.random.uniform(-1, 1, self.dim)\n            mutant += quantum_mutation * mutation_factor\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QDE_Optimizer", "description": "Quantum-inspired Differential Evolution (QDE) employs quantum superposition and probabilistic mutation to enhance exploration and avoid premature convergence.", "configspace": "", "generation": 15, "fitness": 0.2752438596871, "feedback": "The algorithm QDE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.2757159490962027, 0.2751456562287411, 0.27486997373635635]}, "mutation_prompt": null}
{"id": "04d4ac64-98a7-4378-ab88-d37208183cca", "solution": "import numpy as np\n\nclass AGIDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def approximate_gradient(self, target_idx):\n        target = self.population[target_idx]\n        epsilon = 1e-8\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            perturbed = target.copy()\n            perturbed[i] += epsilon\n            grad[i] = (self.evaluate(perturbed) - self.scores[target_idx]) / epsilon\n        return grad\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        gradient = self.approximate_gradient(target_idx)\n        scaled_grad = gradient * (1 - self.evaluations / self.budget)\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c) - scaled_grad\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "AGIDE_Optimizer", "description": "Adaptive Gradient-Informed Differential Evolution (AGIDE) refines mutation strategies using gradient approximations to enhance convergence speed and solution quality.", "configspace": "", "generation": 16, "fitness": 0.26398238224162784, "feedback": "The algorithm AGIDE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.2649392267603141, 0.25745633064478957, 0.26955158931977985]}, "mutation_prompt": null}
{"id": "d41568ad-b3a3-49f5-93c2-c2c1ef771f47", "solution": "import numpy as np\n\nclass QAPSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.alpha = 0.98  # Damping factor for convergence\n        self.beta = 0.02  # Exploration factor\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.population[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_velocities_positions(self, lb, ub):\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            cognitive_component = self.alpha * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.alpha * r2 * (self.global_best_position - self.population[i])\n            quantum_superposition = self.beta * np.random.uniform(lb, ub, self.dim)\n            self.velocities[i] = cognitive_component + social_component + quantum_superposition\n            self.population[i] = np.clip(self.population[i] + self.velocities[i], lb, ub)\n\n    def update_personal_global_best(self):\n        for i in range(self.population_size):\n            score = self.evaluate(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i].copy()\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.velocities = self.velocities[:self.population_size]\n        self.personal_best_positions = self.personal_best_positions[:self.population_size]\n        self.personal_best_scores = self.personal_best_scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            self.update_velocities_positions(lb, ub)\n            self.update_personal_global_best()\n            self.evaluations += self.population_size\n            if self.evaluations >= self.budget:\n                break\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "QAPSO_Optimizer", "description": "Quantum-inspired Adaptive Population Swarm Optimization (QAPSO) integrates quantum superposition principles with adaptive population dynamics to enhance exploration and convergence.", "configspace": "", "generation": 17, "fitness": 0.2732530896560765, "feedback": "The algorithm QAPSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.2761339013118296, 0.2700288195963051, 0.2735965480600947]}, "mutation_prompt": null}
{"id": "357b5cf4-2f1e-4592-8cb0-f91e4aef1e42", "solution": "import numpy as np\n\nclass DADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR_base = 0.9  # Base crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        # Nonlinear control for adaptive mutation factor\n        mutation_factor = self.F_base * np.exp(-5.0 * self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        # Self-adaptive crossover probability\n        CR = self.CR_base * (1 - np.tanh(10 * self.evaluations / self.budget - 5))\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        # Dynamically resize the population\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "DADE_Optimizer", "description": "Dynamic Adaptive Differential Evolution (DADE) introduces a novel adaptive mutation strategy using nonlinear control and self-adaptive crossover to improve convergence speed and solution quality.", "configspace": "", "generation": 18, "fitness": 0.26600540202920275, "feedback": "The algorithm DADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.27124584251832506, 0.2713591353486321, 0.2554112282206511]}, "mutation_prompt": null}
{"id": "82495268-5afd-4ba7-8f54-cdeb56b54de4", "solution": "import numpy as np\n\nclass QIPSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.1  # Learning rate for personal best\n        self.beta = 0.3   # Learning rate for global best\n        self.evaluations = 0\n        self.population = None\n        self.velocities = None\n        self.personal_bests = None\n        self.personal_best_scores = None\n        self.global_best = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(lb, ub, (self.population_size, self.dim)) * 0.1\n        self.personal_bests = self.population.copy()\n        self.personal_best_scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best = self.personal_bests[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def quantum_update(self, lb, ub):\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(), np.random.rand()\n            cognitive_component = self.alpha * r1 * (self.personal_bests[i] - self.population[i])\n            social_component = self.beta * r2 * (self.global_best - self.population[i])\n            self.velocities[i] = cognitive_component + social_component\n\n            # Add a quantum-inspired exploration\n            quantum_exploration = np.random.uniform(lb, ub, self.dim) * np.random.choice([-1, 1], self.dim)\n            self.population[i] += self.velocities[i] + quantum_exploration\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n            # Evaluate and update personal and global bests\n            score = self.evaluate(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_bests[i] = self.population[i].copy()\n                self.personal_best_scores[i] = score\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.population[i].copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.quantum_update(lb, ub)\n            self.evaluations += self.population_size\n            if self.evaluations >= self.budget:\n                break\n\n        return {'solution': self.global_best, 'fitness': self.global_best_score}", "name": "QIPSO_Optimizer", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) leverages quantum superposition principles to enhance diversity and convergence by allowing particles to explore potential solutions in a probabilistic manner and dynamically adapting their learning rates.", "configspace": "", "generation": 19, "fitness": 0.24176633633418898, "feedback": "The algorithm QIPSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.24089890910545264, 0.24323949479021734, 0.24116060510689696]}, "mutation_prompt": null}
{"id": "af1d85f9-9f87-4d16-957f-da43012dc19f", "solution": "import numpy as np\n\nclass QADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR_base = 0.7  # Base crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def quantum_rotation(self, vec):\n        theta = np.pi * np.random.uniform(0, 1, len(vec))\n        q_rot = np.cos(theta) * vec + np.sin(theta) * np.random.uniform(-1, 1, len(vec))\n        return q_rot\n\n    def adaptive_crossover(self, target, mutant):\n        # Adapt crossover probability based on current evaluation ratio\n        CR = self.CR_base + 0.2 * (self.evaluations / self.budget)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                quantum_mutant = self.quantum_rotation(mutant)\n                trial = self.adaptive_crossover(self.population[i], quantum_mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QADE_Optimizer", "description": "Quantum-inspired Adaptive Differential Evolution uses quantum rotation gates and adaptive crossover probabilities to enhance exploration and exploitation in search for optimal solutions.", "configspace": "", "generation": 20, "fitness": 0.2357580256875811, "feedback": "The algorithm QADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.234397985670999, 0.23834480608611286, 0.2345312853056315]}, "mutation_prompt": null}
{"id": "8d49197e-135a-4e2f-8b0b-639baa22e647", "solution": "import numpy as np\n\nclass QIEA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.population = None\n        self.quantum_population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        # Initialize quantum bits as probabilities\n        self.quantum_population = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.population = self.quantum_to_real(self.quantum_population, lb, ub)\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def quantum_to_real(self, quantum_bits, lb, ub):\n        # Convert quantum bits to real values within bounds\n        return lb + (ub - lb) * quantum_bits\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def quantum_rotation_gate(self, quantum_bit, best_bit):\n        rotation_angle = np.pi / 10  # Fixed rotation angle\n        delta = rotation_angle if quantum_bit < best_bit else -rotation_angle\n        new_bit = quantum_bit + delta * (np.random.rand() - 0.5)\n        return np.clip(new_bit, 0, 1)\n\n    def evolve_quantum_population(self):\n        # Apply quantum rotation gate based on best solution\n        best_quantum = self.quantum_to_real(self.quantum_population, self.func.bounds.lb, self.func.bounds.ub)\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                self.quantum_population[i, j] = self.quantum_rotation_gate(self.quantum_population[i, j], best_quantum[j])\n\n    def update_best(self):\n        # Update the best solution found\n        current_real_population = self.quantum_to_real(self.quantum_population, self.func.bounds.lb, self.func.bounds.ub)\n        current_scores = np.array([self.evaluate(ind) for ind in current_real_population])\n        for idx, score in enumerate(current_scores):\n            if score < self.scores[idx]:\n                self.scores[idx] = score\n                self.population[idx] = current_real_population[idx].copy()\n                if score < self.best_score:\n                    self.best_score = score\n                    self.best_solution = current_real_population[idx].copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.evolve_quantum_population()\n            self.update_best()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QIEA_Optimizer", "description": "Quantum-Inspired Evolutionary Algorithm (QIEA) leverages quantum principles to enhance solution diversity and convergence through quantum bit representation and rotation gate updates.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {}, "mutation_prompt": null}
{"id": "5365f078-a1ba-413d-b4b1-f0a77d5c6884", "solution": "import numpy as np\n\nclass EHADE_APM_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.population_size = self.initial_population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(individual) for individual in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        performance_factor = (self.best_score - self.scores[target_idx]) / (self.best_score + 1e-9)\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget) * performance_factor\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        # Dynamically prioritize better-performing individuals\n        sorted_indices = np.argsort(self.scores)\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[sorted_indices][:self.population_size]\n        self.scores = self.scores[sorted_indices][:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "EHADE_APM_Optimizer", "description": "Enhanced Hierarchical Adaptive Differential Evolution with Adaptive Population and Mutation (EHADE-APM) improves convergence by dynamically prioritizing individuals in the population based on performance and introducing adaptive mutation scaling.", "configspace": "", "generation": 22, "fitness": 0.26462071188318287, "feedback": "The algorithm EHADE_APM_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.26482760313983666, 0.26852829164087944, 0.26050624086883256]}, "mutation_prompt": null}
{"id": "6819f8a2-1fc7-4564-a351-2af40e29d2f8", "solution": "import numpy as np\n\nclass AML_DDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solutions = []\n        self.best_scores = []\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best_solutions()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        # Select multiple leaders from the best solutions\n        leaders = np.random.choice(len(self.best_solutions), 3, replace=False)\n        a, b, c = [self.best_solutions[i] for i in leaders]\n        # Adapt mutation factor based on diversity measure\n        diversity = np.std(self.scores)\n        mutation_factor = self.F_base * (1 - diversity / np.max(self.scores))\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < np.min(self.best_scores):\n                self.best_solutions.append(trial.copy())\n                self.best_scores.append(trial_score)\n                self.prune_best_solutions()\n\n    def prune_best_solutions(self):\n        # Keep only the top few best solutions\n        if len(self.best_scores) > 5:\n            worst_idx = np.argmax(self.best_scores)\n            del self.best_scores[worst_idx]\n            del self.best_solutions[worst_idx]\n\n    def update_best_solutions(self):\n        best_idx = np.argmin(self.scores)\n        if not self.best_scores or self.scores[best_idx] < np.min(self.best_scores):\n            self.best_solutions = [self.population[best_idx].copy()]\n            self.best_scores = [self.scores[best_idx]]\n\n    def resize_population(self):\n        # Dynamically resize the population\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(self.best_scores)\n        best_solution = self.best_solutions[best_idx]\n        best_score = self.best_scores[best_idx]\n        return {'solution': best_solution, 'fitness': best_score}", "name": "AML_DDE_Optimizer", "description": "Adaptive Multi-Leader Dynamic Differential Evolution (AML-DDE) employs a multi-leader selection strategy and adaptive mutation scaling to enhance exploration and exploitation balance, improving overall performance.", "configspace": "", "generation": 23, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {}, "mutation_prompt": null}
{"id": "a1267677-d70a-4cbf-826b-6f3ee47b15b9", "solution": "import numpy as np\n\nclass MSPAEA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.population_size = self.initial_population_size\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.F = 0.5  # Initial mutation factor\n        self.CR = 0.9  # Initial crossover probability\n        self.mutation_strategies = [self.rand_1, self.rand_2, self.best_1]\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def adjust_parameters(self):\n        self.F = 0.4 + 0.6 * (self.budget - self.evaluations) / self.budget\n        self.CR = 0.6 + 0.4 * (self.evaluations / self.budget)\n\n    def rand_1(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        return a + self.F * (b - c)\n\n    def rand_2(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c, d, e = self.population[np.random.choice(indices, 5, replace=False)]\n        return a + self.F * (b - c) + self.F * (d - e)\n\n    def best_1(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b = self.population[np.random.choice(indices, 2, replace=False)]\n        return self.best_solution + self.F * (a - b)\n\n    def mutate(self, target_idx):\n        strategy = np.random.choice(self.mutation_strategies)\n        return strategy(target_idx)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - 0.8 * self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            self.adjust_parameters()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "MSPAEA_Optimizer", "description": "Multi-Strategy Parameters Adaptive Evolutionary Algorithm (MSPAEA) leverages multiple mutation strategies and adaptive parameter control to enhance exploration and exploitation in optimization.", "configspace": "", "generation": 24, "fitness": 0.27082151782232805, "feedback": "The algorithm MSPAEA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.268740694683568, 0.2707107499558903, 0.27301310882752594]}, "mutation_prompt": null}
{"id": "87f09396-6497-45ff-a1f6-0ae6376a1936", "solution": "import numpy as np\n\nclass DPC_EHADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR_base = 0.9  # Base crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        adaptation_factor = self.best_score / np.mean(self.scores)\n        mutation_factor = self.F_base * adaptation_factor * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        adaptation_factor = self.best_score / np.mean(self.scores)\n        crossover_rate = self.CR_base * adaptation_factor\n        crossover_mask = np.random.rand(self.dim) < crossover_rate\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        # Dynamically resize the population\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "DPC_EHADE_Optimizer", "description": "Dynamic Population Control EHADE (DPC-EHADE) enhances convergence by integrating adaptive control of mutation factor and crossover rate utilizing fitness-based feedback loops.", "configspace": "", "generation": 25, "fitness": 0.2767039878080464, "feedback": "The algorithm DPC_EHADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.2763871647056543, 0.2770249629393752, 0.2766998357791097]}, "mutation_prompt": null}
{"id": "fb7473b3-7b87-48cc-ac81-91f112e5fe99", "solution": "import numpy as np\n\nclass QIPSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.population = None\n        self.velocities = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.personal_best = None\n        self.personal_best_scores = None\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.personal_best = self.population.copy()\n        self.personal_best_scores = self.scores.copy()\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_particle(self, idx, lb, ub):\n        r1 = np.random.rand(self.dim)\n        r2 = np.random.rand(self.dim)\n        # Quantum inspired amplitude modulation\n        amplitude = np.sin(self.evaluations / self.budget * np.pi)\n        new_velocity = (self.velocities[idx] \n                        + amplitude * r1 * (self.personal_best[idx] - self.population[idx])\n                        + amplitude * r2 * (self.best_solution - self.population[idx]))\n        self.velocities[idx] = new_velocity\n        new_position = self.population[idx] + new_velocity\n        self.population[idx] = np.clip(new_position, lb, ub)\n\n    def update_personal_best(self, idx):\n        score = self.evaluate(self.population[idx])\n        if score < self.personal_best_scores[idx]:\n            self.personal_best[idx] = self.population[idx].copy()\n            self.personal_best_scores[idx] = score\n        if score < self.best_score:\n            self.best_score = score\n            self.best_solution = self.population[idx].copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                self.update_particle(i, lb, ub)\n                self.update_personal_best(i)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QIPSO_Optimizer", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) leverages quantum mechanics principles to enhance exploration and exploitation with dynamic amplitude and phase adaptation.", "configspace": "", "generation": 26, "fitness": 0.27564354681733855, "feedback": "The algorithm QIPSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.27526831721052003, 0.2762669580301307, 0.275395365211365]}, "mutation_prompt": null}
{"id": "b5d2b334-0ac5-495d-a1f8-a256f1991b88", "solution": "import numpy as np\n\nclass AP_EDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def calculate_population_energy(self):\n        # Population energy based on scores' variance\n        return np.var(self.scores)\n\n    def mutate(self, target_idx, energy):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        # Adapt mutation factor based on energy level\n        mutation_factor = self.F_base * (1 + energy / (1 + np.std(self.scores)))\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        # Dynamically resize the population based on energy levels\n        energy = self.calculate_population_energy()\n        self.population_size = max(5, int(self.initial_population_size * (1 - energy)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            energy = self.calculate_population_energy()\n            for i in range(self.population_size):\n                mutant = self.mutate(i, energy)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "AP_EDE_Optimizer", "description": "Adaptive Population-Energy Differential Evolution (AP-EDE) introduces energy-based mutation factor scaling and adaptive population energy to enhance exploration and exploitation.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 29 is out of bounds for axis 0 with size 29').", "error": "IndexError('index 29 is out of bounds for axis 0 with size 29')", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {}, "mutation_prompt": null}
{"id": "c9791f01-d388-493c-9bb9-b9e6935d238e", "solution": "import numpy as np\n\nclass AMDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.local_search_prob = 0.1  # Probability of applying local search\n        self.F_base = 0.5  # Base mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n    \n    def local_search(self, solution, lb, ub):\n        step_size = 0.1 * (ub - lb)\n        perturbation = np.random.uniform(-step_size, step_size, solution.shape)\n        new_solution = solution + perturbation\n        new_solution = np.clip(new_solution, lb, ub)\n        return new_solution\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n\n                if np.random.rand() < self.local_search_prob:\n                    trial = self.local_search(trial, lb, ub)\n\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "AMDE_Optimizer", "description": "Adaptive Memetic Differential Evolution (AMDE) combines local search with adaptive differential evolution to enhance exploration and exploitation capabilities.", "configspace": "", "generation": 28, "fitness": 0.27684611022057287, "feedback": "The algorithm AMDE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.27695251815024546, 0.27649577950860205, 0.27709003300287105]}, "mutation_prompt": null}
{"id": "c0d35d96-7995-47c5-8bf9-e6a2a6ca4da4", "solution": "import numpy as np\n\nclass QIPSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.array([self.evaluate(ind) for ind in self.positions])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1, r2 = np.random.rand(2)\n            cognitive_term = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_term = self.social_coeff * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i]) + cognitive_term + social_term\n            \n            # Quantum inspired position update\n            self.positions[i] = self.positions[i] + self.velocities[i] + \\\n                                np.sin(self.velocities[i]) * (self.global_best_position - self.positions[i])\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n            current_score = self.evaluate(self.positions[i])\n            if current_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = current_score\n                self.personal_best_positions[i] = self.positions[i].copy()\n                if current_score < self.global_best_score:\n                    self.global_best_score = current_score\n                    self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.update_particles(lb, ub)\n            self.evaluations += self.swarm_size\n            if self.evaluations >= self.budget:\n                break\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "QIPSO_Optimizer", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) utilizes principles from quantum mechanics to enhance exploration and exploitation by dynamically adjusting the search space based on quantum potential wells.", "configspace": "", "generation": 29, "fitness": 0.2675642458156157, "feedback": "The algorithm QIPSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.27237312819715764, 0.27274838851535754, 0.2575712207343319]}, "mutation_prompt": null}
{"id": "c8e809ea-fd24-423b-92aa-27efbbec3a64", "solution": "import numpy as np\n\nclass QPSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.alpha = 0.5  # Contraction-expansion coefficient\n        self.best_global_position = None\n        self.best_global_fitness = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_fitness = np.array([self.evaluate(pos) for pos in self.positions])\n        best_idx = np.argmin(self.personal_best_fitness)\n        self.best_global_position = self.personal_best_positions[best_idx]\n        self.best_global_fitness = self.personal_best_fitness[best_idx]\n\n    def evaluate(self, position):\n        return self.func(position)\n\n    def update_particles(self, lb, ub):\n        for i in range(self.population_size):\n            p_best = self.personal_best_positions[i]\n            g_best = self.best_global_position\n            u = np.random.uniform(0, 1, self.dim)\n            mean_best = self.alpha * p_best + (1 - self.alpha) * g_best\n            self.positions[i] = mean_best + self.alpha * np.log(1 / u) * np.sign(u - 0.5)\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n            fitness = self.evaluate(self.positions[i])\n            self.evaluations += 1\n            if fitness < self.personal_best_fitness[i]:\n                self.personal_best_positions[i] = self.positions[i]\n                self.personal_best_fitness[i] = fitness\n            if fitness < self.best_global_fitness:\n                self.best_global_position = self.positions[i]\n                self.best_global_fitness = fitness\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.update_particles(lb, ub)\n            if self.evaluations >= self.budget:\n                break\n\n        return {'solution': self.best_global_position, 'fitness': self.best_global_fitness}", "name": "QPSO_Optimizer", "description": "Quantum-inspired Particle Swarm Optimization (QPSO) incorporates quantum mechanics principles to enhance exploration and exploitation with adaptive parameter control.", "configspace": "", "generation": 30, "fitness": 0.27493016964667366, "feedback": "The algorithm QPSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.2746704606836837, 0.27540737520218106, 0.27471267305415625]}, "mutation_prompt": null}
{"id": "86fa7038-a1c1-4de3-8850-05cd61965a91", "solution": "import numpy as np\n\nclass ADE_SBPA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR_base = 0.9  # Base crossover probability\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.successful_trials = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = self.CR_base * (1 - self.successful_trials / (self.evaluations + 1))\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            self.successful_trials += 1\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "ADE_SBPA_Optimizer", "description": "Adaptive Differential Evolution with Success-Based Parameter Adjustment (ADE-SBPA), dynamically adjusts mutation and crossover rates based on the success rate of past iterations to enhance convergence and solution quality.", "configspace": "", "generation": 31, "fitness": 0.2756793693087158, "feedback": "The algorithm ADE_SBPA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.27604420606682956, 0.27599151278719825, 0.2750023890721195]}, "mutation_prompt": null}
{"id": "176ed4db-56bf-4591-bf5b-d9465c77d76b", "solution": "import numpy as np\n\nclass DALPSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_base = 2.0  # Cognitive coefficient base\n        self.c2_base = 2.0  # Social coefficient base\n        self.inertia = 0.5  # Inertia weight\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.update_personal_best_scores()\n\n    def update_personal_best_scores(self):\n        for i in range(self.population_size):\n            score = self.evaluate(self.population[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = score\n                self.personal_best_positions[i] = self.population[i].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[i].copy()\n            self.evaluations += 1\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_velocity(self, idx, lb, ub):\n        cognitive_component = np.random.rand(self.dim) * self.c1 * (self.personal_best_positions[idx] - self.population[idx])\n        social_component = np.random.rand(self.dim) * self.c2 * (self.global_best_position - self.population[idx])\n        self.velocities[idx] = self.inertia * self.velocities[idx] + cognitive_component + social_component\n        self.velocities[idx] = np.clip(self.velocities[idx], -abs(ub-lb), abs(ub-lb))\n\n    def update_position(self, idx, lb, ub):\n        self.population[idx] += self.velocities[idx]\n        self.population[idx] = np.clip(self.population[idx], lb, ub)\n\n    def adapt_learning_coefficients(self):\n        # Adapt coefficients based on the current evaluation ratio\n        eval_ratio = self.evaluations / self.budget\n        self.c1 = self.c1_base * (1 - eval_ratio)\n        self.c2 = self.c2_base * eval_ratio\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.adapt_learning_coefficients()\n            for i in range(self.population_size):\n                self.update_velocity(i, lb, ub)\n                self.update_position(i, lb, ub)\n            self.update_personal_best_scores()\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "DALPSO_Optimizer", "description": "Dynamic Adaptive Learning Particle Swarm Optimization (DALPSO) leverages adaptive learning coefficients and dynamic neighborhood topology to enhance exploration and exploitation.", "configspace": "", "generation": 32, "fitness": 0.27491129658837604, "feedback": "The algorithm DALPSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.27522232762674737, 0.27611389255193697, 0.27339766958644385]}, "mutation_prompt": null}
{"id": "d76e5f71-05e8-485e-8051-188cf7c1f7fa", "solution": "import numpy as np\n\nclass APSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.evaluations = 0\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n\n    def initialize_population(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.array([self.evaluate(ind) for ind in self.positions])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_velocities_and_positions(self, lb, ub):\n        r1, r2 = np.random.rand(), np.random.rand()\n        self.inertia_weight = 0.4 + 0.5 * (1 - self.evaluations / self.budget)  # Dynamic inertia weight\n        for i in range(self.population_size):\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            self.velocities[i] = (\n                self.inertia_weight * self.velocities[i] +\n                cognitive_velocity +\n                social_velocity\n            )\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n    def update_personal_best(self):\n        for i in range(self.population_size):\n            current_score = self.evaluate(self.positions[i])\n            if current_score < self.personal_best_scores[i]:\n                self.personal_best_scores[i] = current_score\n                self.personal_best_positions[i] = self.positions[i].copy()\n            if current_score < self.global_best_score:\n                self.global_best_score = current_score\n                self.global_best_position = self.positions[i].copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.update_velocities_and_positions(lb, ub)\n            self.update_personal_best()\n            self.evaluations += self.population_size\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "APSO_Optimizer", "description": "Adaptive Particle Swarm Optimization (APSO) with Dynamic Inertia Weight and Constriction Factor enhances exploration and exploitation balance by adapting inertia weight and constriction factor based on convergence progress.", "configspace": "", "generation": 33, "fitness": 0.2659279490197985, "feedback": "The algorithm APSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.25702758496844813, 0.2722844043725742, 0.26847185771837323]}, "mutation_prompt": null}
{"id": "47187b0a-4287-4f27-b4bc-53240e5ce7d7", "solution": "import numpy as np\n\nclass QIEA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.qubit_population = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def measure(self):\n        return np.sign(self.qubit_population) * np.sqrt(np.abs(self.qubit_population))\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def quantum_rotation(self, target_idx, best_qubit):\n        theta = np.random.uniform(-np.pi/4, np.pi/4, self.dim)\n        self.qubit_population[target_idx] += theta * (best_qubit - self.qubit_population[target_idx])\n\n    def update_best(self, measured_population, scores):\n        best_idx = np.argmin(scores)\n        if scores[best_idx] < self.best_score:\n            self.best_score = scores[best_idx]\n            self.best_solution = measured_population[best_idx].copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        while self.evaluations < self.budget:\n            measured_population = self.measure()\n            measured_population = np.clip(measured_population, lb, ub)\n            scores = np.array([self.evaluate(ind) for ind in measured_population])\n\n            self.update_best(measured_population, scores)\n\n            for i in range(self.population_size):\n                self.quantum_rotation(i, self.qubit_population[np.argmin(scores)])\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QIEA_Optimizer", "description": "Quantum-inspired Evolutionary Algorithm (QIEA) leverages quantum superposition and interference principles to enhance exploration and exploitation in the search space.", "configspace": "", "generation": 34, "fitness": 0.20373817039739903, "feedback": "The algorithm QIEA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.20373816968452274, 0.20373817024870755, 0.20373817125896676]}, "mutation_prompt": null}
{"id": "5afad7a6-515c-4307-b14f-7c34474e2b24", "solution": "import numpy as np\nimport heapq\n\nclass EHADE_AA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.archive_size = 5  # Size of the adaptive archive\n        self.population = None\n        self.scores = None\n        self.archive = []\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n        self.archive = [(self.scores[i], self.population[i].copy()) for i in range(self.archive_size)]\n        heapq.heapify(self.archive)\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n            if len(self.archive) < self.archive_size:\n                heapq.heappush(self.archive, (trial_score, trial.copy()))\n            else:\n                heapq.heappushpop(self.archive, (trial_score, trial.copy()))\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def incorporate_archive(self):\n        if len(self.archive) == 0:\n            return\n        archive_indices = np.random.choice(len(self.archive), min(3, len(self.archive)), replace=False)\n        for i in archive_indices:\n            candidate = self.archive[i][1]\n            candidate_mutant = self.mutate_from_archive(candidate)\n            candidate = self.crossover(candidate, candidate_mutant)\n            candidate = np.clip(candidate, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(np.random.randint(self.population_size), candidate)\n\n    def mutate_from_archive(self, target):\n        a, b, c = self.population[np.random.choice(self.population_size, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n            self.incorporate_archive()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "EHADE_AA_Optimizer", "description": "Enhanced Hierarchical Adaptive Differential Evolution with Adaptive Archive (EHADE-AA) incorporates an adaptive archive of elite solutions to enhance exploration and exploitation.", "configspace": "", "generation": 35, "fitness": 0.27704725418761306, "feedback": "The algorithm EHADE_AA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a9f8bc5a-0138-41a5-a4a0-e5acb443a084", "metadata": {"aucs": [0.2770125841355865, 0.27701116419023364, 0.2771180142370191]}, "mutation_prompt": null}
{"id": "fe3533ec-b2cb-4092-aede-17e21964ea39", "solution": "import numpy as np\nimport heapq\n\nclass AMC_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5\n        self.CR = 0.9\n        self.archive_size = 5\n        self.num_cohorts = 3  # Number of cohorts for enhanced exploration\n        self.cohorts = [[] for _ in range(self.num_cohorts)]\n        self.population = None\n        self.scores = None\n        self.archive = []\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        full_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        for i, ind in enumerate(full_population):\n            self.cohorts[i % self.num_cohorts].append(ind)\n        self.population = np.array(full_population)\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n        self.archive = [(self.scores[i], self.population[i].copy()) for i in range(self.archive_size)]\n        heapq.heapify(self.archive)\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx, cohort):\n        indices = list(range(len(cohort)))\n        indices.remove(target_idx)\n        a, b, c = np.array(cohort)[np.random.choice(indices, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial, cohort):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            cohort[target_idx % len(cohort)] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n            if len(self.archive) < self.archive_size:\n                heapq.heappush(self.archive, (trial_score, trial.copy()))\n            else:\n                heapq.heappushpop(self.archive, (trial_score, trial.copy()))\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def incorporate_archive(self):\n        if len(self.archive) == 0:\n            return\n        archive_indices = np.random.choice(len(self.archive), min(3, len(self.archive)), replace=False)\n        for i in archive_indices:\n            candidate = self.archive[i][1]\n            candidate_mutant = self.mutate_from_archive(candidate)\n            candidate = self.crossover(candidate, candidate_mutant)\n            candidate = np.clip(candidate, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(np.random.randint(self.population_size), candidate, self.cohorts[np.random.randint(self.num_cohorts)])\n\n    def mutate_from_archive(self, target):\n        a, b, c = self.population[np.random.choice(self.population_size, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def migrate_between_cohorts(self):\n        for i in range(self.num_cohorts):\n            if np.random.rand() < 0.2:  # Migration probability\n                target_cohort_idx = (i + 1) % self.num_cohorts\n                swap_idx = np.random.randint(len(self.cohorts[i]))\n                self.cohorts[target_cohort_idx].append(self.cohorts[i].pop(swap_idx))\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for cohort in self.cohorts:\n                for i in range(len(cohort)):\n                    mutant = self.mutate(i, cohort)\n                    trial = self.crossover(cohort[i], mutant)\n                    trial = np.clip(trial, lb, ub)\n                    self.select(i, trial, cohort)\n                    self.evaluations += 1\n                    if self.evaluations >= self.budget:\n                        break\n\n            self.incorporate_archive()\n            self.migrate_between_cohorts()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "AMC_DE_Optimizer", "description": "The Adaptive Multi-Cohort Differential Evolution (AMC-DE) extends EHADE-AA by using multiple cohorts with dynamic migration and adaptive control parameters to enhance global exploration and local exploitation.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "5afad7a6-515c-4307-b14f-7c34474e2b24", "metadata": {}, "mutation_prompt": null}
{"id": "0d61a9d6-53b4-4555-aaec-07073eff5d13", "solution": "import numpy as np\nimport heapq\n\nclass HDLADE_DA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5\n        self.CR = 0.9\n        self.archive_base_size = 5\n        self.population = None\n        self.scores = None\n        self.archive = []\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n        self.archive = [(self.scores[i], self.population[i].copy()) for i in range(self.archive_base_size)]\n        heapq.heapify(self.archive)\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def dual_mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        if np.random.rand() < 0.5:\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        else:\n            if len(self.archive) > 0:\n                archive_samples = [x[1] for x in self.archive]\n                a, b, c = np.random.choice(archive_samples, 3, replace=True)\n            else:\n                a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n            self.update_archive(trial_score, trial)\n\n    def update_archive(self, trial_score, trial):\n        improved_rate = (self.initial_population_size - self.population_size) / self.initial_population_size\n        archive_size = int(self.archive_base_size + improved_rate * self.archive_base_size * 2)\n        if len(self.archive) < archive_size:\n            heapq.heappush(self.archive, (trial_score, trial.copy()))\n        else:\n            heapq.heappushpop(self.archive, (trial_score, trial.copy()))\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def incorporate_archive(self):\n        if len(self.archive) == 0:\n            return\n        archive_indices = np.random.choice(len(self.archive), min(3, len(self.archive)), replace=False)\n        for i in archive_indices:\n            candidate = self.archive[i][1]\n            candidate_mutant = self.dual_mutate(candidate)\n            candidate = self.crossover(candidate, candidate_mutant)\n            candidate = np.clip(candidate, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(np.random.randint(self.population_size), candidate)\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.dual_mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n            self.incorporate_archive()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "HDLADE_DA_Optimizer", "description": "Hierarchical Dual-Level Adaptive Differential Evolution with Dynamic Archive (HDLADE-DA) enhances exploration and exploitation by introducing dual mutation strategies and dynamically adjusting the archive size based on convergence rate.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "5afad7a6-515c-4307-b14f-7c34474e2b24", "metadata": {}, "mutation_prompt": null}
{"id": "50445cb4-6982-479b-b3ef-3bbb2a23b5d3", "solution": "import numpy as np\nimport heapq\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nclass EHADE_GP_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  \n        self.CR = 0.9  \n        self.archive_size = 5  \n        self.population = None\n        self.scores = None\n        self.archive = []\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.surrogate_model = GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2)), n_restarts_optimizer=10)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n        self.archive = [(self.scores[i], self.population[i].copy()) for i in range(self.archive_size)]\n        heapq.heapify(self.archive)\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n            if len(self.archive) < self.archive_size:\n                heapq.heappush(self.archive, (trial_score, trial.copy()))\n            else:\n                heapq.heappushpop(self.archive, (trial_score, trial.copy()))\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def incorporate_archive(self):\n        if len(self.archive) == 0:\n            return\n        archive_indices = np.random.choice(len(self.archive), min(3, len(self.archive)), replace=False)\n        for i in archive_indices:\n            candidate = self.archive[i][1]\n            candidate_mutant = self.mutate_from_archive(candidate)\n            candidate = self.crossover(candidate, candidate_mutant)\n            candidate = np.clip(candidate, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(np.random.randint(self.population_size), candidate)\n\n    def mutate_from_archive(self, target):\n        a, b, c = self.population[np.random.choice(self.population_size, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def surrogate_optimize(self, lb, ub):\n        X = np.array([x for _, x in self.archive])\n        y = np.array([score for score, _ in self.archive])\n        self.surrogate_model.fit(X, y)\n        candidates = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        predictions = self.surrogate_model.predict(candidates)\n        best_candidate_idx = np.argmin(predictions)\n        return candidates[best_candidate_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                if self.evaluations / self.budget > 0.75:  # Use surrogate model in later stages\n                    trial = self.surrogate_optimize(lb, ub)\n                else:\n                    mutant = self.mutate(i)\n                    trial = self.crossover(self.population[i], mutant)\n                    trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n            self.incorporate_archive()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "EHADE_GP_Optimizer", "description": "EHADE_GP_Optimizer enhances EHADE-AA by integrating Gaussian Process-based surrogate modeling to improve exploitation in later stages.", "configspace": "", "generation": 38, "fitness": 0.27704725418761306, "feedback": "The algorithm EHADE_GP_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "5afad7a6-515c-4307-b14f-7c34474e2b24", "metadata": {"aucs": [0.2770125841355865, 0.27701116419023364, 0.2771180142370191]}, "mutation_prompt": null}
{"id": "6156e71e-1dce-4d46-9c96-dd39c64acd18", "solution": "import numpy as np\nimport heapq\n\nclass QIDE_AA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_population_size = self.population_size\n        self.F_base = 0.5  # Base mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.archive_size = 5  # Size of the adaptive archive\n        self.population = None\n        self.scores = None\n        self.archive = []\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.qbits = np.ones((self.population_size, self.dim)) / np.sqrt(2)\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n        self.archive = [(self.scores[i], self.population[i].copy()) for i in range(self.archive_size)]\n        heapq.heapify(self.archive)\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def quantum_crossover(self, target, mutant):\n        q_mask = np.random.rand(self.dim) < self.qbits[target]\n        return np.where(q_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            self.qbits[target_idx] = np.clip(self.qbits[target_idx] + 0.1 * (trial < self.population[target_idx]), 0, 1)\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n            if len(self.archive) < self.archive_size:\n                heapq.heappush(self.archive, (trial_score, trial.copy()))\n            else:\n                heapq.heappushpop(self.archive, (trial_score, trial.copy()))\n\n    def resize_population(self):\n        self.population_size = max(5, int(self.initial_population_size * (1 - self.evaluations / self.budget)))\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n        self.qbits = self.qbits[:self.population_size]\n\n    def incorporate_archive(self):\n        if len(self.archive) == 0:\n            return\n        archive_indices = np.random.choice(len(self.archive), min(3, len(self.archive)), replace=False)\n        for i in archive_indices:\n            candidate = self.archive[i][1]\n            candidate_mutant = self.mutate_from_archive(candidate)\n            candidate = self.quantum_crossover(candidate, candidate_mutant)\n            candidate = np.clip(candidate, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(np.random.randint(self.population_size), candidate)\n\n    def mutate_from_archive(self, target):\n        a, b, c = self.population[np.random.choice(self.population_size, 3, replace=False)]\n        mutation_factor = self.F_base * (1 - self.evaluations / self.budget)\n        mutant = a + mutation_factor * (b - c)\n        return mutant\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.resize_population()\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.quantum_crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n            self.incorporate_archive()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QIDE_AA_Optimizer", "description": "Quantum-inspired Differential Evolution with Adaptive Archive (QIDE-AA) integrates quantum-inspired superposition and entanglement principles to enhance exploration and exploitation effectively.", "configspace": "", "generation": 39, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('arrays used as indices must be of integer (or boolean) type').", "error": "IndexError('arrays used as indices must be of integer (or boolean) type')", "parent_id": "5afad7a6-515c-4307-b14f-7c34474e2b24", "metadata": {}, "mutation_prompt": null}
{"id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "solution": "import numpy as np\n\nclass QS_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_ADE_Optimizer", "description": "Quantum-Swarm Adaptive Differential Evolution (QS-ADE) leverages quantum-inspired superposition states combined with adaptive parameter tuning to enhance both exploration and convergence efficiency.", "configspace": "", "generation": 40, "fitness": 0.2775408365844081, "feedback": "The algorithm QS_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "5afad7a6-515c-4307-b14f-7c34474e2b24", "metadata": {"aucs": [0.2773693467666951, 0.27740668859106477, 0.2778464743954644]}, "mutation_prompt": null}
{"id": "c160545e-3a9f-455e-ab93-e93028ab65f5", "solution": "import numpy as np\n\nclass HQ_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.chaos_map = np.random.rand()  # Initial chaos variable\n    \n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def logistic_map(self, x):\n        # Simple logistic map for chaos-inducing parameter adaptation\n        return 4 * x * (1 - x)\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max) * self.logistic_map(self.chaos_map)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max) * self.logistic_map(self.chaos_map)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def local_search_enhancement(self):\n        # Local search improvement for best solution refinement\n        local_search_radius = 0.1 * (self.func.bounds.ub - self.func.bounds.lb)\n        for i in range(self.dim):\n            candidate = self.best_solution.copy()\n            candidate[i] += np.random.uniform(-local_search_radius[i], local_search_radius[i])\n            candidate = np.clip(candidate, self.func.bounds.lb, self.func.bounds.ub)\n            candidate_score = self.evaluate(candidate)\n            if candidate_score < self.best_score:\n                self.best_solution = candidate\n                self.best_score = candidate_score\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.local_search_enhancement()\n            self.evaluations += self.population_size\n            self.chaos_map = self.logistic_map(self.chaos_map)  # Update chaos variable\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "HQ_ADE_Optimizer", "description": "Hybrid Quantum-Inspired Adaptive Differential Evolution (HQ-ADE) incorporates chaos theory for dynamic parameter tuning and local search enhancement, aiming to improve convergence reliability and solution precision.", "configspace": "", "generation": 41, "fitness": 0.2684460397949869, "feedback": "The algorithm HQ_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.25852430819160377, 0.27321849431161405, 0.2735953168817429]}, "mutation_prompt": null}
{"id": "4680f661-1641-4924-a8c0-35a7e5a80096", "solution": "import numpy as np\n\nclass QG_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        if self.evaluations >= self.budget:\n            raise Exception(\"Budget exceeded\")\n        self.evaluations += 1\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def genetic_crossover(self):\n        # Perform crossover between the best solution and random individuals\n        half_population = self.population_size // 2\n        for i in range(half_population, self.population_size):\n            partner_idx = np.random.randint(0, half_population)\n            crossover_point = np.random.randint(1, self.dim)\n            offspring = np.concatenate((self.population[partner_idx, :crossover_point],\n                                        self.population[i, crossover_point:]))\n            offspring = np.clip(offspring, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, offspring)\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                if self.evaluations >= self.budget:\n                    break\n            self.genetic_crossover()\n            self.quantum_inspired_mutation()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QG_ADE_Optimizer", "description": "Quantum Genetic Adaptive Differential Evolution (QG-ADE) enhances QS-ADE by integrating genetic algorithm crossover and mutation strategies with quantum-inspired states for superior convergence.", "configspace": "", "generation": 42, "fitness": -Infinity, "feedback": "An exception occurred: Exception('Budget exceeded').", "error": "Exception('Budget exceeded')", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {}, "mutation_prompt": null}
{"id": "ef21ac05-6c75-4eb4-9c75-53ebf8ccbe46", "solution": "import numpy as np\n\nclass QS_ADE_Dual_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def local_search_mutation(self):\n        # Intensification by perturbing the best solution slightly within bounds\n        local_step = (self.func.bounds.ub - self.func.bounds.lb) * 0.05\n        for i in range(self.population_size):\n            local_mutant = self.best_solution + np.random.uniform(-local_step, local_step, self.dim)\n            local_mutant = np.clip(local_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, local_mutant)\n\n    def dual_layer_mutation(self):\n        self.quantum_inspired_mutation()\n        self.local_search_mutation()\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.dual_layer_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_ADE_Dual_Optimizer", "description": "Quantum-Swarm Adaptive Differential Evolution with Dual-Layer Optimization (QS-ADE-Dual) introduces a dual-layer mutation strategy to enhance diversity and convergence by integrating quantum-inspired exploration with local search intensification.", "configspace": "", "generation": 43, "fitness": 0.2637268000223115, "feedback": "The algorithm QS_ADE_Dual_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.258714294499351, 0.27378351314750116, 0.2586825924200824]}, "mutation_prompt": null}
{"id": "043f67ed-4c1a-49c3-919c-e1a6fd9250a2", "solution": "import numpy as np\n\nclass QGA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.evaluations = 0\n        self.mutation_rate = 0.1\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def quantum_superposition(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def crossover(self, parent1, parent2):\n        crossover_point = np.random.randint(1, self.dim)\n        return np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n\n    def mutate(self, individual):\n        mutation_vector = np.random.uniform(-1, 1, self.dim)\n        mutated_individual = individual + self.mutation_rate * mutation_vector\n        return np.clip(mutated_individual, self.func.bounds.lb, self.func.bounds.ub)\n\n    def select_parents(self):\n        indices = np.random.choice(self.population_size, 2, replace=False)\n        return self.population[indices[0]], self.population[indices[1]]\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            new_population = []\n            for _ in range(self.population_size):\n                parent1, parent2 = self.select_parents()\n                child = self.crossover(parent1, parent2)\n                child = self.mutate(child)\n                new_population.append(child)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            \n            self.population = np.array(new_population)\n            self.scores = np.array([self.evaluate(ind) for ind in self.population])\n            self.update_best()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QGA_Optimizer", "description": "Quantum Genetic Algorithm (QGA) integrates quantum-inspired representation with genetic operators to enhance global exploration and population diversity.", "configspace": "", "generation": 44, "fitness": 0.25126002588068924, "feedback": "The algorithm QGA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2502298287752752, 0.24756605590108105, 0.2559841929657114]}, "mutation_prompt": null}
{"id": "65e67c06-12db-4ebc-b3d2-ee2d33f668d0", "solution": "import numpy as np\n\nclass QD_ACDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.0\n        self.F_max = 1.0\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def quantum_crossover(self, target, mutant):\n        # Quantum-inspired probability for crossover\n        quantum_prob = self.compute_quantum_prob(mutant, target)\n        crossover_mask = np.random.rand(self.dim) < quantum_prob\n        return np.where(crossover_mask, mutant, target)\n\n    def compute_quantum_prob(self, mutant, target):\n        # Use the best solution to influence crossover probability\n        dist_to_best = np.linalg.norm(mutant - self.best_solution) + 1e-10\n        dist_to_target = np.linalg.norm(mutant - target) + 1e-10\n        return 0.5 * (1 + np.tanh((dist_to_best - dist_to_target) / self.dim))\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.quantum_crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QD_ACDE_Optimizer", "description": "Quantum-Driven Adaptive Crossover Differential Evolution (QD-ACDE) introduces quantum-informed crossover strategies with adaptive scaling to enhance diversity and convergence.", "configspace": "", "generation": 45, "fitness": 0.2730843546947242, "feedback": "The algorithm QD_ACDE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2679607053976748, 0.2734751783046647, 0.277817180381833]}, "mutation_prompt": null}
{"id": "132d5169-e80f-4782-bb0b-e1a2d6446816", "solution": "import numpy as np\n\nclass QTE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.tunnel_probability = 0.1\n        self.niches = 5\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n    \n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        niche_size = self.population_size // self.niches\n        niche_idx = (target_idx // niche_size) * niche_size\n        indices = list(range(niche_idx, niche_idx + niche_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(0.5, 0.9)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(0.2, 0.8)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_tunnel(self):\n        for i in range(self.population_size):\n            if np.random.rand() < self.tunnel_probability:\n                target = self.population[i]\n                distance = np.linalg.norm(self.best_solution - target)\n                tunnel_shift = np.random.uniform(-1, 1, self.dim) * distance\n                tunnel_solution = target + tunnel_shift\n                tunnel_solution = np.clip(tunnel_solution, self.func.bounds.lb, self.func.bounds.ub)\n                self.select(i, tunnel_solution)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_tunnel()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QTE_Optimizer", "description": "Quantum Tunnel Evolution (QTE) combines quantum tunneling and dynamic niching to escape local minima and maintain diversity in optimizing complex search spaces.", "configspace": "", "generation": 46, "fitness": 0.2741211723963671, "feedback": "The algorithm QTE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2736690213221207, 0.2738962138748984, 0.2747982819920821]}, "mutation_prompt": null}
{"id": "5a7451b9-951f-4ad1-a86e-caed3fec7d60", "solution": "import numpy as np\n\nclass EQS_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def dynamic_population_size(self):\n        if self.evaluations > self.budget // 2:\n            self.population_size = max(10, self.population_size // 2)\n\n    def feedback_based_mutation(self):\n        if self.best_score < np.median(self.scores):\n            self.F_min = 0.5\n            self.F_max = 1.0\n        else:\n            self.F_min = 0.3\n            self.F_max = 0.8\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                self.feedback_based_mutation()\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.dynamic_population_size()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "EQS_ADE_Optimizer", "description": "Enhanced Quantum-Swarm Adaptive Differential Evolution (EQS-ADE) incorporates dynamic population size adjustment and feedback-based mutation to improve convergence and robustness.", "configspace": "", "generation": 47, "fitness": 0.270721863028365, "feedback": "The algorithm EQS_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.26945126016727605, 0.27361643351284226, 0.26909789540497664]}, "mutation_prompt": null}
{"id": "9f323e13-6169-48b9-8179-ff6c20bc9dc6", "solution": "import numpy as np\n\nclass BSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alph = 0.8\n        self.beta = 1.2\n        self.mutualism_factor = 0.5\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def mutualism(self, ind_a, ind_b):\n        mutual_vector = (ind_a + ind_b) / 2\n        mutual_a = ind_a + np.random.uniform() * (self.best_solution - mutual_vector) * self.mutualism_factor\n        mutual_b = ind_b + np.random.uniform() * (self.best_solution - mutual_vector) * self.mutualism_factor\n        return mutual_a, mutual_b\n\n    def commensalism(self, ind_a):\n        random_neighbor = self.population[np.random.randint(self.population_size)]\n        commensal = ind_a + np.random.uniform(-1, 1) * (self.best_solution - random_neighbor)\n        return commensal\n\n    def parasitism(self, ind_a, lb, ub):\n        parasite = ind_a.copy()\n        idx = np.random.randint(self.dim)\n        parasite[idx] = np.random.uniform(lb[idx], ub[idx])\n        return parasite\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                partner_idx = np.random.randint(self.population_size)\n                if i != partner_idx:\n                    ind_a = self.population[i]\n                    ind_b = self.population[partner_idx]\n\n                    mutual_a, mutual_b = self.mutualism(ind_a, ind_b)\n                    commensal_a = self.commensalism(ind_a)\n                    parasite_b = self.parasitism(ind_b, lb, ub)\n\n                    candidates = [mutual_a, mutual_b, commensal_a, parasite_b]\n                    candidates_scores = [self.evaluate(np.clip(c, lb, ub)) for c in candidates]\n\n                    if min(candidates_scores) < self.scores[i]:\n                        best_candidate_idx = np.argmin(candidates_scores)\n                        self.population[i] = np.clip(candidates[best_candidate_idx], lb, ub)\n                        self.scores[i] = candidates_scores[best_candidate_idx]\n\n                    self.evaluations += len(candidates)\n                    self.update_best()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "BSO_Optimizer", "description": "Bio-inspired Symbiotic Optimization (BSO) utilizes mutualistic interactions and adaptive learning strategies to dynamically enhance exploration and exploitation in high-dimensional search spaces.", "configspace": "", "generation": 48, "fitness": 0.27648347365761866, "feedback": "The algorithm BSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2771080939268875, 0.2761800574006009, 0.2761622696453676]}, "mutation_prompt": null}
{"id": "e1dbcc65-4725-4445-90b3-b9a19d93b9c0", "solution": "import numpy as np\n\nclass CGIO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def generate_wave_interference(self, a, b, c):\n        wave1 = np.sin(a)  # Coherent wave from solution a\n        wave2 = np.cos(b)  # Coherent wave from solution b\n        interference = wave1 + wave2\n        interference_mutant = c + interference * (b - a)\n        return interference_mutant\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = self.generate_wave_interference(a, b, c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = 0.8  # Fixed crossover rate\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def coherence_guided_mutation(self):\n        for i in range(self.population_size):\n            indices = np.random.choice(range(self.population_size), 2, replace=False)\n            a, b = self.population[indices]\n            coherence_mutant = self.best_solution + np.sin(a - b) * (self.best_solution - self.population[i])\n            coherence_mutant = np.clip(coherence_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, coherence_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.coherence_guided_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "CGIO_Optimizer", "description": "Coherence-Guided Interference Optimization (CGIO) utilizes coherent wave interference patterns to guide population-based search, enhancing exploration and convergence across diverse problem landscapes.", "configspace": "", "generation": 49, "fitness": 0.27435892870425216, "feedback": "The algorithm CGIO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.27331556544781666, 0.27699738349737724, 0.2727638371675626]}, "mutation_prompt": null}
{"id": "9ae4b91d-89f8-4c15-a737-e6e852853340", "solution": "import numpy as np\n\nclass QE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.c1 = 1.49618  # Cognitive coefficient\n        self.c2 = 1.49618  # Social coefficient\n        self.w_max = 0.9   # Max inertia weight\n        self.w_min = 0.4   # Min inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best = None\n        self.personal_best_scores = None\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_swarm(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(ind) for ind in self.particles])\n        self.update_global_best()\n\n    def evaluate(self, particle):\n        return self.func(particle)\n\n    def update_global_best(self):\n        best_idx = np.argmin(self.personal_best_scores)\n        if self.personal_best_scores[best_idx] < self.global_best_score:\n            self.global_best = self.personal_best[best_idx].copy()\n            self.global_best_score = self.personal_best_scores[best_idx]\n\n    def quantum_enhancement(self):\n        quantum_positions = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        for i in range(self.swarm_size):\n            quantum_superposition = np.random.rand(self.dim)\n            self.particles[i] = self.global_best + quantum_superposition * (self.particles[i] - self.global_best)\n            self.particles[i] = np.clip(self.particles[i], self.func.bounds.lb, self.func.bounds.ub)\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (self.evaluations / self.budget))\n\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_component = self.c1 * r1 * (self.personal_best[i] - self.particles[i])\n                social_component = self.c2 * r2 * (self.global_best - self.particles[i])\n\n                self.velocities[i] = w * self.velocities[i] + cognitive_component + social_component\n                self.particles[i] = self.particles[i] + self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n                current_score = self.evaluate(self.particles[i])\n                self.evaluations += 1\n\n                if current_score < self.personal_best_scores[i]:\n                    self.personal_best[i] = self.particles[i].copy()\n                    self.personal_best_scores[i] = current_score\n\n            self.update_global_best()\n\n            if self.evaluations + self.swarm_size < self.budget:\n                self.quantum_enhancement()\n                self.evaluations += self.swarm_size\n\n        return {'solution': self.global_best, 'fitness': self.global_best_score}", "name": "QE_PSO_Optimizer", "description": "Quantum-Enhanced Particle Swarm Optimization (QE-PSO) integrates quantum-inspired search with dynamic swarm behavior to balance exploration and exploitation for global optimization.", "configspace": "", "generation": 50, "fitness": 0.27579764909793475, "feedback": "The algorithm QE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2772903046019354, 0.2733461155575815, 0.27675652713428733]}, "mutation_prompt": null}
{"id": "a9aaecf5-df6a-46e1-9d59-991048f88675", "solution": "import numpy as np\n\nclass QCPSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Quantum cloud size\n        self.population = None\n        self.velocities = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.pbest = None\n        self.pbest_scores = None\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.pbest = self.population.copy()\n        self.pbest_scores = self.scores.copy()\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_best(self):\n        for i in range(self.population_size):\n            if self.scores[i] < self.pbest_scores[i]:\n                self.pbest[i] = self.population[i].copy()\n                self.pbest_scores[i] = self.scores[i]\n        best_idx = np.argmin(self.pbest_scores)\n        if self.pbest_scores[best_idx] < self.best_score:\n            self.best_solution = self.pbest[best_idx].copy()\n            self.best_score = self.pbest_scores[best_idx]\n\n    def quantum_position_update(self, lb, ub):\n        for i in range(self.population_size):\n            # Cooperative term\n            gbest = self.best_solution\n            p = self.pbest[i]\n            r1, r2 = np.random.rand(), np.random.rand()\n            mbest = np.mean(self.pbest, axis=0)\n            u = r1 * p + r2 * gbest + (1 - r1 - r2) * mbest\n            phi = np.random.uniform(-1, 1, self.dim)\n            self.population[i] = u + self.alpha * phi * np.abs(self.population[i] - u)\n            self.population[i] = np.clip(self.population[i], lb, ub)\n            self.scores[i] = self.evaluate(self.population[i])\n            self.evaluations += 1\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.quantum_position_update(lb, ub)\n            self.update_best()\n            if self.evaluations >= self.budget:\n                break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QCPSO_Optimizer", "description": "Quantum-Cooperative Particle Swarm Optimization (QCPSO) combines quantum-inspired position update rules and cooperative learning strategies to enhance exploration and exploitation in complex search spaces.", "configspace": "", "generation": 51, "fitness": 0.2726702604949444, "feedback": "The algorithm QCPSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.275886307048789, 0.27565187220440546, 0.2664726022316388]}, "mutation_prompt": null}
{"id": "a4281ccc-6117-46c5-ab72-6e1e19af9c4c", "solution": "import numpy as np\n\nclass QC_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_cooperative_mutation(self):\n        global_mean = np.mean(self.population, axis=0)\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            cooperative_vector = (self.population[i] + global_mean) / 2\n            quantum_mutant = cooperative_vector + quantum_superposition * np.abs(cooperative_vector - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_cooperative_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QC_ADE_Optimizer", "description": "Quantum-Cooperative Adaptive Differential Evolution (QC-ADE) combines quantum-inspired position updates with cooperative learning to enhance diversity and convergence in optimizing photonic structures.", "configspace": "", "generation": 52, "fitness": 0.276997417869774, "feedback": "The algorithm QC_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.27661025968272246, 0.27685233908173845, 0.27752965484486114]}, "mutation_prompt": null}
{"id": "e23f7a04-9b54-4745-800f-faa2148e2c6c", "solution": "import numpy as np\n\nclass AQFPA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.p = 0.8  # switch probability between global and local pollination\n        self.beta_min = 0.5\n        self.beta_max = 1.5\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def levy_flight(self, beta):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n    def global_pollination(self, flower):\n        beta = np.random.uniform(self.beta_min, self.beta_max)\n        step = self.levy_flight(beta)\n        return flower + step * (self.best_solution - flower)\n\n    def local_pollination(self, flower, partner):\n        epsilon = np.random.uniform(0, 1, self.dim)\n        return flower + epsilon * (partner - flower)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_superposition(self, flower):\n        quantum_superposition = np.random.uniform(-1, 1, self.dim)\n        quantum_flower = self.best_solution + quantum_superposition * np.abs(flower - self.best_solution)\n        return np.clip(quantum_flower, self.func.bounds.lb, self.func.bounds.ub)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                flower = self.population[i]\n                if np.random.rand() < self.p:\n                    trial = self.global_pollination(flower)\n                else:\n                    partner_idx = np.random.randint(0, self.population_size)\n                    while partner_idx == i:\n                        partner_idx = np.random.randint(0, self.population_size)\n                    trial = self.local_pollination(flower, self.population[partner_idx])\n\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n            for i in range(self.population_size):\n                quantum_flower = self.quantum_superposition(self.population[i])\n                self.select(i, quantum_flower)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "AQFPA_Optimizer", "description": "The Adaptive Quantum Flower Pollination Algorithm (AQFPA) integrates the quantum-inspired superposition concept with flower pollination dynamics and adaptive parameter control for enhanced exploration and convergence capabilities.", "configspace": "", "generation": 53, "fitness": 0.2685876701175774, "feedback": "The algorithm AQFPA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2584051839143584, 0.27364105811417605, 0.2737167683241978]}, "mutation_prompt": null}
{"id": "300351bd-ab7c-48e4-85fd-f9b88aded09b", "solution": "import numpy as np\n\nclass QE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.inertia_weight = 0.5\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_global_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_global_best(self):\n        best_idx = np.argmin(self.personal_best_scores)\n        if self.personal_best_scores[best_idx] < self.global_best_score:\n            self.global_best_score = self.personal_best_scores[best_idx]\n            self.global_best_position = self.personal_best_positions[best_idx].copy()\n\n    def quantum_entanglement(self):\n        for i in range(self.population_size):\n            entangled_state = np.mean(self.personal_best_positions, axis=0)\n            self.velocities[i] += np.random.uniform(-1, 1, self.dim) * (entangled_state - self.population[i])\n            self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n\n    def update_particle(self, i):\n        inertia = self.inertia_weight * self.velocities[i]\n        cognitive = self.cognitive_coefficient * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i])\n        social = self.social_coefficient * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n        self.velocities[i] = inertia + cognitive + social\n        self.population[i] += self.velocities[i]\n        self.population[i] = np.clip(self.population[i], self.func.bounds.lb, self.func.bounds.ub)\n\n    def update_personal_best(self, i):\n        score = self.evaluate(self.population[i])\n        if score < self.personal_best_scores[i]:\n            self.personal_best_scores[i] = score\n            self.personal_best_positions[i] = self.population[i].copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                self.update_particle(i)\n                self.update_personal_best(i)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_entanglement()\n            self.update_global_best()\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "QE_PSO_Optimizer", "description": "Quantum Entangled Particle Swarm Optimization (QE-PSO) integrates quantum entanglement principles into a particle swarm framework to enhance diversity and convergence in high-dimensional spaces.", "configspace": "", "generation": 54, "fitness": 0.275421294651108, "feedback": "The algorithm QE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.277595763362098, 0.2734358099290023, 0.27523231066222364]}, "mutation_prompt": null}
{"id": "58ea85e9-4d58-4ed3-acd1-98e9f6d7de7c", "solution": "import numpy as np\n\nclass EQS_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return self.func(solution)\n\n    def mutate(self, target_idx, adaptive_factor):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max) * adaptive_factor\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant, adaptive_cr):\n        CR = np.random.uniform(self.CR_min, self.CR_max) * adaptive_cr\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self, adaptive_factor):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution) * adaptive_factor\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def dynamic_population_resizing(self, iteration):\n        new_population_size = max(10, self.population_size - int(iteration / 10))\n        return new_population_size\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        iteration = 0\n        while self.evaluations < self.budget:\n            adaptive_factor = 1 - (iteration / (self.budget / self.population_size))\n            adaptive_cr = np.abs(np.sin(iteration / 100))\n            new_population_size = self.dynamic_population_resizing(iteration)\n\n            for i in range(new_population_size):\n                mutant = self.mutate(i, adaptive_factor)\n                trial = self.crossover(self.population[i], mutant, adaptive_cr)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                if self.evaluations >= self.budget:\n                    break\n\n            self.quantum_inspired_mutation(adaptive_factor)\n            iteration += 1\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "EQS_ADE_Optimizer", "description": "Enhanced Quantum-Swarm Adaptive Differential Evolution (EQS-ADE) integrates dynamic population resizing and adaptive learning rates to improve convergence speed and solution accuracy.", "configspace": "", "generation": 55, "fitness": 0.2734970747210917, "feedback": "The algorithm EQS_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.27769038799235424, 0.27344746781582285, 0.26935336835509804]}, "mutation_prompt": null}
{"id": "58cec56b-d553-4b92-8b6e-c52bd3efc98d", "solution": "import numpy as np\n\nclass QS_EDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.elite_archive_size = 5\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.elite_archive = []\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_elite_archive()\n\n    def evaluate(self, solution):\n        value = self.func(solution)\n        self.evaluations += 1\n        return value\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            self.update_elite_archive()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            elite = self.elite_archive[np.random.randint(len(self.elite_archive))]\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = elite + quantum_superposition * np.abs(self.population[i] - elite)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_elite_archive(self):\n        combined = list(zip(self.scores, self.population))\n        combined.sort(key=lambda x: x[0])\n        self.elite_archive = [ind for _, ind in combined[:self.elite_archive_size]]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n        \n        best_idx = np.argmin(self.scores)\n        return {'solution': self.population[best_idx], 'fitness': self.scores[best_idx]}", "name": "QS_EDE_Optimizer", "description": "Quantum-Swarm Enhanced Differential Evolution (QS-EDE) introduces a quantum-inspired elite archive strategy to preserve and utilize high-quality solutions for adaptive parameter tuning and accelerated convergence.", "configspace": "", "generation": 56, "fitness": 0.26976822399682515, "feedback": "The algorithm QS_EDE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2584483029515924, 0.2732818617285513, 0.27757450731033173]}, "mutation_prompt": null}
{"id": "11b9a2f5-2e67-47a8-8c50-13b235ad7930", "solution": "import numpy as np\n\nclass QIFA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Attraction parameter\n        self.beta_min = 0.2\n        self.gamma = 1.0  # Light absorption coefficient\n        self.q_factor = 0.1  # Quantum factor for superposition\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def move_fireflies(self, lb, ub):\n        for i in range(self.population_size):\n            for j in range(self.population_size):\n                if self.scores[j] < self.scores[i]:\n                    dist = np.linalg.norm(self.population[i] - self.population[j])\n                    beta = (1 - self.beta_min) * np.exp(-self.gamma * dist ** 2) + self.beta_min\n                    random_component = self.alpha * (np.random.rand(self.dim) - 0.5)\n                    attraction = beta * (self.population[j] - self.population[i])\n                    self.population[i] += attraction + random_component\n                    self.population[i] = np.clip(self.population[i], lb, ub)\n                    self.scores[i] = self.evaluate(self.population[i])\n                    if self.scores[i] < self.best_score:\n                        self.best_score = self.scores[i]\n                        self.best_solution = self.population[i].copy()\n                    self.evaluations += 1\n                    if self.evaluations >= self.budget:\n                        return\n\n    def quantum_superposition(self, lb, ub):\n        quantum_positions = self.best_solution + self.q_factor * (2 * np.random.rand(self.population_size, self.dim) - 1)\n        quantum_positions = np.clip(quantum_positions, lb, ub)\n        for i in range(self.population_size):\n            quantum_score = self.evaluate(quantum_positions[i])\n            if quantum_score < self.scores[i]:\n                self.population[i] = quantum_positions[i]\n                self.scores[i] = quantum_score\n                if quantum_score < self.best_score:\n                    self.best_score = quantum_score\n                    self.best_solution = quantum_positions[i].copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.move_fireflies(lb, ub)\n            if self.evaluations < self.budget:\n                self.quantum_superposition(lb, ub)\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QIFA_Optimizer", "description": "Quantum-Inspired Firefly Algorithm (QIFA) synergizes quantum superposition with firefly movement strategies to dynamically balance exploration and exploitation for superior convergence.", "configspace": "", "generation": 57, "fitness": 0.2772616234446413, "feedback": "The algorithm QIFA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.27754615742507904, 0.27742924842209127, 0.2768094644867535]}, "mutation_prompt": null}
{"id": "735cc613-f85c-4cf5-947f-2d65bf44b882", "solution": "import numpy as np\n\nclass QE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.population = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_scores = np.full(self.population_size, float('inf'))\n        for i in range(self.population_size):\n            score = self.evaluate(self.population[i])\n            self.update_personal_best(i, score)\n\n    def evaluate(self, solution):\n        return self.func(solution)\n    \n    def update_personal_best(self, idx, score):\n        if score < self.personal_best_scores[idx]:\n            self.personal_best_scores[idx] = score\n            self.personal_best_positions[idx] = self.population[idx].copy()\n            if score < self.global_best_score:\n                self.global_best_score = score\n                self.global_best_position = self.population[idx].copy()\n\n    def update_velocities_and_positions(self, lb, ub):\n        w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)\n        for i in range(self.population_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.population[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.population[i])\n            self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity\n            self.population[i] = self.population[i] + self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n    \n    def quantum_boundary_exploration(self, lb, ub):\n        quantum_factor = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            candidate = self.global_best_position + quantum_factor[i] * (self.population[i] - self.global_best_position)\n            candidate = np.clip(candidate, lb, ub)\n            score = self.evaluate(candidate)\n            self.evaluations += 1\n            self.update_personal_best(i, score)\n            if self.evaluations >= self.budget:\n                break\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.update_velocities_and_positions(lb, ub)\n            for i in range(self.population_size):\n                score = self.evaluate(self.population[i])\n                self.evaluations += 1\n                self.update_personal_best(i, score)\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_boundary_exploration(lb, ub)\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "QE_PSO_Optimizer", "description": "Quantum-Enhanced Particle Swarm Optimization (QE-PSO) integrates quantum-inspired dynamic boundaries and local search enhancements to improve convergence and exploration in complex search spaces.", "configspace": "", "generation": 58, "fitness": 0.25058178928472014, "feedback": "The algorithm QE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.24483291124224593, 0.24825252050558533, 0.2586599361063292]}, "mutation_prompt": null}
{"id": "111ee488-42a3-4f2e-ad29-456fa9f2f974", "solution": "import numpy as np\n\nclass QS_ADE_DP_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.convergence_metric = []\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def dynamic_population_resizing(self):\n        current_best = self.best_score\n        self.convergence_metric.append(current_best)\n        if len(self.convergence_metric) > 10:  # Evaluate convergence over last 10 generations\n            recent_scores = self.convergence_metric[-10:]\n            if np.std(recent_scores) < 1e-5:  # If converging too slowly, increase diversity\n                additional_individuals = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, (5, self.dim))\n                self.population = np.vstack((self.population, additional_individuals))\n                additional_scores = np.array([self.evaluate(ind) for ind in additional_individuals])\n                self.scores = np.hstack((self.scores, additional_scores))\n                self.population_size += 5\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n            self.dynamic_population_resizing()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_ADE_DP_Optimizer", "description": "Quantum-Swarm Adaptive Differential Evolution with Dynamic Population (QS-ADE-DP) introduces dynamic population resizing based on convergence metrics to maintain diversity and accelerate convergence.", "configspace": "", "generation": 59, "fitness": 0.27754083232169374, "feedback": "The algorithm QS_ADE_DP_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2773693381314952, 0.2774066864401745, 0.2778464723934114]}, "mutation_prompt": null}
{"id": "ad2bda71-bd4a-4c09-b704-f0888367037e", "solution": "import numpy as np\n\nclass BI_MAS_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.evaporation_rate = 0.1\n        self.pheromone_matrix = None\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n        self.pheromone_matrix = np.full((self.population_size, self.dim), 1.0)\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_pheromone(self, idx, increment):\n        self.pheromone_matrix[idx] *= (1 - self.evaporation_rate)\n        self.pheromone_matrix[idx] += increment\n\n    def mutate(self, idx):\n        neighbors = np.random.choice(range(self.population_size), 2, replace=False)\n        a, b = self.population[neighbors]\n        mutant = self.population[idx] + np.random.rand() * (a - b)\n        return mutant\n\n    def crossover(self, target, mutant):\n        pheromones = self.pheromone_matrix[target]\n        prob = pheromones / pheromones.sum()\n        crossover_mask = np.random.rand(self.dim) < prob\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n            self.update_pheromone(target_idx, 1.0 / (1.0 + trial_score))\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "BI_MAS_Optimizer", "description": "Bio-Inspired Multi-Agent System (BI-MAS) utilizing agent cooperation and dynamic pheromone modeling to efficiently navigate complex search spaces.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('arrays used as indices must be of integer (or boolean) type').", "error": "IndexError('arrays used as indices must be of integer (or boolean) type')", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {}, "mutation_prompt": null}
{"id": "9ae311e9-b932-481e-aa37-cdf84c6affc3", "solution": "import numpy as np\n\nclass AQ_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.3\n        self.F_max = 0.8\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        diversity_factor = self.calculate_diversity_factor()\n        F = self.F_min + diversity_factor * (self.F_max - self.F_min)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def calculate_diversity_factor(self):\n        centroid = np.mean(self.population, axis=0)\n        diversity = np.mean(np.linalg.norm(self.population - centroid, axis=1))\n        return np.clip(diversity / np.sqrt(self.dim), 0, 1)\n\n    def crossover(self, target, mutant):\n        progress_factor = self.calculate_progress_factor()\n        CR = self.CR_min + progress_factor * (self.CR_max - self.CR_min)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def calculate_progress_factor(self):\n        return np.clip(1 - (self.evaluations / self.budget), 0, 1)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "AQ_DE_Optimizer", "description": "Adaptive Quantum-Swarm Differential Evolution (AQ-DE) enhances quantum-inspired exploration by dynamically adjusting mutation and crossover parameters based on population diversity and convergence rate.", "configspace": "", "generation": 61, "fitness": 0.276216039315414, "feedback": "The algorithm AQ_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2777486006231079, 0.27737162034939333, 0.2735278969737407]}, "mutation_prompt": null}
{"id": "a90396fa-7f17-4c8a-94b9-9936c6069d76", "solution": "import numpy as np\n\nclass QE_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.population_size = self.initial_population_size\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_perturbation(self):\n        for i in range(self.population_size):\n            quantum_shift = np.random.uniform(-0.1, 0.1, self.dim)\n            perturbed_solution = self.population[i] + quantum_shift\n            perturbed_solution = np.clip(perturbed_solution, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, perturbed_solution)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def dynamic_population_resizing(self):\n        if self.evaluations > self.budget / 2 and self.population_size > self.initial_population_size / 2:\n            self.population_size = max(self.initial_population_size // 2, int(self.population_size * 0.9))\n            self.population = self.population[:self.population_size]\n            self.scores = self.scores[:self.population_size]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_perturbation()\n            self.dynamic_population_resizing()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QE_ADE_Optimizer", "description": "Quantum-Enhanced Adaptive Differential Evolution (QE-ADE) uses quantum-inspired perturbations with dynamic population resizing to boost diversity and convergence.", "configspace": "", "generation": 62, "fitness": 0.27204767441491456, "feedback": "The algorithm QE_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2725664208968894, 0.27049247583769886, 0.27308412651015546]}, "mutation_prompt": null}
{"id": "94fb8080-5a06-42b8-a0f2-bc1d1a79a7d1", "solution": "import numpy as np\n\nclass QS_ADE_DQI_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def dynamic_quantum_interference(self):\n        interference_pattern = np.sin(np.linspace(0, np.pi, self.dim))\n        for i in range(self.population_size):\n            interference = interference_pattern * (np.random.rand(self.dim) - 0.5)\n            quantum_interference_mutant = self.best_solution + interference * np.abs(self.population[i] - self.best_solution)\n            quantum_interference_mutant = np.clip(quantum_interference_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_interference_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.dynamic_quantum_interference()\n            self.evaluations += 2 * self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_ADE_DQI_Optimizer", "description": "Quantum-Swarm Adaptive Differential Evolution with Dynamic Quantum Interference (QS-ADE-DQI) integrates a dynamic quantum interference mechanism to enhance search diversity and convergence by simulating quantum interference patterns.", "configspace": "", "generation": 63, "fitness": 0.2641140573444142, "feedback": "The algorithm QS_ADE_DQI_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.27260593115121434, 0.2709121922106632, 0.24882404867136498]}, "mutation_prompt": null}
{"id": "1e59efb0-55d6-463e-833b-2dc27bee2b57", "solution": "import numpy as np\n\nclass QS_ADE_DQI_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def dynamic_quantum_inspiration(self):\n        patterns = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            dynamic_pattern = np.power(patterns[i], 2) * np.sign(patterns[i])  # Dynamic quantum interference pattern\n            quantum_mutant = self.best_solution + dynamic_pattern * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n \n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.dynamic_quantum_inspiration()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_ADE_DQI_Optimizer", "description": "Quantum-Swarm Adaptive Differential Evolution with Dynamic Quantum Interference (QS-ADE-DQI) dynamically adjusts quantum interference patterns to enhance convergence and diversify exploration.", "configspace": "", "generation": 64, "fitness": 0.25660572768690293, "feedback": "The algorithm QS_ADE_DQI_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2550976866879381, 0.2636765347746205, 0.2510429615981502]}, "mutation_prompt": null}
{"id": "b560c873-12e3-4ca6-815c-00980d048cff", "solution": "import numpy as np\n\nclass QS_ADE_ED_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.entropy_threshold = 0.1  # Threshold for triggering the entropy-based diversification\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def compute_entropy(self):\n        normalized_pop = (self.population - self.func.bounds.lb) / (self.func.bounds.ub - self.func.bounds.lb)\n        entropy = -np.sum(normalized_pop * np.log(normalized_pop + 1e-10), axis=0) / np.log(self.population_size)\n        return np.mean(entropy)\n\n    def entropy_based_diversification(self, lb, ub):\n        entropy = self.compute_entropy()\n        if entropy < self.entropy_threshold:\n            diversified_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            for i in range(self.population_size):\n                trial_score = self.evaluate(diversified_population[i])\n                if trial_score < self.scores[i]:\n                    self.population[i] = diversified_population[i]\n                    self.scores[i] = trial_score\n            self.update_best()\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.entropy_based_diversification(lb, ub)\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_ADE_ED_Optimizer", "description": "Quantum-Swarm Adaptive Differential Evolution with Entropy-based Population Diversification (QS-ADE-ED) integrates entropy calculations to dynamically diversify the population, preventing premature convergence and enhancing exploration in complex landscapes.", "configspace": "", "generation": 65, "fitness": 0.2775408365844081, "feedback": "The algorithm QS_ADE_ED_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2773693467666951, 0.27740668859106477, 0.2778464743954644]}, "mutation_prompt": null}
{"id": "490f4b3e-8b50-4a4d-a1e9-95059dac42e8", "solution": "import numpy as np\n\nclass QAPSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.95  # Temperature decay factor\n        self.temperature = 1.0  # Initial temperature\n        self.velocity = np.zeros((self.population_size, self.dim))\n        self.personal_best = None\n        self.personal_best_scores = None\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.personal_best = self.population.copy()\n        self.personal_best_scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_global_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_global_best(self):\n        best_idx = np.argmin(self.personal_best_scores)\n        if self.personal_best_scores[best_idx] < self.global_best_score:\n            self.global_best_score = self.personal_best_scores[best_idx]\n            self.global_best = self.personal_best[best_idx].copy()\n\n    def quantum_annealing_update(self, lb, ub):\n        for i in range(self.population_size):\n            quantum_move = np.random.uniform(-1, 1, self.dim) * self.temperature\n            new_position = self.personal_best[i] + quantum_move\n            new_position = np.clip(new_position, lb, ub)\n            new_score = self.evaluate(new_position)\n            if new_score < self.personal_best_scores[i]:\n                self.personal_best[i] = new_position\n                self.personal_best_scores[i] = new_score\n            self.velocity[i] = self.alpha * self.velocity[i] + new_position - self.population[i]\n            self.population[i] += self.velocity[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.quantum_annealing_update(lb, ub)\n            self.temperature *= self.alpha  # Cool down the system\n            self.update_global_best()\n            self.evaluations += self.population_size\n\n            if self.evaluations >= self.budget:\n                break\n\n        return {'solution': self.global_best, 'fitness': self.global_best_score}", "name": "QAPSO_Optimizer", "description": "Quantum Annealing Particle Swarm Optimization (QAPSO) combines quantum superposition concepts with temperature-guided particle movements to enhance global search capability and convergence.", "configspace": "", "generation": 66, "fitness": 0.2378367292116971, "feedback": "The algorithm QAPSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.23711096247058394, 0.2416912094370417, 0.2347080157274657]}, "mutation_prompt": null}
{"id": "375b785a-8d06-4a59-b4c6-f69a377d8d75", "solution": "import numpy as np\n\nclass QE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.quantum_coeff = 0.5\n\n    def initialize_population(self, lb, ub):\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(p) for p in self.particles])\n        min_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[min_idx].copy()\n        self.global_best_score = self.personal_best_scores[min_idx]\n\n    def evaluate(self, particle):\n        score = self.func(particle)\n        self.evaluations += 1\n        return score\n\n    def update_particles(self, lb, ub):\n        for i in range(self.population_size):\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            cognitive_velocity = self.cognitive_coeff * r1 * (self.personal_best_positions[i] - self.particles[i])\n            social_velocity = self.social_coeff * r2 * (self.global_best_position - self.particles[i])\n            self.velocities[i] = (self.inertia_weight * self.velocities[i] +\n                                  cognitive_velocity + social_velocity)\n            self.particles[i] += self.velocities[i]\n            self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            current_score = self.evaluate(self.particles[i])\n            if current_score < self.personal_best_scores[i]:\n                self.personal_best_positions[i] = self.particles[i].copy()\n                self.personal_best_scores[i] = current_score\n                if current_score < self.global_best_score:\n                    self.global_best_position = self.particles[i].copy()\n                    self.global_best_score = current_score\n\n    def quantum_entanglement_adjustment(self, lb, ub):\n        entangled_positions = np.array([\n            self.global_best_position + self.quantum_coeff * np.random.rand(self.dim) *\n            (self.personal_best_positions[i] - self.global_best_position)\n            for i in range(self.population_size)\n        ])\n        entangled_positions = np.clip(entangled_positions, lb, ub)\n        for i in range(self.population_size):\n            score = self.evaluate(entangled_positions[i])\n            if score < self.personal_best_scores[i]:\n                self.personal_best_positions[i] = entangled_positions[i].copy()\n                self.personal_best_scores[i] = score\n                if score < self.global_best_score:\n                    self.global_best_position = entangled_positions[i].copy()\n                    self.global_best_score = score\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.update_particles(lb, ub)\n            self.quantum_entanglement_adjustment(lb, ub)\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "QE_PSO_Optimizer", "description": "Quantum-Entangled Particle Swarm Optimization (QE-PSO) integrates quantum entanglement principles and adaptive particle dynamics to balance exploration and exploitation in high-dimensional optimization.", "configspace": "", "generation": 67, "fitness": 0.27638775807941734, "feedback": "The algorithm QE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2780196356441331, 0.27363356090486746, 0.2775100776892514]}, "mutation_prompt": null}
{"id": "d63f87b8-e140-4d5d-885f-d8733477280d", "solution": "import numpy as np\n\nclass QG_ADES_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def dynamic_population_scaling(self):\n        if self.evaluations > self.budget * 0.5:  # start scaling after half of the budget\n            self.population_size = max(10, self.population_size - 1)  # reduce population size to focus exploitation\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.dynamic_population_scaling()\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QG_ADES_Optimizer", "description": "Quantum-Guided Adaptive Differential Evolution with Dynamic Population Scaling (QG-ADES) utilizes quantum-inspired diversity and dynamically adjusts population size to enhance exploration and exploitation balance, improving convergence rates.", "configspace": "", "generation": 68, "fitness": 0.2775408365844081, "feedback": "The algorithm QG_ADES_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2773693467666951, 0.27740668859106477, 0.2778464743954644]}, "mutation_prompt": null}
{"id": "d0ef02ad-4563-4160-94dc-2fcd5fe4cded", "solution": "import numpy as np\n\nclass QS_EDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            elitist_vector = np.random.uniform(0, 1, self.dim) * (self.best_solution - self.population[i])\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(elitist_vector)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_EDE_Optimizer", "description": "Quantum-Swarm Enhanced Differential Evolution (QS-EDE) integrates quantum-inspired superposition with adaptive differential scaling and a novel elitist-guided mutation to improve convergence and diversity.", "configspace": "", "generation": 69, "fitness": 0.27512653197512743, "feedback": "The algorithm QS_EDE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2778569465602414, 0.273828512052245, 0.2736941373128958]}, "mutation_prompt": null}
{"id": "a4045f5a-e158-42fe-9f91-0f83c3fee665", "solution": "import numpy as np\n\nclass QS_ADE_Dynamic_Pop_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_population_size = 30\n        self.population_size = self.init_population_size\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.diversity_threshold = 0.1  # threshold for diversity-based population resizing\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def diversity(self):\n        std_dev = np.std(self.population, axis=0)\n        return np.mean(std_dev)\n\n    def adjust_population_size(self):\n        diversity = self.diversity()\n        if diversity < self.diversity_threshold:\n            self.population_size = max(10, self.population_size // 2)\n        else:\n            self.population_size = min(self.init_population_size, self.population_size + 5)\n        self.population = self.population[:self.population_size]\n        self.scores = self.scores[:self.population_size]\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.adjust_population_size()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_ADE_Dynamic_Pop_Optimizer", "description": "Quantum-Swarm Adaptive Differential Evolution with Dynamic Population (QS-ADE-DP) integrates adaptive population resizing based on fitness diversity to balance exploration and exploitation through the optimization process.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 14 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 14 is out of bounds for axis 0 with size 10')", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {}, "mutation_prompt": null}
{"id": "2b6013d4-a9e3-4688-9cea-54d14cfd1657", "solution": "import numpy as np\n\nclass QGHS_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.harmony_memory_size = 30\n        self.harmony_consideration_rate = 0.9\n        self.pitch_adjustment_rate = 0.3\n        self.mutation_rate = 0.1\n        self.population = None\n        self.harmony_memory = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.harmony_memory = np.copy(self.population)\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def quantum_genetic_encoding(self):\n        return np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n    def harmony_search(self, lb, ub):\n        for i in range(self.population_size):\n            if np.random.rand() < self.harmony_consideration_rate:\n                harmony_index = np.random.randint(self.harmony_memory_size)\n                harmony_vector = self.harmony_memory[harmony_index]\n                pitch_adjustment = np.random.uniform(-1, 1, self.dim) * self.pitch_adjustment_rate\n                new_harmony = np.clip(harmony_vector + pitch_adjustment, lb, ub)\n            else:\n                new_harmony = np.random.uniform(lb, ub, self.dim)\n            \n            if np.random.rand() < self.mutation_rate:\n                qg_encoding = self.quantum_genetic_encoding()\n                new_harmony = np.clip(self.best_solution + qg_encoding[i] * np.abs(new_harmony - self.best_solution), lb, ub)\n\n            trial_score = self.evaluate(new_harmony)\n            if trial_score < self.scores[i]:\n                self.population[i] = new_harmony\n                self.scores[i] = trial_score\n                if trial_score < self.best_score:\n                    self.best_score = trial_score\n                    self.best_solution = new_harmony.copy()\n            self.evaluations += 1\n            if self.evaluations >= self.budget:\n                return\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.harmony_search(lb, ub)\n            self.harmony_memory = np.copy(self.population)\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QGHS_Optimizer", "description": "Quantum Genetic Harmony Search (QGHS) combines quantum genetic encoding with harmony search techniques to balance between exploration and exploitation efficiently.", "configspace": "", "generation": 71, "fitness": 0.2724533625870193, "feedback": "The algorithm QGHS_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2715779344650523, 0.2707598045626247, 0.27502234873338094]}, "mutation_prompt": null}
{"id": "525d6434-5e6a-47f7-933c-a491bcbd6e41", "solution": "import numpy as np\n\nclass Quantum_Harmony_Search:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 30\n        self.harmony_memory = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.harmony_memory_consideration_rate = 0.95\n        self.pitch_adjustment_rate = 0.1\n\n    def initialize_harmony_memory(self, lb, ub):\n        self.harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        self.scores = np.array([self.evaluate(hm) for hm in self.harmony_memory])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def random_walk(self, solution, lb, ub):\n        step_size = 0.01 * (ub - lb)\n        random_step = np.random.uniform(-step_size, step_size, self.dim)\n        new_solution = solution + random_step\n        return np.clip(new_solution, lb, ub)\n\n    def quantum_harmony_search(self, lb, ub):\n        for i in range(self.harmony_memory_size):\n            new_harmony = np.zeros(self.dim)\n            for j in range(self.dim):\n                if np.random.rand() < self.harmony_memory_consideration_rate:\n                    new_harmony[j] = self.harmony_memory[np.random.randint(self.harmony_memory_size)][j]\n                    if np.random.rand() < self.pitch_adjustment_rate:\n                        new_harmony[j] = self.random_walk(new_harmony[j], lb[j], ub[j])\n                else:\n                    new_harmony[j] = np.random.uniform(lb[j], ub[j])\n            self.evaluate_and_update(new_harmony)\n\n    def evaluate_and_update(self, new_harmony):\n        new_score = self.evaluate(new_harmony)\n        if new_score < self.best_score:\n            self.best_score = new_score\n            self.best_solution = new_harmony.copy()\n        worst_idx = np.argmax(self.scores)\n        if new_score < self.scores[worst_idx]:\n            self.harmony_memory[worst_idx] = new_harmony\n            self.scores[worst_idx] = new_score\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.harmony_memory[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_harmony_memory(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.quantum_harmony_search(lb, ub)\n            self.evaluations += self.harmony_memory_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "Quantum_Harmony_Search", "description": "Quantum Harmony Search (QHS) combines quantum-inspired harmonic memory and random walk strategies to balance exploration and exploitation in global optimization.", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {}, "mutation_prompt": null}
{"id": "9376b9e6-965b-451f-bd25-a73d86bd5436", "solution": "import numpy as np\n\nclass BHS_APA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 30\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par_min = 0.1  # Minimum Pitch Adjustment Rate\n        self.par_max = 0.5  # Maximum Pitch Adjustment Rate\n        self.harmony_memory = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_harmony_memory(self, lb, ub):\n        self.harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        self.scores = np.array([self.evaluate(harmony) for harmony in self.harmony_memory])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def pitch_adjust(self, harmony, lb, ub):\n        par = np.random.uniform(self.par_min, self.par_max)\n        adjustment = np.random.uniform(-1, 1, self.dim) * par * (ub - lb)\n        new_harmony = harmony + adjustment\n        return np.clip(new_harmony, lb, ub)\n\n    def improvise_new_harmony(self, lb, ub):\n        new_harmony = np.zeros(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < self.hmcr:\n                idx = np.random.randint(self.harmony_memory_size)\n                new_harmony[i] = self.harmony_memory[idx, i]\n            else:\n                new_harmony[i] = np.random.uniform(lb[i], ub[i])\n        new_harmony = self.pitch_adjust(new_harmony, lb, ub)\n        return new_harmony\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.harmony_memory[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_harmony_memory(lb, ub)\n\n        while self.evaluations < self.budget:\n            new_harmony = self.improvise_new_harmony(lb, ub)\n            new_score = self.evaluate(new_harmony)\n            self.evaluations += 1\n\n            worst_idx = np.argmax(self.scores)\n            if new_score < self.scores[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                self.scores[worst_idx] = new_score\n\n            if new_score < self.best_score:\n                self.best_score = new_score\n                self.best_solution = new_harmony.copy()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "BHS_APA_Optimizer", "description": "Bio-inspired Harmony Search with Adaptive Pitch Adjustment (BHS-APA) that combines harmony memory considerations with adaptive pitch adjustment for efficient exploration and exploitation.", "configspace": "", "generation": 73, "fitness": 0.2708793511414355, "feedback": "The algorithm BHS_APA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.26991479952471475, 0.272396201845029, 0.27032705205456287]}, "mutation_prompt": null}
{"id": "cb5ff78b-68c2-459a-adb6-4262bb7fde69", "solution": "import numpy as np\n\nclass QS_ADE_LF_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def levy_flight(self, target_idx):\n        beta = 1.5\n        sigma_u = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                   (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma_u, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / beta)\n        step_size = 0.01 * step * (self.population[target_idx] - self.best_solution)\n        flight = self.population[target_idx] + step_size\n        flight = np.clip(flight, self.func.bounds.lb, self.func.bounds.ub)\n        self.select(target_idx, flight)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # 10% chance to perform Lévy flight\n                    self.levy_flight(i)\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_ADE_LF_Optimizer", "description": "Quantum-Swarm Adaptive Differential Evolution with Lévy Flights (QS-ADE-LF) integrates quantum-inspired superposition with adaptive parameter tuning and sporadic Lévy flights for enhanced exploration and convergence in complex landscapes.", "configspace": "", "generation": 74, "fitness": 0.26984202147744263, "feedback": "The algorithm QS_ADE_LF_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2586927694336796, 0.27773018782837, 0.2731031071702783]}, "mutation_prompt": null}
{"id": "7f12e29a-f963-43f3-bf0a-015556d4998d", "solution": "import numpy as np\n\nclass QE_HS_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 30\n        self.HMCR = 0.7  # Harmony Memory Consideration Rate\n        self.PAR_min = 0.1  # Pitch Adjusting Rate\n        self.PAR_max = 0.9\n        self.harmony_memory = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_harmony_memory(self, lb, ub):\n        self.harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        self.scores = np.array([self.evaluate(harmony) for harmony in self.harmony_memory])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def improvise_new_harmony(self, lb, ub):\n        new_harmony = np.zeros(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < self.HMCR:\n                new_harmony[i] = np.random.choice(self.harmony_memory[:, i])\n                if np.random.rand() < self.dynamic_PAR():\n                    new_harmony[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i])\n                    new_harmony[i] = np.clip(new_harmony[i], lb[i], ub[i])\n            else:\n                new_harmony[i] = np.random.uniform(lb[i], ub[i])\n        return new_harmony\n\n    def dynamic_PAR(self):\n        return np.random.uniform(self.PAR_min, self.PAR_max)\n\n    def quantum_mutation(self, harmony):\n        quantum_shift = np.random.uniform(-1, 1, self.dim)\n        quantum_harmony = self.best_solution + quantum_shift * np.abs(harmony - self.best_solution)\n        return np.clip(quantum_harmony, self.func.bounds.lb, self.func.bounds.ub)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.harmony_memory[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_harmony_memory(lb, ub)\n\n        while self.evaluations < self.budget:\n            new_harmony = self.improvise_new_harmony(lb, ub)\n            new_score = self.evaluate(new_harmony)\n            self.evaluations += 1\n\n            if new_score < self.best_score:\n                self.best_solution = new_harmony.copy()\n                self.best_score = new_score\n\n            worst_idx = np.argmax(self.scores)\n            if new_score < self.scores[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                self.scores[worst_idx] = new_score\n\n            if self.evaluations < self.budget:\n                quantum_harmony = self.quantum_mutation(new_harmony)\n                quantum_score = self.evaluate(quantum_harmony)\n                self.evaluations += 1\n                if quantum_score < self.best_score:\n                    self.best_solution = quantum_harmony.copy()\n                    self.best_score = quantum_score\n                \n                worst_idx = np.argmax(self.scores)\n                if quantum_score < self.scores[worst_idx]:\n                    self.harmony_memory[worst_idx] = quantum_harmony\n                    self.scores[worst_idx] = quantum_score\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QE_HS_Optimizer", "description": "Quantum-Enhanced Harmony Search (QE-HS) integrates quantum-inspired diversity mechanisms with dynamic harmony memory to optimize exploration and exploitation balance effectively.", "configspace": "", "generation": 75, "fitness": 0.2731826246405981, "feedback": "The algorithm QE_HS_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2728694013218843, 0.27312023429586174, 0.27355823830404824]}, "mutation_prompt": null}
{"id": "6e60effd-b25b-4abb-8c61-d3b4d034402c", "solution": "import numpy as np\n\nclass QS_ADE_LS_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.successful_F = []\n        self.successful_CR = []\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = self.adapt_parameter(self.F_min, self.F_max, self.successful_F)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = self.adapt_parameter(self.CR_min, self.CR_max, self.successful_CR)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial, F, CR):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            self.successful_F.append(F)\n            self.successful_CR.append(CR)\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def adapt_parameter(self, min_val, max_val, successes):\n        if successes:\n            return np.clip(np.mean(successes) + np.random.normal(scale=0.1), min_val, max_val)\n        else:\n            return np.random.uniform(min_val, max_val)\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant, None, None)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                F = self.adapt_parameter(self.F_min, self.F_max, self.successful_F)\n                CR = self.adapt_parameter(self.CR_min, self.CR_max, self.successful_CR)\n                self.select(i, trial, F, CR)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_ADE_LS_Optimizer", "description": "Quantum-Swarm Adaptive Differential Evolution with Learning Strategy (QS-ADE-LS) integrates a self-adaptive learning strategy for parameter tuning to improve exploration-exploitation balance and convergence rates.", "configspace": "", "generation": 76, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for +: 'float' and 'NoneType'\").", "error": "TypeError(\"unsupported operand type(s) for +: 'float' and 'NoneType'\")", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {}, "mutation_prompt": null}
{"id": "d7e8ea41-1cc4-4487-b539-b4a66b45112e", "solution": "import numpy as np\n\nclass AQIDE_DPS_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 30\n        self.min_population_size = 5\n        self.max_population_size = 50\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population_size = self.initial_population_size\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        score = self.func(solution)\n        self.evaluations += 1\n        return score\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def adjust_population_size(self):\n        diversity = np.mean(np.std(self.population, axis=0))\n        if diversity < 1e-5:\n            self.population_size = max(self.min_population_size, self.population_size // 2)\n        else:\n            self.population_size = min(self.max_population_size, self.population_size + 1)\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n            self.quantum_inspired_mutation()\n            self.adjust_population_size()\n            self.population = self.population[:self.population_size]\n            self.scores = self.scores[:self.population_size]\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "AQIDE_DPS_Optimizer", "description": "Adaptive Quantum-Inspired Differential Evolution with Dynamic Population Sizing (AQIDE-DPS) enhances convergence by adjusting population size based on diversity and incorporates quantum-inspired superposition for efficient exploration.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {}, "mutation_prompt": null}
{"id": "3cd3c288-59a7-4e0c-822d-157b02de4eef", "solution": "import numpy as np\n\nclass QE_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_tunneling(self):\n        for i in range(self.population_size):\n            quantum_tunnel = np.random.uniform(-0.5, 0.5, self.dim)\n            quantum_candidate = self.best_solution + quantum_tunnel * np.random.uniform(-1, 1, self.dim)\n            quantum_candidate = np.clip(quantum_candidate, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_candidate)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def adapt_parameters(self):\n        self.F_min += 0.01 * np.random.choice([-1, 1])\n        self.F_max += 0.01 * np.random.choice([-1, 1])\n        self.CR_min += 0.01 * np.random.choice([-1, 1])\n        self.CR_max += 0.01 * np.random.choice([-1, 1])\n        self.F_min, self.F_max = np.clip([self.F_min, self.F_max], 0.1, 1.0)\n        self.CR_min, self.CR_max = np.clip([self.CR_min, self.CR_max], 0.0, 1.0)\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_tunneling()\n            self.evaluations += self.population_size\n            self.adapt_parameters()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QE_ADE_Optimizer", "description": "Quantum-Enhanced Adaptive Differential Evolution (QE-ADE) combines differential evolution with quantum tunneling mechanisms and dynamic parameter adaptation to balance global exploration and local exploitation efficiently.", "configspace": "", "generation": 78, "fitness": 0.2623729220275493, "feedback": "The algorithm QE_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2578043010942649, 0.27226703919293493, 0.25704742579544804]}, "mutation_prompt": null}
{"id": "40f2fdca-c38d-46a1-847d-0f2866185b03", "solution": "import numpy as np\n\nclass QPE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.alpha = 0.5  # Influence of global best\n        self.beta = 0.3   # Influence of individual best\n        self.gamma = 0.2  # Random influence\n        self.population = None\n        self.velocities = None\n        self.scores = None\n        self.individual_best_positions = None\n        self.individual_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.zeros((self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.individual_best_positions = self.population.copy()\n        self.individual_best_scores = self.scores.copy()\n        self.update_global_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_global_best(self):\n        best_idx = np.argmin(self.scores)\n        if self.scores[best_idx] < self.global_best_score:\n            self.global_best_score = self.scores[best_idx]\n            self.global_best_position = self.population[best_idx].copy()\n\n    def update_positions_and_velocities(self, lb, ub):\n        for i in range(self.population_size):\n            r1, r2, r3 = np.random.rand(3, self.dim)\n            cognitive_velocity = self.alpha * r1 * (self.individual_best_positions[i] - self.population[i])\n            social_velocity = self.beta * r2 * (self.global_best_position - self.population[i])\n            quantum_velocity = self.gamma * r3 * (np.random.uniform(lb, ub, self.dim) - self.population[i])\n            self.velocities[i] = cognitive_velocity + social_velocity + quantum_velocity\n            self.population[i] += self.velocities[i]\n            self.population[i] = np.clip(self.population[i], lb, ub)\n            current_score = self.evaluate(self.population[i])\n            if current_score < self.individual_best_scores[i]:\n                self.individual_best_scores[i] = current_score\n                self.individual_best_positions[i] = self.population[i].copy()\n                \n            if self.evaluations < self.budget:\n                self.evaluations += 1\n            else:\n                break\n                \n        self.update_global_best()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.update_positions_and_velocities(lb, ub)\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "QPE_Optimizer", "description": "Quantum Particle Evolution (QPE) utilizes quantum-inspired position updates and collaborative particle interactions for robust exploration and fast convergence.", "configspace": "", "generation": 79, "fitness": 0.2703912780225781, "feedback": "The algorithm QPE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2746637448742093, 0.2709512919946585, 0.26555879719886655]}, "mutation_prompt": null}
{"id": "583f4b13-abc4-4477-b63d-1fda14f11cca", "solution": "import numpy as np\n\nclass QHS_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 30\n        self.harmony_memory_consideration_rate = 0.95\n        self.pitch_adjustment_rate = 0.7\n        self.bandwidth = 0.1\n        self.harmony_memory = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_harmony_memory(self, lb, ub):\n        self.harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        self.scores = np.array([self.evaluate(harmony) for harmony in self.harmony_memory])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def improvise_new_harmony(self, lb, ub):\n        new_harmony = np.zeros(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < self.harmony_memory_consideration_rate:\n                new_harmony[i] = self.harmony_memory[np.random.randint(self.harmony_memory_size)][i]\n                if np.random.rand() < self.pitch_adjustment_rate:\n                    new_harmony[i] += np.random.uniform(-self.bandwidth, self.bandwidth)\n            else:\n                new_harmony[i] = np.random.uniform(lb[i], ub[i])\n        return np.clip(new_harmony, lb, ub)\n\n    def update_harmony_memory(self, new_harmony):\n        new_score = self.evaluate(new_harmony)\n        if new_score < self.best_score:\n            self.best_score = new_score\n            self.best_solution = new_harmony.copy()\n        worst_idx = np.argmax(self.scores)\n        if new_score < self.scores[worst_idx]:\n            self.harmony_memory[worst_idx] = new_harmony\n            self.scores[worst_idx] = new_score\n\n    def quantum_harmony_adjustment(self):\n        for i in range(self.harmony_memory_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_adjusted_harmony = self.best_solution + quantum_superposition * np.abs(self.harmony_memory[i] - self.best_solution)\n            quantum_adjusted_harmony = np.clip(quantum_adjusted_harmony, self.func.bounds.lb, self.func.bounds.ub)\n            self.update_harmony_memory(quantum_adjusted_harmony)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.harmony_memory[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_harmony_memory(lb, ub)\n\n        while self.evaluations < self.budget:\n            new_harmony = self.improvise_new_harmony(lb, ub)\n            self.update_harmony_memory(new_harmony)\n            self.evaluations += 1\n            if self.evaluations >= self.budget:\n                break\n            self.quantum_harmony_adjustment()\n            self.evaluations += self.harmony_memory_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QHS_Optimizer", "description": "Quantum Harmony Search (QHS) employs quantum-inspired harmony memory and adaptive pitch adjustment to enhance exploration and convergence in global optimization tasks.", "configspace": "", "generation": 80, "fitness": 0.2714996958702027, "feedback": "The algorithm QHS_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.25872121769912904, 0.2778470685072735, 0.27793080140420545]}, "mutation_prompt": null}
{"id": "ef1d9823-6ba9-4fc4-89f2-b9c3d2bf2ad4", "solution": "import numpy as np\n\nclass QMO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def quantum_morphogenetic_mutation(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b = self.population[np.random.choice(indices, 2, replace=False)]\n        alpha = np.random.uniform(0, 1)\n        beta = np.random.uniform(0, 1)\n        quantum_factor = np.random.uniform(-1, 1, self.dim)\n\n        morphogenetic_mutant = alpha * a + (1 - alpha) * b + beta * quantum_factor * (self.best_solution - self.population[target_idx])\n        morphogenetic_mutant = np.clip(morphogenetic_mutant, self.func.bounds.lb, self.func.bounds.ub)\n        \n        return morphogenetic_mutant\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                trial = self.quantum_morphogenetic_mutation(i)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n        \n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QMO_Optimizer", "description": "Quantum-Morphogenetic Optimization (QMO) combines principles of quantum superposition with morphogenetic development patterns to dynamically adapt search strategies for enhancing exploration and exploitation.", "configspace": "", "generation": 81, "fitness": 0.2745805518402489, "feedback": "The algorithm QMO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.27277430213835185, 0.27583117294653825, 0.2751361804358565]}, "mutation_prompt": null}
{"id": "00f6ce17-696c-42bc-86ec-2349e8d8c135", "solution": "import numpy as np\n\nclass QHS_Optimizer:\n    def __init__(self, budget, dim, harmony_size=30, harmony_memory_consideration_rate=0.9, pitch_adjustment_rate=0.4):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_size = harmony_size\n        self.harmony_memory_consideration_rate = harmony_memory_consideration_rate\n        self.pitch_adjustment_rate = pitch_adjustment_rate\n        self.harmonies = None\n        self.best_harmony = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_harmonies(self, lb, ub):\n        self.harmonies = np.random.uniform(lb, ub, (self.harmony_size, self.dim))\n        scores = np.array([self.evaluate(harmony) for harmony in self.harmonies])\n        self.best_harmony = self.harmonies[np.argmin(scores)].copy()\n        self.best_score = np.min(scores)\n\n    def evaluate(self, harmony):\n        return self.func(harmony)\n\n    def quantum_inspired_harmony(self, lb, ub):\n        indices = np.random.choice(self.harmony_size, self.dim, replace=True)\n        new_harmony = self.harmonies[indices, np.arange(self.dim)]\n        \n        for i in range(self.dim):\n            if np.random.rand() > self.harmony_memory_consideration_rate:\n                new_harmony[i] = np.random.uniform(lb[i], ub[i])\n        \n        if np.random.rand() < self.pitch_adjustment_rate:\n            adjustment = np.random.uniform(-1, 1, self.dim)\n            new_harmony += adjustment * (ub - lb)\n            new_harmony = np.clip(new_harmony, lb, ub)\n        \n        quantum_superposition = np.random.uniform(-1, 1, self.dim)\n        quantum_harmony = self.best_harmony + quantum_superposition * np.abs(new_harmony - self.best_harmony)\n        return np.clip(quantum_harmony, lb, ub)\n\n    def update_harmony_memory(self, new_harmony):\n        new_score = self.evaluate(new_harmony)\n        if new_score < self.best_score:\n            self.best_score = new_score\n            self.best_harmony = new_harmony.copy()\n\n        worst_idx = np.argmax([self.evaluate(harmony) for harmony in self.harmonies])\n        if new_score < self.evaluate(self.harmonies[worst_idx]):\n            self.harmonies[worst_idx] = new_harmony\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_harmonies(lb, ub)\n\n        while self.evaluations < self.budget:\n            new_harmony = self.quantum_inspired_harmony(lb, ub)\n            self.update_harmony_memory(new_harmony)\n            self.evaluations += 1\n\n        return {'solution': self.best_harmony, 'fitness': self.best_score}", "name": "QHS_Optimizer", "description": "Quantum Harmony Search (QHS) integrates quantum-inspired superposition principles with harmony search to balance exploration and exploitation for global optimization.", "configspace": "", "generation": 82, "fitness": 0.26878374595130455, "feedback": "The algorithm QHS_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.27079916395012904, 0.2678634382556623, 0.2676886356481224]}, "mutation_prompt": null}
{"id": "22e7bc16-c71c-48f8-81de-d206eae2c112", "solution": "import numpy as np\n\nclass QE_APSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.c1_min = 1.5\n        self.c1_max = 2.5\n        self.c2_min = 1.5\n        self.c2_max = 2.5\n        self.population = None\n        self.velocities = None\n        self.scores = None\n        self.best_individual_positions = None\n        self.best_individual_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.best_individual_positions = self.population.copy()\n        self.best_individual_scores = self.scores.copy()\n        self.update_global_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_global_best(self):\n        min_idx = np.argmin(self.scores)\n        if self.scores[min_idx] < self.global_best_score:\n            self.global_best_score = self.scores[min_idx]\n            self.global_best_position = self.population[min_idx].copy()\n\n    def adapt_parameters(self, iteration_ratio):\n        w = self.w_max - (self.w_max - self.w_min) * iteration_ratio\n        c1 = self.c1_min + (self.c1_max - self.c1_min) * iteration_ratio\n        c2 = self.c2_min + (self.c2_max - self.c2_min) * iteration_ratio\n        return w, c1, c2\n\n    def quantum_position_update(self):\n        quantum_superposition = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        return self.global_best_position + quantum_superposition * np.abs(self.population - self.global_best_position)\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        max_iterations = self.budget // self.population_size\n\n        for iter_num in range(max_iterations):\n            iteration_ratio = iter_num / max_iterations\n            w, c1, c2 = self.adapt_parameters(iteration_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = c1 * r1 * (self.best_individual_positions[i] - self.population[i])\n                social = c2 * r2 * (self.global_best_position - self.population[i])\n                self.velocities[i] = w * self.velocities[i] + cognitive + social\n                quantum_update = self.quantum_position_update()[i]\n                self.population[i] = np.clip(self.population[i] + self.velocities[i] + quantum_update, lb, ub)\n\n                self.scores[i] = self.evaluate(self.population[i])\n                self.evaluations += 1\n\n                if self.scores[i] < self.best_individual_scores[i]:\n                    self.best_individual_scores[i] = self.scores[i]\n                    self.best_individual_positions[i] = self.population[i].copy()\n\n            self.update_global_best()\n\n            if self.evaluations >= self.budget:\n                break\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "QE_APSO_Optimizer", "description": "Quantum-Enhanced Adaptive Particle Swarm Optimization (QE-APSO) integrates quantum-inspired position updates with adaptive inertia and acceleration coefficients to balance exploration and exploitation for enhanced global search.", "configspace": "", "generation": 83, "fitness": 0.2519047295303432, "feedback": "The algorithm QE_APSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.24693764200829116, 0.2549956477497137, 0.2537808988330248]}, "mutation_prompt": null}
{"id": "282bbe9f-1525-42fc-b6c2-e833ff09b39b", "solution": "import numpy as np\n\nclass QW_EGA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.mutation_rate_min = 0.01\n        self.mutation_rate_max = 0.2\n        self.crossover_rate_min = 0.6\n        self.crossover_rate_max = 0.9\n        self.population = None\n        self.fitness = None\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.fitness = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def select_parents(self):\n        fitness_inv = 1 / (self.fitness + 1e-12)\n        probabilities = fitness_inv / fitness_inv.sum()\n        parents_idx = np.random.choice(range(self.population_size), size=2, replace=False, p=probabilities)\n        return self.population[parents_idx]\n\n    def crossover(self, parent1, parent2):\n        crossover_rate = np.random.uniform(self.crossover_rate_min, self.crossover_rate_max)\n        mask = np.random.rand(self.dim) < crossover_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual):\n        mutation_rate = np.random.uniform(self.mutation_rate_min, self.mutation_rate_max)\n        mutation_mask = np.random.rand(self.dim) < mutation_rate\n        noise = np.random.normal(0, 1, self.dim)\n        individual = individual + mutation_mask * noise\n        return individual\n\n    def quantum_wave_adjustment(self):\n        wave_patterns = np.sin(np.linspace(0, np.pi, self.population_size))\n        self.mutation_rate_min = 0.01 + 0.1 * wave_patterns.min()\n        self.mutation_rate_max = 0.2 + 0.1 * wave_patterns.max()\n        self.crossover_rate_min = 0.6 + 0.1 * wave_patterns.min()\n        self.crossover_rate_max = 0.9 + 0.1 * wave_patterns.max()\n\n    def update_best(self):\n        best_idx = np.argmin(self.fitness)\n        if self.fitness[best_idx] < self.best_fitness:\n            self.best_solution = self.population[best_idx].copy()\n            self.best_fitness = self.fitness[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            new_population = []\n            for _ in range(self.population_size):\n                parent1, parent2 = self.select_parents()\n                offspring = self.crossover(parent1, parent2)\n                offspring = self.mutate(offspring)\n                offspring = np.clip(offspring, lb, ub)\n                new_population.append(offspring)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n\n            self.population = np.array(new_population)\n            self.fitness = np.array([self.evaluate(ind) for ind in self.population])\n            self.update_best()\n            self.quantum_wave_adjustment()\n\n        return {'solution': self.best_solution, 'fitness': self.best_fitness}", "name": "QW_EGA_Optimizer", "description": "Quantum-Wave Enhanced Genetic Algorithm (QW-EGA) utilizes quantum wave interference patterns to dynamically adjust genetic operator probabilities, improving adaptability and convergence.", "configspace": "", "generation": 84, "fitness": 0.2563978967257226, "feedback": "The algorithm QW_EGA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2624936312881503, 0.2461171292707417, 0.2605829296182758]}, "mutation_prompt": null}
{"id": "b3c0887b-1548-4164-98c7-df3b72e1ade4", "solution": "import numpy as np\n\nclass QS_EDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        enhanced_population = self.elitism_and_diversity_enhancer()\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(enhanced_population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def elitism_and_diversity_enhancer(self):\n        # Hybrid elitism: blend current best and global diversity\n        diversity_factor = np.std(self.population, axis=0)\n        enhanced_population = self.population + diversity_factor\n        for i in range(self.population_size):\n            if np.random.rand() < 0.5:  # With a chance, enhance with the best solution\n                enhanced_population[i] = (enhanced_population[i] + self.best_solution) / 2\n        return np.clip(enhanced_population, self.func.bounds.lb, self.func.bounds.ub)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_EDE_Optimizer", "description": "Quantum-Swarm Enhanced Differential Evolution (QS-EDE) incorporates adaptive quantum-inspired mutation with enhanced elitism and diversity measures to boost exploration and convergence in complex landscapes.", "configspace": "", "generation": 85, "fitness": 0.27494322188356507, "feedback": "The algorithm QS_EDE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.277798405334747, 0.2736179121353448, 0.27341334818060337]}, "mutation_prompt": null}
{"id": "575f6a9c-fd5d-4524-9ada-7c8f2af715c9", "solution": "import numpy as np\n\nclass Hybrid_Quantum_Swarm_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def local_search(self, individual, lb, ub):\n        local_step_size = (ub - lb) * 0.05\n        local_mutant = individual + np.random.uniform(-local_step_size, local_step_size, self.dim)\n        local_mutant = np.clip(local_mutant, lb, ub)\n        return local_mutant\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n            \n            # Implementing local search on best solution\n            if self.evaluations + self.population_size <= self.budget:\n                for i in range(self.population_size):\n                    local_mutant = self.local_search(self.population[i], lb, ub)\n                    self.select(i, local_mutant)\n                self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "Hybrid_Quantum_Swarm_DE", "description": "Hybrid Quantum-Swarm DE combines quantum-inspired operations with a local search strategy for improved convergence and exploration.", "configspace": "", "generation": 86, "fitness": 0.27408181545408056, "feedback": "The algorithm Hybrid_Quantum_Swarm_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.27590614868617136, 0.27340953334541707, 0.2729297643306533]}, "mutation_prompt": null}
{"id": "c9291a71-b22d-4497-af7a-1a04c9991231", "solution": "import numpy as np\n\nclass QTIDE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.5\n        self.F_max = 0.8\n        self.CR_min = 0.2\n        self.CR_max = 0.8\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.turbulence_factor = 0.05\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def apply_turbulence(self):\n        for i in range(self.population_size):\n            turbulence = np.random.uniform(-self.turbulence_factor, self.turbulence_factor, self.dim)\n            turbulent_solution = self.population[i] + turbulence * np.abs(self.best_solution - self.population[i])\n            turbulent_solution = np.clip(turbulent_solution, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, turbulent_solution)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.apply_turbulence()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QTIDE_Optimizer", "description": "Quantum Turbulence-Inspired Differential Evolution (QTIDE) introduces turbulence perturbations into the search process, enhancing diversity and adaptability within the population for improved convergence.", "configspace": "", "generation": 87, "fitness": 0.27284754002768524, "feedback": "The algorithm QTIDE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.271958562535937, 0.2727811767041721, 0.27380288084294657]}, "mutation_prompt": null}
{"id": "472bbcc4-b646-4b19-ad95-6e37196d30af", "solution": "import numpy as np\n\nclass QPF_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.global_best = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.alpha = 0.1\n        self.beta = 2.0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.full(self.population_size, float('inf'))\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_best(self):\n        for i in range(self.population_size):\n            score = self.evaluate(self.population[i])\n            if score < self.scores[i]:\n                self.scores[i] = score\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.population[i].copy()\n\n    def quantum_particle_fusion(self, lb, ub):\n        quantum_states = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        for i in range(self.population_size):\n            fusion_vector = self.global_best + self.alpha * quantum_states[i] * np.abs(self.population[i] - self.global_best)\n            fusion_vector = np.clip(fusion_vector, lb, ub)\n            score = self.evaluate(fusion_vector)\n            if score < self.scores[i]:\n                self.population[i] = fusion_vector\n                self.scores[i] = score\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = fusion_vector.copy()\n\n    def update_population(self, lb, ub):\n        for i in range(self.population_size):\n            rand_idx = np.random.randint(self.population_size)\n            selected_particle = self.population[rand_idx]\n            velocity = self.beta * (selected_particle - self.population[i]) + self.alpha * np.random.uniform(-1, 1, self.dim)\n            new_position = self.population[i] + velocity\n            new_position = np.clip(new_position, lb, ub)\n            score = self.evaluate(new_position)\n            if score < self.scores[i]:\n                self.population[i] = new_position\n                self.scores[i] = score\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = new_position.copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n        self.update_best()\n\n        while self.evaluations < self.budget:\n            self.update_population(lb, ub)\n            self.evaluations += self.population_size\n            self.quantum_particle_fusion(lb, ub)\n            self.evaluations += self.population_size\n\n        return {'solution': self.global_best, 'fitness': self.global_best_score}", "name": "QPF_Optimizer", "description": "Quantum Particle Fusion (QPF) combines quantum-inspired evolutionary strategies with particle fusion to optimize search space exploration and convergence in photonic structure global optimization.", "configspace": "", "generation": 88, "fitness": 0.2636310346571245, "feedback": "The algorithm QPF_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2586890193602045, 0.27353784519236346, 0.2586662394188055]}, "mutation_prompt": null}
{"id": "ad72d4ff-133b-4135-b3f4-dc31da3f4d17", "solution": "import numpy as np\n\nclass QE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.omega = 0.5  # inertia weight\n        self.phi_p = 0.5  # cognitive component\n        self.phi_g = 0.5  # social component\n        self.population = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_personal_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        self.best_positions = self.population.copy()\n        self.best_personal_scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_global_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_global_best(self):\n        min_index = np.argmin(self.best_personal_scores)\n        if self.best_personal_scores[min_index] < self.global_best_score:\n            self.global_best_score = self.best_personal_scores[min_index]\n            self.global_best_position = self.best_positions[min_index].copy()\n\n    def adapt_parameters(self):\n        self.omega = 0.5 + np.random.rand() / 2.0\n        self.phi_p = 0.5 + np.random.rand() / 2.0\n        self.phi_g = 0.5 + np.random.rand() / 2.0\n\n    def quantum_tunneling(self, position, lb, ub):\n        tunneling_vector = np.random.uniform(-1, 1, self.dim)\n        quantum_position = position + tunneling_vector * np.random.uniform(0, np.abs(position - self.global_best_position))\n        return np.clip(quantum_position, lb, ub)\n\n    def update_particles(self, lb, ub):\n        self.adapt_parameters()\n        for i in range(self.population_size):\n            r_p, r_g = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.velocities[i] = (self.omega * self.velocities[i] +\n                                  self.phi_p * r_p * (self.best_positions[i] - self.population[i]) +\n                                  self.phi_g * r_g * (self.global_best_position - self.population[i]))\n            self.population[i] = np.clip(self.population[i] + self.velocities[i], lb, ub)\n\n            quantum_position = self.quantum_tunneling(self.population[i], lb, ub)\n            quantum_score = self.evaluate(quantum_position)\n            \n            current_score = self.evaluate(self.population[i])\n            self.evaluations += 2\n\n            if quantum_score < current_score:\n                self.population[i] = quantum_position\n                current_score = quantum_score\n\n            if current_score < self.best_personal_scores[i]:\n                self.best_personal_scores[i] = current_score\n                self.best_positions[i] = self.population[i].copy()\n\n        self.update_global_best()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.update_particles(lb, ub)\n            if self.evaluations >= self.budget:\n                break\n\n        return {'solution': self.global_best_position, 'fitness': self.global_best_score}", "name": "QE_PSO_Optimizer", "description": "Quantum-Enhanced Particle Swarm Optimization (QE-PSO) integrates quantum tunneling concepts with adaptive velocity and position adjustments to balance exploration and exploitation for improved convergence.", "configspace": "", "generation": 89, "fitness": 0.2757579235519316, "feedback": "The algorithm QE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.277431155265738, 0.2730000862725106, 0.27684252911754625]}, "mutation_prompt": null}
{"id": "f95e4f96-a4e7-4d06-86ae-5a26f65d5e91", "solution": "import numpy as np\n\nclass QHS_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 30\n        self.harmony_memory = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.harmony_consideration_rate = 0.95\n        self.pitch_adjustment_rate = 0.3\n        self.bandwidth = 0.1\n\n    def initialize_harmony_memory(self, lb, ub):\n        self.harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        self.scores = np.array([self.evaluate(harmony) for harmony in self.harmony_memory])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def generate_new_harmony(self, lb, ub):\n        new_harmony = np.zeros(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < self.harmony_consideration_rate:\n                new_harmony[i] = self.harmony_memory[np.random.randint(0, self.harmony_memory_size), i]\n                if np.random.rand() < self.pitch_adjustment_rate:\n                    new_harmony[i] += np.random.uniform(-1, 1) * self.bandwidth\n            else:\n                new_harmony[i] = np.random.uniform(lb[i], ub[i])\n        \n        return np.clip(new_harmony, lb, ub)\n\n    def select(self, new_harmony, new_score):\n        worst_idx = np.argmax(self.scores)\n        if new_score < self.scores[worst_idx]:\n            self.harmony_memory[worst_idx] = new_harmony\n            self.scores[worst_idx] = new_score\n            if new_score < self.best_score:\n                self.best_score = new_score\n                self.best_solution = new_harmony.copy()\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.harmony_memory[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def quantum_inspired_adjustment(self):\n        quantum_superposition = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim))\n        adjustments = quantum_superposition * np.abs(self.harmony_memory - self.best_solution)\n        self.harmony_memory = np.clip(self.harmony_memory + adjustments, self.func.bounds.lb, self.func.bounds.ub)\n        self.scores = np.array([self.evaluate(harmony) for harmony in self.harmony_memory])\n        self.update_best()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_harmony_memory(lb, ub)\n\n        while self.evaluations < self.budget:\n            new_harmony = self.generate_new_harmony(lb, ub)\n            new_score = self.evaluate(new_harmony)\n            self.select(new_harmony, new_score)\n            self.evaluations += 1\n            if self.evaluations >= self.budget:\n                break\n\n            if self.evaluations % self.harmony_memory_size == 0:\n                self.quantum_inspired_adjustment()\n                self.evaluations += self.harmony_memory_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QHS_Optimizer", "description": "Quantum Harmony Search (QHS) integrates quantum-inspired harmony memory with dynamic pitch adjustment for efficient exploration and exploitation in global optimization.", "configspace": "", "generation": 90, "fitness": 0.2757022728481621, "feedback": "The algorithm QHS_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2756441402899579, 0.2753568081467762, 0.2761058701077522]}, "mutation_prompt": null}
{"id": "1c57f212-c31c-443f-88c6-f31f16b7301c", "solution": "import numpy as np\n\nclass QEFO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.n_fireflies = 30\n        self.alpha = 0.1  # Randomness coefficient\n        self.beta_min = 0.2\n        self.gamma = 1.0  # Absorption coefficient\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.n_fireflies, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def move_fireflies(self, lb, ub):\n        for i in range(self.n_fireflies):\n            for j in range(self.n_fireflies):\n                if self.scores[i] > self.scores[j]:\n                    r = np.linalg.norm(self.population[i] - self.population[j])\n                    beta = self.beta_min + (1 - self.beta_min) * np.exp(-self.gamma * r**2)\n                    attraction = beta * (self.population[j] - self.population[i])\n                    randomization = self.alpha * np.random.uniform(-1, 1, self.dim)\n                    entangled_influence = self.quantum_entanglement(self.population[i], self.population[j])\n                    self.population[i] += attraction + randomization + entangled_influence\n                    self.population[i] = np.clip(self.population[i], lb, ub)\n\n    def quantum_entanglement(self, firefly_a, firefly_b):\n        entanglement_strength = np.random.uniform(0.1, 0.5)\n        quantum_state = np.random.choice([-1, 1], self.dim)\n        entangled_influence = entanglement_strength * quantum_state * (firefly_b - firefly_a)\n        return entangled_influence\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.move_fireflies(lb, ub)\n            self.scores = np.array([self.evaluate(ind) for ind in self.population])\n            self.update_best()\n            self.evaluations += self.n_fireflies\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QEFO_Optimizer", "description": "Quantum-Entangled Firefly Optimization (QEFO) utilizes quantum entanglement principles to enhance swarm intelligence and adaptive attraction strategies for robust global optimization.", "configspace": "", "generation": 91, "fitness": 0.27270688471478727, "feedback": "The algorithm QEFO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.27569253368405444, 0.2670968536596533, 0.275331266800654]}, "mutation_prompt": null}
{"id": "b49ac0fe-e37a-4b45-8b9e-bc0fa7f2a36d", "solution": "import numpy as np\n\nclass EQD_DE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.diversity_threshold = 0.1\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def adjust_diversity(self):\n        diversity = np.std(self.population, axis=0).mean()\n        if diversity < self.diversity_threshold:\n            self.F_min = 0.5\n            self.CR_min = 0.2\n        else:\n            self.F_min = 0.4\n            self.CR_min = 0.1\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                self.adjust_diversity()\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "EQD_DE_Optimizer", "description": "Enhanced Quantum Diversity Differential Evolution (EQD-DE) improves exploration by dynamically adjusting diversity mechanisms and integrating quantum-inspired strategies for robust convergence across complex landscapes.", "configspace": "", "generation": 92, "fitness": 0.2775408308051585, "feedback": "The algorithm EQD_DE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2773693315948704, 0.27740668620714004, 0.277846474613465]}, "mutation_prompt": null}
{"id": "c66e19d8-4a1f-4428-bbe8-5e70a3c9aa51", "solution": "import numpy as np\n\nclass QME_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.universes = 5\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.universes, self.population_size, self.dim))\n        self.scores = np.array([[self.evaluate(ind) for ind in universe] for universe in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def quantum_superposition(self, lb, ub):\n        for u_idx in range(self.universes):\n            quantum_universe = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            for i in range(self.population_size):\n                if np.random.rand() < 0.5:\n                    self.population[u_idx][i] = self.best_solution + quantum_universe[i] * np.abs(self.population[u_idx][i] - self.best_solution)\n                else:\n                    random_idx = np.random.randint(self.universes)\n                    if random_idx != u_idx:\n                        self.population[u_idx][i] = self.population[random_idx][np.random.randint(self.population_size)]\n                self.population[u_idx][i] = np.clip(self.population[u_idx][i], lb, ub)\n                self.scores[u_idx][i] = self.evaluate(self.population[u_idx][i])\n            self.evaluations += self.population_size\n            if self.evaluations >= self.budget:\n                return\n\n    def update_best(self):\n        for u_idx in range(self.universes):\n            best_idx = np.argmin(self.scores[u_idx])\n            if self.scores[u_idx][best_idx] < self.best_score:\n                self.best_solution = self.population[u_idx][best_idx].copy()\n                self.best_score = self.scores[u_idx][best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.quantum_superposition(lb, ub)\n            self.update_best()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QME_Optimizer", "description": "Quantum Multiverse Exploration (QME) integrates quantum superposition principles to explore multiple universes of potential solutions, enhancing global search diversity and convergence accuracy.", "configspace": "", "generation": 93, "fitness": 0.2695704549094845, "feedback": "The algorithm QME_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2732131489549787, 0.2771947713485179, 0.2583034444249569]}, "mutation_prompt": null}
{"id": "a214ac60-ec98-4273-ae03-5ae50ad2412f", "solution": "import numpy as np\n\nclass QT_ADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.tunneling_probability = 0.1\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def quantum_tunneling(self):\n        for i in range(self.population_size):\n            if np.random.rand() < self.tunneling_probability:\n                tunnel_jump = np.random.uniform(self.func.bounds.lb, self.func.bounds.ub, self.dim)\n                self.select(i, tunnel_jump)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.quantum_tunneling()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QT_ADE_Optimizer", "description": "Quantum-Tunneling Adaptive Differential Evolution (QT-ADE) enhances QS-ADE by incorporating quantum tunneling mechanisms to escape local optima and improve global convergence.", "configspace": "", "generation": 94, "fitness": 0.2698753412771823, "feedback": "The algorithm QT_ADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2776431347573133, 0.2733924910247072, 0.25859039804952644]}, "mutation_prompt": null}
{"id": "ea878641-ba1f-455d-9fa2-df3faf8c1f0c", "solution": "import numpy as np\n\nclass PIHS_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 30\n        self.harmony_search_rate = 0.8\n        self.adjust_rate_range = (0.1, 0.3)\n        self.harmony_memory = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.interaction_strength = 0.5\n\n    def initialize_harmony_memory(self, lb, ub):\n        self.harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.harmony_memory])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def generate_harmony(self, lb, ub):\n        harmony = np.empty(self.dim)\n        for j in range(self.dim):\n            if np.random.rand() < self.harmony_search_rate:\n                harmony[j] = self.harmony_memory[np.random.randint(self.harmony_memory_size), j]\n                if np.random.rand() < np.random.uniform(*self.adjust_rate_range):\n                    harmony[j] += np.random.uniform(-1, 1) * (ub[j] - lb[j]) * self.interaction_strength\n            else:\n                harmony[j] = np.random.uniform(lb[j], ub[j])\n        harmony = np.clip(harmony, lb, ub)\n        return harmony\n\n    def update_harmony_memory(self, new_harmony):\n        new_score = self.evaluate(new_harmony)\n        worst_idx = np.argmax(self.scores)\n        if new_score < self.scores[worst_idx]:\n            self.harmony_memory[worst_idx] = new_harmony\n            self.scores[worst_idx] = new_score\n            if new_score < self.best_score:\n                self.best_solution = new_harmony.copy()\n                self.best_score = new_score\n\n    def particle_interaction(self):\n        for i in range(self.harmony_memory_size):\n            for j in range(self.dim):\n                forces = np.sum(self.harmony_memory[:, j] - self.harmony_memory[i, j]) / (self.harmony_memory_size - 1)\n                self.harmony_memory[i, j] += self.interaction_strength * forces\n            self.harmony_memory[i] = np.clip(self.harmony_memory[i], self.func.bounds.lb, self.func.bounds.ub)\n            self.scores[i] = self.evaluate(self.harmony_memory[i])\n            if self.scores[i] < self.best_score:\n                self.best_solution = self.harmony_memory[i].copy()\n                self.best_score = self.scores[i]\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.harmony_memory[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_harmony_memory(lb, ub)\n\n        while self.evaluations < self.budget:\n            for _ in range(self.harmony_memory_size):\n                new_harmony = self.generate_harmony(lb, ub)\n                self.update_harmony_memory(new_harmony)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.particle_interaction()\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "PIHS_Optimizer", "description": "Particle Interaction Harmony Search (PIHS) combines harmony search with particle interaction dynamics to enhance global exploration and fine-tune solutions in high-dimensional spaces.", "configspace": "", "generation": 95, "fitness": 0.2757151519390805, "feedback": "The algorithm PIHS_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.27711406077042466, 0.27480849933294627, 0.2752228957138706]}, "mutation_prompt": null}
{"id": "747fbda3-8faf-42c6-b5d1-382f1227933b", "solution": "import numpy as np\n\nclass QE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 40\n        self.inertia_weight = 0.7\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.swarm = None\n        self.velocities = None\n        self.pbest_positions = None\n        self.pbest_scores = None\n        self.gbest_position = None\n        self.gbest_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_swarm(self, lb, ub):\n        self.swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        self.pbest_positions = self.swarm.copy()\n        self.pbest_scores = np.array([self.evaluate(ind) for ind in self.swarm])\n        self.update_gbest()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_gbest(self):\n        best_idx = np.argmin(self.pbest_scores)\n        if self.pbest_scores[best_idx] < self.gbest_score:\n            self.gbest_position = self.pbest_positions[best_idx].copy()\n            self.gbest_score = self.pbest_scores[best_idx]\n\n    def quantum_entanglement(self):\n        for i in range(self.swarm_size):\n            entanglement_effect = np.random.uniform(-0.5, 0.5, self.dim)\n            self.swarm[i] += entanglement_effect * np.abs(self.swarm[i] - self.gbest_position)\n            self.swarm[i] = np.clip(self.swarm[i], self.func.bounds.lb, self.func.bounds.ub)\n\n    def update_velocities_and_positions(self, lb, ub):\n        for i in range(self.swarm_size):\n            inertia = self.inertia_weight * self.velocities[i]\n            cognitive = self.cognitive_component * np.random.rand(self.dim) * (self.pbest_positions[i] - self.swarm[i])\n            social = self.social_component * np.random.rand(self.dim) * (self.gbest_position - self.swarm[i])\n\n            self.velocities[i] = inertia + cognitive + social\n            self.swarm[i] += self.velocities[i]\n            self.swarm[i] = np.clip(self.swarm[i], lb, ub)\n\n            new_score = self.evaluate(self.swarm[i])\n            if new_score < self.pbest_scores[i]:\n                self.pbest_positions[i] = self.swarm[i].copy()\n                self.pbest_scores[i] = new_score\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.update_velocities_and_positions(lb, ub)\n            self.update_gbest()\n            self.quantum_entanglement()\n            self.evaluations += self.swarm_size\n\n        return {'solution': self.gbest_position, 'fitness': self.gbest_score}", "name": "QE_PSO_Optimizer", "description": "The Quantum-Entangled Particle Swarm (QE-PSO) algorithm employs entangled particles inspired by quantum mechanics to dynamically balance exploration and exploitation, enhancing global optimization in complex search spaces.", "configspace": "", "generation": 96, "fitness": 0.27098232394984473, "feedback": "The algorithm QE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2769969918473637, 0.2773455660051686, 0.25860441399700196]}, "mutation_prompt": null}
{"id": "2404a82c-bc39-4b79-a6c3-7dc7bfb653e8", "solution": "import numpy as np\n\nclass QE_PSO_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w = 0.7\n        self.population = None\n        self.velocities = None\n        self.p_best_positions = None\n        self.p_best_scores = None\n        self.g_best_position = None\n        self.g_best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        self.p_best_positions = self.population.copy()\n        self.p_best_scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_global_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def update_personal_best(self, idx):\n        score = self.evaluate(self.population[idx])\n        if score < self.p_best_scores[idx]:\n            self.p_best_scores[idx] = score\n            self.p_best_positions[idx] = self.population[idx].copy()\n        return score\n\n    def update_global_best(self):\n        min_idx = np.argmin(self.p_best_scores)\n        if self.p_best_scores[min_idx] < self.g_best_score:\n            self.g_best_score = self.p_best_scores[min_idx]\n            self.g_best_position = self.p_best_positions[min_idx].copy()\n\n    def quantum_tunneling(self):\n        for i in range(self.population_size):\n            quantum_factor = np.random.uniform(-0.1, 0.1, self.dim)\n            quantum_position = self.g_best_position + quantum_factor * np.abs(self.population[i] - self.g_best_position)\n            quantum_position = np.clip(quantum_position, self.func.bounds.lb, self.func.bounds.ub)\n            quantum_score = self.evaluate(quantum_position)\n            if quantum_score < self.p_best_scores[i]:\n                self.population[i] = quantum_position\n                self.p_best_scores[i] = quantum_score\n                self.p_best_positions[i] = quantum_position\n                if quantum_score < self.g_best_score:\n                    self.g_best_score = quantum_score\n                    self.g_best_position = quantum_position.copy()\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                cognitive_velocity = self.c1 * r1 * (self.p_best_positions[i] - self.population[i])\n                social_velocity = self.c2 * r2 * (self.g_best_position - self.population[i])\n                self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n                self.population[i] += self.velocities[i]\n                self.population[i] = np.clip(self.population[i], lb, ub)\n                self.update_personal_best(i)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.update_global_best()\n            self.quantum_tunneling()\n\n        return {'solution': self.g_best_position, 'fitness': self.g_best_score}", "name": "QE_PSO_Optimizer", "description": "Quantum-Enhanced Particle Swarm Optimization (QE-PSO) integrates quantum tunneling concepts with particle swarm dynamics to achieve improved exploration and convergence in complex landscapes.", "configspace": "", "generation": 97, "fitness": 0.26372847800743376, "feedback": "The algorithm QE_PSO_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.2587170954007749, 0.27384106420146626, 0.25862727442006017]}, "mutation_prompt": null}
{"id": "159d15e5-a8d6-43c2-87e4-4301cacd1251", "solution": "import numpy as np\n\nclass QS_EADE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = np.arange(self.population_size)\n        np.random.shuffle(indices)\n        a, b, c = self.population[indices[:3]]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return np.clip(mutant, self.func.bounds.lb, self.func.bounds.ub)\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        trial = np.where(crossover_mask, mutant, target)\n        return np.clip(trial, self.func.bounds.lb, self.func.bounds.ub)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.choice([-1, 1], self.dim)\n            quantum_mutant = self.best_solution + quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def dynamic_influence(self):\n        influence_factor = np.exp(-self.evaluations / self.budget)\n        for i in range(self.population_size):\n            self.population[i] += influence_factor * (self.best_solution - self.population[i])\n            self.population[i] = np.clip(self.population[i], self.func.bounds.lb, self.func.bounds.ub)\n            self.scores[i] = self.evaluate(self.population[i])\n        self.update_best()\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.dynamic_influence()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_EADE_Optimizer", "description": "Quantum-Swarm Enhanced Adaptive Differential Evolution (QS-EADE) integrates quantum-inspired probability amplitudes and dynamic swarm intelligence to improve exploration and convergence in photonic structure optimization.", "configspace": "", "generation": 98, "fitness": 0.24588849272401406, "feedback": "The algorithm QS_EADE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.01.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.23548034417810293, 0.2556209258629084, 0.24656420813103086]}, "mutation_prompt": null}
{"id": "8cadb2e4-410d-43e2-ae1a-4f6a9b249ae9", "solution": "import numpy as np\n\nclass QS_ADE_DQE_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.F_min = 0.4\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n        self.population = None\n        self.scores = None\n        self.best_solution = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.scores = np.array([self.evaluate(ind) for ind in self.population])\n        self.update_best()\n\n    def evaluate(self, solution):\n        return self.func(solution)\n\n    def mutate(self, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        F = np.random.uniform(self.F_min, self.F_max)\n        mutant = a + F * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        crossover_mask = np.random.rand(self.dim) < CR\n        return np.where(crossover_mask, mutant, target)\n\n    def select(self, target_idx, trial):\n        trial_score = self.evaluate(trial)\n        if trial_score < self.scores[target_idx]:\n            self.population[target_idx] = trial\n            self.scores[target_idx] = trial_score\n            if trial_score < self.best_score:\n                self.best_score = trial_score\n                self.best_solution = trial.copy()\n\n    def quantum_inspired_mutation(self):\n        for i in range(self.population_size):\n            quantum_superposition = np.random.uniform(-1, 1, self.dim)\n            diversity_factor = np.sum(np.std(self.population, axis=0)) / self.dim\n            entanglement_strength = diversity_factor * np.random.rand()\n            quantum_mutant = self.best_solution + entanglement_strength * quantum_superposition * np.abs(self.population[i] - self.best_solution)\n            quantum_mutant = np.clip(quantum_mutant, self.func.bounds.lb, self.func.bounds.ub)\n            self.select(i, quantum_mutant)\n\n    def update_best(self):\n        best_idx = np.argmin(self.scores)\n        self.best_solution = self.population[best_idx].copy()\n        self.best_score = self.scores[best_idx]\n\n    def __call__(self, func):\n        self.func = func\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        self.initialize_population(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(i)\n                trial = self.crossover(self.population[i], mutant)\n                trial = np.clip(trial, lb, ub)\n                self.select(i, trial)\n                self.evaluations += 1\n                if self.evaluations >= self.budget:\n                    break\n            self.quantum_inspired_mutation()\n            self.evaluations += self.population_size\n\n        return {'solution': self.best_solution, 'fitness': self.best_score}", "name": "QS_ADE_DQE_Optimizer", "description": "Quantum-Swarm Adaptive Differential Evolution with Dynamic Quantum Entanglement (QS-ADE-DQE) introduces dynamic quantum entanglement to enhance global search capabilities by synergistically adjusting exploration patterns based on population diversity.", "configspace": "", "generation": 99, "fitness": 0.27247949414471506, "feedback": "The algorithm QS_ADE_DQE_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "e4f0ba8b-faa4-48ab-a445-637e81b25c30", "metadata": {"aucs": [0.272572256875212, 0.2711584982251145, 0.27370772733381865]}, "mutation_prompt": null}

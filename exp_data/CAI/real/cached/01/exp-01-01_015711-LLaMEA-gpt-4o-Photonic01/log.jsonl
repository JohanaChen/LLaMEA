{"id": "c3867b58-9087-452d-a123-e0ccbe949814", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                candidate = population[i] + np.random.uniform(-0.1, 0.1, self.dim) * (best - population[i])\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            # Dynamic parameter adjustment based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "A hybrid exploration-exploitation algorithm using chaotic maps for initialization and dynamic parameter adjustment to optimize photonic structures efficiently.", "configspace": "", "generation": 0, "fitness": 0.2623755564464843, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": null, "metadata": {"aucs": [0.266492971755911, 0.2677695415358726, 0.2528641560476692]}, "mutation_prompt": null}
{"id": "19ef20cb-20ba-43a4-b3b8-8704fee2d331", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                candidate = population[i] + np.random.uniform(-0.05, 0.05, self.dim) * (best - population[i])  # Adjusted perturbation range\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "Optimized the exploration-exploitation balance by adjusting the perturbation range in candidate generation for improved convergence.", "configspace": "", "generation": 1, "fitness": 0.26063382486874304, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "c3867b58-9087-452d-a123-e0ccbe949814", "metadata": {"aucs": [0.2655027559125338, 0.2663308895497647, 0.25006782914393066]}, "mutation_prompt": null}
{"id": "1f94f8d8-daf6-44c8-9f28-cc8ccf8287bd", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                candidate = population[i] + np.random.uniform(-0.1, 0.1, self.dim) * (best - population[i]) + np.random.normal(0, 0.01, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "Enhanced exploration by introducing Gaussian noise in candidate generation to improve convergence.", "configspace": "", "generation": 2, "fitness": 0.26175023058929164, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "c3867b58-9087-452d-a123-e0ccbe949814", "metadata": {"aucs": [0.2673477387632782, 0.2676867847625536, 0.2502161682420432]}, "mutation_prompt": null}
{"id": "e2791cd7-e7e4-4588-bca4-8897b404624c", "solution": "import numpy as np\n\nclass ChaoticPredatorPreyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def predator_prey_dynamics(self, population, fitness, best, lb, ub, func):\n        size = len(population)\n        for _ in range(size // 2):\n            predator_idx = np.random.randint(size)\n            prey_idx = np.random.randint(size)\n            if fitness[predator_idx] > fitness[prey_idx]:\n                continue\n            candidate = population[predator_idx] + np.random.uniform(-0.2, 0.2, self.dim) * (best - population[prey_idx])\n            candidate = np.clip(candidate, lb, ub)\n            candidate_fitness = func(candidate)\n            if candidate_fitness < fitness[prey_idx]:\n                population[prey_idx] = candidate\n                fitness[prey_idx] = candidate_fitness\n        return population, fitness\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            population, fitness = self.predator_prey_dynamics(population, fitness, best, lb, ub, func)\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < best_fitness:\n                best_fitness = fitness[best_idx]\n                best = population[best_idx]\n\n            if evaluations >= self.budget:\n                break\n\n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticPredatorPreyOptimizer", "description": "A chaotic predator-prey optimizer that employs chaotic maps for exploration and predator-prey dynamics for exploitation, enhancing convergence on photonic structure optimization.", "configspace": "", "generation": 3, "fitness": 0.23399280465897584, "feedback": "The algorithm ChaoticPredatorPreyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.01.", "error": "", "parent_id": "c3867b58-9087-452d-a123-e0ccbe949814", "metadata": {"aucs": [0.23986389765339566, 0.24234922097670142, 0.21976529534683042]}, "mutation_prompt": null}
{"id": "157fdb00-a737-4c90-a27e-f03c8a5e708a", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                candidate = population[i] + np.random.uniform(-0.15, 0.15, self.dim) * (best - population[i])  # Enhanced perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            # Dynamic parameter adjustment based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "A hybrid exploration-exploitation algorithm using chaotic maps for initialization, dynamic parameter adjustment, and enhanced perturbation to optimize photonic structures efficiently.", "configspace": "", "generation": 4, "fitness": 0.2626641219597627, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "c3867b58-9087-452d-a123-e0ccbe949814", "metadata": {"aucs": [0.26618210578752954, 0.2681913482250631, 0.2536189118666954]}, "mutation_prompt": null}
{"id": "2507d70c-0e61-4928-ba6a-7421d1201555", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_factor = np.random.uniform(0.1, 0.2)  # Adaptive perturbation\n                candidate = population[i] + perturbation_factor * (best - population[i])\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "A hybrid exploration-exploitation algorithm using chaotic maps for initialization, dynamic parameter adjustment, and adaptive perturbation to optimize photonic structures efficiently.", "configspace": "", "generation": 5, "fitness": 0.23905354845173657, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.00.", "error": "", "parent_id": "157fdb00-a737-4c90-a27e-f03c8a5e708a", "metadata": {"aucs": [0.2374796687715176, 0.2398505691120465, 0.23983040747164563]}, "mutation_prompt": null}
{"id": "9c01633f-3940-43c1-bee8-165e3492d38d", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                candidate = population[i] + np.random.uniform(-0.15, 0.15, self.dim) * (best - population[i]) + np.random.normal(0, 0.05, self.dim)  # Enhanced perturbation with Gaussian noise\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "Enhanced Chaotic Hybrid Optimizer: A refined chaotic hybrid algorithm that improves population diversity through Gaussian noise addition in perturbation, optimizing photonic structures more effectively.", "configspace": "", "generation": 6, "fitness": 0.264464855559654, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "157fdb00-a737-4c90-a27e-f03c8a5e708a", "metadata": {"aucs": [0.26433447797685394, 0.26924306967691336, 0.2598170190251947]}, "mutation_prompt": null}
{"id": "d7ea5951-9cdc-48a2-ab3b-7589f0e108b9", "solution": "import numpy as np\n\nclass AdaptiveChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n            elif chaotic_map == \"tent\":\n                population[i] = lb + (ub - lb) * (2 * r if r < 0.5 else 2 * (1 - r))\n        return np.clip(population, lb, ub)\n\n    def adaptive_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        scale_factor = 0.1\n\n        while evaluations < self.budget:\n            for i in range(size):\n                candidate = population[i] + np.random.uniform(-scale_factor, scale_factor, self.dim) * (best - population[i]) + np.random.normal(0, 0.05, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations >= self.budget:\n                break\n\n            if evaluations % (self.budget // 5) == 0:\n                scale = 0.8 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"tent\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                improved = new_population_fitness < fitness\n                population[improved] = new_population[improved]\n                fitness[improved] = new_population_fitness[improved]\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n            scale_factor = max(0.05, scale_factor * 0.99)  # Adaptive control\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.adaptive_hybrid_search(func, lb, ub)", "name": "AdaptiveChaoticHybridOptimizer", "description": "Adaptive Chaotic Hybrid Optimizer: Integrates adaptive parameter control and dynamic chaotic map switching to enhance exploration and exploitation across varying dimensional landscapes.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "9c01633f-3940-43c1-bee8-165e3492d38d", "metadata": {}, "mutation_prompt": null}
{"id": "12542575-105f-4752-98c6-18c9d3a99683", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.memory_size = 3  # Memory size for storing historical best solutions\n\n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        # Initialize memory with the best initial solutions\n        memory = np.tile(best, (self.memory_size, 1))\n        memory_fitness = np.full(self.memory_size, best_fitness)\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                candidate = population[i] + np.random.uniform(-0.15, 0.15, self.dim) * (best - population[i]) + np.random.normal(0, 0.05, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                        # Update memory\n                        memory[memory_fitness.argmax()] = best\n                        memory_fitness[memory_fitness.argmax()] = best_fitness\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best) + np.mean(memory, axis=0) * 0.1\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n                    memory[memory_fitness.argmax()] = best\n                    memory_fitness[memory_fitness.argmax()] = best_fitness\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "Adaptive Memory-Enhanced Chaotic Hybrid Optimizer: Introducing an adaptive memory mechanism to store and utilize historical best solutions, enhancing performance in photonic structure optimization.", "configspace": "", "generation": 8, "fitness": 0.26440621653492236, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "9c01633f-3940-43c1-bee8-165e3492d38d", "metadata": {"aucs": [0.264319131356923, 0.2692970044438463, 0.2596025138039978]}, "mutation_prompt": null}
{"id": "a2ef7ebf-985b-4fbc-8f9f-be5a159b7b1a", "solution": "import numpy as np\n\nclass AdaptiveChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def calculate_diversity(self, population):\n        return np.mean(np.std(population, axis=0))\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            diversity = self.calculate_diversity(population)\n            for i in range(size):\n                dynamic_scale = 0.1 + (0.5 * diversity)\n                candidate = population[i] + dynamic_scale * np.random.uniform(-0.2, 0.2, self.dim) * (best - population[i]) + np.random.normal(0, 0.05, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "AdaptiveChaoticHybridOptimizer", "description": "Adaptive Chaotic Hybrid Optimizer with Dynamic Perturbation: A novel variant introducing dynamic scaling based on diversity to enhance exploration and exploitation balance in optimizing photonic structures.", "configspace": "", "generation": 9, "fitness": 0.2519360372194025, "feedback": "The algorithm AdaptiveChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.00.", "error": "", "parent_id": "9c01633f-3940-43c1-bee8-165e3492d38d", "metadata": {"aucs": [0.2523293573197233, 0.2505246064976351, 0.25295414784084913]}, "mutation_prompt": null}
{"id": "599a7e22-857c-4734-b243-e39e036ca43a", "solution": "import numpy as np\n\nclass AdaptiveChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                adapt_factor = (fitness[i] - best_fitness) / (np.abs(fitness[i]) + 1e-9)  # Fitness-based adaptation\n                perturbation = np.random.uniform(-0.1, 0.1, self.dim) * (best - population[i]) + adapt_factor * np.random.normal(0, 0.05, self.dim) \n                candidate = population[i] + perturbation\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "AdaptiveChaoticHybridOptimizer", "description": "Adaptive Perturbation-based Chaotic Hybrid Optimizer: Introduces adaptive perturbation based on fitness change rates to enhance convergence and diversity in photonic structure optimization.", "configspace": "", "generation": 10, "fitness": 0.2613733901255023, "feedback": "The algorithm AdaptiveChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "9c01633f-3940-43c1-bee8-165e3492d38d", "metadata": {"aucs": [0.26741134168764513, 0.26739290670776805, 0.24931592198109376]}, "mutation_prompt": null}
{"id": "33d80756-ab01-43da-9c98-67537d11441d", "solution": "import numpy as np\n\nclass EnhancedChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def levy_flight(self, size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size)\n        v = np.random.normal(0, 1, size)\n        step = u / abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = size\n        \n        while evaluations < self.budget:\n            scaling_factor = 0.5 + 0.5 * (1 - evaluations / self.budget)\n            for i in range(size):\n                candidate = population[i] + scaling_factor * (best - population[i]) + self.levy_flight(self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticHybridOptimizer", "description": "Adaptive Search with Chaotic Perturbation: Introduces adaptive scaling and Lévy flight perturbation to enhance exploration and exploitation in optimizing photonic structures.", "configspace": "", "generation": 11, "fitness": 0.24815098635324348, "feedback": "The algorithm EnhancedChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.01.", "error": "", "parent_id": "9c01633f-3940-43c1-bee8-165e3492d38d", "metadata": {"aucs": [0.25134533935465386, 0.2597230538012192, 0.23338456590385737]}, "mutation_prompt": null}
{"id": "dffddb98-30b3-4b77-95da-1634a8dcce88", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                candidate = population[i] + np.random.uniform(-0.10, 0.10, self.dim) * (best - population[i]) + np.random.normal(0, 0.05, self.dim)  # Adjusted uniform noise scale\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "Enhanced Chaotic Hybrid Optimizer with adjusted noise scale to improve convergence speed.", "configspace": "", "generation": 12, "fitness": 0.26257986626882573, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "9c01633f-3940-43c1-bee8-165e3492d38d", "metadata": {"aucs": [0.26852223035904565, 0.2681182165230559, 0.2510991519243757]}, "mutation_prompt": null}
{"id": "78040a0b-84c8-44f7-a2d4-56d8f521fd39", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                idxs = [idx for idx in range(size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                candidate = mutant + np.random.normal(0, 0.05, self.dim)\n                \n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "Stochastic Chaotic Hybrid Optimizer: Combines chaotic maps and differential mutation to improve exploration and exploitation, optimizing photonic structures efficiently.", "configspace": "", "generation": 13, "fitness": 0.26054577280270336, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "9c01633f-3940-43c1-bee8-165e3492d38d", "metadata": {"aucs": [0.26245697095922926, 0.2649143004709644, 0.25426604697791644]}, "mutation_prompt": null}
{"id": "2bfe92fc-dabf-4cc5-bfc3-f55ef2855a30", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                adaptive_scale = 0.05 * (1 - evaluations / self.budget)  # Adaptive Gaussian noise scale\n                candidate = population[i] + np.random.uniform(-0.15, 0.15, self.dim) * (best - population[i]) + np.random.normal(0, adaptive_scale, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "Improved Chaotic Hybrid Optimizer with adaptive Gaussian noise scale for enhanced convergence in photonic structure optimization.", "configspace": "", "generation": 14, "fitness": 0.26369031670838067, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "9c01633f-3940-43c1-bee8-165e3492d38d", "metadata": {"aucs": [0.2639721302665694, 0.26868574764757003, 0.2584130722110026]}, "mutation_prompt": null}
{"id": "4aaabafb-c25d-4cae-a56b-db8cd69bb2f3", "solution": "import numpy as np\n\nclass AdaptiveMemoryChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.memory = []\n\n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n\n        while evaluations < self.budget:\n            self.memory = sorted(self.memory, key=lambda x: x[1])[:min(10, len(self.memory))]\n            for i in range(size):\n                if self.memory:\n                    mem_best = self.memory[np.random.randint(len(self.memory))][0]\n                    candidate = population[i] + np.random.uniform(-0.15, 0.15, self.dim) * (best - mem_best) + np.random.normal(0, 0.05, self.dim * (1 - evaluations / self.budget))\n                else:\n                    candidate = population[i] + np.random.uniform(-0.15, 0.15, self.dim) * (best - population[i]) + np.random.normal(0, 0.05, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    self.memory.append((candidate, candidate_fitness))\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "AdaptiveMemoryChaoticOptimizer", "description": "Adaptive Memory-Based Chaotic Optimizer: Integrates historical memory of solutions and adaptive perturbation strategies to enhance convergence in photonic structure optimization.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"expected a sequence of integers or a single integer, got '9.9935'\").", "error": "TypeError(\"expected a sequence of integers or a single integer, got '9.9935'\")", "parent_id": "9c01633f-3940-43c1-bee8-165e3492d38d", "metadata": {}, "mutation_prompt": null}
{"id": "f7d35482-e2b4-432e-8053-26603b1a1ce1", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.15 * (1 - evaluations / self.budget)  # Adaptive perturbation\n                candidate = population[i] + np.random.uniform(-perturbation_intensity, perturbation_intensity, self.dim) * (best - population[i]) + np.random.normal(0, 0.05, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "An adaptive chaotic hybrid optimizer that enhances convergence by dynamically adjusting the perturbation intensity based on evaluation progress.", "configspace": "", "generation": 16, "fitness": 0.26505250932463986, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "9c01633f-3940-43c1-bee8-165e3492d38d", "metadata": {"aucs": [0.2642468469023532, 0.26926418311492006, 0.2616464979566463]}, "mutation_prompt": null}
{"id": "39afd649-656b-4abb-8591-7e7d4bbe55f9", "solution": "import numpy as np\n\nclass SynergisticChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                f = 0.8 + 0.2 * np.random.rand()  # Differential weight factor\n                r1, r2 = np.random.randint(size, size=2)\n                diff = f * (population[r1] - population[r2])\n                candidate = population[i] + diff + np.random.normal(0, 0.05, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "SynergisticChaoticOptimizer", "description": "A synergistic chaotic optimizer merging differential evolutions with adaptive perturbations to enhance diversification and intensification.", "configspace": "", "generation": 17, "fitness": 0.2648432924972655, "feedback": "The algorithm SynergisticChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "f7d35482-e2b4-432e-8053-26603b1a1ce1", "metadata": {"aucs": [0.2702306151036108, 0.26778160822041086, 0.25651765416777494]}, "mutation_prompt": null}
{"id": "bb57b8ce-e06f-4628-aaee-b3a8d71bff05", "solution": "import numpy as np\n\nclass ChaoticHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.1 * (1 - evaluations / self.budget)  # Adjusted perturbation intensity\n                candidate = population[i] + np.random.uniform(-perturbation_intensity, perturbation_intensity, self.dim) * (best - population[i]) + np.random.normal(0, 0.05, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations >= self.budget:\n                break\n            \n            if evaluations % (self.budget // 10) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "ChaoticHybridOptimizer", "description": "A refined chaotic hybrid optimizer with improved perturbation strategy for enhanced exploitation and exploration balance.", "configspace": "", "generation": 18, "fitness": 0.2628715464188931, "feedback": "The algorithm ChaoticHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.01.", "error": "", "parent_id": "f7d35482-e2b4-432e-8053-26603b1a1ce1", "metadata": {"aucs": [0.2682447467336234, 0.26866193850582176, 0.2517079540172341]}, "mutation_prompt": null}
{"id": "65666206-e67a-4439-8128-453d66871ad0", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - evaluations / self.budget)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "An enhanced chaotic optimizer that incorporates dynamic neighborhood exploration to improve solution diversity and convergence stability.", "configspace": "", "generation": 19, "fitness": 0.27071276266594774, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "f7d35482-e2b4-432e-8053-26603b1a1ce1", "metadata": {"aucs": [0.26708524191876526, 0.27397301295441734, 0.27108003312466067]}, "mutation_prompt": null}
{"id": "8fed7d8e-4703-4805-8d79-7a0ca1d0f73e", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - evaluations / self.budget)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "An enhanced chaotic optimizer with adaptive neighborhood scaling for improved exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.26784289760581176, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.2644307744898007, 0.27020477242050733, 0.2688931459071273]}, "mutation_prompt": null}
{"id": "3b85cd6c-18b2-4434-a771-b7256ed91a91", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - evaluations / self.budget)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\" if evaluations < self.budget / 2 else \"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced chaotic optimizer using adaptive chaotic maps for improved exploration and exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.27071276266594774, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.26708524191876526, 0.27397301295441734, 0.27108003312466067]}, "mutation_prompt": null}
{"id": "931591a8-d90d-46b9-9302-64dd61b36572", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - evaluations / self.budget)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "An enhanced chaotic optimizer with improved perturbation intensity calculation for better exploration and convergence.", "configspace": "", "generation": 22, "fitness": 0.26784289760581176, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.2644307744898007, 0.27020477242050733, 0.2688931459071273]}, "mutation_prompt": null}
{"id": "69c45b19-3e1b-4830-95e0-f6daac45dc21", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - evaluations / self.budget)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\" if evaluations < self.budget // 2 else \"logistic\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced hybrid search by introducing adaptive chaotic map selection to improve convergence.", "configspace": "", "generation": 23, "fitness": 0.2707026409086774, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.267075686346528, 0.2739522032548435, 0.27108003312466067]}, "mutation_prompt": null}
{"id": "0e355d6a-1847-466e-87a5-86fa6a8b2dae", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n            elif chaotic_map == \"tent\":  # Added tent map option\n                population[i] = lb + (ub - lb) * (2 * r) if r < 0.5 else lb + (ub - lb) * (2 * (1 - r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - evaluations / self.budget)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced diversity by adopting a tent map for initial population, improving exploration in diverse search spaces.", "configspace": "", "generation": 24, "fitness": 0.27071276266594774, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.26708524191876526, 0.27397301295441734, 0.27108003312466067]}, "mutation_prompt": null}
{"id": "6934af44-63ff-4bee-8a78-34bebb3a4924", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - evaluations / self.budget)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "An enhanced chaotic optimizer with improved global exploration through adaptive chaotic maps.", "configspace": "", "generation": 25, "fitness": 0.27071276266594774, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.26708524191876526, 0.27397301295441734, 0.27108003312466067]}, "mutation_prompt": null}
{"id": "23f5c198-b337-4086-b7bc-f38747a8f6c2", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.95 * r * (1 - r))  # Adjusted constant\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - evaluations / self.budget)\n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved convergence by adjusting the chaotic map constant for better exploration.", "configspace": "", "generation": 26, "fitness": 0.26990601376460865, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.26849708889700463, 0.27297802035780727, 0.26824293203901406]}, "mutation_prompt": null}
{"id": "fc7c62a3-8cbe-4bca-b2af-2bab7d8f2c1c", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget) ** 2)  # Quadratic decay\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduced a quadratic decay in perturbation intensity to refine exploration and exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.26727527260956546, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.26557911737131, 0.272711107041406, 0.26353559341598043]}, "mutation_prompt": null}
{"id": "75bd58ed-cb98-4a68-b415-3778a6af0e92", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - evaluations / self.budget)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "A refined enhanced chaotic optimizer with an increased perturbation intensity for improved exploration.", "configspace": "", "generation": 28, "fitness": 0.26784289760581176, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.2644307744898007, 0.27020477242050733, 0.2688931459071273]}, "mutation_prompt": null}
{"id": "db1ea70c-5df3-4d73-ae37-d43d65142f8c", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - evaluations / self.budget)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "An enhanced chaotic optimizer with increased perturbation intensity to improve exploration.", "configspace": "", "generation": 29, "fitness": 0.26784289760581176, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.2644307744898007, 0.27020477242050733, 0.2688931459071273]}, "mutation_prompt": null}
{"id": "00caccb1-0f5e-46ed-bf57-94fd917701a3", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**0.5)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved convergence by adjusting perturbation intensity based on a nonlinear function of evaluations.", "configspace": "", "generation": 30, "fitness": 0.2715942976171874, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "65666206-e67a-4439-8128-453d66871ad0", "metadata": {"aucs": [0.26940974202330104, 0.2749919450193612, 0.2703812058089]}, "mutation_prompt": null}
{"id": "37f450ae-1422-4b8d-9cbc-8baddcce9502", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**3)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced convergence by optimizing the perturbation intensity formula based on a cubic function of evaluations.", "configspace": "", "generation": 31, "fitness": 0.2667322899056958, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "00caccb1-0f5e-46ed-bf57-94fd917701a3", "metadata": {"aucs": [0.26497683737340605, 0.2722070912628298, 0.2630129410808516]}, "mutation_prompt": null}
{"id": "abf000ea-e51f-492c-b04f-d3197d1d2869", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**2)  # Adjusted intensity (quadratic)\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced convergence by dynamically adjusting neighborhood size using a quadratic function of evaluations.", "configspace": "", "generation": 32, "fitness": 0.26727527260956546, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "00caccb1-0f5e-46ed-bf57-94fd917701a3", "metadata": {"aucs": [0.26557911737131, 0.272711107041406, 0.26353559341598043]}, "mutation_prompt": null}
{"id": "edf802dd-88cf-4363-9287-ef7a31ef930c", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.1 * (1 - (evaluations / self.budget)**0.5)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Tightened neighborhood exploration by reducing perturbation intensity for better local search.", "configspace": "", "generation": 33, "fitness": 0.2708873765009876, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "00caccb1-0f5e-46ed-bf57-94fd917701a3", "metadata": {"aucs": [0.26830950811421594, 0.27650049531953613, 0.2678521260692107]}, "mutation_prompt": null}
{"id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced exploration by modifying the perturbation intensity formula to use a cubic root for better diversity.", "configspace": "", "generation": 34, "fitness": 0.2722452821499677, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "00caccb1-0f5e-46ed-bf57-94fd917701a3", "metadata": {"aucs": [0.2696106995321996, 0.2762846429197976, 0.2708405039979058]}, "mutation_prompt": null}
{"id": "c8c05255-6557-4093-9faa-a0ebca4ca8db", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.3 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced Chaotic Optimizer with improved perturbation intensity for better convergence.", "configspace": "", "generation": 35, "fitness": 0.270930073134788, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "metadata": {"aucs": [0.2678264918526847, 0.2744362770588449, 0.27052745049283444]}, "mutation_prompt": null}
{"id": "8df69151-58b3-4317-9f8f-b51b940f0e94", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * np.exp(-evaluations / self.budget)  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced local exploitation by adjusting neighbor radius decay with exponential decay for precision.", "configspace": "", "generation": 36, "fitness": 0.2697283686693403, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "metadata": {"aucs": [0.26677038424993227, 0.2729922882753465, 0.2694224334827422]}, "mutation_prompt": null}
{"id": "3c4819b2-8785-4461-bd2a-ec3546887606", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.18 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved exploitation by slightly enhancing perturbation intensity formula for finer adjustments.", "configspace": "", "generation": 37, "fitness": 0.26896010712822455, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.01.", "error": "", "parent_id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "metadata": {"aucs": [0.2678540115464966, 0.2758091373723669, 0.2632171724658102]}, "mutation_prompt": null}
{"id": "2b93cc5d-10dc-41f0-aa64-9cece1dc8ca6", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (3.9 * (evaluations / self.budget) * (1 - (evaluations / self.budget)))**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced solution diversity by integrating a chaotic map into the perturbation intensity formula.", "configspace": "", "generation": 38, "fitness": 0.270893206602372, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "metadata": {"aucs": [0.26827623061571637, 0.2765223887735716, 0.26788100041782803]}, "mutation_prompt": null}
{"id": "a5714c66-0b58-499b-b37e-f378a4525b7e", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx] * 0.9 + best * 0.1  # Modified line for better convergence\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced exploitation by modifying the best solution update mechanism to increase convergence.", "configspace": "", "generation": 39, "fitness": 0.2722452821499677, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "metadata": {"aucs": [0.2696106995321996, 0.2762846429197976, 0.2708405039979058]}, "mutation_prompt": null}
{"id": "3701ea14-c649-4677-9c15-9335a97b49dc", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // int(6 - 3 * (evaluations / self.budget))) == 0:  # Adjusted frequency\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved convergence by adjusting the chaotic map switch frequency based on a dynamic, evaluation-dependent schedule.", "configspace": "", "generation": 40, "fitness": 0.272243995481555, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "metadata": {"aucs": [0.2696106995321996, 0.27627406905680274, 0.27084721785566257]}, "mutation_prompt": null}
{"id": "278b3a3e-99c9-4093-b7b5-0b191a5ca000", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved convergence by adjusting the dynamic neighborhood scaling factor from 0.2 to 0.25 for refined exploration.", "configspace": "", "generation": 41, "fitness": 0.26965229343508024, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "metadata": {"aucs": [0.26809995678857923, 0.27125920080288946, 0.269597722713772]}, "mutation_prompt": null}
{"id": "b0696ed9-8119-428d-8365-ba934f3a2e59", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/2))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced exploration by modifying the perturbation intensity formula to use an inverse square root for improved convergence.", "configspace": "", "generation": 42, "fitness": 0.2715942976171874, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "metadata": {"aucs": [0.26940974202330104, 0.2749919450193612, 0.2703812058089]}, "mutation_prompt": null}
{"id": "4aeab1e2-049e-4dec-b77d-e0b77b99dc95", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i]:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 0.8 * (1.0 - (evaluations / self.budget))  # Changed from 1.0 to 0.8 for dynamic adjustment\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduced a dynamic adjustment to the neighborhood scale factor for better exploitation.", "configspace": "", "generation": 43, "fitness": 0.27221858470376753, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "metadata": {"aucs": [0.2695951539909739, 0.2762805683924162, 0.27078003172791243]}, "mutation_prompt": null}
{"id": "ad408f08-963f-444b-b3d2-34bc08c39e28", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                if candidate_fitness < fitness[i] or np.random.rand() < 0.1:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced selection mechanism by introducing a probability factor for exploration versus exploitation.", "configspace": "", "generation": 44, "fitness": 0.27279251581719227, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "84773c47-962e-4981-b9e0-0110fd1b81e9", "metadata": {"aucs": [0.27225189558276885, 0.2727980014253293, 0.2733276504434786]}, "mutation_prompt": null}
{"id": "66d3b68a-f5a8-4233-a0bb-266ae745a341", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Dynamic probability factor based on improvement\n                improvement_rate = max(0, (fitness[i] - candidate_fitness) / abs(fitness[i])) if fitness[i] != 0 else 0\n                if candidate_fitness < fitness[i] or np.random.rand() < 0.1 + 0.1 * improvement_rate:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Utilize a dynamic probability factor for exploration versus exploitation based on the improvement rate.", "configspace": "", "generation": 45, "fitness": 0.27279251581719227, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "ad408f08-963f-444b-b3d2-34bc08c39e28", "metadata": {"aucs": [0.27225189558276885, 0.2727980014253293, 0.2733276504434786]}, "mutation_prompt": null}
{"id": "12275038-7f6c-4be0-8161-6f4343127e1e", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                if candidate_fitness < fitness[i] or np.random.rand() < 0.15:  # Adjusted probability factor\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved the probability factor for exploration to enhance convergence.", "configspace": "", "generation": 46, "fitness": 0.2728721880557321, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "ad408f08-963f-444b-b3d2-34bc08c39e28", "metadata": {"aucs": [0.2739326956344126, 0.2727273943654448, 0.2719564741673389]}, "mutation_prompt": null}
{"id": "1a11fc39-3689-4e83-aec2-2aea93652a27", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        memory = best.copy()  # Memory mechanism for historical best\n\n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                if candidate_fitness < fitness[i] or np.random.rand() < 0.15:  # Adjusted probability factor\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                        memory = best.copy()  # Update memory\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = memory + scale * (new_population - memory)  # Utilize memory\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduce a memory mechanism to enhance exploration and exploitation balance.", "configspace": "", "generation": 47, "fitness": 0.2728721880557321, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "12275038-7f6c-4be0-8161-6f4343127e1e", "metadata": {"aucs": [0.2739326956344126, 0.2727273943654448, 0.2719564741673389]}, "mutation_prompt": null}
{"id": "3a30c1a8-99b6-4a7a-b9fe-f7b89f7e9b41", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n            elif chaotic_map == \"tent\":\n                population[i] = lb + (ub - lb) * np.where(r < 0.5, 2*r, 2*(1-r))  # New map condition\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/2.5))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                if candidate_fitness < fitness[i] or np.random.rand() < 0.15:  # Adjusted probability factor\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"tent\")  # Chaotic map switch\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduced adaptive chaotic maps and dynamically adjusted perturbation intensity to enhance convergence.", "configspace": "", "generation": 48, "fitness": 0.27145223596747886, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "12275038-7f6c-4be0-8161-6f4343127e1e", "metadata": {"aucs": [0.27168998792070387, 0.27122228099829915, 0.2714444389834335]}, "mutation_prompt": null}
{"id": "552d4180-fb2a-41ab-9441-9eaa929fc0c0", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb) * np.log1p(evaluations)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                if candidate_fitness < fitness[i] or np.random.rand() < 0.15:  # Adjusted probability factor\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced convergence by adjusting neighborhood radius dynamically based on evaluations.", "configspace": "", "generation": 49, "fitness": 0.2529546431495202, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.00.", "error": "", "parent_id": "12275038-7f6c-4be0-8161-6f4343127e1e", "metadata": {"aucs": [0.25114024853823047, 0.2540032560565616, 0.25372042485376856]}, "mutation_prompt": null}
{"id": "06f6b081-fb0b-4f1d-a34f-b26357c94aa6", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        chaotic_map = \"logistic\"\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                if candidate_fitness < fitness[i] or np.random.rand() < 0.15:  # Adjusted probability factor\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                chaotic_map = \"sine\" if chaotic_map == \"logistic\" else \"logistic\"  # Switch chaotic map\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=chaotic_map)\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduce a dynamic chaotic map switching mechanism to improve exploration.", "configspace": "", "generation": 50, "fitness": 0.2728704184700421, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "12275038-7f6c-4be0-8161-6f4343127e1e", "metadata": {"aucs": [0.2739326956344126, 0.27272208560837485, 0.2719564741673389]}, "mutation_prompt": null}
{"id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced selection mechanism incorporating fitness-proportional acceptance and adaptive probability factor.", "configspace": "", "generation": 51, "fitness": 0.27448492195430624, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "12275038-7f6c-4be0-8161-6f4343127e1e", "metadata": {"aucs": [0.27465161885160627, 0.27534155787185843, 0.27346158913945395]}, "mutation_prompt": null}
{"id": "3319fab2-bc70-449c-a403-0b5281e75154", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Enhance the acceptance probability with a chaotic factor\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10) + 0.05 * np.sin(np.pi * evaluations / self.budget)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced selection mechanism with adaptive chaotic exploration using dual chaotic maps.", "configspace": "", "generation": 52, "fitness": 0.27427672333903824, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27431767038203936, 0.2748976329718491, 0.2736148666632262]}, "mutation_prompt": null}
{"id": "69ad75f4-aa36-4006-9ab7-de585819a248", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.15 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Refined perturbation intensity function for smoother convergence.", "configspace": "", "generation": 53, "fitness": 0.2722746386144078, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2716007996449138, 0.27570012052299797, 0.2695229956753117]}, "mutation_prompt": null}
{"id": "fc08c36a-b48d-4155-8139-e5b2b37cd614", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.95 * r * (1 - r))  # Changed parameter from 3.9 to 3.95\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Fine-tuned the chaotic map's parameters for better diversity in search space exploration.", "configspace": "", "generation": 54, "fitness": 0.2720986363923527, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27504741972916713, 0.2712514837158696, 0.26999700573202146]}, "mutation_prompt": null}
{"id": "af514f27-fb24-4804-962b-2ba3e0eee732", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                mutation_intensity = 0.3 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity for mutation\n                neighbor_radius = mutation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 0.5 * (1.0 - (evaluations / self.budget))  # Reduced scaling for better convergence\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduce a dynamic mutation operator and adaptive population scaling for enhanced exploration and convergence.", "configspace": "", "generation": 55, "fitness": 0.2715182287718061, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2704490520390178, 0.2704578307016474, 0.27364780357475305]}, "mutation_prompt": null}
{"id": "dc86cd90-2315-4570-9b2c-f70616f1e745", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Slightly increased perturbation intensity to enhance exploration capability.", "configspace": "", "generation": 56, "fitness": 0.27134531247003296, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.273916856364551, 0.2713162883575544, 0.26880279268799356]}, "mutation_prompt": null}
{"id": "f3203e17-7bcd-4e52-b6f1-a8eb8750b639", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        dynamic_size = 5 + self.dim // 3  # Adjusted dynamic population size\n        population = self.initialize_population(lb, ub, dynamic_size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = dynamic_size\n        \n        while evaluations < self.budget:\n            for i in range(dynamic_size):\n                perturbation_intensity = 0.25 * (1 - (evaluations / self.budget)**(1/2.5))  # Adjusted perturbation strategy\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, dynamic_size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += dynamic_size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introducing a dynamic population size and enhancing perturbation strategies to adaptively refine the search process.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (8,) (8,10) (8,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (8,) (8,10) (8,10) ')", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {}, "mutation_prompt": null}
{"id": "19783c9d-3fda-4eb2-9533-c1c0876689f8", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.2 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced exploitation through adaptive perturbation and acceptance probability for improved convergence.", "configspace": "", "generation": 58, "fitness": 0.2710078861387078, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2720980588984774, 0.26956846314460225, 0.2713571363730437]}, "mutation_prompt": null}
{"id": "baf0042b-9f9e-4e21-8019-60e0619d2507", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n            elif chaotic_map == \"cosine\":  # Introduced cosine map\n                population[i] = lb + (ub - lb) * (np.cos(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                # Adjusted perturbation intensity dynamically\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/2))  \n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduced cosine chaotic map and adjusted perturbation intensity dynamically for improved convergence.", "configspace": "", "generation": 59, "fitness": 0.2728827866261358, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27362566781735775, 0.2706560244919566, 0.2743666675690931]}, "mutation_prompt": null}
{"id": "e7afa6d8-dd31-4bff-805d-aafc1c77d47c", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor with dynamic decay\n                decay_factor = 1.0 - (evaluations / self.budget)  # Dynamic decay\n                acceptance_probability = (0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)) * decay_factor  # Adjusted probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduce a dynamic acceptance probability decay factor to improve exploration-exploitation balance.", "configspace": "", "generation": 60, "fitness": 0.2742436910471294, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2743963177882267, 0.2748802274698312, 0.27345452788333036]}, "mutation_prompt": null}
{"id": "dc4ec287-41ac-4552-a728-c6f1bbb40dbe", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic_sine_blend\":  # New hybrid chaotic map blend\n                population[i] = lb + (ub - lb) * ((3.9 * r * (1 - r)) + np.sin(np.pi * r)) / 2\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic_sine_blend\")  # Use new map\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))\n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved chaotic adaptation by introducing a new hybrid chaotic map blend for initialization.", "configspace": "", "generation": 61, "fitness": 0.2723751863301643, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27311886521404616, 0.27086119875797676, 0.27314549501846996]}, "mutation_prompt": null}
{"id": "877e4cb9-1e70-4bd3-a8ab-64262038c099", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = size\n        memory = [best.copy()] # Memory to store elite solutions\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                adaptive_scale = 0.5 * (np.random.rand() + 0.5)  # Adaptive scaling factor\n                neighbor_radius = adaptive_scale * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.2 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                        memory.append(best.copy())  # Update memory\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        # Integrate memory for final decision\n        for elite in memory:\n            elite_fitness = func(elite)\n            if elite_fitness < best_fitness:\n                best_fitness = elite_fitness\n                best = elite\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Adaptive chaotic exploration with reinforced diversity and memory-based selection for improved optimization.", "configspace": "", "generation": 62, "fitness": 0.2591870383767407, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.25913592814430064, 0.25857347252452456, 0.2598517144613969]}, "mutation_prompt": null}
{"id": "ca7789a6-2f08-4b90-a160-7ad55c8a95fa", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                # Change: Introduced scaling factor to perturbation\n                scale_factor = 0.5 + 0.5 * (evaluations / self.budget)\n                perturbation_intensity = 0.2 * scale_factor * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduced a scaling factor to dynamic neighborhood size for enhanced exploration during later stages.", "configspace": "", "generation": 63, "fitness": 0.2708655922118752, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2714433731207797, 0.27539069333519217, 0.2657627101796537]}, "mutation_prompt": null}
{"id": "a8ba9ab9-cbbf-4ca7-bfe1-b01c9c947b02", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 4) == 0:  # Adjusted frequency\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhance exploration by modifying chaotic map intensity and periodic adjustment frequency.", "configspace": "", "generation": 64, "fitness": 0.2710461502755427, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2732692266441894, 0.27127988309597073, 0.2685893410864679]}, "mutation_prompt": null}
{"id": "4acadc5c-c228-4a36-9c8c-23a4d3515971", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.3 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Fine-tuning the perturbation intensity formula for balanced exploration and exploitation.", "configspace": "", "generation": 65, "fitness": 0.2713890569159109, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2705241157223057, 0.26977906021497855, 0.27386399481044843]}, "mutation_prompt": null}
{"id": "a7390ffa-4b0a-438c-a12d-b881c64cd620", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                # Change: Incorporate cosine annealing into perturbation intensity\n                perturbation_intensity = 0.2 * (1 - 0.5 * (1 + np.cos(np.pi * evaluations / self.budget)))\n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduce adaptive learning rate via cosine annealing to enhance exploration-exploitation balance.", "configspace": "", "generation": 66, "fitness": 0.2610078983506749, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2639417524756179, 0.26407809649486125, 0.2550038460815456]}, "mutation_prompt": null}
{"id": "0125fc2a-9a0b-42f9-9674-74e4e237c56a", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.3 * (1 - (evaluations / self.budget))  # Increased intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 6) == 0:  # More frequent re-initialization trigger\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduced adaptive perturbation and dynamic re-initialization to enhance exploration and convergence balance.", "configspace": "", "generation": 67, "fitness": 0.27171316752929425, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2709631372921829, 0.2718079835992645, 0.2723683816964353]}, "mutation_prompt": null}
{"id": "f24a5105-62cc-4680-ac40-37e28eb818e0", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n            elif chaotic_map == \"gauss\":\n                r = np.mod(1/r, 1)  # A simple Gauss/iterated map\n                population[i] = lb + (ub - lb) * r\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"gauss\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**0.5)  # Adjusted intensity\n            for i in range(size):\n                neighbor_radius = perturbation_intensity * (ub - lb)  \n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.2 + (fitness[i] - candidate_fitness) / (np.abs(fitness[i] + candidate_fitness) + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  \n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Integrating dynamic scaling and adaptive chaotic maps to enhance exploration and exploitation balance.", "configspace": "", "generation": 68, "fitness": 0.2743592747149498, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2749315657693303, 0.27462462515893016, 0.27352163321658896]}, "mutation_prompt": null}
{"id": "c4ef407e-eaaf-4796-b8f3-bed34a8eb673", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (4.0 * r * (1 - r)) # Modified logistic map parameter\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - (evaluations / self.budget)**(1/3)) # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved population initialization and adaptive perturbation intensity for enhanced convergence.", "configspace": "", "generation": 69, "fitness": 0.2727306756421886, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27001020628424144, 0.2741173602798421, 0.27406446036248233]}, "mutation_prompt": null}
{"id": "226d18fb-8955-4b4d-9b08-438a2e91e145", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.15 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.2 + (fitness[i] - candidate_fitness) / (np.abs(fitness[i] + candidate_fitness) + 1e-10)  # Enhanced probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 4) == 0:  # Changed frequency of strategy\n                scale = 0.5 * (1.0 - (evaluations / self.budget))  # Dynamic scaling\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                combined_population = np.vstack((population, new_population))\n                combined_fitness = np.hstack((fitness, new_population_fitness))\n                elite_idx = np.argsort(combined_fitness)[:size]\n                population = combined_population[elite_idx]\n                fitness = combined_fitness[elite_idx]\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved adaptive chaotic optimizer with dynamic scaling and strategic elitism preservation.", "configspace": "", "generation": 70, "fitness": 0.27026162379234714, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2687375751756057, 0.2753481080041872, 0.26669918819724847]}, "mutation_prompt": null}
{"id": "ca5075ca-2f5b-4f47-bb9e-d47f1ef9c36e", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n            else:\n                # New chaotic map for diversity\n                population[i] = lb + (ub - lb) * np.abs(np.tan(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.3 * (1 - (evaluations / self.budget)**(1/4))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.25 + (fitness[i] - candidate_fitness) / np.sqrt(np.abs(fitness[i] + candidate_fitness + 1e-10))  # Non-linear scaling\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 4) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "An improved chaotic optimization strategy using adaptive learning rates and non-linear fitness scaling for robust convergence.", "configspace": "", "generation": 71, "fitness": 0.26994936271423814, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2705876215377253, 0.27136501790807166, 0.2678954486969174]}, "mutation_prompt": null}
{"id": "a67fae76-f9c1-430f-9edc-ea72b75b0b44", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Modified acceptance probability for better convergence\n                acceptance_probability = 0.25 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Altered acceptance probability to improve convergence by enhancing candidate selection.", "configspace": "", "generation": 72, "fitness": 0.27195884984966817, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2734215327311229, 0.2734446275296154, 0.26901038928826626]}, "mutation_prompt": null}
{"id": "b4be03ee-c728-43d6-a190-ea006801fe37", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(2/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced dynamic neighborhood by introducing a nonlinear scaling factor for perturbation intensity.", "configspace": "", "generation": 73, "fitness": 0.26937603195384935, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2692299596273501, 0.2691464470464352, 0.2697516891877628]}, "mutation_prompt": null}
{"id": "b2e05217-9e86-47bc-9be9-3501063cd601", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.3 * (1 - (evaluations / self.budget)**(1/2))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.2 + 0.5 * np.tanh((fitness[i] - candidate_fitness) / 0.1)  # Adjusted probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                elite_fraction = 0.2  # Retain top individuals\n                num_elites = max(1, int(size * elite_fraction))\n                elite_indices = fitness.argsort()[:num_elites]\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n                for elite_idx in elite_indices:\n                    population[elite_idx] = population[elite_idx]  # Retain elite\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Dynamic chaotic exploration with adaptive perturbation and elite retention to enhance global search.", "configspace": "", "generation": 74, "fitness": 0.2706547453067766, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.271172462133621, 0.26916406863858544, 0.2716277051481233]}, "mutation_prompt": null}
{"id": "a4ec9685-a2ba-45f0-886e-57dbb61ba997", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced chaotic exploration with a tuned perturbation intensity factor for improved global search.", "configspace": "", "generation": 75, "fitness": 0.27134531247003296, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.273916856364551, 0.2713162883575544, 0.26880279268799356]}, "mutation_prompt": null}
{"id": "73a94e52-b328-411c-9595-e0638ee5046b", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n\n    def levy_flight(self, step_size):\n        u = np.random.normal(0, 1, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1/3)\n        return step_size * step\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        evaluations = size\n\n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))\n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                if np.random.rand() < 0.5:  # Introduce Levy flight\n                    candidate += self.levy_flight(neighbor_radius)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Advanced chaotic exploration leveraging Levy flights and enhanced selection mechanisms.", "configspace": "", "generation": 76, "fitness": 0.2724292344139569, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27436767697462683, 0.2723871803974446, 0.2705328458697993]}, "mutation_prompt": null}
{"id": "a672d170-190e-4791-b1ad-0c9874b2339a", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.1 * (1 + np.sin((evaluations / self.budget) * np.pi))  # Enhanced perturbation with phase\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced exploration through adaptive perturbation based on the chaotic map phase.", "configspace": "", "generation": 77, "fitness": 0.2670719101773892, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.26555470474692233, 0.2717028480912823, 0.2639581776939629]}, "mutation_prompt": null}
{"id": "a6316654-8caa-48c4-b8f8-10e7402d33ba", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                # Changed perturbation_intensity and added adaptive mutation\n                perturbation_intensity = 0.3 * (1 - (evaluations / self.budget)**(1/3))\n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                if np.random.rand() < 0.1:  # Introduce occasional large mutation\n                    candidate += np.random.uniform(-5*neighbor_radius, 5*neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced chaotic optimization with dynamic population adjustments and adaptive mutation.", "configspace": "", "generation": 78, "fitness": 0.27175951617877525, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2718765434204772, 0.27030314224000085, 0.2730988628758477]}, "mutation_prompt": null}
{"id": "d053a133-068a-4f2d-8da5-a48c5c6166ba", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            # Change the switch frequency to every budget/6 evaluations\n            if evaluations % (self.budget // 6) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved exploration by adjusting the chaotic map switch frequency for enhanced global search capability.", "configspace": "", "generation": 79, "fitness": 0.2739781402222991, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.274252078716102, 0.27475280956352266, 0.2729295323872726]}, "mutation_prompt": null}
{"id": "455aa014-9b57-4e2d-8ed5-65c48b569d16", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / max(np.abs(fitness[i] + candidate_fitness), 1e-10)  # Improved probability formula\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved probability acceptance formula to enhance candidate selection.", "configspace": "", "generation": 80, "fitness": 0.27448492195430624, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27465161885160627, 0.27534155787185843, 0.27346158913945395]}, "mutation_prompt": null}
{"id": "2cf53356-f2ae-460d-90a3-322f650e43fa", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.15 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved dynamic neighborhood by tweaking perturbation intensity formula.", "configspace": "", "generation": 81, "fitness": 0.2722746386144078, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2716007996449138, 0.27570012052299797, 0.2695229956753117]}, "mutation_prompt": null}
{"id": "f28a1221-b031-4fca-8e79-40ba1d435cf6", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced selection mechanism with improved neighborhood exploration and fitness adaptation.", "configspace": "", "generation": 82, "fitness": 0.27448492195430624, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27465161885160627, 0.27534155787185843, 0.27346158913945395]}, "mutation_prompt": null}
{"id": "1d0a654a-6a7d-4f97-9000-3aed25f09f91", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                diversity_measure = np.mean(np.std(population, axis=0))  # Introduce diversity measure\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10) + diversity_measure * 0.05  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced probability factor now incorporates a diversity measure to improve exploration.", "configspace": "", "generation": 83, "fitness": 0.2539339137229984, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2477254493748383, 0.258306850900591, 0.2557694408935658]}, "mutation_prompt": null}
{"id": "a91fe095-c9db-4c8e-af54-82e19bfeb7d6", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            population_std = np.std(population, axis=0)  # Calculate population diversity\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))\n                neighbor_radius = perturbation_intensity * (ub - lb) * (1 + 0.1 * population_std)  # Adjusted radius\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhancing local exploration dynamics using adaptive perturbation scaling based on population diversity.", "configspace": "", "generation": 84, "fitness": 0.26164238856184874, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.26218685611815196, 0.26345901430212604, 0.2592812952652682]}, "mutation_prompt": null}
{"id": "86c774a8-a9cf-4365-8e34-c1d9b613e879", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a dynamic acceptance probability factor\n                acceptance_probability = 0.1 + 0.05 * (self.budget - evaluations) / self.budget + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            # Change: Introduce time-varying chaotic map selection\n            chaotic_map = \"sine\" if evaluations < self.budget // 2 else \"logistic\"\n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=chaotic_map)\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduce a time-varying chaotic map selection and a dynamic acceptance factor to enhance exploration and exploitation balance.", "configspace": "", "generation": 85, "fitness": 0.2740281405617339, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2744178936317828, 0.2747262125659513, 0.27294031548746767]}, "mutation_prompt": null}
{"id": "938b0689-82c2-4868-86b5-e43d2f47dc09", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Improved probability factor to enhance convergence\n                acceptance_probability = 0.15 + 0.85 * (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Enhanced probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved adaptive probability factor to boost exploration and convergence.", "configspace": "", "generation": 86, "fitness": 0.2727942481879211, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2740068986631211, 0.27092093635453673, 0.2734549095461054]}, "mutation_prompt": null}
{"id": "d3d3b6b4-6377-4d33-84bd-44bd1190568c", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Refine probability calculation for candidate acceptance\n                acceptance_probability = 0.25 * (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adjusted probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved adaptive probability for better candidate acceptance balancing exploration and exploitation.", "configspace": "", "generation": 87, "fitness": 0.27170926340581797, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2720027163051797, 0.2716573047862254, 0.27146776912604886]}, "mutation_prompt": null}
{"id": "a78172c6-2043-48ea-900d-e85b9563aeb3", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - (evaluations / self.budget)**(1/3))  # Refined intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced selection mechanism incorporating fitness-proportional acceptance and adaptive probability factor with refined perturbation intensity.", "configspace": "", "generation": 88, "fitness": 0.27134531247003296, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.273916856364551, 0.2713162883575544, 0.26880279268799356]}, "mutation_prompt": null}
{"id": "06e98a40-e66f-4317-8080-980cb635b9d2", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def levy_flight(self, step_size=0.01):\n        sigma = (np.math.gamma(1 + 1.5) * np.sin(np.pi * 1.5 / 2) / \n                 (np.math.gamma((1 + 1.5) / 2) * 1.5 * 2**((1.5 - 1) / 2)))**(1 / 1.5)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v)**(1 / 1.5)\n        return step * step_size\n\n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))\n                neighbor_radius = perturbation_intensity * (ub - lb)\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate += self.levy_flight()  # Incorporate Lévy flight\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n            # Ensure best solution is retained\n            population[0] = best\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Incorporate Lévy flight perturbations for enhanced exploration and incorporate elitism to retain the best solution.", "configspace": "", "generation": 89, "fitness": 0.27425661048601196, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2764621937881697, 0.2754781446142869, 0.27082949305557935]}, "mutation_prompt": null}
{"id": "a2f55d11-1645-400f-9cc0-cc21c4490eb1", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:  # Change: Introduce periodic reinitialization\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "EnhancedChaoticOptimizer now includes a dynamic periodic reinitialization strategy to escape local optima.", "configspace": "", "generation": 90, "fitness": 0.27448492195430624, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27465161885160627, 0.27534155787185843, 0.27346158913945395]}, "mutation_prompt": null}
{"id": "7cd781bb-f89e-4452-b15f-e51d3cc42d89", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                chaotic_map = \"sine\" if np.random.rand() < 0.5 else \"logistic\"  # Dynamic selection\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=chaotic_map)\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduce a dynamic chaotic map selection to enhance exploration and exploitation balance.", "configspace": "", "generation": 91, "fitness": 0.2740006054204925, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2746126380421372, 0.2749847399290305, 0.2724044382903098]}, "mutation_prompt": null}
{"id": "3487c501-d4f9-45d7-8e8f-cf8ab82e7dc3", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.25 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced selection mechanism incorporating fitness-proportional acceptance and a refined chaotic perturbation strategy.", "configspace": "", "generation": 92, "fitness": 0.27134531247003296, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.273916856364551, 0.2713162883575544, 0.26880279268799356]}, "mutation_prompt": null}
{"id": "c84989a9-d9c4-426f-ae45-1ce3d8c08515", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n            # New chaotic map for diversity\n            elif chaotic_map == \"tent\":\n                population[i] = lb + (ub - lb) * (2 * np.minimum(r, 1 - r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Modification: Refined acceptance probability for better convergence\n                acceptance_probability = 0.1 + 0.9 * (fitness[i] - candidate_fitness) / (np.abs(fitness[i] + candidate_fitness + 1e-10) + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"tent\") # Switch map\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Enhanced adaptive selection incorporating dynamic chaotic maps for improved exploration-exploitation balance.", "configspace": "", "generation": 93, "fitness": 0.27263352417206327, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27109359834910807, 0.2724895227905174, 0.27431745137656427]}, "mutation_prompt": null}
{"id": "1b1af047-ebf6-4770-bbc5-b15b97fc7766", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduce a probability factor for selection\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            # Change: Dynamic chaotic map switch\n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                chaotic_map = \"sine\" if evaluations < self.budget / 2 else \"logistic\"\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=chaotic_map)\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduced time-varying chaotic map switching to enhance exploration and exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.2744837450370067, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27464808809970764, 0.27534155787185843, 0.27346158913945395]}, "mutation_prompt": null}
{"id": "375c1973-45f6-428a-9f56-dc22c5e41096", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Adaptive probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                # Changed line: Applying chaotic selection to population update\n                population = np.where(np.random.rand(size, self.dim) < 0.5, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduce a chaotic selection mechanism to enhance exploration by increasing randomness in population update.", "configspace": "", "generation": 95, "fitness": 0.27254631799268825, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2729332468502744, 0.27364220244958537, 0.27106350467820495]}, "mutation_prompt": null}
{"id": "e69d4065-f134-47e7-9451-1a7e319813ea", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Fine-tune the probability factor for better selection pressure\n                acceptance_probability = 0.2 + (fitness[i] - candidate_fitness) / (np.abs(fitness[i] + candidate_fitness + 1e-10) + 1e-2)  # Adjusted probability\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Fine-tuned acceptance probability factor for more adaptive selection pressure.", "configspace": "", "generation": 96, "fitness": 0.2715280834572121, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2733131947159284, 0.27397341484821636, 0.2672976408074915]}, "mutation_prompt": null}
{"id": "c9aff3f2-afb4-416e-b0e0-52c441b37f86", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.3 * (1 - (evaluations / self.budget)**(2/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                # Change: Introduced a dynamic factor for probability\n                acceptance_probability = 0.15 + 0.5 * (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)  # Dynamic probability adjustment\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Introduced a dynamic acceptance probability factor adjustment based on evaluations and improved perturbation intensity scaling.", "configspace": "", "generation": 97, "fitness": 0.2702621517300717, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.2705407965008192, 0.2699647404228037, 0.27028091826659206]}, "mutation_prompt": null}
{"id": "08273c1e-8806-4bb0-a609-f42d4773f647", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/4))  # Adjusted intensity exponent\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / np.abs(fitness[i] + candidate_fitness + 1e-10)\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved perturbation strategy with dynamically adjusted intensity for a more effective search.", "configspace": "", "generation": 98, "fitness": 0.27043406154560357, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27189802071318914, 0.27198352821950134, 0.2674206357041202]}, "mutation_prompt": null}
{"id": "873e1016-e82f-4d46-9d0e-6bfa87d57baf", "solution": "import numpy as np\n\nclass EnhancedChaoticOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def initialize_population(self, lb, ub, size, chaotic_map):\n        population = np.zeros((size, self.dim))\n        for i in range(size):\n            r = np.random.rand(self.dim)\n            if chaotic_map == \"logistic\":\n                population[i] = lb + (ub - lb) * (3.9 * r * (1 - r))\n            elif chaotic_map == \"sine\":\n                population[i] = lb + (ub - lb) * (np.sin(np.pi * r))\n            elif chaotic_map == \"tent\":  # New chaotic map for diversity\n                population[i] = lb + (ub - lb) * (np.where(r < 0.5, r * 2, (1 - r) * 2))\n        return np.clip(population, lb, ub)\n    \n    def chaotic_hybrid_search(self, func, lb, ub):\n        size = 5 + self.dim // 2\n        population = self.initialize_population(lb, ub, size, chaotic_map=\"logistic\")\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best = population[best_idx]\n        best_fitness = fitness[best_idx]\n        \n        evaluations = size\n        \n        while evaluations < self.budget:\n            for i in range(size):\n                perturbation_intensity = 0.2 * (1 - (evaluations / self.budget)**(1/3))  # Adjusted intensity\n                neighbor_radius = perturbation_intensity * (ub - lb)  # Dynamic neighborhood\n                candidate = population[i] + np.random.uniform(-neighbor_radius, neighbor_radius, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                acceptance_probability = 0.15 + (fitness[i] - candidate_fitness) / max(np.abs(fitness[i] + candidate_fitness), 1e-10)  # Refined calculation\n                if candidate_fitness < fitness[i] or np.random.rand() < acceptance_probability:  # Adjusted probability\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n                    if candidate_fitness < best_fitness:\n                        best_fitness = candidate_fitness\n                        best = candidate\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations % (self.budget // 5) == 0:\n                scale = 1.0 - (evaluations / self.budget)\n                new_population = self.initialize_population(lb, ub, size, chaotic_map=\"sine\")\n                new_population = best + scale * (new_population - best)\n                new_population_fitness = np.array([func(ind) for ind in new_population])\n                evaluations += size\n                population = np.where(new_population_fitness < fitness, new_population, population)\n                fitness = np.minimum(new_population_fitness, fitness)\n                best_idx = np.argmin(fitness)\n                if fitness[best_idx] < best_fitness:\n                    best_fitness = fitness[best_idx]\n                    best = population[best_idx]\n\n        return best\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        return self.chaotic_hybrid_search(func, lb, ub)", "name": "EnhancedChaoticOptimizer", "description": "Improved algorithm by enhancing the initialization diversity and refining the acceptance probability calculation.", "configspace": "", "generation": 99, "fitness": 0.27448492195430624, "feedback": "The algorithm EnhancedChaoticOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "0a28b1b4-3e3b-4f7b-b98e-f33b8853671b", "metadata": {"aucs": [0.27465161885160627, 0.27534155787185843, 0.27346158913945395]}, "mutation_prompt": null}

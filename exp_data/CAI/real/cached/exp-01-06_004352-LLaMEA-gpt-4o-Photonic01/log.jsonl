{"id": "f4aac9ea-71a8-43ca-987d-7291a060cbbf", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * r1 * (self.best_positions - self.particles) +\n                self.c2 * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n        \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization (AQPSO) with dynamic boundary adjustments based on the particle's historical performance.", "configspace": "", "generation": 0, "fitness": 0.06773319573114849, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.06541296952286357, 0.06711574502151318, 0.07067087264906868]}, "mutation_prompt": null}
{"id": "4797da06-843f-4bce-9377-f0b1e87647bb", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.9  # Increased initial inertia weight for better exploration\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.w = 0.9 * (1 - self.eval_count / self.budget)  # Nonlinear decay of inertia weight\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * r1 * (self.best_positions - self.particles) +\n                self.c2 * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n        \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Incorporating a nonlinear inertia weight decay into AQPSO to balance exploration and exploitation more effectively.", "configspace": "", "generation": 1, "fitness": 0.06615324998906587, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "f4aac9ea-71a8-43ca-987d-7291a060cbbf", "metadata": {"aucs": [0.0647809613839786, 0.06429979983811374, 0.06937898874510529]}, "mutation_prompt": null}
{"id": "59563e2a-3eef-4fdd-be40-86d79e1cd991", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * r1 * (self.best_positions - self.particles) +\n                self.c2 * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= 0.99  # Line 1 change: Decay the inertia weight\n            if np.random.rand() < 0.05:  # Line 2 change: Random chance\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Line 3 change: Reset velocities\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhanced AQPSO with inertia weight decay and random velocity reset to improve exploration and convergence.", "configspace": "", "generation": 2, "fitness": 0.06788728903393342, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "f4aac9ea-71a8-43ca-987d-7291a060cbbf", "metadata": {"aucs": [0.06591616336218753, 0.06758107910455668, 0.07016462463505602]}, "mutation_prompt": null}
{"id": "2b79d0b3-2254-4c56-bbf9-17f3e48e23ff", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                (self.c1 + 0.5 * np.sin(np.pi * self.eval_count / self.budget)) * r1 * \n                (self.best_positions - self.particles) +\n                self.c2 * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= 0.99  # Line 1 change: Decay the inertia weight\n            if np.random.rand() < 0.05:  # Line 2 change: Random chance\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Line 3 change: Reset velocities\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce adaptive learning rates for self and social components to balance exploration and exploitation dynamically.", "configspace": "", "generation": 3, "fitness": 0.06749494064901755, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "59563e2a-3eef-4fdd-be40-86d79e1cd991", "metadata": {"aucs": [0.06580894426167727, 0.06651213872569006, 0.0701637389596853]}, "mutation_prompt": null}
{"id": "3bf67781-4f36-4470-9832-2390e51447c4", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * r1 * (self.best_positions - self.particles) +\n                self.c2 * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Adaptive inertia weight decay based on fitness improvement\n            fitness_improvement = np.abs(self.best_global_score - scores[min_score_idx])\n            self.w *= (0.99 + 0.01 * fitness_improvement)  # Change made here\n            \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhanced AQPSO with adaptive inertia weight decay based on fitness improvement rate.", "configspace": "", "generation": 4, "fitness": 0.06788728808038284, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "59563e2a-3eef-4fdd-be40-86d79e1cd991", "metadata": {"aucs": [0.06591616283142643, 0.0675810790090795, 0.07016462240064258]}, "mutation_prompt": null}
{"id": "d8af9d66-18e6-41f8-ac52-f238829c4b60", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.6  # Changed from 1.5 to 1.6 to improve the exploration capability\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * r1 * (self.best_positions - self.particles) +\n                self.c2 * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= 0.99  # Line 1 change: Decay the inertia weight\n            if np.random.rand() < 0.05:  # Line 2 change: Random chance\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Line 3 change: Reset velocities\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slightly increase the learning factor `c1` to improve the algorithm's search capability, enhancing convergence performance.", "configspace": "", "generation": 5, "fitness": 0.0675426985284286, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "59563e2a-3eef-4fdd-be40-86d79e1cd991", "metadata": {"aucs": [0.06593565582628214, 0.0665171172350909, 0.07017532252391279]}, "mutation_prompt": null}
{"id": "e913cb4c-4cf7-4de3-abaa-4ee282236f7d", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                (self.c1 * (1 - self.eval_count / self.budget)) * r1 * (self.best_positions - self.particles) +  # Changed line: Dynamic c1\n                self.c2 * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= 0.99  # Line 1 change: Decay the inertia weight\n            if np.random.rand() < 0.05:  # Line 2 change: Random chance\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Line 3 change: Reset velocities\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhanced AQPSO with dynamic personal and global learning factors for adaptive convergence and exploration.", "configspace": "", "generation": 6, "fitness": 0.06828274057457666, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "59563e2a-3eef-4fdd-be40-86d79e1cd991", "metadata": {"aucs": [0.06579552668528588, 0.06874522409763906, 0.07030747094080503]}, "mutation_prompt": null}
{"id": "51c5fa43-4478-49c7-b1b4-b6dc202904c0", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                (self.c1 * (1 - self.eval_count / self.budget)) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= 0.99\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a time-varying acceleration coefficient to improve the convergence speed of the AQPSO algorithm.", "configspace": "", "generation": 7, "fitness": 0.06951657185914058, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "e913cb4c-4cf7-4de3-abaa-4ee282236f7d", "metadata": {"aucs": [0.06915292973401055, 0.06885130883688706, 0.07054547700652414]}, "mutation_prompt": null}
{"id": "10a94e4d-3b68-43c1-b92d-ca799c5074e0", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.momentum = 0.9  # Added line\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.momentum * self.velocities +  # Modified line\n                self.w * self.velocities +\n                (self.c1 * (1 - self.eval_count / self.budget)) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= 0.99\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Adjusted the velocity update formula to incorporate a momentum factor for better convergence.", "configspace": "", "generation": 8, "fitness": 0.06436796394508866, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.01.", "error": "", "parent_id": "51c5fa43-4478-49c7-b1b4-b6dc202904c0", "metadata": {"aucs": [0.06683210903086378, 0.05721351788206064, 0.06905826492234157]}, "mutation_prompt": null}
{"id": "402ae239-4ecf-40dc-b819-a26005d475bf", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +  # Changed line\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= 0.99\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a dynamic personal acceleration coefficient to improve individual exploration rates in AQPSO.", "configspace": "", "generation": 9, "fitness": 0.069517236214368, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "51c5fa43-4478-49c7-b1b4-b6dc202904c0", "metadata": {"aucs": [0.06963684972293527, 0.06844451893837267, 0.07047033998179608]}, "mutation_prompt": null}
{"id": "6f7e6233-39ca-44e5-8ba3-860f94f9483f", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.02 * self.eval_count / self.budget)  # Changed line\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= 0.99\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Refine the adaptive boundary adjustment with decay factor to enhance convergence stability in AQPSO.", "configspace": "", "generation": 10, "fitness": 0.069517236214368, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "402ae239-4ecf-40dc-b819-a26005d475bf", "metadata": {"aucs": [0.06963684972293527, 0.06844451893837267, 0.07047033998179608]}, "mutation_prompt": null}
{"id": "da4b9a57-7384-4b05-9bfd-86bfae0699ab", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n                \n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1.1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +  # Changed line\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= 0.99\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Adjusted the dynamic acceleration coefficients in AQPSO for enhanced convergence.", "configspace": "", "generation": 11, "fitness": 0.06944911457294163, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "402ae239-4ecf-40dc-b819-a26005d475bf", "metadata": {"aucs": [0.06951985588040965, 0.06838909256771142, 0.07043839527070384]}, "mutation_prompt": null}
{"id": "20175fa8-4279-4278-a8f1-faa323e04557", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic inertia weight updating to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.06952142072233718, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "402ae239-4ecf-40dc-b819-a26005d475bf", "metadata": {"aucs": [0.06961507209556317, 0.0684524079399218, 0.07049678213152655]}, "mutation_prompt": null}
{"id": "4ea6a081-6c48-4c52-9e3a-958147e1f63b", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (1.0 + 0.5 * (1.0 - self.best_global_score / np.max(self.best_personal_scores))) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget))\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance the convergence by adjusting the personal learning factor dynamically with respect to the global best score improvement.", "configspace": "", "generation": 13, "fitness": 0.06608315032902208, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "20175fa8-4279-4278-a8f1-faa323e04557", "metadata": {"aucs": [0.06398067565053922, 0.06493700616333176, 0.06933176917319528]}, "mutation_prompt": null}
{"id": "927aa0ff-699f-4886-b381-42f1c7358832", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.c1, self.c2 = 1.5 + 0.5 * np.sin(np.pi * self.eval_count / self.budget),  # Changed line\n                                1.5 + 0.5 * np.cos(np.pi * self.eval_count / self.budget)\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget))\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce time-varying coefficients to enhance the adaptability of the algorithm.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndentationError('unexpected indent', ('<string>', 49, 32, '                                1.5 + 0.5 * np.cos(np.pi * self.eval_count / self.budget)\\n')).", "error": "IndentationError('unexpected indent', ('<string>', 49, 32, '                                1.5 + 0.5 * np.cos(np.pi * self.eval_count / self.budget)\\n'))", "parent_id": "20175fa8-4279-4278-a8f1-faa323e04557", "metadata": {}, "mutation_prompt": null}
{"id": "abb79222-ce88-497c-9411-8d0dbbe5afdb", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(np.pi * self.eval_count / (0.5 * self.budget)))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a non-linear decay function for dynamic inertia weight to subtly balance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": 0.06952142072233718, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "20175fa8-4279-4278-a8f1-faa323e04557", "metadata": {"aucs": [0.06961507209556317, 0.0684524079399218, 0.07049678213152655]}, "mutation_prompt": null}
{"id": "1d34b552-dd23-496c-88a6-21f35440193e", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            diversity = np.std(self.particles, axis=0)  # Changed line\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget) * (1 + diversity)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget))\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic boundary adjustments based on diversity to enhance convergence.", "configspace": "", "generation": 16, "fitness": 0.06952142072233718, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "20175fa8-4279-4278-a8f1-faa323e04557", "metadata": {"aucs": [0.06961507209556317, 0.0684524079399218, 0.07049678213152655]}, "mutation_prompt": null}
{"id": "671f0192-5ad3-45cf-8a8b-eb0cb8541fde", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget))  \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n            # Dynamic learning factor adjustment\n            self.c1, self.c2 = 1.5 + 0.5 * np.sin(2 * np.pi * self.eval_count / self.budget), 1.5 + 0.5 * np.cos(2 * np.pi * self.eval_count / self.budget)\n\n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a dynamic learning factor adjustment to improve convergence speed.", "configspace": "", "generation": 17, "fitness": 0.06882473873300625, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "20175fa8-4279-4278-a8f1-faa323e04557", "metadata": {"aucs": [0.06953102656861576, 0.06668197857650682, 0.07026121105389616]}, "mutation_prompt": null}
{"id": "c2a839c1-90ba-4759-a773-01ca03ca5e01", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget) + np.random.normal(0, 0.005))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce stochasticity in inertia weight decay for enhanced exploration.", "configspace": "", "generation": 18, "fitness": 0.06934912263177946, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "20175fa8-4279-4278-a8f1-faa323e04557", "metadata": {"aucs": [0.06965820448031934, 0.06774738164469762, 0.07064178177032143]}, "mutation_prompt": null}
{"id": "9477ed11-d4d2-478c-b3c2-3b04733b5158", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget) + 0.01 * np.sin(4 * np.pi * self.eval_count / self.budget))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a periodic sine modulation to inertia weight for enhanced convergence control.", "configspace": "", "generation": 19, "fitness": 0.0694143134594312, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "20175fa8-4279-4278-a8f1-faa323e04557", "metadata": {"aucs": [0.06938977311009598, 0.06835472635724482, 0.07049844091095281]}, "mutation_prompt": null}
{"id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce adaptive velocity scaling to further refine exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.06966146344303015, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "20175fa8-4279-4278-a8f1-faa323e04557", "metadata": {"aucs": [0.06969604872019397, 0.06877137577717518, 0.07051696583172129]}, "mutation_prompt": null}
{"id": "9cd1d2e6-c44d-4361-bc25-86aa5bb32fa8", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / (2 * self.budget)) * r1 * (self.best_positions - self.particles) +  # Changed line\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  \n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slightly alter the velocity update formula to enhance exploitation in later stages by adjusting the coefficient scaling.", "configspace": "", "generation": 21, "fitness": 0.06963415593547866, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06960407750599684, 0.06875964914972488, 0.07053874115071423]}, "mutation_prompt": null}
{"id": "a23cd83b-cfc1-492f-acf5-445dfb743a2d", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            adaptive_c1 = self.c1 * (0.5 + self.eval_count / (2 * self.budget))  # Changed line\n            adaptive_c2 = self.c2 * (1 + self.eval_count / self.budget)\n            self.velocities = (\n                self.w * self.velocities +\n                adaptive_c1 * r1 * (self.best_positions - self.particles) +\n                adaptive_c2 * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance convergence by adjusting the influence of personal and global learning factors dynamically.", "configspace": "", "generation": 22, "fitness": 0.06772954966375304, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06577977347785613, 0.06687004302075894, 0.07053883249264403]}, "mutation_prompt": null}
{"id": "b5701bec-b501-4ee1-9f34-844fe1554dd3", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget) ** 2) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Incorporate non-linear inertia weight decay to enhance convergence speed and balance between exploration and exploitation.", "configspace": "", "generation": 23, "fitness": 0.06962326763756628, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.0696943857094584, 0.0686720680190388, 0.07050334918420165]}, "mutation_prompt": null}
{"id": "5df9aae9-cec7-4f64-9d0f-b67c61ee7016", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Implemented an adaptive learning factor for better dynamic exploration-exploitation trade-off.", "configspace": "", "generation": 24, "fitness": 0.06966146344303015, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969604872019397, 0.06877137577717518, 0.07051696583172129]}, "mutation_prompt": null}
{"id": "0c21ffd2-b08d-419a-90a9-d12213dac35a", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * np.sqrt(r1) * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance exploitation by introducing a square root scaling factor to the personal best influence.", "configspace": "", "generation": 25, "fitness": 0.06947587024528552, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06951763243650433, 0.06847455492394128, 0.07043542337541098]}, "mutation_prompt": null}
{"id": "26a7418b-2918-4497-842a-9aa3bfe63f72", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += np.sin(0.9 * self.velocities)  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic velocity scaling based on harmonic oscillation to enhance adaptive exploration and exploitation balance.", "configspace": "", "generation": 26, "fitness": 0.05040635086792803, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.047830694876585644, 0.049060568303119445, 0.05432778942407901]}, "mutation_prompt": null}
{"id": "a21adec9-e713-4a76-aa24-d0090296fa5b", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.98 + 0.02 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance exploration by adjusting the inertia weight decay for better convergence.", "configspace": "", "generation": 27, "fitness": 0.06962370140003467, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969457076329466, 0.06866577495567683, 0.07051075848113253]}, "mutation_prompt": null}
{"id": "cb24307f-5e18-42cd-85ee-48547a56c629", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                (self.c2 + 0.1) * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slightly increased the influence of the global best position on velocity updates to enhance convergence speed.", "configspace": "", "generation": 28, "fitness": 0.06925734915974113, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06968470478582955, 0.06802948827543764, 0.0700578544179562]}, "mutation_prompt": null}
{"id": "b4bf5232-c18d-471d-89c1-6aa99acb90ea", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += (0.9 + 0.1 * np.sin(2 * np.pi * self.eval_count / self.budget)) * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic component scaling in velocity update to enhance exploration-exploitation trade-off.", "configspace": "", "generation": 29, "fitness": 0.06939780516726383, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06965111050361694, 0.06868152257776183, 0.06986078242041271]}, "mutation_prompt": null}
{"id": "e3b6b98c-6177-4f5a-8631-dccac45b88c2", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.7 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slightly adjust the velocity scaling factor to further refine convergence behavior.", "configspace": "", "generation": 30, "fitness": 0.0688802636211342, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06729325170138356, 0.0688867618966793, 0.07046077726533972]}, "mutation_prompt": null}
{"id": "730d469b-34de-40fe-9322-c271d0b54aa9", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget) + np.random.rand() * 0.01)  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a slight randomness to inertia weight decay for enhanced exploration in AQPSO.", "configspace": "", "generation": 31, "fitness": 0.06941720154993758, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06956586216472038, 0.06833680972786094, 0.07034893275723142]}, "mutation_prompt": null}
{"id": "08942917-0225-4c17-82f3-8bc1dc5df3ec", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight adjustment: Dynamically decrease to quicken convergence\n            self.w = 0.9 - 0.5 * (self.eval_count / self.budget)\n\n            # Enhance personal learning: Vary c1 with time to improve local search\n            self.c1 = 2.0 - (self.eval_count / self.budget)\n\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a dynamically adjusting inertia weight and personal learning coefficient to enhance convergence speed and solution quality.", "configspace": "", "generation": 32, "fitness": 0.06779098925813294, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06867987902322059, 0.06512844552316499, 0.06956464322801326]}, "mutation_prompt": null}
{"id": "775db351-6e6d-487b-989a-c761ba195c39", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.55 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slightly enhance global best attraction by adjusting the coefficient dynamically.", "configspace": "", "generation": 33, "fitness": 0.06932666779754337, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06949625635535517, 0.06800102868601188, 0.07048271835126307]}, "mutation_prompt": null}
{"id": "9df12330-34d4-424e-8ab3-eaa317ce8ad0", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            diversity_factor = np.std(self.particles, axis=0).mean() / (ub - lb).mean()  # Changed line\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + diversity_factor) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance global exploration by adjusting cognitive coefficient scaling based on particle diversity.", "configspace": "", "generation": 34, "fitness": 0.06963673347550307, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06960019427712305, 0.06878185203688014, 0.07052815411250601]}, "mutation_prompt": null}
{"id": "13d1c74e-b86a-40e7-b78b-ba2e55a24b4a", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.7 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance convergence by increasing velocity scaling during early iterations.", "configspace": "", "generation": 35, "fitness": 0.0688802636211342, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06729325170138356, 0.0688867618966793, 0.07046077726533972]}, "mutation_prompt": null}
{"id": "3d80f0b0-89f2-414d-88c0-e658d3cd9ad8", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            distance_from_bounds = np.min([self.particles - lb, ub - self.particles], axis=0)  # Changed line\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a dynamic exploration factor in velocity update to adaptively enhance exploration based on distance from bounds.", "configspace": "", "generation": 36, "fitness": 0.06966146344303015, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969604872019397, 0.06877137577717518, 0.07051696583172129]}, "mutation_prompt": null}
{"id": "507eaf3f-f443-41c7-8cea-e1bca4758004", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 1.0 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance the exploration capability by slightly increasing the velocity scaling factor.", "configspace": "", "generation": 37, "fitness": 0.06952142072233718, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06961507209556317, 0.0684524079399218, 0.07049678213152655]}, "mutation_prompt": null}
{"id": "7cc0a723-ba6d-45eb-8e97-fbbafdb2d903", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + 1.5 * self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +  # Changed line\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a dynamic adjustment factor to the cognitive coefficient for enhanced personal best search capabilities.", "configspace": "", "generation": 38, "fitness": 0.06961602513281011, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06966427672452014, 0.06870349913613016, 0.07048029953778001]}, "mutation_prompt": null}
{"id": "7fdf794b-7143-47e2-a12a-938161b92890", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.85 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance global exploration by reducing velocity scaling factor.", "configspace": "", "generation": 39, "fitness": 0.06930950391323631, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06956484657943496, 0.06855473915554455, 0.06980892600472943]}, "mutation_prompt": null}
{"id": "d7569ae9-e6e8-42b5-9e06-3df9eab96b88", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            constriction_factor = 0.7289  # Changed line\n            self.velocities = (\n                constriction_factor * (\n                    self.w * self.velocities +\n                    self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                    self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n                )\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a dynamic constriction factor to improve convergence speed and stability.", "configspace": "", "generation": 40, "fitness": 0.06880742674766245, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06900695509768151, 0.06881410193642556, 0.06860122320888029]}, "mutation_prompt": null}
{"id": "e91eedad-ebf5-4d4d-9ad0-d6dfbd715395", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += self.velocities  # Restored line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Fine-tune the balance between exploration and exploitation by adjusting the velocity scaling factor.", "configspace": "", "generation": 41, "fitness": 0.06952142072233718, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06961507209556317, 0.0684524079399218, 0.07049678213152655]}, "mutation_prompt": null}
{"id": "f1068b3b-d2a3-4c17-a2c5-c6e103b7d4f9", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += (0.9 - 0.2 * (self.eval_count / self.budget)) * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic adjustment of the velocity scaling factor to further refine exploration and exploitation balance.", "configspace": "", "generation": 42, "fitness": 0.06962449609944836, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06965919636015849, 0.06868314182971558, 0.070531150108471]}, "mutation_prompt": null}
{"id": "b5ab7213-8ac8-4457-a497-66ae76da7a0f", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget) + np.random.rand() * 0.02)  # Updated line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a stochastic inertia weight scaling to enhance adaptability during optimization.", "configspace": "", "generation": 43, "fitness": 0.06941449704864466, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06955883035609112, 0.06832152419852644, 0.07036313659131643]}, "mutation_prompt": null}
{"id": "761f75d5-af9c-4ce5-8370-adc5f2d8bf94", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            stochastic_control = 0.8 + 0.4 * np.sin(np.pi * self.eval_count / self.budget)  # Changed line\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += stochastic_control * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce stochastic control for velocity scaling and adaptive neighborhood search for enhanced convergence.", "configspace": "", "generation": 44, "fitness": 0.06926009056768279, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.0695477696947665, 0.06817017408175441, 0.07006232792652745]}, "mutation_prompt": null}
{"id": "418b9253-c032-499c-9829-110c66d7e648", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (1.8 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Fine-tune velocity scaling factor to enhance convergence precision.", "configspace": "", "generation": 45, "fitness": 0.06958994820076166, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06960654991247361, 0.0686762052791261, 0.07048708941068527]}, "mutation_prompt": null}
{"id": "5b35993e-fef5-4669-9691-628dfbb8a424", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * 1.1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +  # Changed line\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slightly increase the influence of personal best positions in velocity update to enhance convergence speed.", "configspace": "", "generation": 46, "fitness": 0.06959741043785705, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969445239725358, 0.06862558424379495, 0.07047219467252264]}, "mutation_prompt": null}
{"id": "eaafd180-ee7f-461d-8a45-efa69f9aae48", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.52 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance global exploration by slightly increasing the velocity update scaling factor.", "configspace": "", "generation": 47, "fitness": 0.06962122896814808, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06968200852207229, 0.06867965867359282, 0.07050201970877912]}, "mutation_prompt": null}
{"id": "731e353d-d5da-413a-950f-a450d4fda43f", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += np.tanh(0.9 * self.velocities)  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce nonlinear velocity scaling to enhance exploration in early stages of optimization.", "configspace": "", "generation": 48, "fitness": 0.05313811237468687, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.05146568977230703, 0.05109048356021051, 0.05685816379154307]}, "mutation_prompt": null}
{"id": "5885c207-0e66-4035-934e-fcfe25c677ad", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.98 + 0.02 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Fine-tune the inertia weight decay for a more precise convergence control.", "configspace": "", "generation": 49, "fitness": 0.06962370140003467, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969457076329466, 0.06866577495567683, 0.07051075848113253]}, "mutation_prompt": null}
{"id": "6554270b-0da0-41e7-9f27-9cf55b0aa9fd", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(3 * np.pi * self.eval_count / self.budget))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce adaptive inertia weight scaling for enhanced convergence efficiency.", "configspace": "", "generation": 50, "fitness": 0.06962317201585151, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969626710813126, 0.06866552826212946, 0.07050772067729383]}, "mutation_prompt": null}
{"id": "0592cbc7-ed99-463d-a720-cc5441b3cff5", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            momentum = 0.9  # Changed line\n            self.velocities = (\n                momentum * self.velocities +  # Changed line\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a momentum factor in velocity update for smoother convergence.", "configspace": "", "generation": 51, "fitness": 0.06279980930118123, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.0635110377652639, 0.056663776855348624, 0.06822461328293117]}, "mutation_prompt": null}
{"id": "3fd5739c-d4b2-4f82-a287-d22d0c85276f", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.75 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Adjust the scaling factor of the velocity update to enhance convergence speed.", "configspace": "", "generation": 52, "fitness": 0.06815208483251027, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06512016158815248, 0.06871617690722054, 0.07061991600215778]}, "mutation_prompt": null}
{"id": "993284c4-1b45-4f12-a41d-0583ecd82462", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n            if np.random.rand() < 0.02:  # New line\n                self.particles += np.random.normal(0, 0.1, self.particles.shape)  # New line\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce random perturbations to particles occasionally to enhance exploration.", "configspace": "", "generation": 53, "fitness": 0.06933152641226725, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06979308424019104, 0.06819510410586715, 0.07000639089074356]}, "mutation_prompt": null}
{"id": "fa172346-3057-4191-9be5-9a7dd06af70a", "solution": "class AQPSO:\n    # ... [rest of the code remains unchanged]\n\n    def __call__(self, func):\n        # ... [rest of the code remains unchanged]\n        \n        for _ in range(self.budget):\n            # ... [rest of the code remains unchanged]\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.95 * self.velocities  # Adjusted line\n\n            # ... [rest of the code remains unchanged]\n\n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce adaptive particle position adjustment to enhance convergence speed.", "configspace": "", "generation": 54, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('AQPSO() takes no arguments').", "error": "TypeError('AQPSO() takes no arguments')", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {}, "mutation_prompt": null}
{"id": "e09d336b-99d8-4e37-90c9-de8d81cd9cea", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05 or np.std(self.velocities) < 0.1:  # Changed line\n                self.velocities = np.random.uniform(-2, 2, (self.population_size, self.dim))  # Changed line\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic velocity reinitialization to enhance exploration in stagnant phases.", "configspace": "", "generation": 55, "fitness": 0.06965238389958921, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969601348302457, 0.06877137577717518, 0.07048976243856786]}, "mutation_prompt": null}
{"id": "f35688be-c0f5-46b7-8e9b-059aedc444b1", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.6 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a dynamic coefficient adjustment to enhance convergence precision.", "configspace": "", "generation": 56, "fitness": 0.06923881034886636, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06927866303947172, 0.0679355476973531, 0.07050222030977427]}, "mutation_prompt": null}
{"id": "d815be38-cd35-4f8b-809f-7c072aa3d40a", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += np.random.uniform(0.8, 1.0) * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce stochastic velocity scaling to enhance convergence reliability.", "configspace": "", "generation": 57, "fitness": 0.06948531653394412, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06989476143310014, 0.0683934714041129, 0.0701677167646193]}, "mutation_prompt": null}
{"id": "3e16cea5-bca5-4567-bea6-21095dfb970c", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 2.0  # Changed line\n        self.c2 = 2.0  # Changed line\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (0.5 + self.eval_count / (2 * self.budget)) * r1 * (self.best_positions - self.particles) +  # Changed line\n                self.c2 * (1 + self.eval_count / self.budget) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += self.velocities + 0.1 * np.random.uniform(-1, 1, (self.population_size, self.dim))  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance convergence by introducing a dynamic social-cognitive balance and improved exploration through random perturbations.", "configspace": "", "generation": 58, "fitness": 0.0643030041197263, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.06 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.061105955214645014, 0.06200657417352107, 0.06979648297101282]}, "mutation_prompt": null}
{"id": "6c43aafb-90c9-43c7-a218-78600d9cdded", "solution": "import numpy as np\n\nclass EnhancedAQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.c3 = 0.5  # Added line\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.normal(0, 0.1, (self.population_size, self.dim))  # Changed line\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * np.cos(np.pi * self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +  # Changed line\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "EnhancedAQPSO", "description": "Introduce a dynamic learning factor and adjust particle initialization to enhance diversity for improved convergence.", "configspace": "", "generation": 59, "fitness": 0.06945952309321986, "feedback": "The algorithm EnhancedAQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06945715785596063, 0.06901316446662009, 0.06990824695707887]}, "mutation_prompt": null}
{"id": "0150f1fe-f638-431f-bdb5-73de6c0af5a8", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            phi = self.c1 * r1 + self.c2 * r2  # New line\n            k = 2 / abs(2 - phi - np.sqrt(phi**2 - 4 * phi))  # New line\n            self.velocities = (\n                k * (self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles))\n            )  # Modified line\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic constriction coefficients to balance exploration and exploitation more effectively.", "configspace": "", "generation": 60, "fitness": 0.04840631575714035, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.046145555170092334, 0.046968965689622055, 0.05210442641170665]}, "mutation_prompt": null}
{"id": "113cfb39-9b8b-400b-a4b5-893da6131723", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.98 + 0.02 * np.cos(2 * np.pi * self.eval_count / self.budget))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic inertia weight update using cosine function for enhanced exploration-exploitation trade-off.", "configspace": "", "generation": 61, "fitness": 0.06962370140003467, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969457076329466, 0.06866577495567683, 0.07051075848113253]}, "mutation_prompt": null}
{"id": "28ec1ed8-8db9-4caf-9a2c-b8f24586ab81", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.55  # Changed line\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance exploration by increasing inertia weight slightly.", "configspace": "", "generation": 62, "fitness": 0.0695989716551821, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06960560356123091, 0.06870846451025803, 0.07048284689405737]}, "mutation_prompt": null}
{"id": "75db38c8-35e2-4531-802d-36ec3230d57d", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.92 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance adaptability by subtly adjusting the velocity factor.", "configspace": "", "generation": 63, "fitness": 0.06960797074018465, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06966497141427819, 0.06865301578927285, 0.07050592501700292]}, "mutation_prompt": null}
{"id": "e61a5a69-95c0-4804-b865-cbf759865092", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += (0.9 + 0.1 * (1 - self.eval_count / self.budget)) * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce gradual velocity scaling factor to enhance fine-tuning near the solution.", "configspace": "", "generation": 64, "fitness": 0.06949389680088942, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06963446588153643, 0.06836452895051182, 0.07048269557062004]}, "mutation_prompt": null}
{"id": "b9c540a1-c594-4a21-9024-9c1b0f4aa222", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.91 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slightly increase the velocity scaling factor to enhance exploration capabilities and avoid premature convergence.", "configspace": "", "generation": 65, "fitness": 0.06964045287599126, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06965153399211166, 0.0687652971903443, 0.07050452744551783]}, "mutation_prompt": null}
{"id": "bb752272-a719-410b-a57a-1dcfb5c3ebe1", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.95 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic adaptive velocity scaling by altering the velocity update equation for enhanced search efficiency.", "configspace": "", "generation": 66, "fitness": 0.06939029455766581, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06964061351167095, 0.06851666370132059, 0.07001360646000587]}, "mutation_prompt": null}
{"id": "6f077fea-b347-474d-9b1b-c457be40973b", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.95 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduced enhanced velocity control through dynamic adjustment of velocity scaling factor for better convergence.", "configspace": "", "generation": 67, "fitness": 0.06939029455766581, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06964061351167095, 0.06851666370132059, 0.07001360646000587]}, "mutation_prompt": null}
{"id": "173bd3d8-b91d-47ba-a8ec-811ff1761e30", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            ) * (1 + 0.1 * np.sin(np.pi * self.eval_count / self.budget))  # Changed line\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Refine velocity update by adding a nonlinear dynamic component to enhance convergence efficiency.", "configspace": "", "generation": 68, "fitness": 0.06953597344564288, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.069636986198917, 0.06850552670712617, 0.07046540743088547]}, "mutation_prompt": null}
{"id": "da71910c-a1b0-4114-9898-327b8f010e9f", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.55 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slight increase in velocity scaling factor to enhance global exploration.", "configspace": "", "generation": 69, "fitness": 0.06932666779754337, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06949625635535517, 0.06800102868601188, 0.07048271835126307]}, "mutation_prompt": null}
{"id": "10d7fbd8-0517-49ff-87e9-3d0b0c364a3e", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.02 * np.sin(2 * np.pi * self.eval_count / self.budget))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce adaptive inertia weight oscillation to enhance convergence dynamics.", "configspace": "", "generation": 70, "fitness": 0.06962289757319669, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.0696373334082, 0.06877846707212809, 0.07045289223926199]}, "mutation_prompt": null}
{"id": "46334bbc-b9ea-4f22-a834-4400fa917413", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.55 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Adjusted velocity scaling factor to enhance convergence speed by fine-tuning particle updates.", "configspace": "", "generation": 71, "fitness": 0.06932666779754337, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06949625635535517, 0.06800102868601188, 0.07048271835126307]}, "mutation_prompt": null}
{"id": "c3450826-b851-4642-b27d-58c8c2bb7be2", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.6 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance convergence by slightly increasing exploitation in the velocity update.", "configspace": "", "generation": 72, "fitness": 0.06923881034886636, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06927866303947172, 0.0679355476973531, 0.07050222030977427]}, "mutation_prompt": null}
{"id": "2cf0d0f7-4e40-4c5e-b777-276a7c3b9939", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.6 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slightly increase the velocity scaling factor to enhance adaptive exploration.", "configspace": "", "generation": 73, "fitness": 0.06923881034886636, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06927866303947172, 0.0679355476973531, 0.07050222030977427]}, "mutation_prompt": null}
{"id": "25beb810-7e20-4c99-b4ee-e19e7cb93f87", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n            # Population size adjustment\n            self.population_size = min(self.population_size + int(0.01 * self.budget), 10 * self.dim)\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic population size adjustment based on performance to enhance exploration and exploitation balance.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (36,6) (30,6) ').", "error": "ValueError('operands could not be broadcast together with shapes (36,6) (30,6) ')", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {}, "mutation_prompt": null}
{"id": "1ab92fde-e631-4c4a-8726-5061f2eab1cc", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + 0.5 * (1 - self.eval_count / self.budget)) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce adaptive cognitive scaling to dynamically adjust personal attraction towards personal best.", "configspace": "", "generation": 75, "fitness": 0.06947784310682148, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06957271510783514, 0.06838836833834228, 0.07047244587428703]}, "mutation_prompt": null}
{"id": "77ec6b72-7471-44e3-a658-ff69d7e08a5c", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            velocity_factor = 1 + (0.1 * np.sin(2 * np.pi * self.eval_count / self.budget))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += velocity_factor * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce a dynamic component to the velocity update to enhance adaptability.", "configspace": "", "generation": 76, "fitness": 0.06950986927132581, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06943192980270585, 0.06851102987590363, 0.07058664813536797]}, "mutation_prompt": null}
{"id": "b34bc322-064a-4858-8883-ec133cf114ad", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1.1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance the velocity update rule by slightly increasing the influence of personal bests for better exploration.", "configspace": "", "generation": 77, "fitness": 0.06959675206167104, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06968050795393654, 0.06862150222602847, 0.0704882460050481]}, "mutation_prompt": null}
{"id": "ecbe6df1-e529-47cf-8635-359a55e37dbd", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                (0.5 + 2.5 * self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +  # Changed line\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce nonlinear time-varying acceleration coefficients to enhance convergence speed.", "configspace": "", "generation": 78, "fitness": 0.06964953236392386, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06970294448426817, 0.06887292625610886, 0.07037272635139458]}, "mutation_prompt": null}
{"id": "46b65601-1180-4a0f-848c-3d7f41efc0df", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce adaptive velocity scaling to further refine exploration and exploitation balance.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969604872019397, 0.06877137577717518, 0.07051696583172129]}, "mutation_prompt": null}
{"id": "7230c24c-7fc6-4493-a1de-397136ced31f", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                (self.c1 + 0.1 * np.sin(2 * np.pi * self.eval_count / self.budget)) * r1 * (self.best_positions - self.particles) +  # Changed line\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic acceleration coefficients to enhance adaptability in optimization.", "configspace": "", "generation": 80, "fitness": 0.06961520085939943, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06959582309078693, 0.06874078592103061, 0.07050899356638074]}, "mutation_prompt": null}
{"id": "d5df9239-cfab-457d-802a-fe8b84b16db3", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * (np.cos(2 * np.pi * self.eval_count / self.budget) + np.random.rand() * 0.1))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce slight randomness in updating inertia weight to enhance exploration.", "configspace": "", "generation": 81, "fitness": 0.06939262647454636, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06951206126585963, 0.06831302440474496, 0.07035279375303449]}, "mutation_prompt": null}
{"id": "b7b54125-cab1-48c5-aa69-1b540ba481c5", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            r3 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + r3 * self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (1.5 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.85 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance adaptive exploration by adjusting personal best influence with a dynamic social component.", "configspace": "", "generation": 82, "fitness": 0.06932018012715195, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06929215280421663, 0.068161142625907, 0.0705072449513322]}, "mutation_prompt": null}
{"id": "99317a9c-966e-4fe2-86f5-e432498e6e1e", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += np.random.uniform(0.8, 1.0) * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.03:  # Changed line\n                self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Changed line\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance convergence by integrating dynamic social learning and personalized velocity adaptation.", "configspace": "", "generation": 83, "fitness": 0.06948465990269263, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06989279153934569, 0.0683934714041129, 0.0701677167646193]}, "mutation_prompt": null}
{"id": "4396e477-a233-48d8-8617-c7e2ecfbb364", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n                \n            # Dynamic neighborhood search\n            if np.random.rand() < 0.3:\n                local_best_idx = np.random.choice(self.population_size, size=1)\n                self.best_global_position = self.particles[local_best_idx].copy()\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance convergence by introducing an adaptive dimensional learning rate and dynamic neighborhood search.", "configspace": "", "generation": 84, "fitness": 0.06919368037382023, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06951391046302258, 0.06810543729065954, 0.06996169336777858]}, "mutation_prompt": null}
{"id": "35a05ac0-2291-485d-a171-55d2249813f1", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.92 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Fine-tune velocity update for improved exploration-exploitation balance.", "configspace": "", "generation": 85, "fitness": 0.06960797074018465, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06966497141427819, 0.06865301578927285, 0.07050592501700292]}, "mutation_prompt": null}
{"id": "50f66ce7-7ee2-4203-ad89-cc094bff817e", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.52 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slightly increase velocity scaling factor to refine exploration-exploitation balance.", "configspace": "", "generation": 86, "fitness": 0.06962122896814808, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06968200852207229, 0.06867965867359282, 0.07050201970877912]}, "mutation_prompt": null}
{"id": "2aec4fb6-a832-4ce7-8fe5-532195e79d8e", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + np.random.rand() * self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce randomized acceleration decay parameter for dynamically altering global learning influence.", "configspace": "", "generation": 87, "fitness": 0.06902546571984132, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06931102573304693, 0.06747717304330325, 0.0702881983831738]}, "mutation_prompt": null}
{"id": "a1d0b925-36e6-49e0-bac8-81f560c49c9a", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(20, 5 * dim)\n        self.population_size = self.initial_population_size\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n            # Dynamic population resizing\n            if self.eval_count % (self.budget // 10) == 0:\n                self.population_size = max(10, self.initial_population_size - (self.eval_count * self.initial_population_size) // self.budget)\n                self.particles = self.particles[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                self.best_positions = self.best_positions[:self.population_size]\n                self.best_personal_scores = self.best_personal_scores[:self.population_size]\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance AQPSO by introducing dynamic population resizing for better balance between exploration and exploitation.", "configspace": "", "generation": 88, "fitness": 0.06956878986068445, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06923138390019579, 0.0690647129488633, 0.07041027273299427]}, "mutation_prompt": null}
{"id": "19e19432-7e4f-4000-a13e-5087550e104d", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            # Dynamic population size adjustment\n            if self.eval_count % 100 == 0 and self.eval_count < self.budget:\n                self.population_size = min(self.population_size + 5, int(1.5 * self.population_size))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic population size adjustment to enhance adaptability across different problem landscapes.", "configspace": "", "generation": 89, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (35,6) (30,6) ').", "error": "ValueError('operands could not be broadcast together with shapes (35,6) (30,6) ')", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {}, "mutation_prompt": null}
{"id": "0d76fa66-c57e-432b-af82-19b8acced99f", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n        self.stall_count = np.zeros(self.population_size)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            self.stall_count[~improved_mask] += 1  # Added line\n            self.stall_count[improved_mask] = 0  # Added line\n            \n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n            # Burst exploitation if stalling\n            burst_exploit = self.stall_count > 10  # Added line\n            self.velocities[burst_exploit] = np.random.uniform(-0.5, 0.5, (burst_exploit.sum(), self.dim))  # Added line\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce local search intensification by allowing particle stalling detection and burst exploitation.", "configspace": "", "generation": 90, "fitness": 0.06966054643695008, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969604872019397, 0.06877137577717518, 0.07051421481348108]}, "mutation_prompt": null}
{"id": "78b7ed1f-3c27-48d6-a80b-61422b0096a3", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                (self.c1 + 0.1 * self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +  # Changed line\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce time-varying acceleration coefficients to enhance convergence speed.", "configspace": "", "generation": 91, "fitness": 0.06959710864669, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06953847535994617, 0.06873979920074913, 0.07051305137937469]}, "mutation_prompt": null}
{"id": "940a1c29-e94d-4299-ae34-bc8f28828d14", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.55 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Slightly adjust velocity update formula for enhanced convergence.", "configspace": "", "generation": 92, "fitness": 0.06932666779754337, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06949625635535517, 0.06800102868601188, 0.07048271835126307]}, "mutation_prompt": null}
{"id": "9b991bfe-bb93-47d0-a5e3-e6305fb6162e", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * np.tanh(self.velocities)  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Adjust particle update to incorporate nonlinear velocity scaling to enhance convergence behavior.", "configspace": "", "generation": 93, "fitness": 0.05294640305410436, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.05126123865027954, 0.050877378786136074, 0.056700591725897476]}, "mutation_prompt": null}
{"id": "42176008-e878-4e70-ba4f-4039a37df5c4", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.98 + 0.02 * np.cos(2 * np.pi * self.eval_count / self.budget))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance adaptive velocity scaling by tweaking inertia weight formula for better convergence.", "configspace": "", "generation": 94, "fitness": 0.06962370140003467, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969457076329466, 0.06866577495567683, 0.07051075848113253]}, "mutation_prompt": null}
{"id": "b698c981-f82c-469b-9e43-9b268201a686", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + 2 * self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            ) # Enhanced line\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Enhance velocity update by increasing the influence of the global best position over time.", "configspace": "", "generation": 95, "fitness": 0.06949202490176336, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06962765401522653, 0.06862289169596769, 0.07022552899409584]}, "mutation_prompt": null}
{"id": "d2e2d788-ce1d-41f8-868c-dc83915f24f9", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.98 + 0.02 * np.cos(2 * np.pi * self.eval_count / self.budget))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic inertia weight adjustment to enhance global and local search balance.", "configspace": "", "generation": 96, "fitness": 0.06962370140003467, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969457076329466, 0.06866577495567683, 0.07051075848113253]}, "mutation_prompt": null}
{"id": "afa54d70-9996-44aa-bc1f-4135061f8bfd", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.005 * np.cos(2 * np.pi * self.eval_count / self.budget))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Alter the inertia weight update to introduce a more responsive adjustment based on convergence.", "configspace": "", "generation": 97, "fitness": 0.06963515510719435, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969642608365745, 0.06866995355090089, 0.07053908568702472]}, "mutation_prompt": null}
{"id": "20b9b33a-5e5b-4911-8336-a6e7e6a3184e", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.8 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)  # Changed line\n            )\n            self.particles += 0.9 * self.velocities\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.99 + 0.01 * np.cos(2 * np.pi * self.eval_count / self.budget)) \n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Fine-tune exploration by adjusting velocity update parameter to improve convergence speed.", "configspace": "", "generation": 98, "fitness": 0.0683809377003309, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06593387002352147, 0.06863977742269778, 0.07056916565477345]}, "mutation_prompt": null}
{"id": "15e0b225-ff3d-4768-9bbb-7f6fa682ed0d", "solution": "import numpy as np\n\nclass AQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.particles = None\n        self.velocities = None\n        self.best_positions = None\n        self.best_global_position = None\n        self.best_personal_scores = None\n        self.best_global_score = np.inf\n        self.eval_count = 0\n\n    def __call__(self, func):\n        # Initialize particles\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_positions = self.particles.copy()\n        self.best_personal_scores = np.array([np.inf] * self.population_size)\n        \n        for _ in range(self.budget):\n            scores = np.array([func(p) for p in self.particles])\n            self.eval_count += self.population_size\n            \n            # Update personal bests\n            improved_mask = scores < self.best_personal_scores\n            self.best_personal_scores[improved_mask] = scores[improved_mask]\n            self.best_positions[improved_mask] = self.particles[improved_mask]\n            \n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.best_global_score:\n                self.best_global_score = scores[min_score_idx]\n                self.best_global_position = self.particles[min_score_idx].copy()\n\n            if self.eval_count >= self.budget:\n                break\n            \n            # Update velocities and particles\n            r1 = np.random.uniform(size=(self.population_size, self.dim))\n            r2 = np.random.uniform(size=(self.population_size, self.dim))\n            self.velocities = (\n                self.w * self.velocities +\n                self.c1 * (1 + self.eval_count / self.budget) * r1 * (self.best_positions - self.particles) +\n                self.c2 * (0.5 + self.eval_count / (2 * self.budget)) * r2 * (self.best_global_position - self.particles)\n            )\n            self.particles += 0.9 * self.velocities  # Changed line\n            \n            # Constrain particles to within bounds\n            out_of_bounds_low = self.particles < lb\n            out_of_bounds_high = self.particles > ub\n            \n            self.particles = np.where(out_of_bounds_low, lb, self.particles)\n            self.particles = np.where(out_of_bounds_high, ub, self.particles)\n            \n            # Adaptive boundary adjustment\n            range_adjustment = (ub - lb) * np.exp(-0.01 * self.eval_count / self.budget)\n            lb = np.maximum(lb, self.particles.min(axis=0) - range_adjustment)\n            ub = np.minimum(ub, self.particles.max(axis=0) + range_adjustment)\n            \n            # Inertia weight decay and velocity reset\n            self.w *= (0.98 + 0.02 * np.cos(2 * np.pi * self.eval_count / self.budget))  # Changed line\n            if np.random.rand() < 0.05:\n                self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            \n        return self.best_global_position, self.best_global_score", "name": "AQPSO", "description": "Introduce dynamic adjustment of the inertia weight to enhance convergence speed.", "configspace": "", "generation": 99, "fitness": 0.06962370140003467, "feedback": "The algorithm AQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.07 with standard deviation 0.00.", "error": "", "parent_id": "497d4a0a-2695-41a6-a23f-ef9b4483e62e", "metadata": {"aucs": [0.06969457076329466, 0.06866577495567683, 0.07051075848113253]}, "mutation_prompt": null}

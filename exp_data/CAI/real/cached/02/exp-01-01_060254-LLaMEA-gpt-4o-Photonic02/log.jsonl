{"id": "6283d181-c709-4479-aa32-4619df4768ba", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on progress made during exploration\n        adaptive_factor = 0.1 + 0.4 * (1 - best_value / float('inf'))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Swarm-inspired dual-phase optimization combining exploration via random sampling and exploitation through a local search adjusted by a novel adaptive factor.", "configspace": "", "generation": 0, "fitness": 0.6529050379271595, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.6547933125389307, 0.6510167633153883]}, "mutation_prompt": null}
{"id": "3166bab3-f139-4068-ba5d-5d7523d49626", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced Adaptive factor based on both exploration and exploitation\n        adaptive_factor = 0.1 + 0.4 * (1 - (best_value / float('inf') + np.mean(lb + (ub-lb)*np.random.rand(self.dim)))/2)\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced adaptive factor by considering both local and global information to balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.6478653467656992, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.65 with standard deviation 0.00.", "error": "", "parent_id": "6283d181-c709-4479-aa32-4619df4768ba", "metadata": {"aucs": [0.6514514864961891, 0.6442792070352092]}, "mutation_prompt": null}
{"id": "4446759f-bd01-4a48-9084-329b9a44947d", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on progress made during exploration\n        adaptive_factor = 0.1 + 0.4 * np.exp(-best_value / float('inf'))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced adaptive factor with exponential decay for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.6594153459041572, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.02.", "error": "", "parent_id": "6283d181-c709-4479-aa32-4619df4768ba", "metadata": {"aucs": [0.6767571901441005, 0.6420735016642138]}, "mutation_prompt": null}
{"id": "4fc8985c-90ac-4d10-bea8-351242b331a4", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on progress made during exploration\n        adaptive_factor = 0.1 + 0.4 * np.exp(-best_value / float('inf'))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)  # Changed line: dynamic step size\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced local search with dynamic step size adaptation for refined exploitation.", "configspace": "", "generation": 3, "fitness": 0.6735434440590773, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.02.", "error": "", "parent_id": "4446759f-bd01-4a48-9084-329b9a44947d", "metadata": {"aucs": [0.6564739653766182, 0.6906129227415365]}, "mutation_prompt": null}
{"id": "7eb25817-7763-4ee2-ae67-eacb907ca229", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on progress made during exploration\n        adaptive_factor = 0.1 + 0.4 * np.exp(-best_value / float('inf'))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        momentum = np.zeros(self.dim)  # Added line: Initialize momentum\n\n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n                \n                candidate_position += 0.9 * momentum  # Changed line: Apply momentum\n                momentum = candidate_position - local_best_position  # Update momentum\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Refined exploitation with adaptive momentum for improved convergence speed.", "configspace": "", "generation": 4, "fitness": 0.6580107978743203, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.01.", "error": "", "parent_id": "4fc8985c-90ac-4d10-bea8-351242b331a4", "metadata": {"aucs": [0.6475959157091764, 0.6684256800394641]}, "mutation_prompt": null}
{"id": "9818dc33-0bc3-4819-941c-149f27ecee41", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on dynamic exploration feedback\n        adaptive_factor = 0.1 + 0.4 * np.exp(-best_value / (best_value + 1e-9))  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Improved adaptive factor calculation using dynamic exploration feedback for enhanced convergence.", "configspace": "", "generation": 5, "fitness": 0.741458375029024, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.01.", "error": "", "parent_id": "4fc8985c-90ac-4d10-bea8-351242b331a4", "metadata": {"aucs": [0.7358569097034272, 0.7470598403546207]}, "mutation_prompt": null}
{"id": "07ff2500-9742-4c82-9383-9e01b7ceaff5", "solution": "# Description: Enhanced local search with a refined adaptive factor for improved convergence.\n# Code:\nimport numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on dynamic exploration feedback\n        adaptive_factor = 0.05 + 0.45 * np.exp(-best_value / (best_value + 1e-9))  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 2.0)  # Changed line\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced local search with a refined adaptive factor for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.741007983780179, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.00.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.7430653743771645, 0.7389505931831934]}, "mutation_prompt": null}
{"id": "7962786b-4db7-48b8-a100-712447b6d436", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.5)  # Changed line\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on dynamic exploration feedback\n        adaptive_factor = 0.1 + 0.5 * np.exp(-best_value / (best_value + 1e-9))  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced convergence through adaptive sampling and step size modulation.", "configspace": "", "generation": 7, "fitness": 0.7327698521491242, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.03.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.7623543045666396, 0.7031853997316089]}, "mutation_prompt": null}
{"id": "2d426bba-1da3-49be-9bfe-243ce8cf74c9", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        adaptive_factor = 0.1 + 0.4 * np.exp(-best_value / (best_value + 1e-9))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n\n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step_scale = (1.5 - (best_value / (best_value + 1e-9)))  # Changed line\n                step = adaptive_factor * step_scale * (ub[d] - lb[d]) * (np.random.rand() - 0.5)  # Changed line\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced local search with adaptive step scaling for improved convergence.", "configspace": "", "generation": 8, "fitness": 0.7320535418633566, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.7365954612950962, 0.7275116224316169]}, "mutation_prompt": null}
{"id": "d714604b-fbba-4017-9016-f4a28dd4f32d", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on dynamic exploration feedback\n        adaptive_factor = 0.1 + 0.3 * np.exp(-best_value / (best_value + 1e-9))  # Adjusted factor from 0.4 to 0.3\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Fine-tune exploration and exploitation balance by adjusting the adaptive factor calculation formula.", "configspace": "", "generation": 9, "fitness": 0.6812089454450204, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.02.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.6615338587643698, 0.7008840321256711]}, "mutation_prompt": null}
{"id": "0c48b1f9-a8f5-4a60-bbcc-af936632c4a7", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on dynamic exploration feedback\n        adaptive_factor = 0.1 + 0.4 * np.exp(-best_value / (best_value + 1e-9))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                angle = np.pi * (np.random.rand() - 0.5)  # Stochastic rotation\n                candidate_position[d] += step * np.cos(angle)  # Changed line\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced position update strategy using stochastic rotation for better local exploitation.", "configspace": "", "generation": 10, "fitness": 0.740529384682836, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.01.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.7256504456003617, 0.7554083237653103]}, "mutation_prompt": null}
{"id": "ef5e9e73-e0b0-495e-a09f-9932a4dd3196", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Non-linear adjustment in adaptive factor\n        adaptive_factor = 0.1 + 0.4 * np.exp(-best_value**2 / (best_value**2 + 1e-9))  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced convergence by introducing non-linear adjustment in adaptive factor calculation.", "configspace": "", "generation": 11, "fitness": 0.7056412899649347, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.02.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.7305190134985835, 0.6807635664312858]}, "mutation_prompt": null}
{"id": "4b0125a6-0009-4583-bf73-4ea2f9b5734f", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on dynamic exploration feedback\n        adaptive_factor = 0.1 + 0.4 * np.exp(-best_value / (best_value + 1e-9))  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * np.random.normal(0, 1)  # Changed line\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced mutation strategy for adaptive factor using Gaussian noise for better local exploration.", "configspace": "", "generation": 12, "fitness": 0.7303703908811194, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.01.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.7220009711700129, 0.738739810592226]}, "mutation_prompt": null}
{"id": "dda3f6ff-dbdf-4312-89c9-fc12d7bcc35c", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on dynamic exploration feedback\n        adaptive_factor = 0.1 + 0.4 * np.exp(-best_value / (best_value + 1e-9)) * np.cos(best_value)  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a cosine modulation to the adaptive factor for improved local search precision.", "configspace": "", "generation": 13, "fitness": 0.6601000826406969, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.01.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.6730065389631537, 0.6471936263182402]}, "mutation_prompt": null}
{"id": "b86cd937-013e-4c57-ad7b-bbc6626aa93f", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Adaptive factor based on dynamic exploration feedback\n        adaptive_factor = 0.15 + 0.4 * np.exp(-best_value / (best_value + 1e-9))  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.4, 1.6)  # Changed line\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced adaptive factor computation with improved local search precision for better convergence.", "configspace": "", "generation": 14, "fitness": 0.737539056424871, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.01.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.726972674482685, 0.7481054383670571]}, "mutation_prompt": null}
{"id": "174453b0-c0de-4d73-9b41-37f9342c9c22", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor calculation\n        adaptive_factor = 0.15 + 0.3 * np.exp(-best_value / (best_value + 1e-9))  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.7, 1.3)  # Changed line\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced adaptive factor and strategic local step scaling for superior convergence.", "configspace": "", "generation": 15, "fitness": 0.706151341420248, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.01.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.7176905432580845, 0.6946121395824116]}, "mutation_prompt": null}
{"id": "60308b32-f444-4d0f-9cb0-66be268e91a4", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced adaptive factor with nonlinear decay for improved local search efficiency.", "configspace": "", "generation": 16, "fitness": 0.7414593624824191, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.01.", "error": "", "parent_id": "9818dc33-0bc3-4819-941c-149f27ecee41", "metadata": {"aucs": [0.735855176429709, 0.7470635485351291]}, "mutation_prompt": null}
{"id": "86d63352-9d51-41e2-a1a0-bdd32d170ac2", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.3, 1.2)  # Modified to dynamic scaling\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introducing a dynamic step size scaling mechanism in the exploitation phase to enhance convergence.", "configspace": "", "generation": 17, "fitness": 0.7251046197334886, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.01.", "error": "", "parent_id": "60308b32-f444-4d0f-9cb0-66be268e91a4", "metadata": {"aucs": [0.736630207902406, 0.7135790315645713]}, "mutation_prompt": null}
{"id": "3af4b477-7d39-4d32-8958-4cd7a34700a1", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search and momentum\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        momentum = np.zeros(self.dim)  # Added line\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                momentum[d] = 0.9 * momentum[d] + step  # Modified line\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += momentum[d] * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a momentum factor in the local search phase to accelerate convergence towards promising regions.", "configspace": "", "generation": 18, "fitness": 0.6916050292476241, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.02.", "error": "", "parent_id": "60308b32-f444-4d0f-9cb0-66be268e91a4", "metadata": {"aucs": [0.7127253636359191, 0.6704846948593293]}, "mutation_prompt": null}
{"id": "3d47f234-1a1d-409b-8bb0-67de0b35f847", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.15 + 0.35 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.6, 1.4)  # Changed line\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Dual-phase optimizer with enhanced local search using adaptive factor variation and selective stochastic perturbations.", "configspace": "", "generation": 19, "fitness": 0.731463153835816, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.01.", "error": "", "parent_id": "60308b32-f444-4d0f-9cb0-66be268e91a4", "metadata": {"aucs": [0.7188515448362527, 0.7440747628353792]}, "mutation_prompt": null}
{"id": "7afdac87-da84-437b-8a80-7551fdaf8444", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Refined adaptive factor with improved formula\n        adaptive_factor = 0.1 + 0.5 * np.exp(-np.sqrt(best_value / (best_value + 1e-8)))  # Changed line\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for _ in range(remaining_budget):\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5)\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Refined DualPhaseSwarmOptimizer with improved adaptive factor formula for enhanced global to local transition.", "configspace": "", "generation": 20, "fitness": 0.7266068238809078, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00.", "error": "", "parent_id": "60308b32-f444-4d0f-9cb0-66be268e91a4", "metadata": {"aucs": [0.7231252101030784, 0.7300884376587371]}, "mutation_prompt": null}
{"id": "cccaaf3a-77c5-4f27-935e-59fb8442b22d", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  # Changed line\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay  # Changed line\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introducing a dynamically adjusted exploitation phase factor based on iteration count to enhance convergence speed.", "configspace": "", "generation": 21, "fitness": 0.7437035964679286, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.00.", "error": "", "parent_id": "60308b32-f444-4d0f-9cb0-66be268e91a4", "metadata": {"aucs": [0.7413613157963506, 0.7460458771395068]}, "mutation_prompt": null}
{"id": "dd7a64dd-e617-42ec-b743-373e067b8277", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for i in range(samples):\n            decay = np.sin(i / samples * np.pi / 2)  # Changed line\n            position = lb + (ub - lb) * (np.random.rand(self.dim) * decay)  # Changed line\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  # Changed line\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay  # Changed line\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Incorporate a nonlinear exploration phase to initially focus on diverse sampling, gradually enhancing local search precision.", "configspace": "", "generation": 22, "fitness": 0.6807380625186893, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.01.", "error": "", "parent_id": "cccaaf3a-77c5-4f27-935e-59fb8442b22d", "metadata": {"aucs": [0.6709291044375965, 0.6905470205997821]}, "mutation_prompt": null}
{"id": "b7b5aa32-bece-4c22-bda8-dcbd6f1d0f99", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)\n            for d in range(self.dim):\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * np.random.uniform(0.8, 1.2)  # Changed line\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introducing stochastic scaling in the step size to enhance exploration diversity and convergence precision.", "configspace": "", "generation": 23, "fitness": 0.7159324280307892, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.01.", "error": "", "parent_id": "cccaaf3a-77c5-4f27-935e-59fb8442b22d", "metadata": {"aucs": [0.7274073069322065, 0.7044575491293719]}, "mutation_prompt": null}
{"id": "e88e02f2-ef24-488b-93ca-cfdccb558a30", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            for d in range(self.dim):\n                step_scaling = np.random.rand()  # Changed line: introduce probabilistic step size scaling\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a probabilistic step size scaling factor for enhanced local exploration during exploitation phase.", "configspace": "", "generation": 24, "fitness": 0.7490701006403265, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.01.", "error": "", "parent_id": "cccaaf3a-77c5-4f27-935e-59fb8442b22d", "metadata": {"aucs": [0.7408630969714796, 0.7572771043091735]}, "mutation_prompt": null}
{"id": "f818ead2-f41d-45ea-8d43-57391f44d503", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        momentum = np.zeros(self.dim)  # Added line: Initialize momentum\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            for d in range(self.dim):\n                step_scaling = np.random.rand()  # Changed line: introduce probabilistic step size scaling\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                momentum[d] = 0.9 * momentum[d] + step  # Introduce momentum-like effect\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += momentum[d] * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a momentum-like term to enhance convergence speed in local search phase.", "configspace": "", "generation": 25, "fitness": 0.6969124103250985, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.01.", "error": "", "parent_id": "e88e02f2-ef24-488b-93ca-cfdccb558a30", "metadata": {"aucs": [0.6866928609657882, 0.7071319596844088]}, "mutation_prompt": null}
{"id": "b7062a8a-45c6-4b64-8078-1a8f736907f9", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            dynamic_learning_rate = 0.5 + 0.5 * np.cos(np.pi * i / remaining_budget)  # Changed line: introduce dynamic learning rate\n            for d in range(self.dim):\n                step_scaling = np.random.rand()  # Introduce probabilistic step size scaling\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * dynamic_learning_rate\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce dynamic learning rates during exploitation for enhanced convergence precision.", "configspace": "", "generation": 26, "fitness": 0.7257195649798973, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.02.", "error": "", "parent_id": "e88e02f2-ef24-488b-93ca-cfdccb558a30", "metadata": {"aucs": [0.7030241649879609, 0.7484149649718338]}, "mutation_prompt": null}
{"id": "73e5d255-c6d9-44f1-af6e-1674d57d2a37", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            for d in range(self.dim):\n                step_scaling = np.random.rand()  # Changed line: introduce probabilistic step size scaling\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Added stochastic perturbation\n                candidate_position += np.random.normal(0, 0.01, self.dim) \n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce stochastic perturbation in the exploitation phase to enhance local search diversity.", "configspace": "", "generation": 27, "fitness": 0.7454316616971733, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.02.", "error": "", "parent_id": "e88e02f2-ef24-488b-93ca-cfdccb558a30", "metadata": {"aucs": [0.7638240465396393, 0.7270392768547074]}, "mutation_prompt": null}
{"id": "07ce4674-43a8-4f33-879a-c9ed6a41702b", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling and opposition-based learning\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            opposition_position = lb + ub - position  # New line: Opposition-based learning\n            value = func(position)\n            opposition_value = func(opposition_position)  # New line: Evaluate opposition\n            if opposition_value < value:\n                value = opposition_value\n                position = opposition_position\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce dynamic opposition-based learning to diversify exploration and enhance convergence in photonic structure optimization.", "configspace": "", "generation": 28, "fitness": 0.7157376290190745, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.02.", "error": "", "parent_id": "e88e02f2-ef24-488b-93ca-cfdccb558a30", "metadata": {"aucs": [0.6991892747289765, 0.7322859833091724]}, "mutation_prompt": null}
{"id": "b0711da5-2864-417f-bf78-4826ab8fb35a", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / (remaining_budget + 0.5))  # Changed line: slightly modified decay function\n            for d in range(self.dim):\n                step_scaling = np.random.uniform(0.8, 1.2)  # Changed line: adjusted range of step_scaling\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhanced decay function and step scaling factor to improve local search convergence.", "configspace": "", "generation": 29, "fitness": 0.6677560316332127, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.03.", "error": "", "parent_id": "e88e02f2-ef24-488b-93ca-cfdccb558a30", "metadata": {"aucs": [0.6372090123698732, 0.6983030508965522]}, "mutation_prompt": null}
{"id": "9aeecc70-bce1-439d-85d6-67680741a7d4", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            # Introducing random reset mechanism\n            if np.random.rand() < 0.01:  # Random reset condition\n                best_position = lb + (ub - lb) * np.random.rand(self.dim)\n            for d in range(self.dim):\n                step_scaling = np.random.rand()  # Changed line: introduce probabilistic step size scaling\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a random reset mechanism for the best position to escape local optima during exploitation phase.", "configspace": "", "generation": 30, "fitness": 0.7228747273652825, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.02.", "error": "", "parent_id": "e88e02f2-ef24-488b-93ca-cfdccb558a30", "metadata": {"aucs": [0.7438175373200258, 0.7019319174105392]}, "mutation_prompt": null}
{"id": "225a7465-e005-4774-8da0-d6839353c9fe", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            adaptive_factor *= (1 - i / remaining_budget)  # Changed line: dynamic decay adjustment\n            decay = 1 - (i / remaining_budget)\n            for d in range(self.dim):\n                step_scaling = np.random.rand()  # Changed line: introduce probabilistic step size scaling\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Implement a dynamic decay strategy by adjusting the adaptive factor based on current iteration, enhancing convergence.", "configspace": "", "generation": 31, "fitness": 0.7401273285408847, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.00.", "error": "", "parent_id": "e88e02f2-ef24-488b-93ca-cfdccb558a30", "metadata": {"aucs": [0.7401221202700675, 0.7401325368117018]}, "mutation_prompt": null}
{"id": "a0d252fc-9f7b-4e2d-b9b2-0453382b38cc", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            for d in range(self.dim):\n                step_scaling = np.random.rand()  # Changed line: introduce probabilistic step size scaling\n                step = adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce non-uniform mutation for enhanced exploration in the local search phase.", "configspace": "", "generation": 32, "fitness": 0.7490701006403265, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.01.", "error": "", "parent_id": "e88e02f2-ef24-488b-93ca-cfdccb558a30", "metadata": {"aucs": [0.7408630969714796, 0.7572771043091735]}, "mutation_prompt": null}
{"id": "2b84dd85-6e87-4097-a0d6-9618c0de6c54", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * (i / remaining_budget)  # Changed line: introduce dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a dynamic inertia weight that decreases over iterations to balance exploration and exploitation.", "configspace": "", "generation": 33, "fitness": 0.7535598928157743, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.01.", "error": "", "parent_id": "e88e02f2-ef24-488b-93ca-cfdccb558a30", "metadata": {"aucs": [0.7396646496234275, 0.7674551360081212]}, "mutation_prompt": null}
{"id": "889331e6-ca09-401f-ad81-7053d7b3a353", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a sinusoidal dynamic inertia weight to balance exploration and exploitation more effectively.", "configspace": "", "generation": 34, "fitness": 0.7538563305202302, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.01.", "error": "", "parent_id": "2b84dd85-6e87-4097-a0d6-9618c0de6c54", "metadata": {"aucs": [0.7399074217890683, 0.7678052392513919]}, "mutation_prompt": null}
{"id": "d18c6d51-b2e2-448f-b880-f52599338715", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce adaptive sinusoidal dynamic inertia for enhanced balance between search phases.", "configspace": "", "generation": 35, "fitness": 0.7542376191232862, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.01.", "error": "", "parent_id": "889331e6-ca09-401f-ad81-7053d7b3a353", "metadata": {"aucs": [0.7402489141145825, 0.7682263241319901]}, "mutation_prompt": null}
{"id": "f68cc362-799c-402f-bf97-6af915cd0c61", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.65)  # Change: increase exploration percentage\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce adaptive sinusoidal dynamic inertia for enhanced balance between search phases, with a slight increase in exploration phase.", "configspace": "", "generation": 36, "fitness": 0.7444901588335248, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "d18c6d51-b2e2-448f-b880-f52599338715", "metadata": {"aucs": [0.7186657678889352, 0.7703145497781143]}, "mutation_prompt": null}
{"id": "00f2fcdb-a926-4083-b49f-9438a29db27c", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        # Chaotic sine mapping\n        sine_map = np.sin(np.arange(remaining_budget) * np.pi / 2)  \n\n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * sine_map[i] + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce chaotic sine mapping\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce chaotic sine mapping for improved exploration and convergence during the search process.", "configspace": "", "generation": 37, "fitness": 0.6940366858237634, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.05.", "error": "", "parent_id": "d18c6d51-b2e2-448f-b880-f52599338715", "metadata": {"aucs": [0.6453553586374011, 0.7427180130101256]}, "mutation_prompt": null}
{"id": "835e0322-b5e3-484b-a749-5d46a1b25c73", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling using chaotic map\n        samples = int(self.budget * 0.6)\n        chaotic_map = np.random.rand(self.dim)  # Initialize chaotic map\n        for _ in range(samples):\n            chaotic_map = 1 - 2 * (chaotic_map ** 2)  # Logistic map update for chaos\n            position = lb + (ub - lb) * chaotic_map\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Integrate chaotic maps for a more unpredictable exploration phase, enhancing global search capacity.", "configspace": "", "generation": 38, "fitness": 0.5996763750544568, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.60 with standard deviation 0.01.", "error": "", "parent_id": "d18c6d51-b2e2-448f-b880-f52599338715", "metadata": {"aucs": [0.5927713332110407, 0.6065814168978729]}, "mutation_prompt": null}
{"id": "98db3620-71b7-41b1-94d4-661fcce313c0", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.cos(np.pi * i / remaining_budget)  # Changed line: use cosine wave for inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Refine inertia weight update to use a cosine wave for improved convergence.", "configspace": "", "generation": 39, "fitness": 0.6973871354267648, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.06.", "error": "", "parent_id": "d18c6d51-b2e2-448f-b880-f52599338715", "metadata": {"aucs": [0.7538953773879291, 0.6408788934656005]}, "mutation_prompt": null}
{"id": "e2af25be-0d4c-4b6f-be7c-818956b3aed9", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        for _ in range(samples):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget) + 0.05 * np.random.uniform(-1, 1)  # Changed line: introduce chaotic perturbation in inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce chaotic perturbation in the inertia weight for enhanced exploration.", "configspace": "", "generation": 40, "fitness": 0.6990927906415263, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.01.", "error": "", "parent_id": "d18c6d51-b2e2-448f-b880-f52599338715", "metadata": {"aucs": [0.6884061117979479, 0.7097794694851046]}, "mutation_prompt": null}
{"id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a chaotic map for diversified sampling in the exploration phase.", "configspace": "", "generation": 41, "fitness": 0.8175737634445762, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.82 with standard deviation 0.02.", "error": "", "parent_id": "d18c6d51-b2e2-448f-b880-f52599338715", "metadata": {"aucs": [0.8351412847886411, 0.8000062421005113]}, "mutation_prompt": null}
{"id": "0b51ad38-711b-447f-b947-258f2aceeaa0", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            scaling_factor = 0.5 + 0.5 * np.sin(x * np.pi)  # Changed line: introduce dynamic adjustment based on chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim) * scaling_factor\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a feedback mechanism to dynamically adjust chaotic sequence scaling during exploration.", "configspace": "", "generation": 42, "fitness": 0.6650787450133063, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6584664891603385, 0.6716910008662742]}, "mutation_prompt": null}
{"id": "bb388404-deb4-41a3-8b48-06f06b2a2721", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds and apply Gaussian perturbation\n                candidate_position = np.clip(candidate_position + np.random.normal(0, 0.01, self.dim), lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce Gaussian perturbation in local search for enhanced exploitation around promising regions.", "configspace": "", "generation": 43, "fitness": 0.745773011549024, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.75 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.717210630671591, 0.7743353924264569]}, "mutation_prompt": null}
{"id": "561474eb-9769-426e-bd7d-640e5c7f583a", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Changed line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * x  # Change: use chaotic x to scale position initialization\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Refine chaotic mapping to improve exploration diversity in the initial phase.", "configspace": "", "generation": 44, "fitness": 0.6191815828993126, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.62 with standard deviation 0.00.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6216682710149734, 0.6166948947836519]}, "mutation_prompt": null}
{"id": "2351fd27-dd0a-447f-a38d-ff5c96fb0c58", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  \n        for _ in range(samples):\n            x = 4 * x * (1 - x)\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            position += (0.1 * x - 0.05) * (ub - lb)  # Modified line: scale positional update by chaotic map\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Refine chaotic sequence impact by scaling logistic map iterations for enhanced exploration.", "configspace": "", "generation": 45, "fitness": 0.7141684621465618, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7266481984930657, 0.701688725800058]}, "mutation_prompt": null}
{"id": "7ff23db8-e431-4ce4-b043-c78ba3a9e485", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for i in range(samples):\n            x = 4 * x * (1 - x) + 0.01 * np.sin(2 * np.pi * i / samples)  # Changed line: introduce sinusoidal factor into logistic map\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance chaotic sampling by introducing a sinusoidal factor into the logistic map for better exploration.", "configspace": "", "generation": 46, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "2fcf1f7f-f15d-4174-95d7-5c31cd7c3141", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a chaotic map for diversified sampling in the exploration phase and refine the exploitation phase with a nonlinear chaotic factor.", "configspace": "", "generation": 47, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "38d48b7a-ae12-4be6-9f47-baed8d4f34fd", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.tan(np.pi * i / remaining_budget)  # Changed line: introduce adaptive tangent dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a tangent function to enhance the dynamic sinusoidal inertia weight for improved exploitation control.", "configspace": "", "generation": 48, "fitness": 0.7393120169166669, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.769042254619987, 0.709581779213347]}, "mutation_prompt": null}
{"id": "9a9655ff-59e5-4ead-a5e3-279145f9aeb0", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = np.sin(4 * x * (1 - x))  # Changed line: non-linear transformation to chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a non-linear transformation to the chaotic sequence for improved exploratory diversity.", "configspace": "", "generation": 49, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "b9e70d07-6882-4267-a469-b905293a5d7b", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x) * np.random.uniform(0.8, 1.2)  # Changed line: adaptive chaotic variable\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce adaptive chaotic variable for enhanced diversification in exploration.", "configspace": "", "generation": 50, "fitness": 0.7278158630668166, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.02.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7044699495106388, 0.7511617766229942]}, "mutation_prompt": null}
{"id": "7e3f428f-67f2-451d-b123-2b11589daedc", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 3.9 * x * (1 - x)  # Changed line: logistic map with slightly varied control parameter\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a chaotic map for diversified sampling in the exploration phase with logistic map varying control parameter.", "configspace": "", "generation": 51, "fitness": 0.6874934121201055, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6556636200755738, 0.7193232041646372]}, "mutation_prompt": null}
{"id": "cd7ecdd8-d427-43c9-874d-9b6f86f52620", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = np.sin(np.pi * 4 * x * (1 - x))  # Changed line: apply a non-linear transformation to chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance diversification by applying a non-linear transformation to the chaotic sequence.", "configspace": "", "generation": 52, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "0ce9a5c7-4aea-40ae-bbcc-b56c8e60fe15", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        spread_factor = 0.1  # Added line: adjust spread of chaotic map\n        for _ in range(samples):\n            x = 4 * x * (1 - x + spread_factor * np.random.rand())  # Changed line: logistic map with spread factor\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance sampling by incorporating a spread factor in the chaotic map for better exploration.", "configspace": "", "generation": 53, "fitness": 0.7278158630668166, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.02.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7044699495106388, 0.7511617766229942]}, "mutation_prompt": null}
{"id": "652d0f18-1e39-498b-bf88-b7e02a932740", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with polynomial decay\n        adaptive_factor = 0.1 + 0.4 * ((1 - best_value / (best_value + 1e-9)) ** 2)  # Changed line: utilize polynomial decay\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Refine the adaptive factor in Phase 2 to improve convergence by introducing polynomial decay instead of exponential.", "configspace": "", "generation": 54, "fitness": 0.7373028163372141, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7288507180466743, 0.7457549146277538]}, "mutation_prompt": null}
{"id": "308b63cb-7e95-4a6f-a4c9-8c70999a819c", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            \n            # Mutation Operator: Introduce Gaussian noise for position mutation\n            position += np.random.normal(0, 0.1, self.dim)  \n            \n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance exploration by incorporating a mutation operator based on Gaussian noise.", "configspace": "", "generation": 55, "fitness": 0.704785473213809, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.06.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6494544397514654, 0.7601165066761526]}, "mutation_prompt": null}
{"id": "b3f03667-5095-46ff-b730-fd40b8782349", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * x * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling  # Changed line: Include chaotic element in step calculation\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce adaptive chaotic inertia for enhanced convergence.", "configspace": "", "generation": 56, "fitness": 0.6714393125511117, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.02.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6497827171528201, 0.6930959079494032]}, "mutation_prompt": null}
{"id": "8252b659-0790-4404-89de-28bb7c1c9732", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a chaotic map for diversified sampling in the exploration phase, enhancing exploitation with sinusoidal dynamic inertia.", "configspace": "", "generation": 57, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "717936cd-e436-4cc2-a63e-69cd4907d513", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5) + np.random.normal(0, 0.01)  # Modified line: Added Gaussian perturbation\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Improve convergence by introducing Gaussian perturbation during exploitation phase.", "configspace": "", "generation": 58, "fitness": 0.7166305293471137, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.00.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7166409099711317, 0.7166201487230957]}, "mutation_prompt": null}
{"id": "1f5228c7-9538-4e69-909f-e35badb4af3b", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 3.9 * x * (1 - x)  # Changed line: adjusted logistic map parameter for improved exploration\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Refine chaotic diversification by adjusting chaotic map parameters for better exploration.", "configspace": "", "generation": 59, "fitness": 0.7073768375083181, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.02.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6900163704707853, 0.724737304545851]}, "mutation_prompt": null}
{"id": "dedef470-2e22-4b6d-a6ca-be6fa691ecae", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget) \n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling * (0.5 + 0.5 * x)  # Changed line: introduce exploration-exploitation balance factor with chaotic influence\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce an exploration-exploitation balance factor using chaotic sequences to further improve convergence.", "configspace": "", "generation": 60, "fitness": 0.7250208086809052, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.00.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7286891546005132, 0.7213524627612973]}, "mutation_prompt": null}
{"id": "d356ade0-6c59-4a1e-acb4-359a12fe0376", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.cos(np.pi * i / remaining_budget)  # Changed line: introduce adaptive cosine dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a chaotic map for diversified sampling in the exploration phase.", "configspace": "", "generation": 61, "fitness": 0.7393876942913526, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.02.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7640642105298903, 0.7147111780528151]}, "mutation_prompt": null}
{"id": "e857fb18-42a6-451a-8cf6-c950cd993b36", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Integrate a dynamic adaptive factor based on function value variance to enhance local search.", "configspace": "", "generation": 62, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "64ff96a3-3453-487c-89a7-81022f809d06", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with sinusoidal map for chaotic sequence\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = np.sin(np.pi * x)  # Changed line: sinusoidal map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Adjust the chaotic map to a sinusoidal map to enhance exploration diversity.", "configspace": "", "generation": 63, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "a5da0789-981f-406d-935f-5a343454094a", "solution": "import numpy as np\nfrom scipy.stats.qmc import Sobol\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        # Changed line: Initialize chaotic variable with Sobol sequence for improved diversity\n        sobol_engine = Sobol(d=self.dim, scramble=True)\n        x = sobol_engine.random_base2(m=int(np.log2(samples)))\n        for i in range(samples):\n            x[i] = 4 * x[i] * (1 - x[i])  # logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance chaotic sequence initialization with Sobol sequence for better initial diversification.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 1024 is out of bounds for axis 0 with size 1024').", "error": "IndexError('index 1024 is out of bounds for axis 0 with size 1024')", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {}, "mutation_prompt": null}
{"id": "1b5f6dd0-4a55-4225-b938-13e68c439b09", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Logistic map for chaotic sequence\n            position = lb + (ub - lb) * x * np.random.rand(self.dim)  # Added line: use chaotic perturbation\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.cos(np.pi * i / remaining_budget)  # Changed line: introduce adaptive cosine dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance exploration using chaotic perturbation and cosine inertia weight for exploitation.", "configspace": "", "generation": 65, "fitness": 0.6716288628838545, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6786680857836345, 0.6645896399840745]}, "mutation_prompt": null}
{"id": "52524d59-2afd-40c9-8270-754fafbd2316", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand() * 0.5 + 0.75  # Changed line: adjust step scaling factor for better exploration-exploitation balance\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance local search by adjusting the scaling factor for exploration-exploitation balance.", "configspace": "", "generation": 66, "fitness": 0.6808606383717705, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6741714545173594, 0.6875498222261816]}, "mutation_prompt": null}
{"id": "e04b04e2-4ef0-455b-957e-01e3f5bd5db5", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Chaotic variable for diversification\n        for _ in range(samples):\n            x = 3.9 * x * (1 - x)  # Changed parameter: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Adjust the chaotic map's logistic parameter for enhanced exploration stability.", "configspace": "", "generation": 67, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "d047255b-73ca-448b-8966-6d912eea97b6", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Logistic map for chaotic sequence\n            position = lb + (ub - lb) * x  # Changed line: use chaotic sequence for initial position\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce chaotic sequence initialization for enhanced global exploration.", "configspace": "", "generation": 68, "fitness": 0.6162207117244592, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.62 with standard deviation 0.00.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6151304768129706, 0.6173109466359479]}, "mutation_prompt": null}
{"id": "c6f74bd0-fb23-4c4f-9b63-4a33207d99e6", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * x  # Changed line: use dynamic chaotic factor 'x' in step calculation\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance exploration by replacing a constant factor with a dynamic chaos-based factor.", "configspace": "", "generation": 69, "fitness": 0.6867564219093238, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.05.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6378028665402893, 0.7357099772783584]}, "mutation_prompt": null}
{"id": "2a6957f1-0f8a-4cee-8988-c41c8dcf5d15", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)\n            x = 4 * x * (1 - x)  # Chaotic map scaling factor (changed line)\n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a chaotic map-based scaling factor in the exploitation phase for enhanced diversification.", "configspace": "", "generation": 70, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "008ebeda-85ce-4991-9420-4bb557464677", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = np.sin(4 * x * (1 - x))  # Changed line: use sinusoidal transformation for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a nonlinear chaotic sequence to enhance exploration diversification.", "configspace": "", "generation": 71, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "bd95adc5-4fee-4535-9205-21965ed78aca", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = np.sin(np.pi * x)  # Changed line: sinusoidal chaotic map for sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Utilize a sinusoidal chaotic map for enhanced exploration phase diversification.", "configspace": "", "generation": 72, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "815b75f1-391f-4e8c-bb11-9792d1bcf0ae", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand() * 0.8 + 0.1  # Changed line: initialize chaotic variable within specific range for improved diversity\n        for _ in range(samples):\n            x = 4 * x * (1 - x)\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance chaotic sequence initialization for improved sampling diversity.", "configspace": "", "generation": 73, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "bc8631a9-03e5-4677-882f-67f24818d869", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Adaptive sinusoidal dynamic inertia weight\n            x = 4 * x * (1 - x)  # Perturbation factor for diversification\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                step *= (1 + 0.1 * x)  # Introduce chaotic perturbation factor for diversification\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance the exploitation phase by introducing a perturbation factor based on chaotic sequence for local search diversification.", "configspace": "", "generation": 74, "fitness": 0.7406884285045298, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7709443958357092, 0.7104324611733503]}, "mutation_prompt": null}
{"id": "0ec9cfc1-0f8d-482b-af3a-216e6a5cd206", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand() * 0.25 + 0.5  # Changed line: initialize chaotic variable with higher mid-range value for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Improve chaotic map initialization for enhanced diversification in exploration.", "configspace": "", "generation": 75, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "46a2d95c-bbc0-49e4-b8e1-559d7603b130", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        \n        for _ in range(samples):\n            x = np.random.rand()  # Modified line: initialize chaotic variable for each sample\n            x = 4 * x * (1 - x)  # Logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance exploration by using a chaotic map with a different initial value for each sample.", "configspace": "", "generation": 76, "fitness": 0.7144935414908372, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7218418145162564, 0.707145268465418]}, "mutation_prompt": null}
{"id": "fc480d26-dccd-413d-a104-a0e173124cc2", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x) + 0.05 * np.sin(np.pi * x)  # Modified line: add sinusoidal perturbation to chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance chaotic map by using a sinusoidal perturbation to further diversify exploration.", "configspace": "", "generation": 77, "fitness": 0.658087655572454, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.06.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.714383647394879, 0.6017916637500289]}, "mutation_prompt": null}
{"id": "0860b67c-74fa-45f0-b375-7eb0061bcd32", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x) * np.sin(x)  # Changed line: sinusoidal factor introduced in the logistic map\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a sinusoidal factor in the chaotic map for enhanced randomness.", "configspace": "", "generation": 78, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "94e903ae-ed3d-431f-862e-3d6aa779ae54", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Introduce adaptive sinusoidal dynamic inertia weight\n            for d in np.random.choice(self.dim, size=int(self.dim * np.random.uniform(0.1, 0.5)), replace=False):  # Changed line: adaptive dimensional perturbation\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance local search with adaptive dimensional perturbation for finer exploitation.", "configspace": "", "generation": 79, "fitness": 0.6590542138651678, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.02.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6422009286589583, 0.6759074990713774]}, "mutation_prompt": null}
{"id": "1ca065e7-1201-4d4e-b3e5-f60891870e03", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Dynamic inertia weight\n            x = 4 * x * (1 - x)  # Chaotic sequence for exploitation\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Integrate chaotic sampling in local search for enhanced exploitation.", "configspace": "", "generation": 80, "fitness": 0.7103646970808297, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.07.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7777946050111239, 0.6429347891505355]}, "mutation_prompt": null}
{"id": "fe07ecec-1f99-497b-a3f4-a38542cfbf84", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            x = 4 * x * (1 - x)  # Changed line: recalibrate chaotic sequence each iteration\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Incorporate a chaotic sequence recalibration at each local search iteration to enhance convergence.", "configspace": "", "generation": 81, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "fb22ec5f-352e-41f1-880c-09afb8b99e0d", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.cos(np.pi * i / remaining_budget)  # Changed line: replacing sin with cos for dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance the inertia weight's dynamic adaptation with a cosine function for improved convergence.", "configspace": "", "generation": 82, "fitness": 0.7393876942913526, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.02.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7640642105298903, 0.7147111780528151]}, "mutation_prompt": null}
{"id": "1e4a816e-6137-4867-b8ab-46ec00c2a5ed", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                step += 0.01 * np.random.standard_cauchy()  # Changed line: Levy flight step addition\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance local search by introducing a Levy flight step for improved exploration-exploitation balance.", "configspace": "", "generation": 83, "fitness": 0.7030639998939614, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.70 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6941461235757118, 0.711981876212211]}, "mutation_prompt": null}
{"id": "e04518f4-eaab-4fe1-a82d-fafd11969f76", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x) + np.random.normal(scale=0.01)  # Changed line: add stochastic perturbation to chaotic map\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce stochastic perturbations to the chaotic map enhancing exploration diversity.", "configspace": "", "generation": 84, "fitness": 0.7650888167246178, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.77 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7309570546833746, 0.7992205787658611]}, "mutation_prompt": null}
{"id": "7fa38285-2f69-42d5-bc66-3a9457767e12", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * (np.sin(np.pi * i / remaining_budget) + np.cos(np.pi * i / remaining_budget))  # Changed line: introduce cosine component for smoother inertia transition\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance adaptive sinusoidal dynamic inertia weight by including a cosine component for smoother transitions.", "configspace": "", "generation": 85, "fitness": 0.6563028775174434, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.66 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6255094874286347, 0.6870962676062522]}, "mutation_prompt": null}
{"id": "9453c017-baf6-4dee-8b55-f7779d0dd54f", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.5)  # Changed line: slightly reduced exploration samples for better balance\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a dynamic adjustment to the sample size between exploration and exploitation phases.", "configspace": "", "generation": 86, "fitness": 0.731799877097602, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.73 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7218912298076956, 0.7417085243875083]}, "mutation_prompt": null}
{"id": "c9036361-8049-4342-b26c-b1647d2f0baf", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                adaptive_factor = 0.1 + 0.4 / (1 + np.exp(-0.1 * (i - remaining_budget / 2)))  # Changed line: apply sigmoid function for adaptive factor adjustment\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Incorporate a sigmoid function to dynamically adjust the adaptive factor in exploitation for refined convergence.", "configspace": "", "generation": 87, "fitness": 0.6654738036379613, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.67 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6311168352331675, 0.699830772042755]}, "mutation_prompt": null}
{"id": "45f9a436-bec3-4e98-9941-eefcdc2c92d7", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * (0.5 + 0.5 * np.sin(2 * np.pi * x))  # Changed line: dynamic influence using sine function\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance chaotic mapping by dynamically adjusting its influence for more robust exploration.", "configspace": "", "generation": 88, "fitness": 0.6162036279996904, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.62 with standard deviation 0.00.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6189979435668687, 0.6134093124325122]}, "mutation_prompt": null}
{"id": "f894830b-a8ea-4b4c-b47b-e6ac1aa2ede9", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x + 0.01)  # Changed line: refined logistic map for improved chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance exploration phase by refining the logistic map's chaotic sequence.", "configspace": "", "generation": 89, "fitness": 0.7182998542118214, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.72 with standard deviation 0.05.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6651120734233058, 0.771487635000337]}, "mutation_prompt": null}
{"id": "c6456a04-27ea-4856-810d-3f8356c819ae", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 2 * x * x if x < 0.5 else 2 * (1 - x) * (1 - x)  # Changed line: quadratic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Implement a quadratic chaotic map for improved exploration diversity.", "configspace": "", "generation": 90, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "9e052bb2-6fb3-4233-947c-f213e350d86f", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(2 * np.pi * i / remaining_budget)  # Changed line: refine sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Refine the sinusoidal dynamic inertia weight to enhance convergence stability.", "configspace": "", "generation": 91, "fitness": 0.7397343993309149, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7688654027031684, 0.7106033959586613]}, "mutation_prompt": null}
{"id": "b91eb06c-eaeb-4f60-bd9c-0205552678db", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            modulated_position = position * (0.5 + 0.5 * np.cos(np.pi * x))  # Added line: cosine modulation for enhanced exploration\n            value = func(modulated_position)  # Used modulated position\n            if value < best_value:\n                best_value = value\n                best_position = modulated_position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Integrated a cosine modulation to enhance the chaotic exploration phase.", "configspace": "", "generation": 92, "fitness": 0.6381846643172066, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.64 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6436315388101566, 0.6327377898242565]}, "mutation_prompt": null}
{"id": "eef5b8b9-7473-4649-b1e5-380f8c1863e9", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.uniform(0.8, 1.2)  # Changed line: adjusted step scaling for improved local search convergence\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance local exploitation by modifying the step scale adjustment to improve convergence.", "configspace": "", "generation": 93, "fitness": 0.6782413120863654, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.68 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6654743557531972, 0.6910082684195336]}, "mutation_prompt": null}
{"id": "7a5442d8-4e7f-4982-aab7-1450c5c594e1", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()\n        for _ in range(samples):\n            x = 4 * x * (1 - x + np.sin(x))  # Changed line: dynamic modulation of the logistic map\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance chaos through dynamic modulation of the logistic map's parameter for better exploration.", "configspace": "", "generation": 94, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "298827e2-c3e3-4c5c-a135-214341aec905", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Changed line: introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.standard_cauchy()  # Changed line: introduce Levy flight (Cauchy distribution) for step scaling\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a Levy flight-based step scaling for enhanced exploration in the exploitation phase.", "configspace": "", "generation": 95, "fitness": 0.6906723420242761, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.69 with standard deviation 0.02.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6704126520668487, 0.7109320319817034]}, "mutation_prompt": null}
{"id": "abc3407e-7360-465b-b42d-7980ac4ce8d0", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()\n        for _ in range(samples):\n            x = 4 * x * (1 - x)\n            # Change: Improved chaotic initialization for position\n            position = lb + (ub - lb) * np.random.rand(self.dim) * x\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Enhance the exploration phase with chaotic sequence initialization for improved sampling diversity.", "configspace": "", "generation": 96, "fitness": 0.7446340234192674, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.02.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7621254549271049, 0.7271425919114298]}, "mutation_prompt": null}
{"id": "3b0898b7-6665-42a7-b0dc-ef327e3065ca", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            # Changed line: introduce exponential decay in inertia weight\n            inertia_weight = (0.9 - 0.5 * adaptive_factor) * np.exp(-i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  \n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Refine inertia weight dynamics by introducing exponential decay for better convergence control.", "configspace": "", "generation": 97, "fitness": 0.71136563072444, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.71 with standard deviation 0.01.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.6987150366130396, 0.7240162248358406]}, "mutation_prompt": null}
{"id": "a57b6eb1-5da3-4763-a8db-8a962e6719b6", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with refined chaotic sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = np.exp(-x**2)  # Changed line: Use Gauss map for refined chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(np.pi * i / remaining_budget)  # Introduce adaptive sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Refine chaotic sampling by incorporating the Gauss map for improved exploration.", "configspace": "", "generation": 98, "fitness": 0.7392582386953691, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7690432119621013, 0.7094732654286369]}, "mutation_prompt": null}
{"id": "a77f8268-3dde-4a99-b033-18f85e6b7900", "solution": "import numpy as np\n\nclass DualPhaseSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_position = None\n        best_value = float('inf')\n        \n        # Phase 1: Exploration with random sampling\n        samples = int(self.budget * 0.6)\n        x = np.random.rand()  # Added line: initialize chaotic variable for diversification\n        for _ in range(samples):\n            x = 4 * x * (1 - x)  # Added line: logistic map for chaotic sequence\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            value = func(position)\n            if value < best_value:\n                best_value = value\n                best_position = position\n\n        # Enhanced adaptive factor with nonlinear decay\n        adaptive_factor = 0.1 + 0.4 * np.exp(-np.sqrt(best_value / (best_value + 1e-9)))\n\n        # Phase 2: Exploitation with local search\n        remaining_budget = self.budget - samples\n        local_best_position = np.copy(best_position)\n        local_best_value = best_value\n        \n        for i in range(remaining_budget):\n            decay = 1 - (i / remaining_budget)  \n            inertia_weight = 0.9 - 0.5 * adaptive_factor * (i / remaining_budget) + 0.1 * np.sin(1.5 * np.pi * i / remaining_budget)  # Changed line: increased frequency of sinusoidal dynamic inertia weight\n            for d in range(self.dim):\n                step_scaling = np.random.rand()\n                step = inertia_weight * adaptive_factor * (ub[d] - lb[d]) * (np.random.rand() - 0.5) * decay * step_scaling\n                candidate_position = np.copy(local_best_position)\n                candidate_position[d] += step * np.random.uniform(0.5, 1.5)\n\n                # Ensure the candidate stays within bounds\n                candidate_position = np.clip(candidate_position, lb, ub)\n                \n                candidate_value = func(candidate_position)\n                if candidate_value < local_best_value:\n                    local_best_value = candidate_value\n                    local_best_position = candidate_position\n\n        return local_best_position, local_best_value", "name": "DualPhaseSwarmOptimizer", "description": "Introduce a chaotic map for diversified sampling in the exploration phase and leverage sinusoidal inertia dynamics for enhanced exploitation.", "configspace": "", "generation": 99, "fitness": 0.7395348289869236, "feedback": "The algorithm DualPhaseSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.74 with standard deviation 0.03.", "error": "", "parent_id": "a1bdc5f5-6679-4c3a-aa95-0fb9b1bd088a", "metadata": {"aucs": [0.7689535043591402, 0.7101161536147069]}, "mutation_prompt": null}

{"id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Adaptive Particle Swarm Optimization enhanced with Quantum-inspired dynamics for efficient exploration and exploitation in high-dimensional spaces.", "configspace": "", "generation": 0, "fitness": 0.12968741859042499, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.13081236898314708, 0.13000827314392094, 0.12824161364420694]}, "mutation_prompt": null}
{"id": "c1de44c4-a9b7-417a-9067-9e8e0f7ab496", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        self.w = 0.9 - 0.4 * (self.evaluations / self.budget)  # Dynamic inertia weight\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce dynamic inertia weight adaptation based on function evaluations to balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.12799774078786394, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13149594871863923, 0.12979274016554576, 0.1227045334794068]}, "mutation_prompt": null}
{"id": "1cd6ad11-f244-454f-95a4-d46ddd52b75f", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Inertia weight, adjusted for improved exploration\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhanced inertia weight adaptation for improved exploration-exploitation balance in QuantumAdaptivePSO.", "configspace": "", "generation": 2, "fitness": 0.12557714190914737, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1271651990887167, 0.12755518020784373, 0.12201104643088168]}, "mutation_prompt": null}
{"id": "eefd76a9-e392-4b68-a493-1c411bb89e36", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.75  # Inertia weight (slightly increased for better exploration)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhanced global search capability by slightly increasing the inertia weight for improved exploration.", "configspace": "", "generation": 3, "fitness": 0.1274156632694522, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13086780150542776, 0.12850048223803445, 0.12287870606489437]}, "mutation_prompt": null}
{"id": "e12bfbe2-f0cc-4d66-bb32-295970e83da4", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        self.w = 0.9 - 0.5 * (self.evaluations / self.budget)  # Dynamic inertia weight adjustment\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introducing dynamic inertia weight adjustment for enhanced convergence in QuantumAdaptivePSO.", "configspace": "", "generation": 4, "fitness": 0.12765050253979512, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13153951930365693, 0.12815832802848415, 0.12325366028724427]}, "mutation_prompt": null}
{"id": "9cd05e32-8d3a-4a2f-a666-69e6e7524f3d", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        self.w = 0.5 + 0.5 * (self.budget - self.evaluations) / self.budget  # Dynamic inertia weight\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhanced QuantumAdaptivePSO with dynamic inertia weight adjustment for improved convergence speed.", "configspace": "", "generation": 5, "fitness": 0.12690677509427215, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.12652827506539588, 0.1276551543159945, 0.12653689590142603]}, "mutation_prompt": null}
{"id": "001e6353-36cd-42b9-997f-ec2da8f029ea", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (self.evaluations / self.budget)  # Dynamic inertia adjustment\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhanced QuantumAdaptivePSO with dynamic inertia weight adjustment for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.12765619551688376, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.12945629198601794, 0.12994679306993795, 0.12356550149469536]}, "mutation_prompt": null}
{"id": "7e00e589-8c6d-4cc3-8a8b-76e4dd5837f3", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        self.w = 0.9 - 0.5 * (self.evaluations / self.budget)  # Dynamic adjustment of inertia weight\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a dynamic inertia weight adjustment based on evaluations to enhance convergence.", "configspace": "", "generation": 7, "fitness": 0.12765050253979512, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13153951930365693, 0.12815832802848415, 0.12325366028724427]}, "mutation_prompt": null}
{"id": "28d290f7-760d-4b47-af6a-ede15d037889", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Inertia weight (changed from 0.7 to 0.9)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhance convergence by increasing the inertia weight for better exploration in larger search spaces.", "configspace": "", "generation": 8, "fitness": 0.12557714190914737, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1271651990887167, 0.12755518020784373, 0.12201104643088168]}, "mutation_prompt": null}
{"id": "35c0f610-312a-4f64-a551-608e0059bac2", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Initial inertia weight (changed from 0.7 to 0.9)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "QuantumAdaptivePSO with an adaptive inertia weight for improved convergence speed.", "configspace": "", "generation": 9, "fitness": 0.12557714190914737, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1271651990887167, 0.12755518020784373, 0.12201104643088168]}, "mutation_prompt": null}
{"id": "6620ab34-1d6d-41c6-8749-0689a24d352c", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhanced global convergence by increasing the inertia weight for improved exploration.", "configspace": "", "generation": 10, "fitness": 0.12557714190914737, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1271651990887167, 0.12755518020784373, 0.12201104643088168]}, "mutation_prompt": null}
{"id": "3b48b553-d879-4946-983a-91724d3a322b", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n        \n        # Dynamic inertia weight decay\n        self.w *= 0.99  # Decrease inertia weight over iterations", "name": "QuantumAdaptivePSO", "description": "Introduced dynamic inertia weight decay to improve convergence speed while maintaining exploration, by decreasing inertia weight over time.", "configspace": "", "generation": 11, "fitness": 0.1289524266677314, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13072418609608538, 0.12924880635924196, 0.12688428754786685]}, "mutation_prompt": null}
{"id": "7c478525-7e9b-49e2-bb91-0f2a40716d3a", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 5 + int(2 * np.sqrt(dim))  # Adjusted swarm size formula\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Tweaked swarm size to enhance exploration vs. exploitation balance for diverse dimensional spaces.", "configspace": "", "generation": 12, "fitness": 0.12575904859052903, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.12626871104227477, 0.1274424380380501, 0.12356599669126223]}, "mutation_prompt": null}
{"id": "147d01f0-9a3a-4eb4-98c1-353b0f407ad2", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Initial inertia weight, changed from 0.7\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.local_best_positions = None  # New line: for local neighborhood strategy\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n            self.w = 0.4 + 0.5 * (self.budget - self.evaluations) / self.budget  # Change: adapt inertia weight\n\n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        self.local_best_positions = self.positions.copy()  # Initialize local best positions\n\n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            local_best_velocity = self.c2 * r2 * (self.local_best_positions[i] - self.positions[i])  # New line: incorporate local best\n\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity + local_best_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introducing dynamic adaptation of the inertia weight and inclusion of a local neighborhood strategy to enhance convergence in QuantumAdaptivePSO.", "configspace": "", "generation": 13, "fitness": 0.12358563573632049, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.12226316218141642, 0.1274424380380501, 0.12105130698949496]}, "mutation_prompt": null}
{"id": "1a92de13-f752-4500-93b8-40610f39b573", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Initial inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.w = 0.4 + 0.5 * (1 - self.evaluations / self.budget)  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce dynamic inertia weight adaptation to enhance convergence speed and avoid local optima.", "configspace": "", "generation": 14, "fitness": 0.12765619551688376, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.12945629198601794, 0.12994679306993795, 0.12356550149469536]}, "mutation_prompt": null}
{"id": "925bd89d-d296-4910-92c0-fdfed80353a6", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        self.w = 0.9 - 0.5 * (self.evaluations / self.budget)  # Adaptive inertia weight\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "QuantumAdaptivePSO with enhanced inertia weight adaptation based on convergence rate to improve exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.12765050253979512, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13153951930365693, 0.12815832802848415, 0.12325366028724427]}, "mutation_prompt": null}
{"id": "d9824853-cb3e-4562-aa33-274479a1b15f", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w + 0.3 * (1 - self.evaluations / self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhanced inertia weight adaptation in QuantumAdaptivePSO for improved convergence.", "configspace": "", "generation": 16, "fitness": 0.12671516371525163, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1269506305087087, 0.1280452658928527, 0.12514959474419352]}, "mutation_prompt": null}
{"id": "21b4a795-3bd4-4f15-8dc0-85195481bf5f", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.2  # Cognitive coefficient (changed)\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhanced cognitive coefficient adaptation for improved convergence in Quantum Adaptive PSO.", "configspace": "", "generation": 17, "fitness": 0.12582319246544263, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.12882113317362398, 0.1285228824733542, 0.12012556174934974]}, "mutation_prompt": null}
{"id": "353a2f3d-2c2e-414b-ac00-a08ba2c84888", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Inertia weight modified\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Dynamic adjustment of inertia weight to enhance convergence speed while maintaining exploration capabilities.", "configspace": "", "generation": 18, "fitness": 0.12557714190914737, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1271651990887167, 0.12755518020784373, 0.12201104643088168]}, "mutation_prompt": null}
{"id": "88ebc3d0-caf3-48bf-99aa-eaabce1156ca", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Dynamic inertia weight (start value changed)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "QuantumAdaptivePSO with dynamic inertia weight for enhanced convergence rate.", "configspace": "", "generation": 19, "fitness": 0.12557714190914737, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1271651990887167, 0.12755518020784373, 0.12201104643088168]}, "mutation_prompt": null}
{"id": "ebcd6d31-dd49-4b2c-95e4-81c6b9c3ad83", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.1  # Social coefficient - slightly increased for enhanced social influence\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "QuantumAdaptivePSO with enhanced social influence by slightly increasing social coefficient for improved convergence.", "configspace": "", "generation": 20, "fitness": 0.12881294327893555, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1304893734575976, 0.1301329174105348, 0.12581653896867429]}, "mutation_prompt": null}
{"id": "202aedd1-9e62-4d13-a7ff-04bbc8e4d849", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (self.evaluations / self.budget)  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduced dynamic inertia weight adjustment to enhance convergence speed while maintaining exploration capabilities.", "configspace": "", "generation": 21, "fitness": 0.12765619551688376, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.12945629198601794, 0.12994679306993795, 0.12356550149469536]}, "mutation_prompt": null}
{"id": "5dbba26c-b5c3-4878-959c-782cd76afaa5", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.72  # Inertia weight (slightly increased)\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Slightly increased the inertia weight to enhance exploration capabilities while maintaining the balance between exploration and exploitation.", "configspace": "", "generation": 22, "fitness": 0.1284027130740207, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13026343148538044, 0.13142048801576156, 0.12352421972092009]}, "mutation_prompt": null}
{"id": "633e6e9e-432e-49dd-aefd-3768125197f3", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Initial inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.w = 0.9 - 0.5 * (self.evaluations / self.budget)  # Dynamic inertia weight adaptation\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce dynamic inertia weight adaptation to balance exploration and exploitation more effectively.", "configspace": "", "generation": 23, "fitness": 0.12765619551688376, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.12945629198601794, 0.12994679306993795, 0.12356550149469536]}, "mutation_prompt": null}
{"id": "b6cbbd46-9ad2-437f-b4bd-3351a8f34d13", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Updated inertia weight for dynamic adjustment\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a dynamic inertia weight strategy to balance exploration and exploitation more effectively.", "configspace": "", "generation": 24, "fitness": 0.12557714190914737, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1271651990887167, 0.12755518020784373, 0.12201104643088168]}, "mutation_prompt": null}
{"id": "29777b75-a57a-44df-bab6-cfb47c5f713e", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Adjusted inertia weight for better balance\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduced dynamic inertia weight adjustment for better balance between exploration and exploitation.", "configspace": "", "generation": 25, "fitness": 0.12557714190914737, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1271651990887167, 0.12755518020784373, 0.12201104643088168]}, "mutation_prompt": null}
{"id": "3798bb1c-5167-43b2-90b7-c3c1216f5545", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.w = 0.9 - 0.5 * (self.evaluations / self.budget)  # Modified line\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Tweak the inertia weight `w` to dynamically reduce, encouraging exploration early on and exploitation later.", "configspace": "", "generation": 26, "fitness": 0.12765050253979512, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13153951930365693, 0.12815832802848415, 0.12325366028724427]}, "mutation_prompt": null}
{"id": "af692a8a-289c-49b6-b89b-9c2ace31c38c", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.w = 0.9 - self.evaluations * (0.9 - 0.4) / self.budget  # Dynamic inertia weight adjustment\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduced dynamic inertia weight to balance exploration and exploitation phases more effectively.", "configspace": "", "generation": 27, "fitness": 0.12765050253979512, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13153951930365693, 0.12815832802848415, 0.12325366028724427]}, "mutation_prompt": null}
{"id": "70acdc09-2055-4585-8a07-8df96c6fd2eb", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Inertia weight, changed from 0.7 to 0.9\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "QuantumAdaptivePSO with adaptive inertia weight dynamically adjusted based on evaluations to improve convergence.", "configspace": "", "generation": 28, "fitness": 0.12557714190914737, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.1271651990887167, 0.12755518020784373, 0.12201104643088168]}, "mutation_prompt": null}
{"id": "c130f762-e45b-43f0-bc2b-fe3a79d0763a", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        self.w = 0.9 - (0.9 - 0.4) * (self.evaluations / self.budget)  # Dynamic inertia weight\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce dynamic inertia weight to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 29, "fitness": 0.12765050253979512, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13153951930365693, 0.12815832802848415, 0.12325366028724427]}, "mutation_prompt": null}
{"id": "f5735cb1-e312-468c-9090-dc5581038fc3", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introducing a dynamic cognitive coefficient to enhance individual exploration as particles approach their personal best.", "configspace": "", "generation": 30, "fitness": 0.1299556527558434, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "7bda98e1-9136-4fc9-92b0-ef9f405454c3", "metadata": {"aucs": [0.13290604047827137, 0.13047089156164282, 0.12649002622761596]}, "mutation_prompt": null}
{"id": "dbe48537-a50a-4736-a9d3-53afaaf8c0b6", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.w = 0.9 - (0.5 * self.evaluations / self.budget)  # Adaptive inertia weight\n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introducing adaptive inertia weight based on evaluations to balance exploration and exploitation.", "configspace": "", "generation": 31, "fitness": 0.12922999304153826, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "f5735cb1-e312-468c-9090-dc5581038fc3", "metadata": {"aucs": [0.13167269319872954, 0.13077651650267796, 0.12524076942320728]}, "mutation_prompt": null}
{"id": "bbd19f10-d10f-4673-9ee5-ac7e7c38cc43", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 * (1 - self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduced a dynamic social coefficient to balance exploration and exploitation based on progress towards the budget.", "configspace": "", "generation": 32, "fitness": 0.12972080078493328, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "f5735cb1-e312-468c-9090-dc5581038fc3", "metadata": {"aucs": [0.13273543108329477, 0.12959357107012237, 0.12683340020138267]}, "mutation_prompt": null}
{"id": "cc3b936f-5d3a-4f2c-9e78-31a51df7e037", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Initial inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = ((0.9 - 0.4) * (self.budget - self.evaluations) / self.budget + 0.4) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Increase inertia weight linearly to enhance exploration in early iterations.", "configspace": "", "generation": 33, "fitness": 0.12922999304153826, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "f5735cb1-e312-468c-9090-dc5581038fc3", "metadata": {"aucs": [0.13167269319872954, 0.13077651650267796, 0.12524076942320728]}, "mutation_prompt": null}
{"id": "99e62700-7782-4189-8aaf-0d81d51cc4aa", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Adaptive inertia weight, changed from 0.7 to 0.9\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce an adaptive inertia weight to balance exploration and exploitation dynamically.", "configspace": "", "generation": 34, "fitness": 0.12784982383057653, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "f5735cb1-e312-468c-9090-dc5581038fc3", "metadata": {"aucs": [0.12505281466012885, 0.13080900525218364, 0.12768765157941708]}, "mutation_prompt": null}
{"id": "36cf432e-46df-4c73-8f4a-0a3e6d967b91", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Add a component in inertia weight to favor convergence towards the global best as evaluations progress.", "configspace": "", "generation": 35, "fitness": 0.1313611354067951, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "f5735cb1-e312-468c-9090-dc5581038fc3", "metadata": {"aucs": [0.13343447603565095, 0.13082213417220978, 0.12982679601252456]}, "mutation_prompt": null}
{"id": "a838687c-076d-44d9-8de4-1e2f6201f6ad", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a velocity clamping mechanism to control step sizes and improve convergence.", "configspace": "", "generation": 36, "fitness": 0.13341000411510914, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "36cf432e-46df-4c73-8f4a-0a3e6d967b91", "metadata": {"aucs": [0.13330488307792032, 0.13362342311273057, 0.1333017061546765]}, "mutation_prompt": null}
{"id": "f4019439-3b11-4fab-a343-509447f14b42", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget) ** 2) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhance convergence by adjusting the inertia weight dynamically based on evaluations.", "configspace": "", "generation": 37, "fitness": 0.13309954041668545, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "a838687c-076d-44d9-8de4-1e2f6201f6ad", "metadata": {"aucs": [0.1345484181769966, 0.13156612251681854, 0.1331840805562412]}, "mutation_prompt": null}
{"id": "af82719e-517f-41ae-ac3e-0c9b9fad9266", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * np.cos(np.pi * self.evaluations / self.budget))) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce dynamic adjustment to cognitive coefficient (c1) for improved exploration-exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.1328190713174532, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "a838687c-076d-44d9-8de4-1e2f6201f6ad", "metadata": {"aucs": [0.13325350086994636, 0.133796047712331, 0.1314076653700823]}, "mutation_prompt": null}
{"id": "57101dfd-a013-4db3-ad77-6bd76812bd11", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Initial inertia weight, decays over time\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (0.5 + 0.5 * (1 - self.evaluations/self.budget))) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Incorporate a decaying inertia weight to balance exploration and exploitation dynamically.", "configspace": "", "generation": 39, "fitness": 0.13320782964159003, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "a838687c-076d-44d9-8de4-1e2f6201f6ad", "metadata": {"aucs": [0.13314434439602374, 0.13293303746896923, 0.1335461070597771]}, "mutation_prompt": null}
{"id": "33447265-499e-4a01-9747-e26a76ac2633", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Initial inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (0.5 + 0.5 * (1 - self.evaluations/self.budget))) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Add adaptive inertia weight decay for enhanced exploration-exploitation balancing.", "configspace": "", "generation": 40, "fitness": 0.13321583261664716, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "a838687c-076d-44d9-8de4-1e2f6201f6ad", "metadata": {"aucs": [0.1328890537725842, 0.13351432338350433, 0.13324412069385294]}, "mutation_prompt": null}
{"id": "1fab1d9b-8175-4c72-bd1e-579f2294b394", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 1.5  # Cognitive coefficient adjusted for better balance\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Adjust cognitive coefficient to balance exploration and exploitation.", "configspace": "", "generation": 41, "fitness": 0.13279363855921278, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "a838687c-076d-44d9-8de4-1e2f6201f6ad", "metadata": {"aucs": [0.13413799446520192, 0.1337550049543067, 0.13048791625812972]}, "mutation_prompt": null}
{"id": "710ea73f-02d6-494d-ba34-1d3952eccc48", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = ((self.w * (1 - (0.5 * (self.evaluations/self.budget)))) * self.velocities[i]) + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhance convergence by adapting the inertia weight dynamically based on evaluations.", "configspace": "", "generation": 42, "fitness": 0.13321583261664716, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "a838687c-076d-44d9-8de4-1e2f6201f6ad", "metadata": {"aucs": [0.1328890537725842, 0.13351432338350433, 0.13324412069385294]}, "mutation_prompt": null}
{"id": "002af38d-905d-43f9-a505-d79a05283238", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Initial inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce dynamic inertia weight adjustment to enhance exploration-exploitation balance.", "configspace": "", "generation": 43, "fitness": 0.13330958055967765, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "a838687c-076d-44d9-8de4-1e2f6201f6ad", "metadata": {"aucs": [0.13360068129389768, 0.13309377396835753, 0.1332342864167777]}, "mutation_prompt": null}
{"id": "3775ebee-a9c0-4126-b8b5-180ad96acf5c", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 * (self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a dynamic social coefficient to adaptively balance exploration and exploitation.", "configspace": "", "generation": 44, "fitness": 0.13319789555619063, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "a838687c-076d-44d9-8de4-1e2f6201f6ad", "metadata": {"aucs": [0.13407771200996454, 0.13184563919669112, 0.1336703354619162]}, "mutation_prompt": null}
{"id": "1863dac0-df7c-49f4-a493-1b2ca8dc6516", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce gradual reduction of quantum attraction to balance exploration and exploitation.", "configspace": "", "generation": 45, "fitness": 0.13451967827937586, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "a838687c-076d-44d9-8de4-1e2f6201f6ad", "metadata": {"aucs": [0.13429917802862879, 0.1351200654437773, 0.13413979136572152]}, "mutation_prompt": null}
{"id": "b665a6c0-5f97-4110-a399-2b7b9a97c886", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.momentum = 0.9  # Momentum term for velocity update\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity + self.momentum * self.velocities[i]  # Momentum added\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce momentum term to enhance convergence speed while maintaining exploration-exploitation balance.", "configspace": "", "generation": 46, "fitness": 0.13228007900605723, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1863dac0-df7c-49f4-a493-1b2ca8dc6516", "metadata": {"aucs": [0.13326111221116943, 0.1338288471125385, 0.1297502776944638]}, "mutation_prompt": null}
{"id": "798033c8-a6cc-410f-8e63-7cf82e2d8362", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.1  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Slightly increase the social coefficient c2 to enhance global search capability.", "configspace": "", "generation": 47, "fitness": 0.13314295558876807, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1863dac0-df7c-49f4-a493-1b2ca8dc6516", "metadata": {"aucs": [0.13458132074664153, 0.13385828664491817, 0.13098925937474448]}, "mutation_prompt": null}
{"id": "34081dae-4963-4377-a3a9-4372041fd858", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Initial inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            # Change: Reduce inertia weight linearly\n            inertia_weight = self.w * (1 - self.evaluations/self.budget)\n            self.velocities[i] = inertia_weight * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Reduce inertia weight linearly to improve convergence speed.", "configspace": "", "generation": 48, "fitness": 0.13451967827937586, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1863dac0-df7c-49f4-a493-1b2ca8dc6516", "metadata": {"aucs": [0.13429917802862879, 0.1351200654437773, 0.13413979136572152]}, "mutation_prompt": null}
{"id": "4d51919f-9917-4360-b2fc-b4fce864afc1", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (0.5 + 0.5 * (1 - self.evaluations/self.budget))) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhance convergence by adapting the inertia weight more dynamically.", "configspace": "", "generation": 49, "fitness": 0.13233209854114003, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1863dac0-df7c-49f4-a493-1b2ca8dc6516", "metadata": {"aucs": [0.13332240505953752, 0.1332445513077456, 0.13042933925613698]}, "mutation_prompt": null}
{"id": "202b37b6-bb76-4ae5-98ca-97b4a2e7759a", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = (self.w * (1 - self.evaluations/self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce gradual reduction of quantum attraction to balance exploration and exploitation.", "configspace": "", "generation": 46, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "1863dac0-df7c-49f4-a493-1b2ca8dc6516", "metadata": {"aucs": [0.13429917802862879, 0.1351200654437773, 0.13413979136572152]}, "mutation_prompt": null}
{"id": "9346564e-d656-4566-b431-d2407454c906", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        w = self.w_max - (self.w_max - self.w_min) * (self.evaluations / self.budget)\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Adaptive harmony between exploration and exploitation using dynamic inertia and swarm size adjustment.", "configspace": "", "generation": 51, "fitness": 0.13436306077188287, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1863dac0-df7c-49f4-a493-1b2ca8dc6516", "metadata": {"aucs": [0.13390589762974936, 0.13456839674840504, 0.1346148879374942]}, "mutation_prompt": null}
{"id": "d17e3b60-2c17-484c-b79c-efa44c1c2811", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.velocities[i] = ((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a dynamic inertia weight to adaptively balance exploration and exploitation throughout the optimization process.", "configspace": "", "generation": 52, "fitness": 0.13455655250096477, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1863dac0-df7c-49f4-a493-1b2ca8dc6516", "metadata": {"aucs": [0.1341395670638269, 0.13487749449828113, 0.13465259594078627]}, "mutation_prompt": null}
{"id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729  # New line added\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a dynamic constriction factor to refine velocity updates and improve convergence stability.", "configspace": "", "generation": 53, "fitness": 0.1349099023572654, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "d17e3b60-2c17-484c-b79c-efa44c1c2811", "metadata": {"aucs": [0.13482493757008585, 0.13483829530995994, 0.13506647419175044]}, "mutation_prompt": null}
{"id": "36f8b703-de70-4736-8722-8c9052ee49a2", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729  # New line added\n            # Changed line: Introduce nonlinear adaptive inertia weight\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * np.sin(np.pi * self.evaluations/self.budget)) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a nonlinear adaptive inertia weight to enhance exploration and exploitation balance.", "configspace": "", "generation": 54, "fitness": 0.13409548746031744, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "metadata": {"aucs": [0.1334037919119131, 0.13395277659516358, 0.13492989387387566]}, "mutation_prompt": null}
{"id": "bfca6cfd-3a47-477c-a601-701cb3f38696", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.739  # Changed line: increased constriction factor\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Increase the constriction factor slightly to improve convergence speed and stability.", "configspace": "", "generation": 55, "fitness": 0.13438581350895487, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "metadata": {"aucs": [0.13438873728148037, 0.13365344299872983, 0.13511526024665443]}, "mutation_prompt": null}
{"id": "30fdbab6-98ae-4c5a-9948-7fa1f8bff866", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            # Modified line: Introduce dynamic inertia based on fitness improvement\n            dynamic_w = self.w * (1 - (self.personal_best_scores[i] - score)/abs(self.personal_best_scores[i]) if self.personal_best_scores[i] != float('inf') else 1)\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * dynamic_w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhance velocity update strategy by introducing a dynamic inertia term based on fitness improvement.", "configspace": "", "generation": 56, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'score' is not defined\").", "error": "NameError(\"name 'score' is not defined\")", "parent_id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "metadata": {}, "mutation_prompt": null}
{"id": "dc970ed5-1757-4065-b96f-dc41a6ca3145", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729 - (0.329 * self.evaluations/self.budget)  # Updated line\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a time-varying constriction factor to enhance convergence dynamics by gradually reducing it over the budget.", "configspace": "", "generation": 57, "fitness": 0.13389248303078724, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "metadata": {"aucs": [0.13221213291040046, 0.13466709409635313, 0.1347982220856081]}, "mutation_prompt": null}
{"id": "97ddecca-df0c-46ca-b8f5-2c2b34b010b1", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729 * (1 - self.evaluations/self.budget)  # Change made here for dynamic decay\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a dynamic linear decay in the constriction factor to better balance exploration and exploitation.", "configspace": "", "generation": 58, "fitness": 0.13279792532229717, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "metadata": {"aucs": [0.13239282353292936, 0.1312176604647569, 0.13478329196920524]}, "mutation_prompt": null}
{"id": "fb51ad35-42fa-4a99-a3ae-80ee2ed2b4db", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729  \n            self.w = 0.7 - (0.5 * self.evaluations / self.budget)  # New line added\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce adaptive inertia weight that decreases linearly as evaluations progress to enhance the algorithm's balance between exploration and exploitation.", "configspace": "", "generation": 59, "fitness": 0.13460266714005645, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "metadata": {"aucs": [0.13494580210113116, 0.1338666271019675, 0.1349955722170707]}, "mutation_prompt": null}
{"id": "e7b25ca0-84c9-4c4c-8d65-26a86a3b9dbd", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 1.5  # Adjusted Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729  # New line added\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Adjust the cognitive coefficient during the optimization to enhance exploration and exploitation balance.", "configspace": "", "generation": 60, "fitness": 0.1346018929753479, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "metadata": {"aucs": [0.13394726796556677, 0.1353539980194851, 0.1345044129409918]}, "mutation_prompt": null}
{"id": "d503ff15-765c-4208-8af5-91936ec81c92", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.w = 0.9 - 0.4 * (self.evaluations / self.budget)  # New line added\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Incorporate adaptive inertia weight to balance exploration and exploitation dynamically.", "configspace": "", "generation": 61, "fitness": 0.1339111895752967, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "metadata": {"aucs": [0.13528031514278216, 0.13517636888356166, 0.13127688469954635]}, "mutation_prompt": null}
{"id": "13c8be75-414a-4c0b-aff0-b024f2965cbe", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729  # New line added\n            self.w = 0.9 - 0.4 * (self.evaluations/self.budget)  # Modified line for adaptive inertia\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce adaptive inertia weight damping to enhance exploration-exploitation balance over iterations.", "configspace": "", "generation": 62, "fitness": 0.1339111895752967, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "metadata": {"aucs": [0.13528031514278216, 0.13517636888356166, 0.13127688469954635]}, "mutation_prompt": null}
{"id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Adjust the cognitive coefficient dynamically based on particle convergence to enhance exploration-exploitation balance.", "configspace": "", "generation": 63, "fitness": 0.13497464724783803, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "1d4d6b43-0642-4b02-9361-32ee05ed36a2", "metadata": {"aucs": [0.13473759535764085, 0.13512952580653748, 0.13505682057933577]}, "mutation_prompt": null}
{"id": "c29a9410-14cd-4427-928f-5b5c1aca2de3", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            self.w = 0.9 - 0.5 * self.evaluations/self.budget  # Dynamic inertia weight\n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a dynamic inertia weight to enhance the balance between exploration and exploitation over iterations.", "configspace": "", "generation": 64, "fitness": 0.1346555498172196, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.13469574699993359, 0.13524916658687325, 0.134021735864852]}, "mutation_prompt": null}
{"id": "9fd88548-1674-4fdd-ba8b-dd6ee91c5694", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb) + 0.1))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Refine the cognitive coefficient update to be more sensitive to particle convergence, improving the balance between exploration and exploitation.", "configspace": "", "generation": 65, "fitness": 0.1348965335399719, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.1347265221033126, 0.1348584704723218, 0.13510460804428137]}, "mutation_prompt": null}
{"id": "2a1868b8-533c-47a5-9ab2-a908f03d37dd", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)\n        self.c1 = 2.0 + 0.5 * (self.evaluations / self.budget)  # Newly added line for gradual increase of c1", "name": "QuantumAdaptivePSO", "description": "Increase cognitive coefficient gradually over iterations to enhance exploration initially and refinement later.", "configspace": "", "generation": 66, "fitness": 0.13445568704938657, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.13476569543360195, 0.13367607891022393, 0.1349252868043338]}, "mutation_prompt": null}
{"id": "776d9d08-2148-4cfe-bd16-ebe55019ec3f", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = (self.c2 * (1 - self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])  # Modified line\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a dynamic social coefficient adjustment for improved balance between exploration and exploitation in QuantumAdaptivePSO.", "configspace": "", "generation": 67, "fitness": 0.13405266108839944, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.1328207948973894, 0.13448708007831023, 0.13485010828949873]}, "mutation_prompt": null}
{"id": "92fcd00a-c301-43ca-9e08-215f621b0eda", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.25*(ub-lb), 0.25*(ub-lb))  # Slightly wider velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhance exploration by slightly increasing the range of velocity clamping.", "configspace": "", "generation": 68, "fitness": 0.1348193976801, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.13509056812198728, 0.13574203533125206, 0.13362558958706072]}, "mutation_prompt": null}
{"id": "3b23e39a-e744-411b-9017-ca6ab8ea20f7", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n            \n            # Introduced a decay factor to the cognitive coefficient\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb))) * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a decay factor to the cognitive coefficient to gradually reduce self-attraction, enhancing exploration.", "configspace": "", "generation": 69, "fitness": 0.13409688581237647, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.13142295475550558, 0.13584631291743732, 0.13502138976418654]}, "mutation_prompt": null}
{"id": "d42722cd-457b-46d4-8b36-21df65dfb76d", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            self.w = 0.9 - 0.8 * (self.evaluations / self.budget)  # Changed line\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Modify inertia weight to decrease linearly, improving dynamic adaptability and convergence.", "configspace": "", "generation": 70, "fitness": 0.13476777319450592, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.13512740288275404, 0.13517359308794308, 0.1340023236128206]}, "mutation_prompt": null}
{"id": "3eb173eb-62af-4438-a85a-ce55ef7cf9b8", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.739  # Changed from 0.729 to 0.739\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Increase the constriction factor to fine-tune the balance between exploration and exploitation.", "configspace": "", "generation": 71, "fitness": 0.13428545380162626, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.1342526368146887, 0.13367528509163817, 0.13492843949855193]}, "mutation_prompt": null}
{"id": "d8cb84f6-21f7-4647-93ee-7c2ff72f4a67", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Adjust the cognitive coefficient dynamically based on particle convergence to enhance exploration-exploitation balance.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.13473759535764085, 0.13512952580653748, 0.13505682057933577]}, "mutation_prompt": null}
{"id": "3d7e9612-4c2d-4c69-89e0-48fb06cbfe14", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.9  # Start with a higher inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            self.w = 0.9 - 0.8 * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            levy_flight = np.random.standard_cauchy(self.dim) * (ub - lb) * 0.01  # Levy flight step\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * levy_flight\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a dynamic inertia weight adjustment and improved exploration by leveraging levy flight steps in the particle update rules.", "configspace": "", "generation": 73, "fitness": 0.13480641743360555, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.13573856921780603, 0.13410900566484374, 0.1345716774181669]}, "mutation_prompt": null}
{"id": "eb3f564c-d243-4054-9eae-93f7803c9702", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        diversity = np.std(self.positions, axis=0).sum() / self.dim  # Calculate swarm diversity\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 + 0.5 * diversity) * r2 * (self.global_best_position - self.positions[i])  # Adjusted social coefficient\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce dynamic adjustment of social coefficient based on swarm diversity to enhance convergence.", "configspace": "", "generation": 74, "fitness": 0.13347142506803797, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.13321138502484853, 0.13446585637977193, 0.13273703379949342]}, "mutation_prompt": null}
{"id": "909d5717-5fd5-41b6-8cee-c54b8ebe47d3", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * (self.evaluations/self.budget)**2) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)  # Changed line\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce nonlinear inertia weight decay to enhance exploration early on and improve convergence speed later.", "configspace": "", "generation": 75, "fitness": 0.13399331116546387, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.13239778297313132, 0.1349805678103687, 0.13460158271289158]}, "mutation_prompt": null}
{"id": "36ec9868-6920-4ddd-b623-66c83c7cfaf1", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        diversity = np.mean(np.std(self.positions, axis=0))\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * ((0.9 - 0.5 * diversity / np.linalg.norm(ub-lb)) * self.w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)  # Modified line\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Add dynamic inertia weight adjustment based on swarm diversity for enhanced convergence.", "configspace": "", "generation": 76, "fitness": 0.1347572021025226, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.1341600639656324, 0.13525535036039138, 0.13485619198154397]}, "mutation_prompt": null}
{"id": "6e9c7e73-d7ed-4de1-a2f1-37980fec2f56", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w = 0.7  # Inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            cognitive_velocity = (self.c1 * (0.5 + 0.5 * (1 - np.linalg.norm(self.velocities[i])/np.linalg.norm(ub-lb)))) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Modified line\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = (self.c3 * (1 - self.evaluations/self.budget) * np.random.rand()) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i])  # Added randomness\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (((0.9 - 0.5 * self.evaluations/self.budget) * self.w) * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce randomness to the quantum-inspired attraction component to enhance exploration.", "configspace": "", "generation": 77, "fitness": 0.13509323303753573, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "01a00bba-e434-4aa8-8b39-3cfe2becfdec", "metadata": {"aucs": [0.1355404555005083, 0.13449011357995744, 0.13524913003214145]}, "mutation_prompt": null}
{"id": "0d7e6fa4-9102-4066-835e-1ed2c181a13d", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhance global exploration by introducing dynamic inertia weight and adaptive quantum attraction based on convergence state.", "configspace": "", "generation": 78, "fitness": 0.13519744660481306, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "6e9c7e73-d7ed-4de1-a2f1-37980fec2f56", "metadata": {"aucs": [0.13554608273676083, 0.13542416410953362, 0.13462209296814476]}, "mutation_prompt": null}
{"id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Integrate an exponential decay into the cognitive coefficient to balance exploration and exploitation over time.", "configspace": "", "generation": 79, "fitness": 0.1353096561567101, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "0d7e6fa4-9102-4066-835e-1ed2c181a13d", "metadata": {"aucs": [0.13526447907970296, 0.13558125491289752, 0.1350832344775298]}, "mutation_prompt": null}
{"id": "2d1faa35-6f1a-463a-a2c6-a7ccaf972459", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.004 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Slightly faster decay\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Modify the cognitive coefficient to decay slightly faster, improving exploitation.", "configspace": "", "generation": 80, "fitness": 0.13470047436568802, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13492934024413294, 0.13418780311329137, 0.13498427973963978]}, "mutation_prompt": null}
{"id": "9a6c8685-68e0-4dad-bbf7-f35cd04d043e", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.004 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Slightly increased decay rate\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Slightly increase the cognitive coefficient decay rate to enhance exploration early in the search process.", "configspace": "", "generation": 81, "fitness": 0.13470047436568802, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13492934024413294, 0.13418780311329137, 0.13498427973963978]}, "mutation_prompt": null}
{"id": "cbe0e1ed-7bb2-427b-9f7f-68f2d96acbde", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)  # Linear decrease\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Adjusted the quantum-inspired attraction coefficient to decrease linearly, enhancing convergence in later stages.", "configspace": "", "generation": 82, "fitness": 0.1345920884775426, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13494962684434375, 0.13421985107511736, 0.13460678751316668]}, "mutation_prompt": null}
{"id": "49fc064f-4c0c-4335-9eb1-c00a5a1c1132", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.005 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Adjusted decay rate\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Refine the decay rate in the cognitive coefficient for better exploration-exploitation balance.", "configspace": "", "generation": 83, "fitness": 0.13492672253752439, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13502609309957625, 0.13489250968999267, 0.13486156482300427]}, "mutation_prompt": null}
{"id": "143616e3-792b-43fc-b841-342665b2ebe5", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.6  # Quantum-inspired attraction, increased for early exploration\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Slightly adjust the quantum attraction coefficient to improve exploration in early stages.", "configspace": "", "generation": 84, "fitness": 0.13452941166382218, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13416109488711925, 0.13481189086098921, 0.1346152492433581]}, "mutation_prompt": null}
{"id": "3d87fd45-f2a0-449a-b4da-5d15399ad87c", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.6  # Quantum-inspired attraction (increased)\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhance global exploration by slightly increasing the quantum-inspired attraction factor.", "configspace": "", "generation": 85, "fitness": 0.13452941166382218, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13416109488711925, 0.13481189086098921, 0.1346152492433581]}, "mutation_prompt": null}
{"id": "dfd84f86-cba7-4a22-ad4b-c4a587a5d31c", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 15 + int(2 * np.sqrt(dim))  # Adaptive swarm size (Increased from 10 to 15)\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Increase the swarm size to enhance exploration capabilities.", "configspace": "", "generation": 86, "fitness": 0.1340581867658475, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.1348163200630722, 0.1331977657449266, 0.1341604744895437]}, "mutation_prompt": null}
{"id": "83b0867c-1aa4-4f0b-97b4-9002b0526438", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations * (1 - self.evaluations/self.budget)) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Enhanced decay\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a temperature-based exponential decay in the cognitive coefficient for enhanced adaptive balance.", "configspace": "", "generation": 87, "fitness": 0.13526324854902805, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13518575651342735, 0.1354305291079263, 0.1351734600257305]}, "mutation_prompt": null}
{"id": "861538d9-1a43-4ded-be65-4a368d12a86b", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.6  # Quantum-inspired attraction (adjusted)\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Fine-tune the quantum-inspired attraction coefficient for enhanced exploration.", "configspace": "", "generation": 88, "fitness": 0.13452941166382218, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13416109488711925, 0.13481189086098921, 0.1346152492433581]}, "mutation_prompt": null}
{"id": "a045673a-1a14-4ce0-bd12-318552a14f31", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.6  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Fine-tune the quantum-inspired attraction parameter to enhance convergence speed.", "configspace": "", "generation": 89, "fitness": 0.13452941166382218, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13416109488711925, 0.13481189086098921, 0.1346152492433581]}, "mutation_prompt": null}
{"id": "406b096b-c67c-4728-801d-d06007de85b0", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.004 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = self.c2 * r2 * (self.global_best_position - self.positions[i])\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Increase the cognitive coefficient's decay rate slightly to enhance balance between exploration and exploitation.", "configspace": "", "generation": 90, "fitness": 0.13470047436568802, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13492934024413294, 0.13418780311329137, 0.13498427973963978]}, "mutation_prompt": null}
{"id": "5d8a4777-2a04-4b7a-9f6d-def9f40190f9", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 + 0.5 * (self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])  # Dynamic social coefficient\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhance social learning by modifying the social coefficient dynamically based on evaluations.", "configspace": "", "generation": 91, "fitness": 0.1353669377056236, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "4f18b843-2a6d-43b9-9d8a-fd1b08481b01", "metadata": {"aucs": [0.13532859762177074, 0.1357417078446036, 0.1350305076504965]}, "mutation_prompt": null}
{"id": "dd113c20-6e99-4c92-9c89-1372b17e2fc0", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 + 0.5 * (self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])  # Dynamic social coefficient\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.3*(ub-lb), 0.3*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Adjust the velocity clamping range to improve exploration and avoid premature convergence.", "configspace": "", "generation": 92, "fitness": 0.1340548570673612, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "5d8a4777-2a04-4b7a-9f6d-def9f40190f9", "metadata": {"aucs": [0.1341498124804512, 0.13307858950373674, 0.13493616921789564]}, "mutation_prompt": null}
{"id": "adb6b1ab-03a1-486c-a324-e7b50a933620", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n        prev_global_best_score = self.global_best_score\n        \n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            # Adjust quantum attraction based on global best improvement\n            improvement_rate = (prev_global_best_score - self.global_best_score) / (abs(prev_global_best_score) + 1e-10)\n            self.c3 = 0.5 + 0.5 * improvement_rate  # Dynamic adjustment\n            prev_global_best_score = self.global_best_score\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 + 0.5 * (self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])  # Dynamic social coefficient\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Enhance convergence by dynamically adjusting the quantum-inspired attraction based on the global best improvement rate.", "configspace": "", "generation": 93, "fitness": 0.1181877968680803, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.01.", "error": "", "parent_id": "5d8a4777-2a04-4b7a-9f6d-def9f40190f9", "metadata": {"aucs": [0.11837969375208957, 0.12598634942163223, 0.11019734743051912]}, "mutation_prompt": null}
{"id": "622485a9-59d9-48d3-8e7e-d65256e19d57", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 + 0.5 * (self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])  # Dynamic social coefficient\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - (self.evaluations/self.budget))**2 * np.exp(-0.002 * self.evaluations)  # Decay factor added\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a decay factor in the quantum-inspired attraction to provide stronger early exploration and controlled exploitation.", "configspace": "", "generation": 94, "fitness": 0.13498874343157038, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.00.", "error": "", "parent_id": "5d8a4777-2a04-4b7a-9f6d-def9f40190f9", "metadata": {"aucs": [0.1353502084660425, 0.13529700662499033, 0.13431901520367828]}, "mutation_prompt": null}
{"id": "3dc8d84c-b278-4f93-b5fa-793bf9406aec", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 + (self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])  # More aggressive adaptation\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a more aggressive adaptation of the social coefficient to enhance exploitation during the latter evaluations.", "configspace": "", "generation": 95, "fitness": 0.1351502977885066, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "5d8a4777-2a04-4b7a-9f6d-def9f40190f9", "metadata": {"aucs": [0.1351114248811215, 0.135747564170434, 0.13459190431396428]}, "mutation_prompt": null}
{"id": "e1f4f0de-6122-4534-bf3b-2fcfdd726621", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 + 0.5 * (self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])  # Dynamic social coefficient\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            # Add a particle weight multiplier to enhance convergence speed\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + 1.2 * (cognitive_velocity + social_velocity + quantum_velocity))\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a particle weight multiplier to enhance convergence speed across iterations.", "configspace": "", "generation": 96, "fitness": 0.1350271912541837, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "5d8a4777-2a04-4b7a-9f6d-def9f40190f9", "metadata": {"aucs": [0.13500268807809368, 0.13550756498673133, 0.13457132069772604]}, "mutation_prompt": null}
{"id": "1b12eae9-184f-425a-9408-30fd2fc90365", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 + 0.6 * (self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])  # Dynamic social coefficient\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Refine QuantumAdaptivePSO by increasing the influence of the global best position slightly earlier in the optimization process.", "configspace": "", "generation": 97, "fitness": 0.13524154970681998, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "5d8a4777-2a04-4b7a-9f6d-def9f40190f9", "metadata": {"aucs": [0.1351867954258078, 0.13575695290868905, 0.13478090078596305]}, "mutation_prompt": null}
{"id": "1ef1a9ba-f0af-4ddc-8ab4-1c48d2321f11", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = (self.c1 + 0.5 * (self.evaluations/self.budget)) * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])  # Slightly adjusted cognitive component\n            social_velocity = (self.c2 + 0.5 * (self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])  # Dynamic social coefficient\n            quantum_velocity = self.c3 * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Refine the QuantumAdaptivePSO by adjusting the cognitive coefficient based on the ratio of evaluations to budget.", "configspace": "", "generation": 98, "fitness": 0.13521336802768216, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "5d8a4777-2a04-4b7a-9f6d-def9f40190f9", "metadata": {"aucs": [0.13517534147313792, 0.1354397253962185, 0.13502503721369008]}, "mutation_prompt": null}
{"id": "d525de8d-6879-4d62-9206-902e9b9bd42a", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 10 + int(2 * np.sqrt(dim))  # Adaptive swarm size\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.c3 = 0.5  # Quantum-inspired attraction\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.positions = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_swarm(lb, ub)\n\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if self.evaluations >= self.budget:\n                    break\n                score = func(self.positions[i])\n                self.evaluations += 1\n                \n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n            \n            self.update_particles(lb, ub)\n        \n        return self.global_best_position, self.global_best_score\n\n    def initialize_swarm(self, lb, ub):\n        self.positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        self.velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.swarm_size, float('inf'))\n        \n    def update_particles(self, lb, ub):\n        for i in range(self.swarm_size):\n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            q = np.random.rand(self.dim)\n\n            w = self.w_init - (self.w_init - self.w_final) * (self.evaluations / self.budget)  # Dynamic inertia weight\n            cognitive_velocity = self.c1 * np.exp(-0.003 * self.evaluations) * r1 * (self.personal_best_positions[i] - self.positions[i])\n            social_velocity = (self.c2 + 0.5 * (self.evaluations/self.budget)) * r2 * (self.global_best_position - self.positions[i])  # Dynamic social coefficient\n            quantum_velocity = self.c3 * (1 - 0.5 * (self.evaluations/self.budget)) * q * (np.random.uniform(lb, ub, self.dim) - self.positions[i]) * (1 - self.evaluations/self.budget)**2  # Adaptive quantum\n            \n            constriction_factor = 0.729\n            self.velocities[i] = constriction_factor * (w * self.velocities[i] + cognitive_velocity + social_velocity + quantum_velocity)\n            self.velocities[i] = np.clip(self.velocities[i], -0.2*(ub-lb), 0.2*(ub-lb))  # Velocity clamping\n            self.positions[i] += self.velocities[i]\n            self.positions[i] = np.clip(self.positions[i], lb, ub)", "name": "QuantumAdaptivePSO", "description": "Introduce a decay factor in the quantum-inspired attraction to enhance convergence stability.", "configspace": "", "generation": 99, "fitness": 0.1351044120769623, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.00.", "error": "", "parent_id": "5d8a4777-2a04-4b7a-9f6d-def9f40190f9", "metadata": {"aucs": [0.1353300060407291, 0.1357730205589166, 0.1342102096312412]}, "mutation_prompt": null}

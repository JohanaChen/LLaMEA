{"id": "777c5461-589f-480a-adfb-4f931450fc6f", "solution": "import numpy as np\n\nclass HybridHarmonyDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9  # Harmony Memory Consideration Rate\n        self.par = 0.3   # Pitch Adjustment Rate\n        self.f = 0.8     # Differential weight\n        self.cr = 0.9    # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            # Generate new harmony vector\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            # Differential Evolution mutation and crossover\n            if evaluations + 3 < self.budget:\n                indices = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x0, x1, x2 = harmony_memory[indices]\n                mutant = np.clip(x0 + self.f * (x1 - x2), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, new_harmony)\n            else:\n                trial = new_harmony\n\n            new_score = func(trial)\n            evaluations += 1\n\n            # Update harmony memory\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = trial\n                scores[worst_index] = new_score\n\n        # Return the best solution found\n        best_index = np.argmin(scores)\n        return harmony_memory[best_index], scores[best_index]", "name": "HybridHarmonyDE", "description": "A hybrid Harmony Search and Differential Evolution algorithm that balances exploration and exploitation by evolving a harmony memory with differential mutation and crossover.", "configspace": "", "generation": 0, "fitness": 0.28990992218737577, "feedback": "The algorithm HybridHarmonyDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.28990992218737577]}, "mutation_prompt": null}
{"id": "362b9783-3bfd-4b7b-bdef-773e4ea5a413", "solution": "import numpy as np\n\nclass GaussianHarmonyEvolutionStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9  # Harmony Memory Consideration Rate\n        self.par = 0.3   # Pitch Adjustment Rate\n        self.gaussian_sigma = 0.1\n        self.local_search_rate = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.normal(0, self.gaussian_sigma) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n            \n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Local search strategy\n            if np.random.rand() < self.local_search_rate:\n                local_harmony = new_harmony + np.random.normal(0, self.gaussian_sigma, self.dim)\n                local_harmony = np.clip(local_harmony, lb, ub)\n                local_score = func(local_harmony)\n                evaluations += 1\n                if local_score < func(new_harmony):\n                    new_harmony = local_harmony\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Update harmony memory\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n        best_index = np.argmin(scores)\n        return harmony_memory[best_index], scores[best_index]", "name": "GaussianHarmonyEvolutionStrategy", "description": "Gaussian Harmony Evolutionary Strategy (GHES) combines harmony search with Gaussian mutations and a local search strategy to more effectively explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": 0.2884861200401575, "feedback": "The algorithm GaussianHarmonyEvolutionStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "777c5461-589f-480a-adfb-4f931450fc6f", "metadata": {"aucs": [0.2884861200401575]}, "mutation_prompt": null}
{"id": "67dac3ba-3b35-48b4-b3ba-7739ecf1a06e", "solution": "import numpy as np\n\nclass AdaptiveMemeticDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.f = 0.5     # Initial differential weight\n        self.cr = 0.9    # Crossover probability\n        self.mutation_strategies = ['rand', 'best']\n        self.strategy_weights = np.array([0.5, 0.5])  # Start with equal strategy weights\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = np.empty_like(population)\n            new_scores = np.empty(self.population_size)\n\n            for i in range(self.population_size):\n                strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.strategy_weights)\n                if self.mutation_strategies[strategy_idx] == 'rand':\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x0, x1, x2 = population[indices]\n                    mutant = np.clip(x0 + self.f * (x1 - x2), lb, ub)\n                else:  # 'best' strategy\n                    best_idx = np.argmin(scores)\n                    x1, x2 = population[np.random.choice(self.population_size, 2, replace=False)]\n                    mutant = np.clip(population[best_idx] + self.f * (x1 - x2), lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n                # Local search (e.g., simple gradient step)\n                if np.random.rand() < 0.1 and evaluations < self.budget:\n                    gradient = np.random.uniform(-0.01, 0.01, self.dim)\n                    trial = np.clip(trial + gradient, lb, ub)\n                    evaluations += 1\n\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    new_population[i] = trial\n                    new_scores[i] = trial_score\n                    self.strategy_weights[strategy_idx] += 0.1  # Boost successful strategy\n                else:\n                    new_population[i] = population[i]\n                    new_scores[i] = scores[i]\n\n            # Normalize strategy weights\n            self.strategy_weights /= self.strategy_weights.sum()\n            population, scores = new_population, new_scores\n\n        best_index = np.argmin(scores)\n        return population[best_index], scores[best_index]", "name": "AdaptiveMemeticDE", "description": "Adaptive Memetic Differential Evolution (AMDE): An adaptive algorithm that combines differential evolution with local search, dynamically adjusting mutation strategies based on performance to optimize diverse problem landscapes.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('probabilities do not sum to 1').", "error": "ValueError('probabilities do not sum to 1')", "parent_id": "777c5461-589f-480a-adfb-4f931450fc6f", "metadata": {}, "mutation_prompt": null}
{"id": "ec977b70-8aec-4a55-8048-25dddfb699b0", "solution": "import numpy as np\n\nclass HybridHarmonyDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9  # Harmony Memory Consideration Rate\n        self.par = 0.3   # Pitch Adjustment Rate\n        self.f = 0.8     # Differential weight\n        self.cr = 0.9    # Crossover probability\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        # Dynamically adapt parameters based on the ratio of evaluations to budget\n        progress = self.evaluations / self.budget\n        self.hmcr = 0.9 - 0.2 * progress  # Decrease hmcr to promote exploration\n        self.par = 0.3 + 0.4 * progress   # Increase par to promote exploitation\n        self.f = 0.8 + 0.2 * progress     # Slightly increase differential weight for later stages\n        self.cr = 0.9 - 0.3 * progress    # Decrease crossover probability for diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        self.evaluations = self.harmony_memory_size\n\n        while self.evaluations < self.budget:\n            self.adapt_parameters()\n\n            # Generate new harmony vector\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            # Differential Evolution mutation and crossover\n            if self.evaluations + 3 < self.budget:\n                indices = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x0, x1, x2 = harmony_memory[indices]\n                mutant = np.clip(x0 + self.f * (x1 - x2), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, new_harmony)\n            else:\n                trial = new_harmony\n\n            new_score = func(trial)\n            self.evaluations += 1\n\n            # Update harmony memory\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = trial\n                scores[worst_index] = new_score\n\n        # Return the best solution found\n        best_index = np.argmin(scores)\n        return harmony_memory[best_index], scores[best_index]", "name": "HybridHarmonyDE", "description": "A hybrid Harmony Search and Differential Evolution algorithm enhanced with dynamic parameter adaptation to improve exploration-exploitation balance over time.", "configspace": "", "generation": 3, "fitness": 0.2891250383449615, "feedback": "The algorithm HybridHarmonyDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "777c5461-589f-480a-adfb-4f931450fc6f", "metadata": {"aucs": [0.2891250383449615]}, "mutation_prompt": null}
{"id": "39e30dd2-66e7-481d-86f0-0f6c0b2e70a3", "solution": "import numpy as np\n\nclass AdaptiveHarmonyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9  # Initial Harmony Memory Consideration Rate\n        self.par = 0.3   # Initial Pitch Adjustment Rate\n        self.f = 0.8     # Differential weight\n        self.cr = 0.9    # Crossover probability\n        self.inertia = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5       # Cognitive coefficient\n        self.c2 = 1.5       # Social coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim)) * (ub - lb)\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            # Adaptive parameter adjustment\n            self.hmcr = 0.7 + 0.3 * (1 - evaluations / self.budget)\n            self.par = 0.2 + 0.5 * (evaluations / self.budget)\n\n            # Generate new harmony vector\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            # PSO update\n            if evaluations + 1 < self.budget:\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities = (self.inertia * velocities +\n                              self.c1 * r1 * (personal_best_positions - harmony_memory) +\n                              self.c2 * r2 * (global_best_position - harmony_memory))\n                harmony_memory = np.clip(harmony_memory + velocities, lb, ub)\n\n            # Evaluate new harmony\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Update personal and global best\n            if new_score < personal_best_scores.max():\n                worst_index = np.argmax(personal_best_scores)\n                harmony_memory[worst_index] = new_harmony\n                personal_best_scores[worst_index] = new_score\n                personal_best_positions[worst_index] = new_harmony\n\n            if new_score < personal_best_scores[global_best_index]:\n                global_best_index = worst_index\n                global_best_position = new_harmony\n\n        # Return the best solution found\n        return global_best_position, personal_best_scores[global_best_index]", "name": "AdaptiveHarmonyPSO", "description": "Adaptive Harmony-PSO Hybrid, a novel algorithm that dynamically adjusts harmony memory parameters and incorporates Particle Swarm Optimization (PSO) for enhanced convergence.", "configspace": "", "generation": 4, "fitness": 0.2902559653267309, "feedback": "The algorithm AdaptiveHarmonyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "777c5461-589f-480a-adfb-4f931450fc6f", "metadata": {"aucs": [0.2902559653267309]}, "mutation_prompt": null}
{"id": "83ce6004-9a8b-4ed5-8d69-04f69bdafb07", "solution": "import numpy as np\n\nclass QuantumInspiredFirefly:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, dim)\n        self.alpha = 0.5  # Randomization parameter\n        self.gamma = 1.0  # Absorption coefficient\n        self.beta0 = 1.0  # Initial attractiveness\n        self.q_prob = 0.8 # Quantum behavior probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        brightness = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                for j in range(self.population_size):\n                    if brightness[i] > brightness[j]:\n                        dist = np.linalg.norm(population[i] - population[j])\n                        beta = self.beta0 * np.exp(-self.gamma * dist ** 2)\n                        step = beta * (population[j] - population[i])\n                        if np.random.rand() < self.q_prob:\n                            # Quantum-inspired behavior\n                            step += self.alpha * (np.random.rand(self.dim) - 0.5) * (ub - lb)\n                        new_solution = population[i] + step\n                        new_solution = np.clip(new_solution, lb, ub)\n                        new_brightness = func(new_solution)\n                        evaluations += 1\n                        if new_brightness < brightness[i]:\n                            population[i] = new_solution\n                            brightness[i] = new_brightness\n                            if evaluations >= self.budget:\n                                break\n                if evaluations >= self.budget:\n                    break\n\n        best_index = np.argmin(brightness)\n        return population[best_index], brightness[best_index]", "name": "QuantumInspiredFirefly", "description": "Quantum-Inspired Firefly Algorithm (QFA) that incorporates quantum behavior principles with firefly attractiveness dynamics to enhance global search capabilities.", "configspace": "", "generation": 5, "fitness": 0.2779719389858778, "feedback": "The algorithm QuantumInspiredFirefly got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "39e30dd2-66e7-481d-86f0-0f6c0b2e70a3", "metadata": {"aucs": [0.2779719389858778]}, "mutation_prompt": null}
{"id": "046c3b0e-f0d1-4b7b-888e-bf654af1acce", "solution": "import numpy as np\n\nclass QuantumSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.temperature = 100  # Initial temperature for simulated annealing\n        self.cooling_rate = 0.95  # Cooling rate for temperature\n        self.quantum_bits = 2  # Number of quantum bits to consider\n        self.population_size = max(10, dim)  # Population size\n        self.alpha = 0.5  # Probability amplitude decay factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(individual) for individual in population])\n        evaluations = self.population_size\n\n        best_index = np.argmin(scores)\n        best_position = population[best_index].copy()\n        best_score = scores[best_index]\n\n        while evaluations < self.budget:\n            self.temperature *= self.cooling_rate\n            \n            for i in range(self.population_size):\n                # Generate candidate using quantum superposition principles\n                candidate = population[i] + np.random.normal(0, 1, self.dim) * (ub - lb) / self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                \n                # Simulated annealing acceptance criterion\n                candidate_score = func(candidate)\n                acceptance_probability = np.exp((scores[i] - candidate_score) / self.temperature)\n                evaluations += 1\n                \n                if candidate_score < scores[i] or np.random.rand() < acceptance_probability:\n                    population[i] = candidate\n                    scores[i] = candidate_score\n\n            best_index = np.argmin(scores)\n            if scores[best_index] < best_score:\n                best_score = scores[best_index]\n                best_position = population[best_index].copy()\n\n        return best_position, best_score", "name": "QuantumSimulatedAnnealing", "description": "Quantum-inspired Simulated Annealing (QSA), an algorithm leveraging quantum superposition principles in combination with simulated annealing to enhance exploration and exploitation in complex search spaces.", "configspace": "", "generation": 6, "fitness": 0.2758419614634854, "feedback": "The algorithm QuantumSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "39e30dd2-66e7-481d-86f0-0f6c0b2e70a3", "metadata": {"aucs": [0.2758419614634854]}, "mutation_prompt": null}
{"id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "solution": "import numpy as np\n\nclass QuantumHarmonyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9  # Initial Harmony Memory Consideration Rate\n        self.par = 0.3   # Initial Pitch Adjustment Rate\n        self.f = 0.8     # Differential weight\n        self.cr = 0.9    # Crossover probability\n        self.inertia = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5       # Cognitive coefficient\n        self.c2 = 1.5       # Social coefficient\n        self.beta = 0.05    # Quantum-inspired learning rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim)) * (ub - lb)\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            # Adaptive parameter adjustment\n            self.hmcr = 0.7 + 0.3 * (1 - evaluations / self.budget)\n            self.par = 0.2 + 0.5 * (evaluations / self.budget)\n\n            # Generate new harmony vector with quantum-inspired exploration\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n                    \n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            # PSO update\n            if evaluations + 1 < self.budget:\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities = (self.inertia * velocities +\n                              self.c1 * r1 * (personal_best_positions - harmony_memory) +\n                              self.c2 * r2 * (global_best_position - harmony_memory))\n                harmony_memory = np.clip(harmony_memory + velocities, lb, ub)\n\n            # Evaluate new harmony\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Update personal and global best\n            if new_score < personal_best_scores.max():\n                worst_index = np.argmax(personal_best_scores)\n                harmony_memory[worst_index] = new_harmony\n                personal_best_scores[worst_index] = new_score\n                personal_best_positions[worst_index] = new_harmony\n\n            if new_score < personal_best_scores[global_best_index]:\n                global_best_index = worst_index\n                global_best_position = new_harmony\n\n        # Return the best solution found\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumHarmonyPSO", "description": "Quantum-Inspired Dynamic Harmony-PSO, an enhanced algorithm integrating quantum-inspired exploration with adaptive memory parameters and PSO for improved global optimization.", "configspace": "", "generation": 7, "fitness": 0.29771456917054484, "feedback": "The algorithm QuantumHarmonyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "39e30dd2-66e7-481d-86f0-0f6c0b2e70a3", "metadata": {"aucs": [0.29771456917054484]}, "mutation_prompt": null}
{"id": "ed108a34-8906-43bf-889c-351c16461690", "solution": "import numpy as np\n\nclass QuantumEnhancedHarmonyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(20, dim)\n        self.hmcr = 0.9\n        self.par = 0.3\n        self.inertia = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.beta = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim)) * (ub - lb)\n        temp_harmony_memory = harmony_memory.copy()\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            self.hmcr = 0.7 + 0.3 * (1 - evaluations / self.budget)\n            self.par = 0.2 + 0.5 * (evaluations / self.budget)\n\n            for i in range(self.harmony_memory_size):\n                new_harmony = np.empty(self.dim)\n                for d in range(self.dim):\n                    if np.random.rand() < self.hmcr:\n                        new_harmony[d] = harmony_memory[np.random.randint(self.harmony_memory_size), d]\n                        if np.random.rand() < self.par:\n                            new_harmony[d] += np.random.uniform(-0.1, 0.1) * (ub[d] - lb[d])\n                    else:\n                        new_harmony[d] = np.random.uniform(lb[d], ub[d])\n\n                    if np.random.rand() < self.beta:\n                        q = np.random.normal(loc=0, scale=1)\n                        new_harmony[d] = global_best_position[d] + q * (ub[d] - lb[d])\n\n                new_score = func(new_harmony)\n                evaluations += 1\n\n                if new_score < personal_best_scores[i]:\n                    personal_best_positions[i] = new_harmony\n                    personal_best_scores[i] = new_score\n                    if new_score < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = new_harmony\n\n            r1, r2 = np.random.rand(self.harmony_memory_size, self.dim), np.random.rand(self.harmony_memory_size, self.dim)\n            velocities = (self.inertia * velocities +\n                          self.c1 * r1 * (personal_best_positions - harmony_memory) +\n                          self.c2 * r2 * (global_best_position - harmony_memory))\n            temp_harmony_memory = np.clip(harmony_memory + velocities, lb, ub)\n\n            for i in range(self.harmony_memory_size):\n                temp_score = func(temp_harmony_memory[i])\n                evaluations += 1\n                if temp_score < personal_best_scores[i]:\n                    harmony_memory[i] = temp_harmony_memory[i]\n                    personal_best_scores[i] = temp_score\n                    if temp_score < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = temp_harmony_memory[i]\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumEnhancedHarmonyPSO", "description": "A Quantum-Enhanced Adaptive Harmony-PSO that dynamically balances exploration and exploitation by integrating quantum perturbations, adaptive memory parameters, and dual population strategies for superior optimization.", "configspace": "", "generation": 8, "fitness": 0.2856435257926585, "feedback": "The algorithm QuantumEnhancedHarmonyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2856435257926585]}, "mutation_prompt": null}
{"id": "10ab6575-9888-45cf-bde0-42d847772244", "solution": "import numpy as np\n\nclass EnhancedQuantumHarmonyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9  # Initial Harmony Memory Consideration Rate\n        self.par = 0.3   # Initial Pitch Adjustment Rate\n        self.f = 0.8     # Differential weight\n        self.cr = 0.9    # Crossover probability\n        self.inertia = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5       # Cognitive coefficient\n        self.c2 = 1.5       # Social coefficient\n        self.beta = 0.05    # Quantum-inspired learning rate\n        self.swarms = 3     # Number of sub-swarms\n        self.memory_split = np.array_split(range(self.harmony_memory_size), self.swarms)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim)) * (ub - lb)\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_idx].copy()\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            self.hmcr = 0.7 + 0.3 * (1 - evaluations / self.budget)\n            self.par = 0.2 + 0.5 * (evaluations / self.budget)\n            self.beta = 0.05 + 0.45 * (evaluations / self.budget)\n\n            for swarm_indices in self.memory_split:\n                local_best_idx = swarm_indices[np.argmin(personal_best_scores[swarm_indices])]\n                local_best_position = harmony_memory[local_best_idx].copy()\n\n                for idx in swarm_indices:\n                    new_harmony = np.empty(self.dim)\n                    for i in range(self.dim):\n                        if np.random.rand() < self.hmcr:\n                            new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                            if np.random.rand() < self.par:\n                                new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                        else:\n                            new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                        if np.random.rand() < self.beta:\n                            q = np.random.normal(loc=0, scale=1)\n                            new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n                    if evaluations + 1 < self.budget:\n                        r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                        velocities[idx] = (self.inertia * velocities[idx] +\n                                           self.c1 * r1 * (personal_best_positions[idx] - harmony_memory[idx]) +\n                                           self.c2 * r2 * (local_best_position - harmony_memory[idx]))\n                        harmony_memory[idx] = np.clip(harmony_memory[idx] + velocities[idx], lb, ub)\n\n                    new_score = func(new_harmony)\n                    evaluations += 1\n\n                    if new_score < personal_best_scores[idx]:\n                        personal_best_scores[idx] = new_score\n                        personal_best_positions[idx] = new_harmony\n\n                    if new_score < personal_best_scores[global_best_idx]:\n                        global_best_idx = idx\n                        global_best_position = new_harmony\n\n        return global_best_position, personal_best_scores[global_best_idx]", "name": "EnhancedQuantumHarmonyPSO", "description": "Enhanced Quantum Harmony-PSO with Adaptive Learning and Multi-Swarm Dynamics, integrating diverse swarm dynamics and adaptive quantum-inspired parameters for improved exploration and convergence.", "configspace": "", "generation": 9, "fitness": 0.2932298099955124, "feedback": "The algorithm EnhancedQuantumHarmonyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2932298099955124]}, "mutation_prompt": null}
{"id": "f744e52b-a61c-4f2e-a6e4-10894163b30a", "solution": "import numpy as np\n\nclass QuantumHarmonyPSOAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9\n        self.par = 0.3\n        self.f = 0.8\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.beta = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim)) * (ub - lb)\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n\n        def adaptive_neighborhood(index):\n            neighbors = np.random.choice(self.harmony_memory_size, 3, replace=False)\n            worst_neighbor = neighbors[np.argmax(personal_best_scores[neighbors])]\n            return worst_neighbor\n\n        while evaluations < self.budget:\n            self.hmcr = 0.6 + 0.4 * (1 - evaluations / self.budget)\n            self.par = 0.1 + 0.6 * (evaluations / self.budget)\n\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            if evaluations + 1 < self.budget:\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                for idx in range(self.harmony_memory_size):\n                    neighbor_idx = adaptive_neighborhood(idx)\n                    velocities[idx] = (self.inertia * velocities[idx] +\n                                       self.c1 * r1 * (personal_best_positions[idx] - harmony_memory[idx]) +\n                                       self.c2 * r2 * (harmony_memory[neighbor_idx] - harmony_memory[idx]))\n                harmony_memory = np.clip(harmony_memory + velocities, lb, ub)\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            worst_index = np.argmax(personal_best_scores)\n            if new_score < personal_best_scores[worst_index]:\n                harmony_memory[worst_index] = new_harmony\n                personal_best_scores[worst_index] = new_score\n                personal_best_positions[worst_index] = new_harmony\n\n            if new_score < personal_best_scores[global_best_index]:\n                global_best_index = worst_index\n                global_best_position = new_harmony\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumHarmonyPSOAdaptive", "description": "Quantum-Inspired Dynamic Harmony-PSO with Adaptive Neighborhood, enhancing exploration and exploitation by integrating adaptive neighborhood structures for collective learning.", "configspace": "", "generation": 10, "fitness": 0.2822170857507029, "feedback": "The algorithm QuantumHarmonyPSOAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2822170857507029]}, "mutation_prompt": null}
{"id": "6efff07c-096d-4a24-b609-4db7abd34d6c", "solution": "import numpy as np\n\nclass AdaptiveQuantumMemetic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, dim)\n        self.alpha = 0.9  # Initial global search rate\n        self.beta = 0.1   # Initial local search rate\n        self.local_search_intensity = 5\n        self.global_search_intensity = 10\n        self.mutation_rate = 0.05  # Mutation rate for memetic search\n        self.quantum_influence = 0.1  # Quantum influence factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_index = np.argmin(scores)\n        best_solution = population[best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptively adjust global and local search rates\n            self.alpha = 0.8 + 0.2 * (1 - evaluations / self.budget)\n            self.beta = 0.2 + 0.8 * (evaluations / self.budget)\n\n            # Quantum-inspired global search\n            for _ in range(self.global_search_intensity):\n                if evaluations >= self.budget:\n                    break\n                new_solution = best_solution + self.quantum_influence * np.random.normal(size=self.dim)\n                new_solution = np.clip(new_solution, lb, ub)\n                new_score = func(new_solution)\n                evaluations += 1\n                if new_score < scores[best_index]:\n                    scores[best_index] = new_score\n                    best_solution = new_solution\n\n            # Memetic local search\n            for _ in range(self.local_search_intensity):\n                if evaluations >= self.budget:\n                    break\n                local_candidate = best_solution + self.mutation_rate * np.random.uniform(-1, 1, self.dim) * (ub - lb)\n                local_candidate = np.clip(local_candidate, lb, ub)\n                local_score = func(local_candidate)\n                evaluations += 1\n                if local_score < scores[best_index]:\n                    scores[best_index] = local_score\n                    best_solution = local_candidate\n\n        # Return the best solution found\n        return best_solution, scores[best_index]", "name": "AdaptiveQuantumMemetic", "description": "Adaptive Quantum Memetic Algorithm (AQMA), a novel hybrid algorithm combining adaptive local search with quantum-inspired global exploration for efficient optimization of complex landscapes.", "configspace": "", "generation": 11, "fitness": 0.28632394191597965, "feedback": "The algorithm AdaptiveQuantumMemetic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.28632394191597965]}, "mutation_prompt": null}
{"id": "fc65253d-f27e-41d3-82fb-d807584001f9", "solution": "import numpy as np\n\nclass QuantumHarmonyGPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9  # Initial Harmony Memory Consideration Rate\n        self.par = 0.3   # Initial Pitch Adjustment Rate\n        self.f = 0.8     # Differential weight\n        self.cr = 0.9    # Crossover probability\n        self.inertia = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5       # Cognitive coefficient\n        self.c2 = 1.5       # Social coefficient\n        self.beta = 0.05    # Quantum-inspired learning rate\n        self.memeplex_segments = 3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim)) * (ub - lb)\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            self.hmcr = 0.7 + 0.3 * (1 - evaluations / self.budget)\n            self.par = 0.2 + 0.5 * (evaluations / self.budget)\n            \n            # Dynamic memeplex segmentation\n            indices = np.argsort(personal_best_scores)\n            memeplexes = np.array_split(indices, self.memeplex_segments)\n\n            # Generate new harmony vector with quantum-inspired exploration\n            for memeplex in memeplexes:\n                new_harmony = np.empty(self.dim)\n                for i in range(self.dim):\n                    if np.random.rand() < self.hmcr:\n                        new_harmony[i] = harmony_memory[np.random.choice(memeplex), i]\n                        if np.random.rand() < self.par:\n                            new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                    else:\n                        new_harmony[i] = np.random.uniform(lb[i], ub[i])\n                    \n                    if np.random.rand() < self.beta:\n                        q = np.random.normal(loc=0, scale=1)\n                        new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n                # Evaluate new harmony\n                new_score = func(new_harmony)\n                evaluations += 1\n\n                # Update personal and global best\n                if new_score < personal_best_scores[memeplex[-1]]:\n                    worst_index = memeplex[-1]\n                    harmony_memory[worst_index] = new_harmony\n                    personal_best_scores[worst_index] = new_score\n                    personal_best_positions[worst_index] = new_harmony\n\n                if new_score < personal_best_scores[global_best_index]:\n                    global_best_index = worst_index\n                    global_best_position = new_harmony\n\n                if evaluations >= self.budget:\n                    break\n\n            # PSO update\n            if evaluations < self.budget:\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities = (self.inertia * velocities +\n                              self.c1 * r1 * (personal_best_positions - harmony_memory) +\n                              self.c2 * r2 * (global_best_position - harmony_memory))\n                harmony_memory = np.clip(harmony_memory + velocities, lb, ub)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumHarmonyGPSO", "description": "Quantum Harmony-Guided Particle Swarm Optimization with Dynamic Memeplex Strategies (QH-GPSO): An advanced algorithm that combines quantum-inspired exploration, adaptive parameter tuning, and dynamic memeplex-based diversity strategies for enhanced global optimization.", "configspace": "", "generation": 12, "fitness": 0.2891106505491189, "feedback": "The algorithm QuantumHarmonyGPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2891106505491189]}, "mutation_prompt": null}
{"id": "d07455f4-945e-4b23-a968-90dc7caa137d", "solution": "import numpy as np\n\nclass QuantumHarmonyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_harmony_memory_size = 10 + dim\n        self.hmcr = 0.9  # Initial Harmony Memory Consideration Rate\n        self.par = 0.3   # Initial Pitch Adjustment Rate\n        self.f = 0.8     # Differential weight\n        self.cr = 0.9    # Crossover probability\n        self.inertia = 0.7  # Inertia weight for PSO\n        self.c1 = 1.5       # Cognitive coefficient\n        self.c2 = 1.5       # Social coefficient\n        self.beta = 0.05    # Quantum-inspired learning rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.initial_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (harmony_memory_size, self.dim)) * (ub - lb)\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n\n        while evaluations < self.budget:\n            for i in range(harmony_memory_size):\n                # Adaptive parameter adjustment\n                self.hmcr = 0.7 + 0.3 * (1 - evaluations / self.budget)\n                self.par = 0.2 + 0.5 * (evaluations / self.budget)\n\n                # Generate new harmony vector with quantum-inspired exploration\n                new_harmony = np.empty(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.hmcr:\n                        new_harmony[j] = harmony_memory[np.random.randint(harmony_memory_size), j]\n                        if np.random.rand() < self.par:\n                            new_harmony[j] += np.random.uniform(-0.1, 0.1) * (ub[j] - lb[j])\n                    else:\n                        new_harmony[j] = np.random.uniform(lb[j], ub[j])\n\n                    # Quantum-inspired update\n                    if np.random.rand() < self.beta:\n                        q = np.random.normal(loc=0, scale=1)\n                        new_harmony[j] = global_best_position[j] + q * (ub[j] - lb[j])\n\n                # Evaluate new harmony\n                new_score = func(new_harmony)\n                evaluations += 1\n\n                # Update personal and global best asynchronously\n                if new_score < personal_best_scores[i]:\n                    personal_best_positions[i] = new_harmony\n                    personal_best_scores[i] = new_score\n\n                if new_score < personal_best_scores[global_best_index]:\n                    global_best_index = i\n                    global_best_position = new_harmony\n\n                # PSO update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - harmony_memory[i]) +\n                                 self.c2 * r2 * (global_best_position - harmony_memory[i]))\n                harmony_memory[i] = np.clip(harmony_memory[i] + velocities[i], lb, ub)\n\n            # Dynamically adjust memory size to balance exploration and exploitation\n            if evaluations > self.budget / 2 and harmony_memory_size > self.dim:\n                harmony_memory_size -= 1\n\n        # Return the best solution found\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumHarmonyPSO", "description": "Quantum Harmony PSO with Adaptive Memory and Asynchronous Update, enhancing exploitation and exploration by incorporating adaptive memory size and asynchronous updates to balance the search process dynamically.", "configspace": "", "generation": 13, "fitness": 0.2958597418922889, "feedback": "The algorithm QuantumHarmonyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2958597418922889]}, "mutation_prompt": null}
{"id": "163b19f9-b454-408f-b946-03b6a40318e7", "solution": "import numpy as np\n\nclass AdaptiveQuantumGenetic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(15, dim)\n        self.mutation_rate = 0.1\n        self.quantum_rate = 0.1\n        self.crossover_rate = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(population[i]) for i in range(self.population_size)])\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Select parents for crossover using tournament selection\n            new_population = []\n            for _ in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                parent1 = min(indices, key=lambda idx: scores[idx])\n                parent2 = min(set(indices) - {parent1}, key=lambda idx: scores[idx])\n                new_population.append(self._crossover(population[parent1], population[parent2], lb, ub))\n            \n            # Mutation and quantum-inspired mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    new_population[i] = self._mutate(new_population[i], lb, ub)\n                if np.random.rand() < self.quantum_rate:\n                    new_population[i] = self._quantum_mutate(new_population[i], population, scores, lb, ub)\n\n            # Evaluate new population\n            new_scores = np.array([func(individual) for individual in new_population])\n            evaluations += self.population_size\n\n            # Select the next generation\n            combined_population = np.vstack((population, new_population))\n            combined_scores = np.hstack((scores, new_scores))\n            best_indices = np.argsort(combined_scores)[:self.population_size]\n            population = combined_population[best_indices]\n            scores = combined_scores[best_indices]\n\n        best_index = np.argmin(scores)\n        return population[best_index], scores[best_index]\n\n    def _crossover(self, parent1, parent2, lb, ub):\n        if np.random.rand() < self.crossover_rate:\n            alpha = np.random.rand(self.dim)\n            child = alpha * parent1 + (1 - alpha) * parent2\n            return np.clip(child, lb, ub)\n        return parent1 if np.random.rand() > 0.5 else parent2\n\n    def _mutate(self, individual, lb, ub):\n        mutation_vector = np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n        return np.clip(individual + mutation_vector, lb, ub)\n\n    def _quantum_mutate(self, individual, population, scores, lb, ub):\n        best_individual = population[np.argmin(scores)]\n        quantum_step = np.random.normal(loc=0, scale=0.1, size=self.dim) * (ub - lb)\n        return np.clip(best_individual + quantum_step, lb, ub)", "name": "AdaptiveQuantumGenetic", "description": "Adaptive Quantum Genetic Algorithm (AQGA), an innovative approach combining adaptive quantum mutation and genetic crossover for enhanced exploration in global optimization tasks.", "configspace": "", "generation": 14, "fitness": 0.2900408780803765, "feedback": "The algorithm AdaptiveQuantumGenetic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2900408780803765]}, "mutation_prompt": null}
{"id": "1ab554dc-29d8-42b3-8c60-8eae30a03530", "solution": "import numpy as np\n\nclass AdaptiveQuantumSwarmHarmony:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9\n        self.par = 0.3\n        self.f = 0.8\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.beta = 0.05\n\n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim)) * (ub - lb)\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n\n        # Initialize chaotic variable\n        chaotic_var = np.random.rand()\n\n        while evaluations < self.budget:\n            # Adaptive and chaotic parameter adjustment\n            self.hmcr = 0.7 + 0.3 * (1 - evaluations / self.budget)\n            self.par = 0.2 + 0.5 * (evaluations / self.budget)\n            chaotic_var = self.logistic_map(chaotic_var)\n\n            # Generate new harmony vector with chaotic quantum-inspired exploration\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n                    \n                # Quantum-inspired update with chaotic adjustment\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1) * chaotic_var\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            # PSO update\n            if evaluations + 1 < self.budget:\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities = (self.inertia * velocities +\n                              self.c1 * r1 * (personal_best_positions - harmony_memory) +\n                              self.c2 * r2 * (global_best_position - harmony_memory))\n                harmony_memory = np.clip(harmony_memory + velocities, lb, ub)\n\n            # Evaluate new harmony\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Update personal and global best\n            if new_score < personal_best_scores.max():\n                worst_index = np.argmax(personal_best_scores)\n                harmony_memory[worst_index] = new_harmony\n                personal_best_scores[worst_index] = new_score\n                personal_best_positions[worst_index] = new_harmony\n\n            if new_score < personal_best_scores[global_best_index]:\n                global_best_index = worst_index\n                global_best_position = new_harmony\n\n        # Return the best solution found\n        return global_best_position, personal_best_scores[global_best_index]", "name": "AdaptiveQuantumSwarmHarmony", "description": "Adaptive Quantum Swarm Harmony Search, a hybrid of quantum-inspired exploration, adaptive parameters, and swarm intelligence enhanced with chaotic systems for global optimization.", "configspace": "", "generation": 15, "fitness": 0.29610318261242696, "feedback": "The algorithm AdaptiveQuantumSwarmHarmony got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.29610318261242696]}, "mutation_prompt": null}
{"id": "aa000bef-2409-457f-9d1e-8a6d58af7b72", "solution": "import numpy as np\n\nclass AdaptiveQuantumButterflyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.a = 0.5  # Movement intensity constant\n        self.c = 0.1  # Sensory modality constant\n        self.beta = 0.05  # Quantum-inspired update probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                if r1 < 0.5:\n                    # Local search\n                    step_size = self.a * r2 * (best_position - population[i])\n                else:\n                    # Global search\n                    random_partner = population[np.random.randint(self.population_size)]\n                    step_size = self.c * r2 * (random_partner - population[i])\n                \n                # Quantum-inspired perturbation\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    step_size += q * (ub - lb)\n                \n                # Update position\n                population[i] = np.clip(population[i] + step_size, lb, ub)\n                \n                # Evaluate new position\n                new_fitness = func(population[i])\n                evaluations += 1\n\n                # Update the best solution\n                if new_fitness < fitness[i]:\n                    fitness[i] = new_fitness\n                    if new_fitness < fitness[best_index]:\n                        best_index = i\n                        best_position = population[i].copy()\n\n                if evaluations >= self.budget:\n                    break\n                    \n        return best_position, fitness[best_index]", "name": "AdaptiveQuantumButterflyOptimization", "description": "Adaptive Quantum-Enhanced Butterfly Optimization integrates quantum superposition and adaptive mechanisms to dynamically balance exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.2694111380604163, "feedback": "The algorithm AdaptiveQuantumButterflyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2694111380604163]}, "mutation_prompt": null}
{"id": "057e7842-3da2-499e-8314-ba1b41c9d59b", "solution": "import numpy as np\n\nclass QuantumBeesIDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 2 * dim)\n        self.f = 0.7      # DE Mutation factor\n        self.cr = 0.9     # Crossover rate\n        self.waggle_rate = 0.1  # Probability of waggle dance communication\n        self.beta = 0.05  # Quantum-inspired learning rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_index = np.argmin(fitness)\n        best_position = population[best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # DE Mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                mutant = np.clip(x1 + self.f * (x2 - x3), lb, ub)\n                \n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, population[i])\n\n                # Quantum-inspired exploration\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    trial += q * (best_position - trial)\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Waggle dance communication\n                if np.random.rand() < self.waggle_rate:\n                    for j in range(self.dim):\n                        neighbor = np.random.choice(self.population_size)\n                        if fitness[neighbor] < fitness[i]:\n                            population[i][j] = np.random.normal(loc=population[neighbor][j], scale=abs(population[i][j] - population[neighbor][j]))\n\n            # Update the best solution found\n            best_index = np.argmin(fitness)\n            if fitness[best_index] < func(best_position):\n                best_position = population[best_index].copy()\n\n        return best_position, fitness[best_index]", "name": "QuantumBeesIDE", "description": "Quantum-Bees-Inspired Differential Evolution (QBIDE), an innovative approach combining quantum-inspired mechanisms and bee swarm intelligence with differential evolution for robust exploration and exploitation.", "configspace": "", "generation": 17, "fitness": 0.28525146671558066, "feedback": "The algorithm QuantumBeesIDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.28525146671558066]}, "mutation_prompt": null}
{"id": "d3967fd6-a7cc-402e-af5d-d8c27ba69813", "solution": "import numpy as np\n\nclass AdaptiveQuantumEvolutionary:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 2 * dim)\n        self.beta = 0.1   # Quantum-inspired learning rate\n        self.mutation_rate = 0.2\n        self.crossover_rate = 0.9\n        self.inertia = 0.5  # Initial inertia weight\n        self.cognitive_coeff = 1.0\n        self.social_coeff = 1.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * (ub - lb)\n        personal_best_positions = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            inertia = self.inertia + 0.2 * (1 - evaluations / self.budget)\n\n            # Evolutionary Crossover and Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    parents = np.random.choice(self.population_size, 2, replace=False)\n                    crossover_point = np.random.randint(1, self.dim)\n                    population[i, :crossover_point] = personal_best_positions[parents[0], :crossover_point]\n                    population[i, crossover_point:] = personal_best_positions[parents[1], crossover_point:]\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                    population[i] = np.clip(population[i] + mutation_vector, lb, ub)\n\n            # Quantum-inspired PSO update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (inertia * velocities +\n                          self.cognitive_coeff * r1 * (personal_best_positions - population) +\n                          self.social_coeff * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Quantum-inspired exploration\n            if np.random.rand() < self.beta:\n                q = np.random.normal(loc=0, scale=1, size=self.dim)\n                new_particle = global_best_position + q * (ub - lb)\n                population[np.random.randint(self.population_size)] = np.clip(new_particle, lb, ub)\n\n            # Evaluate the new population\n            scores = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            improved = scores < personal_best_scores\n            personal_best_scores[improved] = scores[improved]\n            personal_best_positions[improved] = population[improved]\n\n            global_best_index = np.argmin(personal_best_scores)\n            global_best_position = personal_best_positions[global_best_index].copy()\n\n        # Return the best solution found\n        return global_best_position, personal_best_scores[global_best_index]", "name": "AdaptiveQuantumEvolutionary", "description": "Adaptive Quantum-Evolutionary Hybrid, a novel algorithm synergizing quantum-inspired exploration with evolutionary strategy adjustments for dynamic global optimization.", "configspace": "", "generation": 18, "fitness": 0.2768167698585263, "feedback": "The algorithm AdaptiveQuantumEvolutionary got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2768167698585263]}, "mutation_prompt": null}
{"id": "a84ab0af-fb67-43a1-834b-bd1351a3f936", "solution": "import numpy as np\n\nclass AdaptiveNeuroEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.learning_rate = 0.1  # Initial learning rate for adaptive updates\n        self.mutation_strength = 0.1  # Initial mutation strength\n        self.crossover_rate = 0.7  # Probability of crossover\n        self.adaptive_rate = 0.5  # Rate for adapting learning parameters\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_index = np.argmin(scores)\n        best_solution = population[best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive learning rate adjustment\n            self.learning_rate = 0.05 + 0.45 * (1 - evaluations / self.budget)\n\n            new_population = np.empty_like(population)\n            for i in range(self.population_size):\n                # Mutation via Gaussian noise\n                noise = np.random.normal(0, self.mutation_strength, self.dim)\n                offspring = population[i] + noise * self.learning_rate\n\n                # Crossover with the best solution\n                if np.random.rand() < self.crossover_rate:\n                    cross_points = np.random.rand(self.dim) < self.adaptive_rate\n                    offspring[cross_points] = best_solution[cross_points]\n\n                # Ensure offspring are within bounds\n                offspring = np.clip(offspring, lb, ub)\n                new_population[i] = offspring\n\n            # Evaluate new population\n            new_scores = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n\n            # Select the best individuals from parent and offspring\n            combined_population = np.vstack((population, new_population))\n            combined_scores = np.hstack((scores, new_scores))\n            best_indices = np.argsort(combined_scores)[:self.population_size]\n            population = combined_population[best_indices]\n            scores = combined_scores[best_indices]\n\n            # Update best solution\n            if scores[0] < func(best_solution):\n                best_solution = population[0].copy()\n\n        # Return the best solution found\n        return best_solution, func(best_solution)", "name": "AdaptiveNeuroEvolution", "description": "Adaptive Neuro-Evolution Strategy (ANES): A hybrid algorithm combining adaptive learning rates from neural networks with evolution strategy for robust global optimization.", "configspace": "", "generation": 19, "fitness": 0.27855044588951183, "feedback": "The algorithm AdaptiveNeuroEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.27855044588951183]}, "mutation_prompt": null}
{"id": "df793008-ab6a-4ac2-a48e-87695d6cc3c0", "solution": "import numpy as np\n\nclass BioAM_ABC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_bees = max(10, dim)\n        self.limit = self.num_bees * 1.5  # Limit for abandonment\n        self.local_search_intensity = 0.1  # Local exploitation intensity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.num_bees, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = self.num_bees\n        trial = np.zeros(self.num_bees)\n\n        # Helper functions\n        def local_search(ind):\n            direction = np.random.normal(0, 1, self.dim)\n            step_size = self.local_search_intensity * (ub - lb)\n            new_ind = ind + step_size * direction\n            return np.clip(new_ind, lb, ub)\n\n        def random_selection(exclude_idx):\n            indices = list(range(self.num_bees))\n            indices.remove(exclude_idx)\n            return np.random.choice(indices)\n\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = fitness.min()\n\n        while evaluations < self.budget:\n            # Employed bee phase\n            for i in range(self.num_bees):\n                phi = np.random.uniform(-1, 1, self.dim)\n                partner_idx = random_selection(i)\n                new_solution = population[i] + phi * (population[i] - population[partner_idx])\n                new_solution = np.clip(new_solution, lb, ub)\n                new_fitness = func(new_solution)\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    population[i] = new_solution\n                    fitness[i] = new_fitness\n                    trial[i] = 0\n                else:\n                    trial[i] += 1\n\n                # Memetic local search\n                if np.random.rand() < 0.1:\n                    refined_solution = local_search(population[i])\n                    refined_fitness = func(refined_solution)\n                    evaluations += 1\n                    if refined_fitness < fitness[i]:\n                        population[i] = refined_solution\n                        fitness[i] = refined_fitness\n\n            # Onlooker bee phase\n            total_fitness = np.sum(1 / (1 + fitness))\n            probabilities = (1 / (1 + fitness)) / total_fitness\n            for _ in range(self.num_bees):\n                i = np.random.choice(range(self.num_bees), p=probabilities)\n                phi = np.random.uniform(-1, 1, self.dim)\n                partner_idx = random_selection(i)\n                new_solution = population[i] + phi * (population[i] - population[partner_idx])\n                new_solution = np.clip(new_solution, lb, ub)\n                new_fitness = func(new_solution)\n                evaluations += 1\n                if new_fitness < fitness[i]:\n                    population[i] = new_solution\n                    fitness[i] = new_fitness\n                    trial[i] = 0\n                else:\n                    trial[i] += 1\n\n            # Scout bee phase\n            for i in range(self.num_bees):\n                if trial[i] > self.limit:\n                    population[i] = np.random.uniform(lb, ub, self.dim)\n                    fitness[i] = func(population[i])\n                    evaluations += 1\n                    trial[i] = 0\n\n            # Update best solution\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_fitness = fitness[current_best_idx]\n                best_solution = population[current_best_idx]\n\n        return best_solution, best_fitness", "name": "BioAM_ABC", "description": "Bio-Inspired Adaptive Memetic Artificial Bee Colony (BioAM-ABC), leveraging advanced memetic strategies and adaptive exploration-exploitation balance for enhanced optimization efficiency.", "configspace": "", "generation": 20, "fitness": 0.2836073717300578, "feedback": "The algorithm BioAM_ABC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2836073717300578]}, "mutation_prompt": null}
{"id": "afce29cd-ef3b-4134-9863-b772159f5d8d", "solution": "import numpy as np\n\nclass EnhancedQuantumHarmonyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9\n        self.par = 0.3\n        self.f = 0.8\n        self.cr = 0.9\n        self.inertia = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.beta = 0.05\n        self.quantum_tunneling_prob = 0.1  # Prob. of quantum tunneling for escaping local optima\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim)) * (ub - lb)\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            self.hmcr = 0.7 + 0.3 * (1 - evaluations / self.budget)\n            self.par = 0.2 + 0.5 * (evaluations / self.budget)\n\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n                    \n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            if evaluations + 1 < self.budget:\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities = (self.inertia * velocities +\n                              self.c1 * r1 * (personal_best_positions - harmony_memory) +\n                              self.c2 * r2 * (global_best_position - harmony_memory))\n                harmony_memory = np.clip(harmony_memory + velocities, lb, ub)\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            if new_score < personal_best_scores.max():\n                worst_index = np.argmax(personal_best_scores)\n                harmony_memory[worst_index] = new_harmony\n                personal_best_scores[worst_index] = new_score\n                personal_best_positions[worst_index] = new_harmony\n\n            if new_score < personal_best_scores[global_best_index]:\n                global_best_index = worst_index\n                global_best_position = new_harmony\n\n            if evaluations % (self.budget // 10) == 0 and np.random.rand() < self.quantum_tunneling_prob:\n                tunnel_index = np.random.randint(self.harmony_memory_size)\n                perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                harmony_memory[tunnel_index] = np.clip(harmony_memory[tunnel_index] + perturbation, lb, ub)\n                score = func(harmony_memory[tunnel_index])\n                evaluations += 1\n                if score < personal_best_scores[tunnel_index]:\n                    personal_best_scores[tunnel_index] = score\n                    personal_best_positions[tunnel_index] = harmony_memory[tunnel_index]\n                if score < personal_best_scores[global_best_index]:\n                    global_best_index = tunnel_index\n                    global_best_position = harmony_memory[tunnel_index]\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "EnhancedQuantumHarmonyPSO", "description": "Enhanced Quantum Harmony-PSO with Adaptive Quantum Tunneling and Diversity-Boost Mechanism to improve exploration and convergence.", "configspace": "", "generation": 21, "fitness": 0.2945691123381815, "feedback": "The algorithm EnhancedQuantumHarmonyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2945691123381815]}, "mutation_prompt": null}
{"id": "8d2c13c2-6564-4df2-8aa9-5ff0f9487911", "solution": "import numpy as np\n\nclass QuantumAnnealedES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.t0 = 100   # Initial temperature for annealing\n        self.alpha = 0.95  # Cooling rate\n        self.beta = 0.05  # Quantum-inspired learning rate\n        self.sigma = 0.1  # Mutation step size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_index = np.argmin(scores)\n        best_position = population[best_index].copy()\n        best_score = scores[best_index]\n        temperature = self.t0\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Annealing-inspired random exploration\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                new_candidate = population[i] + np.random.normal(0, self.sigma * (ub - lb), self.dim)\n                new_candidate = np.clip(new_candidate, lb, ub)\n                \n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_candidate += q * (best_position - new_candidate)\n                \n                new_score = func(new_candidate)\n                evaluations += 1\n\n                # Accept new candidate based on simulated annealing criteria\n                if new_score < scores[i] or np.random.rand() < np.exp((scores[i] - new_score) / temperature):\n                    population[i] = new_candidate\n                    scores[i] = new_score\n\n                    # Update the best solution found\n                    if new_score < best_score:\n                        best_position = new_candidate\n                        best_score = new_score\n\n            # Cooling schedule\n            temperature *= self.alpha\n\n        # Return the best solution found\n        return best_position, best_score", "name": "QuantumAnnealedES", "description": "Adaptive Quantum-Annealed Evolutionary Strategy, combining adaptive quantum exploration, simulated annealing, and evolutionary strategy to enhance convergence in high-dimensional spaces.", "configspace": "", "generation": 22, "fitness": 0.28334835975669836, "feedback": "The algorithm QuantumAnnealedES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.28334835975669836]}, "mutation_prompt": null}
{"id": "e896c8e6-7346-4872-9a24-d1345a2f6398", "solution": "import numpy as np\n\nclass AdaptiveQuantumGeneticPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.inertia = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.crossover_rate = 0.8\n        self.mutation_rate = 0.2\n        self.beta = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * (ub - lb)\n        personal_best_positions = population.copy()\n        personal_best_scores = np.array([func(population[i]) for i in range(self.population_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = population[global_best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive mutation and crossover rates\n            self.crossover_rate = 0.6 + 0.4 * (1 - evaluations / self.budget)\n            self.mutation_rate = 0.1 + 0.3 * (evaluations / self.budget)\n\n            # Quantum-inspired genetic operations\n            new_population = np.empty((self.population_size, self.dim))\n            for i in range(0, self.population_size, 2):\n                parent1, parent2 = population[np.random.choice(self.population_size, 2, replace=False)]\n                crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n                new_population[i] = np.where(crossover_mask, parent1, parent2)\n                if i + 1 < self.population_size:\n                    new_population[i + 1] = np.where(crossover_mask, parent2, parent1)\n\n                mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n                new_population[i] += mutation_mask * np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                if i + 1 < self.population_size:\n                    new_population[i + 1] += mutation_mask * np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                \n                # Quantum-inspired adjustment\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_population[i] = global_best_position + q * (ub - lb)\n                    if i + 1 < self.population_size:\n                        new_population[i + 1] = global_best_position + q * (ub - lb)\n\n            # PSO velocity and position update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new population\n            new_scores = np.array([func(new_population[i]) for i in range(self.population_size)])\n            evaluations += self.population_size\n\n            # Update personal and global bests\n            update_mask = new_scores < personal_best_scores\n            personal_best_positions[update_mask] = new_population[update_mask]\n            personal_best_scores[update_mask] = new_scores[update_mask]\n\n            new_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[new_global_best_index] < personal_best_scores[global_best_index]:\n                global_best_index = new_global_best_index\n                global_best_position = personal_best_positions[global_best_index]\n\n        # Return the best solution found\n        return global_best_position, personal_best_scores[global_best_index]", "name": "AdaptiveQuantumGeneticPSO", "description": "Adaptive Quantum Genetic PSO (AQG-PSO), a hybrid algorithm combining adaptive genetic operators, quantum-inspired updates, and PSO for robust exploration and exploitation.", "configspace": "", "generation": 23, "fitness": 0.28490186767314496, "feedback": "The algorithm AdaptiveQuantumGeneticPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.28490186767314496]}, "mutation_prompt": null}
{"id": "0aac8b7d-406d-4b20-a012-d2c60e142976", "solution": "import numpy as np\n\nclass QuantumGeneticPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.inertia = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.7\n        self.beta = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * (ub - lb)\n        personal_best_positions = population.copy()\n        personal_best_scores = np.array([func(population[i]) for i in range(self.population_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = population[global_best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Crossover and Mutation (Quantum-inspired Genetic Operations)\n            new_population = np.empty((self.population_size, self.dim))\n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    partner_index = np.random.randint(self.population_size)\n                    crossover_point = np.random.randint(1, self.dim)\n                    new_population[i, :crossover_point] = personal_best_positions[i, :crossover_point]\n                    new_population[i, crossover_point:] = personal_best_positions[partner_index, crossover_point:]\n                else:\n                    new_population[i] = personal_best_positions[i]\n                \n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.normal(0, 1, self.dim) * (ub - lb)\n                    new_population[i] += mutation_vector * self.beta\n                    new_population[i] = np.clip(new_population[i], lb, ub)\n\n            # PSO velocity and position update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia * velocities +\n                          self.c1 * r1 * (personal_best_positions - population) +\n                          self.c2 * r2 * (global_best_position - population))\n            population = np.clip(population + velocities, lb, ub)\n\n            # Evaluate new population\n            new_scores = np.array([func(new_population[i]) for i in range(self.population_size)])\n            evaluations += self.population_size\n\n            # Update personal and global best\n            for i in range(self.population_size):\n                if new_scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = new_scores[i]\n                    personal_best_positions[i] = new_population[i]\n\n            current_global_best_index = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_index] < personal_best_scores[global_best_index]:\n                global_best_index = current_global_best_index\n                global_best_position = personal_best_positions[global_best_index]\n\n        # Return the best solution found\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumGeneticPSO", "description": "Quantum Genetic Particle Swarm Optimization (QGPSO), a hybrid approach combining quantum-inspired genetic operations with particle swarm dynamics to enhance exploration and convergence in global optimization.", "configspace": "", "generation": 24, "fitness": 0.2820229383316073, "feedback": "The algorithm QuantumGeneticPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.2820229383316073]}, "mutation_prompt": null}
{"id": "008f17ea-4b20-41f6-a6ab-53bd10478708", "solution": "import numpy as np\n\nclass QuantumAdaptiveSwarmHarmony:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9  # Initial Harmony Memory Consideration Rate\n        self.par = 0.3   # Initial Pitch Adjustment Rate\n        self.inertia = 0.7  # Inertia weight for PSO\n        self.cognitive_coef = 1.5  # Cognitive coefficient\n        self.social_coef = 1.5  # Social coefficient\n        self.beta = 0.05  # Quantum-inspired learning rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        velocities = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim)) * (ub - lb)\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            # Adaptive adjustments\n            self.hmcr = 0.7 + 0.3 * (1 - evaluations / self.budget)\n            self.par = 0.2 + 0.5 * (evaluations / self.budget)\n\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    selected = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Update personal and global bests\n            if new_score < personal_best_scores.max():\n                worst_index = np.argmax(personal_best_scores)\n                harmony_memory[worst_index] = new_harmony\n                personal_best_scores[worst_index] = new_score\n                personal_best_positions[worst_index] = new_harmony\n\n            if new_score < personal_best_scores[global_best_index]:\n                global_best_index = np.argmin(personal_best_scores)\n                global_best_position = harmony_memory[global_best_index].copy()\n\n            # Swarm dynamic update\n            if evaluations < self.budget:\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities = (self.inertia * velocities +\n                              self.cognitive_coef * r1 * (personal_best_positions - harmony_memory) +\n                              self.social_coef * r2 * (global_best_position - harmony_memory))\n                harmony_memory = np.clip(harmony_memory + velocities, lb, ub)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumAdaptiveSwarmHarmony", "description": "Quantum-Adaptive Swarm Harmony (QASH), a novel approach combining dynamic swarm intelligence with quantum-inspired adaptive harmony search for efficient global optimization.", "configspace": "", "generation": 25, "fitness": 0.30720927917683616, "feedback": "The algorithm QuantumAdaptiveSwarmHarmony got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.00.", "error": "", "parent_id": "1de52c22-4abf-4f11-99ac-1e3699270ae6", "metadata": {"aucs": [0.30720927917683616]}, "mutation_prompt": null}
{"id": "38326b2c-0069-48cf-9cd5-64746eaa6a7d", "solution": "import numpy as np\n\nclass QuantumCooperativeParticleSwarmHarmony:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9  # Harmony Memory Consideration Rate\n        self.par = 0.3   # Pitch Adjustment Rate\n        self.inertia = 0.7  # Inertia weight for PSO\n        self.cognitive_coef = 1.5  # Cognitive coefficient\n        self.social_coef = 1.5  # Social coefficient\n        self.beta = 0.05  # Quantum-inspired learning rate\n        self.cooperation_factor = 2.0  # Cooperation factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        personal_best_positions = harmony_memory.copy()\n        personal_best_scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        velocities = np.random.uniform(-1, 1, (self.harmony_memory_size, self.dim)) * (ub - lb)\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            # Dynamic adjustments based on progress\n            self.hmcr = 0.7 + 0.3 * (1 - evaluations / self.budget)\n            self.par = 0.2 + 0.5 * (evaluations / self.budget)\n\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    selected = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-0.1, 0.1) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Update personal and global bests if new harmony is better\n            if new_score < personal_best_scores.max():\n                worst_index = np.argmax(personal_best_scores)\n                harmony_memory[worst_index] = new_harmony\n                personal_best_scores[worst_index] = new_score\n                personal_best_positions[worst_index] = new_harmony\n\n            if new_score < personal_best_scores[global_best_index]:\n                global_best_index = np.argmin(personal_best_scores)\n                global_best_position = harmony_memory[global_best_index].copy()\n\n            # Cooperative swarm dynamic update\n            if evaluations < self.budget:\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities = (self.inertia * velocities +\n                              self.cognitive_coef * r1 * (personal_best_positions - harmony_memory) +\n                              self.social_coef * r2 * (global_best_position - harmony_memory) +\n                              self.cooperation_factor * np.random.rand(self.harmony_memory_size, self.dim) * \n                              (global_best_position - harmony_memory.mean(axis=0)))\n\n                harmony_memory = np.clip(harmony_memory + velocities, lb, ub)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumCooperativeParticleSwarmHarmony", "description": "Quantum-Inspired Cooperative Particle Swarm Harmony (QCPSH), an innovative methodology integrating cooperative particle dynamics with quantum-inspired selection and harmony memory enhancement for superior global search optimization.", "configspace": "", "generation": 26, "fitness": 0.28692696577957, "feedback": "The algorithm QuantumCooperativeParticleSwarmHarmony got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "008f17ea-4b20-41f6-a6ab-53bd10478708", "metadata": {"aucs": [0.28692696577957]}, "mutation_prompt": null}
{"id": "689bdacb-a8e2-4626-891c-670d6b9cd70f", "solution": "import numpy as np\n\nclass QuantumEnhancedExplorer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, dim)\n        self.alpha = 0.8  # Initial exploration factor for search space contraction\n        self.beta = 0.05  # Quantum-inspired adjustment rate\n        self.sigma_decay = 0.99  # Decay rate for quantum adjustment range\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_index = np.argmin(scores)\n        best_position = population[best_index].copy()\n        evaluations = self.population_size\n        sigma = (ub - lb) * 0.1  # Initial quantum adjustment range\n\n        while evaluations < self.budget:\n            # Adaptive contraction of search space\n            contraction_center = (1 - self.alpha) * best_position + self.alpha * np.mean(population, axis=0)\n            new_population = np.random.uniform(\n                np.maximum(lb, contraction_center - (ub - lb) / 2 * self.alpha),\n                np.minimum(ub, contraction_center + (ub - lb) / 2 * self.alpha),\n                (self.population_size, self.dim)\n            )\n\n            # Quantum-inspired exploration\n            for i in range(self.population_size):\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(0, sigma, self.dim)\n                    new_population[i] = np.clip(best_position + q, lb, ub)\n\n            new_scores = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n\n            # Update best position\n            for i in range(self.population_size):\n                if new_scores[i] < scores[best_index]:\n                    best_index = i\n                    best_position = new_population[best_index].copy()\n\n            population = new_population\n            scores = new_scores\n            sigma *= self.sigma_decay  # Decay the quantum adjustment range\n\n        return best_position, scores[best_index]", "name": "QuantumEnhancedExplorer", "description": "Quantum-Enhanced Explorer (QEE), a novel metaheuristic combining quantum-inspired exploration with dynamic search space contraction for efficient global optimization.", "configspace": "", "generation": 27, "fitness": 0.2810655831726351, "feedback": "The algorithm QuantumEnhancedExplorer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "008f17ea-4b20-41f6-a6ab-53bd10478708", "metadata": {"aucs": [0.2810655831726351]}, "mutation_prompt": null}
{"id": "22d8d856-1984-47e8-8297-2a13233de0d9", "solution": "import numpy as np\n\nclass QuantumAnnealedGeneticSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 2 * dim)\n        self.crossover_rate = 0.8\n        self.mutation_rate = 0.1\n        self.inertia = 0.7\n        self.cognitive_coef = 1.5\n        self.social_coef = 1.5\n        self.annealing_rate = 0.98\n        self.initial_temperature = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * (ub - lb)\n        personal_best_positions = population.copy()\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        evaluations = self.population_size\n        temperature = self.initial_temperature\n\n        while evaluations < self.budget:\n            new_population = population.copy()\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.crossover_rate:\n                    # Perform crossover\n                    partner_index = np.random.randint(self.population_size)\n                    point = np.random.randint(1, self.dim)\n                    new_population[i, :point] = population[i, :point]\n                    new_population[i, point:] = population[partner_index, point:]\n\n                # Quantum annealing-inspired mutation\n                for j in range(self.dim):\n                    if np.random.rand() < self.mutation_rate:\n                        new_population[i, j] += np.random.normal(0, temperature) * (ub[j] - lb[j])\n                        new_population[i, j] = np.clip(new_population[i, j], lb[j], ub[j])\n\n            # Evaluate the new population\n            new_scores = np.array([func(individual) for individual in new_population])\n            evaluations += self.population_size\n\n            # Select the best individuals\n            for i in range(self.population_size):\n                if new_scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = new_scores[i]\n                    personal_best_positions[i] = new_population[i].copy()\n\n                if new_scores[i] < personal_best_scores[global_best_index]:\n                    global_best_index = i\n                    global_best_position = new_population[i].copy()\n\n            # Update population and velocities using swarm dynamics\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia * velocities +\n                          self.cognitive_coef * r1 * (personal_best_positions - population) +\n                          self.social_coef * r2 * (global_best_position - population))\n            population = np.clip(new_population + velocities, lb, ub)\n\n            # Cool down the temperature\n            temperature *= self.annealing_rate\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumAnnealedGeneticSwarm", "description": "Quantum-Annealed Genetic Swarm (QAGS), a novel hybrid combining quantum annealing-based exploration with genetic algorithm crossovers and swarm intelligence for robust global optimization.", "configspace": "", "generation": 28, "fitness": 0.2786147513234112, "feedback": "The algorithm QuantumAnnealedGeneticSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "008f17ea-4b20-41f6-a6ab-53bd10478708", "metadata": {"aucs": [0.2786147513234112]}, "mutation_prompt": null}
{"id": "b1537a39-5d89-4ed7-8495-0a0132274707", "solution": "import numpy as np\n\nclass QuantumVariableSwarmExploration:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(15, dim * 2)\n        self.alpha = 0.5  # Balance between exploration and exploitation\n        self.beta = 0.1  # Quantum exploration rate\n        self.gamma = 0.7  # Swarm update influence\n        self.momentum = 0.6  # Initial momentum\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * (ub - lb)\n        scores = np.array([func(individual) for individual in population])\n        evaluations = self.population_size\n        \n        best_index = np.argmin(scores)\n        best_position = population[best_index].copy()\n        \n        while evaluations < self.budget:\n            new_population = np.empty_like(population)\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                rand_quantum = np.random.normal(0, self.beta, self.dim) * (ub - lb)\n                \n                # Quantum-inspired variable exploration\n                quantum_jump = best_position + rand_quantum\n                quantum_jump = np.clip(quantum_jump, lb, ub)\n                \n                if np.random.rand() < self.alpha:\n                    new_population[i] = quantum_jump\n                else:\n                    # Swarm dynamics update\n                    inertia = self.momentum * velocities[i]\n                    cognitive = self.gamma * r1 * (best_position - population[i])\n                    \n                    velocities[i] = inertia + cognitive\n                    new_population[i] = population[i] + velocities[i]\n                    new_population[i] = np.clip(new_population[i], lb, ub)\n            \n            new_scores = np.array([func(individual) for individual in new_population])\n            evaluations += self.population_size\n            \n            # Update the best found solution\n            current_best_index = np.argmin(new_scores)\n            if new_scores[current_best_index] < scores[best_index]:\n                best_index = current_best_index\n                best_position = new_population[best_index].copy()\n\n            # Keep the new population and scores\n            population, scores = new_population, new_scores\n        \n        return best_position, scores[best_index]", "name": "QuantumVariableSwarmExploration", "description": "Quantum-Variable Swarm Exploration (QVSE), a hybrid optimization algorithm merging quantum-inspired variable exploration with swarm dynamics for robust search in complex landscapes.", "configspace": "", "generation": 29, "fitness": 0.2860748216179393, "feedback": "The algorithm QuantumVariableSwarmExploration got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "008f17ea-4b20-41f6-a6ab-53bd10478708", "metadata": {"aucs": [0.2860748216179393]}, "mutation_prompt": null}
{"id": "c52b24bf-633a-4663-ac07-068b7583dcc0", "solution": "import numpy as np\n\nclass QuantumGuidedEvolutionaryHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9\n        self.par = 0.3\n        self.evolution_rate = 0.1\n        self.beta = 0.1  # Quantum learning rate\n        self.mutation_strength = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    selected = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Stochastic evolutionary mutation\n            if evaluations < self.budget and np.random.rand() < self.evolution_rate:\n                mutation_indices = np.random.choice(self.harmony_memory_size, size=int(self.harmony_memory_size * self.evolution_rate), replace=False)\n                for index in mutation_indices:\n                    mutation_vector = np.random.normal(0, self.mutation_strength, self.dim)\n                    harmony_memory[index] = np.clip(harmony_memory[index] + mutation_vector * (ub - lb), lb, ub)\n                    scores[index] = func(harmony_memory[index])\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumGuidedEvolutionaryHarmonySearch", "description": "Quantum-Guided Evolutionary Harmony Search (QGEHS) combines evolutionary strategies with quantum-driven refinement for enhanced exploration and exploitation in global optimization.", "configspace": "", "generation": 30, "fitness": 0.3314073075088986, "feedback": "The algorithm QuantumGuidedEvolutionaryHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.00.", "error": "", "parent_id": "008f17ea-4b20-41f6-a6ab-53bd10478708", "metadata": {"aucs": [0.3314073075088986]}, "mutation_prompt": null}
{"id": "df37916d-1ad7-4eca-843f-c5bc5f6e08e5", "solution": "import numpy as np\n\nclass AdaptiveSpiralDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.85\n        self.par = 0.3\n        self.spiral_factor = 0.5\n        self.adaptive_memory_scale = 0.1\n        self.mutation_strength = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n        \n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    selected = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                        \n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n             \n                # Spiral Dynamic update\n                if np.random.rand() < self.spiral_factor:\n                    theta = np.random.uniform(0, 2 * np.pi)\n                    radius = np.random.uniform(0, np.linalg.norm(ub - lb) / 2)\n                    new_harmony[i] = global_best_position[i] + radius * np.cos(theta)\n                    new_harmony[i] = np.clip(new_harmony[i], lb[i], ub[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n            \n            # Adaptive Memory Replacement\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n                \n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n            \n            # Adaptive memory refinement\n            if evaluations < self.budget and np.random.rand() < self.adaptive_memory_scale:\n                mutation_indices = np.random.choice(self.harmony_memory_size, size=int(self.harmony_memory_size * self.adaptive_memory_scale), replace=False)\n                for index in mutation_indices:\n                    mutation_vector = np.random.normal(0, self.mutation_strength, self.dim)\n                    harmony_memory[index] = np.clip(harmony_memory[index] + mutation_vector * (ub - lb), lb, ub)\n                    scores[index] = func(harmony_memory[index])\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n        return global_best_position, scores[global_best_index]", "name": "AdaptiveSpiralDynamicHarmonySearch", "description": "Adaptive Spiral Dynamic Harmony Search (ASDHS) combines spiral dynamics with adaptive harmony memory to enhance convergence and diversity in global optimization tasks.", "configspace": "", "generation": 31, "fitness": 0.2852180653342977, "feedback": "The algorithm AdaptiveSpiralDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "c52b24bf-633a-4663-ac07-068b7583dcc0", "metadata": {"aucs": [0.2852180653342977]}, "mutation_prompt": null}
{"id": "ddfb2df7-d52d-4cef-90f4-605401f5fdf8", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr = 0.9\n        self.par = 0.3\n        self.evolution_rate = 0.1\n        self.beta = 0.1\n        self.mutation_strength = 0.1\n        self.adaptive_factor = 0.05  # Adaptive factor for parameter tuning\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    selected = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < self.par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            self.beta = max(0.01, self.beta - self.adaptive_factor * (scores.min() / scores.mean()))\n            self.mutation_strength = max(0.01, self.mutation_strength - self.adaptive_factor * (scores.min() / scores.mean()))\n\n            # Stochastic evolutionary mutation\n            if evaluations < self.budget and np.random.rand() < self.evolution_rate:\n                mutation_indices = np.random.choice(self.harmony_memory_size, size=int(self.harmony_memory_size * self.evolution_rate), replace=False)\n                for index in mutation_indices:\n                    mutation_vector = np.random.normal(0, self.mutation_strength, self.dim)\n                    harmony_memory[index] = np.clip(harmony_memory[index] + mutation_vector * (ub - lb), lb, ub)\n                    scores[index] = func(harmony_memory[index])\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumEnhancedAdaptiveHarmonySearch", "description": "Quantum-Enhanced Adaptive Harmony Search (QEAHS) enhances exploration and exploitation by introducing adaptive parameters and quantum-inspired perturbations to dynamically balance search capabilities.", "configspace": "", "generation": 32, "fitness": 0.30660188800511734, "feedback": "The algorithm QuantumEnhancedAdaptiveHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.00.", "error": "", "parent_id": "c52b24bf-633a-4663-ac07-068b7583dcc0", "metadata": {"aucs": [0.30660188800511734]}, "mutation_prompt": null}
{"id": "b058b7a3-526b-4661-b981-97b34ccd5900", "solution": "import numpy as np\n\nclass EnhancedQuantumGuidedEvolutionaryHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.1  # Quantum learning rate\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.005\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Local neighborhood search\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                local_search_position = global_best_position + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                local_search_position = np.clip(local_search_position, lb, ub)\n                local_search_score = func(local_search_position)\n                evaluations += 1\n                if local_search_score < scores[global_best_index]:\n                    global_best_position = local_search_position\n                    scores[global_best_index] = local_search_score\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumGuidedEvolutionaryHarmonySearch", "description": "Enhanced Quantum-Guided Evolutionary Harmony Search (Enhanced QGEHS) integrates adaptive parameter tuning and neighborhood search to improve convergence speed and solution quality in global optimization.", "configspace": "", "generation": 33, "fitness": 0.33756132179082743, "feedback": "The algorithm EnhancedQuantumGuidedEvolutionaryHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.00.", "error": "", "parent_id": "c52b24bf-633a-4663-ac07-068b7583dcc0", "metadata": {"aucs": [0.33756132179082743]}, "mutation_prompt": null}
{"id": "3c03ea04-1559-46aa-850b-c8a226f232f0", "solution": "import numpy as np\n\nclass QuantumEnhancedDynamicAdaptiveHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.1\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.005\n        self.diversification_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Local neighborhood search\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                local_search_position = global_best_position + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                local_search_position = np.clip(local_search_position, lb, ub)\n                local_search_score = func(local_search_position)\n                evaluations += 1\n                if local_search_score < scores[global_best_index]:\n                    global_best_position = local_search_position\n                    scores[global_best_index] = local_search_score\n\n            # Diversification step\n            if evaluations < self.budget and np.random.rand() < self.diversification_rate:\n                diversification_position = np.random.uniform(lb, ub, self.dim)\n                diversification_score = func(diversification_position)\n                evaluations += 1\n                if diversification_score < scores.max():\n                    worst_index = np.argmax(scores)\n                    harmony_memory[worst_index] = diversification_position\n                    scores[worst_index] = diversification_score\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumEnhancedDynamicAdaptiveHarmonySearch", "description": "Quantum-Enhanced Dynamic Adaptive Harmony Search (QEDAH) employs dynamic learning rates and strategic diversification for superior convergence and solution quality in global optimization.", "configspace": "", "generation": 34, "fitness": 0.3325859332778055, "feedback": "The algorithm QuantumEnhancedDynamicAdaptiveHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.00.", "error": "", "parent_id": "b058b7a3-526b-4661-b981-97b34ccd5900", "metadata": {"aucs": [0.3325859332778055]}, "mutation_prompt": null}
{"id": "95f5c6b9-2a64-4206-ab55-8b66d429e93e", "solution": "import numpy as np\n\nclass QuantumEnhancedDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = max(10, dim)\n        self.hmcr_min = 0.7\n        self.hmcr_max = 0.99\n        self.par_min = 0.1\n        self.par_max = 0.5\n        self.beta = 0.1  # Quantum learning rate\n        self.mutation_strength = 0.1\n        self.exploration_strength = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            hmcr = self.hmcr_min + (self.hmcr_max - self.hmcr_min) * (1 - evaluations / self.budget)\n            par = self.par_min + (self.par_max - self.par_min) * (evaluations / self.budget)\n            new_harmony = np.empty(self.dim)\n            \n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * self.exploration_strength * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Quantum-enhanced local search\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                local_search_position = global_best_position + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                local_search_position = np.clip(local_search_position, lb, ub)\n                local_search_score = func(local_search_position)\n                evaluations += 1\n                if local_search_score < scores[global_best_index]:\n                    global_best_position = local_search_position\n                    scores[global_best_index] = local_search_score\n        \n        return global_best_position, scores[global_best_index]", "name": "QuantumEnhancedDynamicHarmonySearch", "description": "Quantum-Enhanced Dynamic Harmony Search (QEDHS) synergizes dynamic exploration-exploitation balancing with quantum-inspired local search to boost convergence and solution quality in photonic structure optimization.", "configspace": "", "generation": 35, "fitness": 0.3132621985086912, "feedback": "The algorithm QuantumEnhancedDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.00.", "error": "", "parent_id": "b058b7a3-526b-4661-b981-97b34ccd5900", "metadata": {"aucs": [0.3132621985086912]}, "mutation_prompt": null}
{"id": "10608a30-f5fa-4a7a-8666-83a285d9e6dd", "solution": "import numpy as np\n\nclass AdaptiveQuantumGuidedEvolutionaryHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.1  # Quantum learning rate\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.005\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % (self.budget // 10) == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                # Adjust harmony memory size\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "AdaptiveQuantumGuidedEvolutionaryHarmonySearch", "description": "Adaptive Quantum-Guided Evolutionary Harmony Search (AQGEHS) enhances solution quality and convergence by integrating dynamic memory size adjustment and strategic explorative search.", "configspace": "", "generation": 36, "fitness": 0.33981304553132763, "feedback": "The algorithm AdaptiveQuantumGuidedEvolutionaryHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.00.", "error": "", "parent_id": "b058b7a3-526b-4661-b981-97b34ccd5900", "metadata": {"aucs": [0.33981304553132763]}, "mutation_prompt": null}
{"id": "ee924e42-9258-4091-9f5e-da09d67f084c", "solution": "import numpy as np\n\nclass EnhancedQuantumEvolutionaryHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.1  # Quantum learning rate\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.002\n        self.elite_preservation_rate = 0.05\n        self.dynamic_learning_rate = 0.025\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update with dynamic learning rate\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=1)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i]) * self.dynamic_learning_rate\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Elite preservation and evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            if np.random.rand() < self.elite_preservation_rate:\n                elite_index = np.random.randint(harmony_memory_size)\n                if scores[elite_index] < scores[global_best_index]:\n                    global_best_index = elite_index\n                    global_best_position = harmony_memory[global_best_index].copy()\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % (self.budget // 10) == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumEvolutionaryHarmonySearch", "description": "Enhanced Quantum Evolutionary Harmony Search with Dynamic Learning Rate and Elite Preservation for improved convergence and exploration.", "configspace": "", "generation": 37, "fitness": 0.29068505175411063, "feedback": "The algorithm EnhancedQuantumEvolutionaryHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "10608a30-f5fa-4a7a-8666-83a285d9e6dd", "metadata": {"aucs": [0.29068505175411063]}, "mutation_prompt": null}
{"id": "e9ee30c8-58db-408b-bf9a-efbca6978182", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialEvolutionAdaptiveMemorySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 3 * dim)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.alpha = 0.1  # Quantum superposition factor\n        self.adaptive_rate = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        global_best_index = np.argmin(scores)\n        global_best_position = population[global_best_index].copy()\n\n        while evaluations < self.budget:\n            new_population = np.empty_like(population)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Quantum-inspired perturbation\n                if np.random.rand() < self.alpha:\n                    q = np.random.normal(0, 1, self.dim)\n                    trial += q * (global_best_position - trial)\n\n                new_population[i] = np.clip(trial, lb, ub)\n                new_score = func(new_population[i])\n                evaluations += 1\n\n                if new_score < scores[i]:\n                    scores[i] = new_score\n                    population[i] = new_population[i]\n                    if new_score < scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = new_population[i].copy()\n\n            # Adaptive parameter tuning\n            self.F = max(0.1, self.F - self.adaptive_rate * (evaluations / self.budget))\n            self.CR = min(1.0, self.CR + self.adaptive_rate * (evaluations / self.budget))\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumInspiredDifferentialEvolutionAdaptiveMemorySearch", "description": "Quantum-Inspired Differential Evolution with Adaptive Memory Search (QIDEAMS) combines quantum superposition principles with differential evolution and adaptive memory to enhance exploration and exploitation dynamically.", "configspace": "", "generation": 38, "fitness": 0.28378222477056536, "feedback": "The algorithm QuantumInspiredDifferentialEvolutionAdaptiveMemorySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "10608a30-f5fa-4a7a-8666-83a285d9e6dd", "metadata": {"aucs": [0.28378222477056536]}, "mutation_prompt": null}
{"id": "dee79a29-0ad7-4bc2-8a7c-767279f2dc3e", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(20, 5 * dim)\n        self.c1_initial = 2.0  # Cognitive component\n        self.c2_initial = 2.0  # Social component\n        self.w_initial = 0.9   # Inertia weight\n        self.w_final = 0.4\n        self.quantum_probability = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        swarm_velocities = np.zeros((self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_scores = np.array([func(swarm_positions[i]) for i in range(self.swarm_size)])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            c1 = self.c1_initial - evaluations / self.budget * (self.c1_initial - 1.5)\n            c2 = self.c2_initial + evaluations / self.budget * (2.5 - self.c2_initial)\n            w = self.w_initial - evaluations / self.budget * (self.w_initial - self.w_final)\n\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                swarm_velocities[i] = (w * swarm_velocities[i] +\n                                       c1 * r1 * (personal_best_positions[i] - swarm_positions[i]) +\n                                       c2 * r2 * (global_best_position - swarm_positions[i]))\n\n                # Quantum-inspired position update\n                if np.random.rand() < self.quantum_probability:\n                    q = np.random.normal(loc=0, scale=1, size=self.dim)\n                    swarm_positions[i] = global_best_position + q * (ub - lb)\n                else:\n                    swarm_positions[i] += swarm_velocities[i]\n\n                swarm_positions[i] = np.clip(swarm_positions[i], lb, ub)\n                score = func(swarm_positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm_positions[i].copy()\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm_positions[i].copy()\n\n        return global_best_position, global_best_score", "name": "QuantumInspiredAdaptiveParticleSwarmOptimization", "description": "Quantum-Inspired Adaptive Particle Swarm Optimization (QIAPSO) enhances search efficiency by integrating quantum exploration with adaptive parameters for dynamic swarm behavior.", "configspace": "", "generation": 39, "fitness": 0.2842103830224634, "feedback": "The algorithm QuantumInspiredAdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "10608a30-f5fa-4a7a-8666-83a285d9e6dd", "metadata": {"aucs": [0.2842103830224634]}, "mutation_prompt": null}
{"id": "02e98837-8eee-4e4b-9248-3202cf00b110", "solution": "import numpy as np\n\nclass QuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.2  # Increased quantum learning rate for more exploration\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.01  # Increased adaptive rate for dynamic adjustments\n        self.memory_update_frequency = budget // 20  # Adjust harmony memory size more frequently\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.5)  # More controlled quantum step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumInspiredDynamicHarmonySearch", "description": "Quantum-Inspired Dynamic Harmony Search (QIDHS) leverages adaptive memory management and quantum-based explorative mechanisms to enhance convergence and solution quality.", "configspace": "", "generation": 40, "fitness": 0.3523345129813712, "feedback": "The algorithm QuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.00.", "error": "", "parent_id": "10608a30-f5fa-4a7a-8666-83a285d9e6dd", "metadata": {"aucs": [0.3523345129813712]}, "mutation_prompt": null}
{"id": "4f287618-b453-4e95-835f-0e14523de2de", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.25  # Fine-tuned quantum learning rate\n        self.mutation_strength = 0.15\n        self.adaptive_rate = 0.02  # Enhanced adaptive rate for dynamic adjustments\n        self.memory_update_frequency = budget // 15  # More frequent updates\n        self.diff_weight = 0.8  # Weight for differential evolution component\n        self.crossover_prob = 0.9  # Crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.5)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            # Hybrid Differential Evolution: DE/rand/1/bin strategy\n            if evaluations < self.budget and np.random.rand() < self.crossover_prob:\n                indices = np.random.choice(harmony_memory_size, 3, replace=False)\n                a, b, c = harmony_memory[indices]\n                mutant_vector = a + self.diff_weight * (b - c)\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.crossover_prob or j == jrand:\n                        new_harmony[j] = mutant_vector[j]\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) incorporates hybrid differential evolution blending and adaptive quantum leaps to improve exploration and exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.29139033121977365, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.29139033121977365]}, "mutation_prompt": null}
{"id": "04ebfe90-3bc4-4c42-82cc-0e3688db0d61", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.2\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.01\n        self.memory_update_frequency = budget // 20\n        self.memory_expansion_factor = 1.2  # Memory expansion factor based on diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.5)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            diversity = np.std(harmony_memory, axis=0).mean()  # Calculate diversity\n            if diversity < (ub - lb).mean() * 0.05:  # If diversity is low, expand memory\n                expanded_memory_size = int(harmony_memory_size * self.memory_expansion_factor)\n                extra_memory = np.random.uniform(lb, ub, (expanded_memory_size - harmony_memory_size, self.dim))\n                harmony_memory = np.vstack((harmony_memory, extra_memory))\n                extra_scores = np.array([func(extra_memory[i]) for i in range(extra_memory.shape[0])])\n                scores = np.hstack((scores, extra_scores))\n                evaluations += extra_memory.shape[0]\n                harmony_memory_size = len(harmony_memory)\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) introduces multi-objective adaptive harmony consideration and dynamic memory expansion based on fitness landscape analysis to improve convergence speed and solution robustness.", "configspace": "", "generation": 42, "fitness": 0.3523345129813712, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3523345129813712]}, "mutation_prompt": null}
{"id": "08e3e2ae-1b5c-4b09-8a37-8725669f3906", "solution": "import numpy as np\n\nclass EnhancedQuantumHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.25  # Further increased quantum learning rate for more exploration\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.02  # Further increased adaptive rate for dynamic adjustments\n        self.memory_update_frequency = budget // 15  # More frequent harmony memory size adjustment\n        self.reinitialization_prob = 0.1  # Probability to reinitialize a portion of harmony memory\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.5)  # More controlled quantum step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n            # Reinitialization of part of the harmony memory for enhanced exploration\n            if np.random.rand() < self.reinitialization_prob:\n                reinitialize_count = int(harmony_memory_size * 0.1)\n                indices = np.random.choice(harmony_memory_size, reinitialize_count, replace=False)\n                for idx in indices:\n                    harmony_memory[idx] = np.random.uniform(lb, ub, self.dim)\n                    scores[idx] = func(harmony_memory[idx])\n                    evaluations += 1\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumHarmonySearch", "description": "Enhanced Quantum-Inspired Harmony Search with dynamically adaptive quantum leaps and strategic reinitialization for improved exploration and exploitation balance.", "configspace": "", "generation": 43, "fitness": 0.337565972409698, "feedback": "The algorithm EnhancedQuantumHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.337565972409698]}, "mutation_prompt": null}
{"id": "f105393f-a434-4c81-83c2-b1a3018b57c1", "solution": "import numpy as np\n\nclass NeuralInspiredSelfOrganizingSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.learning_rate = 0.1\n        self.inertia_weight = 0.5\n        self.cognitive_component = 1.5\n        self.social_component = 1.5\n        self.neural_influence = 0.05\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = swarm.copy()\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_velocity = self.cognitive_component * r1 * (personal_best_positions[i] - swarm[i])\n                social_velocity = self.social_component * r2 * (global_best_position - swarm[i])\n                velocities[i] = (self.inertia_weight * velocities[i]\n                                + cognitive_velocity\n                                + social_velocity)\n                \n                # Neural-inspired influence\n                neural_adjustment = self.neural_influence * np.tanh(velocities[i])\n                velocities[i] += neural_adjustment\n                \n                # Update position\n                swarm[i] = np.clip(swarm[i] + velocities[i], lb, ub)\n                \n                # Evaluation\n                score = func(swarm[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n                    if score < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = swarm[i]\n                \n        return global_best_position, personal_best_scores[global_best_index]", "name": "NeuralInspiredSelfOrganizingSwarm", "description": "Neural-Inspired Self-Organizing Swarm (NISOS) integrates neural network-inspired adaptive learning and self-organizing swarm intelligence to optimize black box functions efficiently and robustly.", "configspace": "", "generation": 44, "fitness": 0.2883735007445951, "feedback": "The algorithm NeuralInspiredSelfOrganizingSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2883735007445951]}, "mutation_prompt": null}
{"id": "dc857d08-89d5-4b46-9cbb-243e003b790e", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.95  # Higher harmony consideration rate\n        self.initial_par = 0.4  # Higher pitch adjustment rate\n        self.beta = 0.3  # More aggressive quantum learning rate\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.02  # Faster adaptive rate for dynamic adjustments\n        self.memory_update_frequency = budget // 10  # More frequent memory updates\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Enhanced quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(0, 0.5) * (1 - evaluations/self.budget)  # Controlled quantum step reduced over time\n                    new_harmony[i] += q * (global_best_position[i] - new_harmony[i])\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Diversity-preserving replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with diversity control\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning with decay\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) incorporates adaptive quantum exploration and diversity-preserving strategies to improve convergence and robustness in high-dimensional spaces.", "configspace": "", "generation": 45, "fitness": 0.2870909151130143, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2870909151130143]}, "mutation_prompt": null}
{"id": "cddb673a-2932-4740-8eeb-e68659034ce7", "solution": "import numpy as np\n\nclass SwarmEnhancedQuantumAdaptiveNeighborhoodSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.quantum_rate = 0.3\n        self.swarm_influence = 0.5\n        self.velocity_weight = 0.7\n        self.local_attraction = 1.5\n        self.global_attraction = 1.5\n        self.adaptive_rate = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        scores = np.array([func(population[i]) for i in range(self.population_size)])\n        personal_best_positions = population.copy()\n        personal_best_scores = scores.copy()\n        global_best_index = np.argmin(scores)\n        global_best_position = population[global_best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Swarm-based velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.velocity_weight * velocities[i] +\n                                 self.local_attraction * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.global_attraction * r2 * (global_best_position - population[i]))\n\n                # Update position\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Quantum-inspired mutation\n                if np.random.rand() < self.quantum_rate:\n                    q = np.random.normal(0, 0.5, self.dim)\n                    population[i] += q * (ub - lb)\n\n                # Evaluate new position\n                new_score = func(population[i])\n                evaluations += 1\n\n                # Update personal best\n                if new_score < personal_best_scores[i]:\n                    personal_best_scores[i] = new_score\n                    personal_best_positions[i] = population[i].copy()\n\n                # Update global best\n                if new_score < personal_best_scores[global_best_index]:\n                    global_best_index = i\n                    global_best_position = population[i].copy()\n\n            # Adaptive parameter adjustment\n            self.quantum_rate = 0.3 - self.adaptive_rate * (evaluations / self.budget)\n            self.velocity_weight = 0.7 - self.adaptive_rate * (evaluations / self.budget)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "SwarmEnhancedQuantumAdaptiveNeighborhoodSearch", "description": "Swarm-Enhanced Quantum Adaptive Neighborhood Search (SEQANS) utilizes a hybrid approach combining quantum-inspired mutations and swarm intelligence to dynamically balance exploration and exploitation in optimization.", "configspace": "", "generation": 46, "fitness": 0.2991736219789942, "feedback": "The algorithm SwarmEnhancedQuantumAdaptiveNeighborhoodSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2991736219789942]}, "mutation_prompt": null}
{"id": "3820d1de-e66a-41af-8f4c-c2b88d65846d", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(20, 2 * dim)\n        self.omega = 0.5  # Inertia weight\n        self.phi_p = 0.5  # Cognitive coefficient\n        self.phi_g = 0.5  # Social coefficient\n        self.alpha = 0.75  # Constriction factor\n        self.quantum_delta = 0.1  # Step size in quantum behavior\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pos = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        vel = np.zeros((self.swarm_size, self.dim))\n        personal_best_pos = pos.copy()\n        personal_best_scores = np.array([func(x) for x in pos])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_pos = pos[global_best_index].copy()\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                r_p = np.random.rand(self.dim)\n                r_g = np.random.rand(self.dim)\n\n                # Update velocity with quantum behavior\n                vel[i] = (self.omega * vel[i] +\n                          self.phi_p * r_p * (personal_best_pos[i] - pos[i]) +\n                          self.phi_g * r_g * (global_best_pos - pos[i]))\n\n                pos[i] += self.alpha * vel[i] + self.quantum_delta * np.random.normal(size=self.dim) * (ub - lb)\n                pos[i] = np.clip(pos[i], lb, ub)\n\n                score = func(pos[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_pos[i] = pos[i].copy()\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_pos = pos[i].copy()\n\n        return global_best_pos, global_best_score", "name": "QuantumParticleSwarmOptimization", "description": "Quantum Particle Swarm Optimization (QPSO) integrates quantum behaviors into particle swarm optimization to enhance exploration and exploitation balance.", "configspace": "", "generation": 47, "fitness": 0.2869990244974563, "feedback": "The algorithm QuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2869990244974563]}, "mutation_prompt": null}
{"id": "e9fec09b-8637-4a12-aec7-cc2e12282ec1", "solution": "import numpy as np\n\nclass BiologicallyInspiredCellularEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.mutation_rate = 0.1\n        self.crossover_rate = 0.8\n        self.grid_size = int(np.sqrt(self.population_size)) ** 2\n        self.local_interaction_radius = 1\n        self.replenish_rate = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.grid_size, self.dim))\n        scores = np.array([func(individual) for individual in population])\n        evaluations = self.grid_size\n\n        while evaluations < self.budget:\n            new_population = population.copy()\n            for index in range(self.grid_size):\n                local_best = self._get_local_best(population, scores, index)\n                offspring = self._crossover(population[index], local_best, ub, lb)\n                offspring = self._mutate(offspring, ub, lb)\n                offspring_score = func(offspring)\n                evaluations += 1\n\n                if offspring_score < scores[index]:\n                    new_population[index] = offspring\n                    scores[index] = offspring_score\n\n                # Apply replenishment strategy\n                if np.random.rand() < self.replenish_rate:\n                    new_population[index] = np.random.uniform(lb, ub, self.dim)\n                    scores[index] = func(new_population[index])\n                    evaluations += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            population = new_population\n\n        best_index = np.argmin(scores)\n        return population[best_index], scores[best_index]\n\n    def _crossover(self, parent1, parent2, ub, lb):\n        if np.random.rand() < self.crossover_rate:\n            crossover_point = np.random.randint(1, self.dim - 1)\n            offspring = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n            return np.clip(offspring, lb, ub)\n        return parent1\n\n    def _mutate(self, individual, ub, lb):\n        mutation_vector = np.random.normal(0, self.mutation_rate, self.dim) * (ub - lb)\n        return np.clip(individual + mutation_vector, lb, ub)\n\n    def _get_local_best(self, population, scores, index):\n        row_size = int(np.sqrt(self.grid_size))\n        row, col = divmod(index, row_size)\n        local_indices = [(row + i, col + j) for i in range(-self.local_interaction_radius, self.local_interaction_radius + 1)\n                         for j in range(-self.local_interaction_radius, self.local_interaction_radius + 1)\n                         if 0 <= row + i < row_size and 0 <= col + j < row_size]\n        local_indices = [i * row_size + j for (i, j) in local_indices]\n        local_scores = scores[local_indices]\n        best_local_index = local_indices[np.argmin(local_scores)]\n        return population[best_local_index]", "name": "BiologicallyInspiredCellularEvolution", "description": "Biologically-Inspired Cellular Evolution (BICE) emulates cellular automata and genetic evolution to explore and exploit the search space dynamically for photonic structure optimization.", "configspace": "", "generation": 48, "fitness": 0.285330781007308, "feedback": "The algorithm BiologicallyInspiredCellularEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.285330781007308]}, "mutation_prompt": null}
{"id": "b27ae056-a33e-4677-b678-2ad6d762f51d", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.hmcr_initial = 0.9\n        self.par_initial = 0.3\n        self.quantum_prob = 0.25\n        self.mutation_strength = 0.1\n        self.memory_update_frequency = budget // 10\n        self.adaptive_learning_rate = 0.015\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.hmcr_initial\n        par = self.par_initial\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                if np.random.rand() < self.quantum_prob:\n                    q = np.random.normal(loc=0, scale=0.5)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            if evaluations < self.budget and np.random.rand() < self.quantum_prob:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            hmcr = self.hmcr_initial - self.adaptive_learning_rate * (evaluations / self.budget)\n            par = self.par_initial + self.adaptive_learning_rate * (evaluations / self.budget)\n\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumEnhancedAdaptiveHarmonySearch", "description": "The Quantum Enhanced Adaptive Harmony Search (QE-AHS) integrates adaptive quantum-inspired search dynamics with multi-scale memory updates for improved optimization performance.", "configspace": "", "generation": 49, "fitness": 0.3338840442121205, "feedback": "The algorithm QuantumEnhancedAdaptiveHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3338840442121205]}, "mutation_prompt": null}
{"id": "421a26e5-7f7e-400c-9a7b-1fcc6a99a431", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.95\n        self.initial_par = 0.25\n        self.beta = 0.25\n        self.mutation_strength = 0.15\n        self.adaptive_rate = 0.015\n        self.memory_update_frequency = budget // 15\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.25)  # Refined quantum step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            if evaluations < self.budget and np.random.rand() < self.beta / 2:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength / 2, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) employs a multi-phase exploration-exploitation balance and adaptive quantum strategies to improve convergence and solution diversity.", "configspace": "", "generation": 50, "fitness": 0.3117838146017937, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3117838146017937]}, "mutation_prompt": null}
{"id": "f7ccdf17-7d85-4e71-8edd-a21021f539b2", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.15  # Reduced quantum learning rate for balanced exploration\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.02  # Enhanced adaptive rate for fine adjustments\n        self.memory_update_frequency = budget // 10  # More frequent memory updates\n        self.dynamic_beta_rate = 0.02  # Variable quantum exploration rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Variable Quantum-inspired update\n                quantum_adjustment = np.random.normal(loc=0, scale=self.dynamic_beta_rate)\n                new_harmony[i] += quantum_adjustment * (global_best_position[i] - new_harmony[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with variable quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "The Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) introduces a variable quantum leap strategy, adaptive parameter learning, and dynamic harmony memory size adjustment to boost convergence and solution quality.", "configspace": "", "generation": 51, "fitness": 0.28936314354205495, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.28936314354205495]}, "mutation_prompt": null}
{"id": "2cd6bbda-266a-4f85-b9aa-20f50a9edfe9", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)  # Larger initial population based on dimension\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.7\n        self.beta = 0.3  # Quantum influence factor\n        self.q_learning_rate = 0.05  # Quantum learning rate for adaptability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        evaluations = self.population_size\n        best_index = np.argmin(scores)\n        best_position = population[best_index].copy()\n\n        while evaluations < self.budget:\n            for j in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != j]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n  \n                cross_points = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[j])\n\n                # Quantum-inspired perturbation\n                if np.random.rand() < self.beta:\n                    q_step = np.random.normal(0, self.q_learning_rate, self.dim) * (ub - lb)\n                    trial += q_step\n\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[j]:\n                    population[j] = trial\n                    scores[j] = trial_score\n\n                if trial_score < scores[best_index]:\n                    best_position = trial\n                    best_index = j\n\n            # Adapt mutation factor and crossover probability\n            self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n            self.crossover_probability = 0.5 + 0.2 * np.random.rand()\n\n        return best_position, scores[best_index]", "name": "QuantumEnhancedAdaptiveDifferentialEvolution", "description": "Quantum-Enhanced Adaptive Differential Evolution (QEADE) integrates quantum-based perturbations into a self-adaptive differential evolution framework to enhance diversity and convergence in complex optimization landscapes.", "configspace": "", "generation": 52, "fitness": 0.2799832193831421, "feedback": "The algorithm QuantumEnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2799832193831421]}, "mutation_prompt": null}
{"id": "bfa2ea95-603d-4cef-ae4f-55177cb3473f", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.85\n        self.initial_par = 0.25\n        self.beta = 0.3  # Further increased quantum learning rate for exploration\n        self.mutation_strength = 0.05\n        self.adaptive_rate = 0.02  # Enhanced adaptive rate for dynamic adjustments\n        self.multi_modal_learning_rate = 0.1\n        self.memory_update_frequency = budget // 15  # More frequent memory updates\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q_factor = np.random.normal(loc=0, scale=0.5)  # Controlled quantum step\n                    new_harmony[i] = global_best_position[i] + q_factor * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            # Multi-modal learning strategy\n            if evaluations < self.budget and np.random.rand() < self.multi_modal_learning_rate:\n                random_positions = np.random.uniform(lb, ub, self.dim)\n                random_score = func(random_positions)\n                evaluations += 1\n                if random_score < scores.max():\n                    worst_index = np.argmax(scores)\n                    harmony_memory[worst_index] = random_positions\n                    scores[worst_index] = random_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search incorporates multi-modal learning and adaptive quantum fluctuations for diversified exploration and improved convergence.", "configspace": "", "generation": 53, "fitness": 0.3208048282319743, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3208048282319743]}, "mutation_prompt": null}
{"id": "e48da9f2-ab46-45ee-8d77-9d873768884a", "solution": "import numpy as np\n\nclass EnhancedQuantumAdaptiveHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.25  # Enhanced quantum learning rate for more adaptive exploration\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.02  # Further increased adaptive rate for dynamic response\n        self.memory_update_frequency = budget // 15  # More frequent harmony memory adjustments\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.3)  # Adjusted for more precise step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumAdaptiveHarmonySearch", "description": "Enhanced Quantum Adaptive Harmony Search (EQAHS) optimizes dynamic harmony memory with adaptive quantum-inspired explorative mechanisms for superior convergence in high-dimensional optimization tasks.", "configspace": "", "generation": 54, "fitness": 0.32821003743261246, "feedback": "The algorithm EnhancedQuantumAdaptiveHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.32821003743261246]}, "mutation_prompt": null}
{"id": "63174951-1d68-4938-a843-9bd959da1ba3", "solution": "import numpy as np\n\nclass QuantumEnhancedEvolutionaryParticleSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(20, 5 * dim)\n        self.cognitive_coef = 2.0\n        self.social_coef = 2.0\n        self.quantum_coef = 0.2\n        self.inertia_weight = 0.7\n        self.inertia_damping = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.array([func(pos) for pos in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                cognitive_velocity = self.cognitive_coef * r1 * (personal_best_positions[i] - positions[i])\n                social_velocity = self.social_coef * r2 * (global_best_position - positions[i])\n                velocities[i] = self.inertia_weight * velocities[i] + cognitive_velocity + social_velocity\n\n                # Quantum-inspired update\n                if np.random.rand() < self.quantum_coef:\n                    q = np.random.normal(0, 0.5)\n                    quantum_velocity = q * (ub - lb) * (global_best_position - positions[i])\n                    velocities[i] += quantum_velocity\n\n                # Update particle position\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i].copy()\n                    personal_best_scores[i] = score\n                    if score < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = personal_best_positions[i].copy()\n\n            self.inertia_weight *= self.inertia_damping\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumEnhancedEvolutionaryParticleSwarm", "description": "Quantum-Enhanced Evolutionary Particle Swarm Optimization (QE-PSO) integrates quantum-inspired position updates with dynamic swarm adaptation for enhanced exploration and exploitation balance.", "configspace": "", "generation": 55, "fitness": 0.28722339149217113, "feedback": "The algorithm QuantumEnhancedEvolutionaryParticleSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.28722339149217113]}, "mutation_prompt": null}
{"id": "4a05db90-91cb-41ee-a220-fdb20a1a34b3", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.95  # Higher harmony memory consideration rate\n        self.initial_par = 0.3\n        self.beta = 0.25  # Increased quantum learning rate for better exploration\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.015  # Increased adaptive rate for dynamic adjustments\n        self.memory_update_frequency = budget // 15  # More frequent memory updates\n        self.elite_memory_size = 3  # Elite memory size to store best solutions\n        self.elite_memory = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update with elite memory consideration\n                if np.random.rand() < self.beta:\n                    elite_choice = np.random.choice(self.elite_memory) if self.elite_memory else global_best_position\n                    q = np.random.normal(loc=0, scale=0.3)  # More controlled quantum step\n                    new_harmony[i] = elite_choice[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Update elite memory\n            if len(self.elite_memory) < self.elite_memory_size:\n                self.elite_memory.append(new_harmony)\n            else:\n                worst_elite_index = np.argmax([func(e) for e in self.elite_memory])\n                if new_score < func(self.elite_memory[worst_elite_index]):\n                    self.elite_memory[worst_elite_index] = new_harmony\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredHarmonySearch", "description": "Enhanced Quantum-Inspired Harmony Search (EQIHS) introduces a dynamic elite memory and adaptive quantum leap for improved exploration and convergence.", "configspace": "", "generation": 56, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {}, "mutation_prompt": null}
{"id": "9eaa6b8e-101a-41f6-8496-a224c95fbc2e", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptiveParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(10, dim * 2)\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.quantum_swarm_size = self.swarm_size // 2\n        self.inertia_weight = 0.9\n        self.inertia_damping = 0.99\n        self.quantum_factor = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        position = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.swarm_size, self.dim)) * (ub - lb)\n        personal_best_position = position.copy()\n        scores = np.array([func(position[i]) for i in range(self.swarm_size)])\n        personal_best_scores = scores.copy()\n        global_best_index = np.argmin(scores)\n        global_best_position = position[global_best_index].copy()\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n            cognitive_velocity = self.c1 * r1 * (personal_best_position - position)\n            social_velocity = self.c2 * r2 * (global_best_position - position)\n            velocity = self.inertia_weight * velocity + cognitive_velocity + social_velocity\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(position[i]) for i in range(self.swarm_size)])\n            evaluations += self.swarm_size\n\n            # Update personal and global bests\n            better_mask = scores < personal_best_scores\n            personal_best_position[better_mask] = position[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n            if scores.min() < personal_best_scores[global_best_index]:\n                global_best_index = scores.argmin()\n                global_best_position = position[global_best_index]\n\n            # Quantum-inspired swarm exploration\n            if evaluations < self.budget:\n                quantum_positions = global_best_position + np.random.normal(0, self.quantum_factor, (self.quantum_swarm_size, self.dim)) * (ub - lb)\n                quantum_positions = np.clip(quantum_positions, lb, ub)\n                quantum_scores = np.array([func(quantum_positions[i]) for i in range(self.quantum_swarm_size)])\n                evaluations += self.quantum_swarm_size\n                if quantum_scores.min() < personal_best_scores[global_best_index]:\n                    global_best_index = quantum_scores.argmin()\n                    global_best_position = quantum_positions[global_best_index]\n\n            # Adaptive inertia update\n            self.inertia_weight *= self.inertia_damping\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumInspiredAdaptiveParticleSwarmOptimization", "description": "Quantum-Inspired Adaptive Particle Swarm Optimization (QIAPSO) combines quantum state representation and adaptive strategies to dynamically balance exploration and exploitation for solving complex optimization tasks.", "configspace": "", "generation": 57, "fitness": 0.28299509428301983, "feedback": "The algorithm QuantumInspiredAdaptiveParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.28299509428301983]}, "mutation_prompt": null}
{"id": "f8fd8a9d-a1f1-449b-8a27-24f031edfdb2", "solution": "import numpy as np\nfrom multiprocessing import Pool\n\nclass ParallelQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(20, dim * 5)\n        self.alpha = 0.1  # Initial learning rate\n        self.beta = 0.4   # Quantum exploration factor\n        self.max_inertia = 0.9\n        self.min_inertia = 0.4\n        self.cognitive_coefficient = 2.0\n        self.social_coefficient = 2.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        # Initialize swarm and velocities\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = swarm.copy()\n        personal_best_scores = np.array([func(p) for p in personal_best_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        evaluations = self.swarm_size\n\n        inertia = self.max_inertia\n\n        def update_particle(i):\n            nonlocal swarm, velocities, personal_best_positions, personal_best_scores\n            r1, r2 = np.random.rand(), np.random.rand()\n\n            # Update velocity\n            velocities[i] = (inertia * velocities[i] +\n                             self.cognitive_coefficient * r1 * (personal_best_positions[i] - swarm[i]) +\n                             self.social_coefficient * r2 * (global_best_position - swarm[i]))\n\n            # Apply quantum-inspired exploration\n            if np.random.rand() < self.beta:\n                q_step = np.random.normal(0, 1, self.dim) * (ub - lb)\n                velocities[i] += q_step\n\n            # Update position\n            swarm[i] += velocities[i]\n            swarm[i] = np.clip(swarm[i], lb, ub)\n\n            # Evaluate new position\n            score = func(swarm[i])\n            evaluations += 1\n\n            # Update personal best\n            if score < personal_best_scores[i]:\n                personal_best_positions[i] = swarm[i]\n                personal_best_scores[i] = score\n\n            return score, i\n\n        # Main optimization loop\n        while evaluations < self.budget:\n            with Pool() as pool:\n                results = pool.map(update_particle, range(self.swarm_size))\n\n            # Update global best\n            for score, i in results:\n                if score < personal_best_scores[global_best_index]:\n                    global_best_index = i\n                    global_best_position = personal_best_positions[global_best_index].copy()\n\n            # Adjust inertia weight\n            inertia = self.max_inertia - (self.max_inertia - self.min_inertia) * (evaluations / self.budget)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "ParallelQuantumParticleSwarmOptimization", "description": "Parallel Quantum Particle Swarm Optimization (PQPSO) utilizes a population of particles with quantum-inspired movements and parallel exploration to enhance convergence speed and solution diversity.", "configspace": "", "generation": 58, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"Can't pickle local object 'ParallelQuantumParticleSwarmOptimization.__call__.<locals>.update_particle'\").", "error": "AttributeError(\"Can't pickle local object 'ParallelQuantumParticleSwarmOptimization.__call__.<locals>.update_particle'\")", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {}, "mutation_prompt": null}
{"id": "e1a45cc8-392f-412e-9624-e36e11985538", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(30, 5 * dim)\n        self.initial_cognitive_weight = 1.5\n        self.initial_social_weight = 1.5\n        self.quantum_factor = 0.1\n        self.adaptive_rate = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim)) * (ub - lb)\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        evaluations = self.num_particles\n        cognitive_weight = self.initial_cognitive_weight\n        social_weight = self.initial_social_weight\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                velocities[i] += cognitive_weight * np.random.rand(self.dim) * (personal_best_positions[i] - positions[i])\n                velocities[i] += social_weight * np.random.rand(self.dim) * (global_best_position - positions[i])\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))\n\n                # Quantum-inspired position update\n                if np.random.rand() < self.quantum_factor:\n                    q = np.random.normal(0, 0.1, self.dim)\n                    positions[i] = global_best_position + q * (ub - lb)\n                else:\n                    positions[i] += velocities[i]\n\n                positions[i] = np.clip(positions[i], lb, ub)\n                score = func(positions[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n\n                if score < personal_best_scores[global_best_index]:\n                    global_best_index = i\n                    global_best_position = personal_best_positions[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            cognitive_weight = self.initial_cognitive_weight - self.adaptive_rate * (evaluations / self.budget)\n            social_weight = self.initial_social_weight + self.adaptive_rate * (evaluations / self.budget)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "The Adaptive Quantum Particle Swarm Optimization (AQPSO) integrates quantum-inspired position updates and adaptive velocity control to enhance exploration and convergence in high-dimensional spaces.", "configspace": "", "generation": 59, "fitness": 0.27957389989553805, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.27957389989553805]}, "mutation_prompt": null}
{"id": "5884e33f-b216-4446-be06-9aeb853f1196", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.f_cr = 0.9  # Crossover probability\n        self.f_f = 0.8  # Differential weight\n        self.beta = 0.3  # Quantum-inspired coefficient\n        self.adaptive_rate = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(individual) for individual in population])\n        global_best_index = np.argmin(scores)\n        global_best_position = population[global_best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = np.empty_like(population)\n            for i in range(self.population_size):\n                idxs = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                a, b, c = population[idxs]\n                mutant = a + self.f_f * (b - c)\n                mutant = np.clip(mutant, lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.f_cr, mutant, population[i])\n                \n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.5)\n                    trial += q * (global_best_position - trial)\n\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    new_population[i] = trial\n                    scores[i] = trial_score\n                else:\n                    new_population[i] = population[i]\n\n            population = new_population\n            global_best_index = np.argmin(scores)\n            global_best_position = population[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            self.f_cr = max(0.5, self.f_cr - self.adaptive_rate * (evaluations / self.budget))\n            self.f_f = min(1.0, self.f_f + self.adaptive_rate * (evaluations / self.budget))\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumInspiredAdaptiveDifferentialEvolution", "description": "Quantum-Inspired Adaptive Differential Evolution (QIADE) integrates quantum mechanics principles with adaptive differential evolution strategies to enhance exploration and exploitation in high-dimensional search spaces.", "configspace": "", "generation": 60, "fitness": 0.2821188672869934, "feedback": "The algorithm QuantumInspiredAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2821188672869934]}, "mutation_prompt": null}
{"id": "2d3daeff-4f91-4d32-843b-584609a3ef38", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.2\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.01\n        self.memory_update_frequency = budget // 20\n        self.quantum_step_decay = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n        quantum_step_size = 0.5\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=quantum_step_size)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n                quantum_step_size *= self.quantum_step_decay\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) incorporates adaptive quantum leap size and memory diversification, boosting exploration and exploitation balance for improved convergence.", "configspace": "", "generation": 61, "fitness": 0.3342874741033711, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3342874741033711]}, "mutation_prompt": null}
{"id": "82e41dab-732c-4b70-b886-657b04c2eba5", "solution": "import numpy as np\n\nclass SwarmSynergisticQuantumAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 2.0\n        self.annealing_rate = 0.99\n        self.min_temp = 1e-3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * (ub - lb)\n        personal_best_positions = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.population_size\n        temperature = 1.0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.social_coeff * r2 * (global_best_position - population[i]))\n                population[i] = np.clip(population[i] + velocities[i], lb, ub)\n\n                # Quantum annealing inspired update\n                if np.random.rand() < np.exp(-1.0 / max(temperature, self.min_temp)):\n                    quantum_flip = np.random.normal(scale=temperature, size=self.dim) * (ub - lb)\n                    population[i] = np.clip(population[i] + quantum_flip, lb, ub)\n\n                score = func(population[i])\n                evaluations += 1\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = population[i].copy()\n                    personal_best_scores[i] = score\n                    if score < global_best_score:\n                        global_best_position = population[i].copy()\n                        global_best_score = score\n\n            temperature *= self.annealing_rate\n\n        return global_best_position, global_best_score", "name": "SwarmSynergisticQuantumAnnealing", "description": "Swarm-Synergistic Quantum Annealing (SSQA) combines swarm intelligence and quantum annealing for adaptive exploration and exploitation in optimization.", "configspace": "", "generation": 62, "fitness": 0.2807505381682266, "feedback": "The algorithm SwarmSynergisticQuantumAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2807505381682266]}, "mutation_prompt": null}
{"id": "83f040bf-9cee-4317-8063-77b9d2e7c10a", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(30, 10 * dim)\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.5  # inertia weight\n        self.q_factor = 0.1  # quantum factor for enhanced exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * (ub - lb)\n        personal_best_positions = population.copy()\n        personal_best_scores = np.array([func(indiv) for indiv in population])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i]))\n                quantum_jump = np.random.normal(0, self.q_factor, self.dim)  # Quantum step\n                velocities[i] += quantum_jump * (ub - lb)\n                \n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n                \n                current_score = func(population[i])\n                evaluations += 1\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_positions[i] = population[i].copy()\n                    personal_best_scores[i] = current_score\n\n                    if current_score < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = personal_best_positions[i].copy()\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumEnhancedAdaptiveSwarmOptimization", "description": "Quantum-Enhanced Adaptive Swarm Optimization (QEASO) combines quantum-inspired particle dynamics with adaptive velocity and position adjustments to efficiently explore and exploit the search space.", "configspace": "", "generation": 63, "fitness": 0.2800793673185654, "feedback": "The algorithm QuantumEnhancedAdaptiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2800793673185654]}, "mutation_prompt": null}
{"id": "54fa2f72-4481-4e5d-9755-d89281244d70", "solution": "import numpy as np\n\nclass AdaptiveMemeticQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim)\n        self.inertia_weight = 0.7\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.quantum_prob = 0.3\n        self.local_search_prob = 0.1\n        self.search_strength = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        position = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim)) * (ub - lb) / 10\n        personal_best_position = position.copy()\n        personal_best_score = np.array([func(pos) for pos in position])\n        global_best_index = np.argmin(personal_best_score)\n        global_best_position = personal_best_position[global_best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocity[i] = (self.inertia_weight * velocity[i]\n                               + self.cognitive_const * r1 * (personal_best_position[i] - position[i])\n                               + self.social_const * r2 * (global_best_position - position[i]))\n                position[i] += velocity[i]\n                position[i] = np.clip(position[i], lb, ub)\n\n                # Quantum-inspired perturbation\n                if np.random.rand() < self.quantum_prob:\n                    position[i] += np.random.normal(0, 0.1, self.dim) * (global_best_position - position[i])\n\n                # Local search enhancement\n                if np.random.rand() < self.local_search_prob:\n                    neighbor = position[i] + np.random.uniform(-self.search_strength, self.search_strength, self.dim) * (ub - lb)\n                    neighbor = np.clip(neighbor, lb, ub)\n                    neighbor_score = func(neighbor)\n                    evaluations += 1\n                    if neighbor_score < personal_best_score[i]:\n                        personal_best_position[i] = neighbor\n                        personal_best_score[i] = neighbor_score\n\n                new_score = func(position[i])\n                evaluations += 1\n\n                if new_score < personal_best_score[i]:\n                    personal_best_position[i] = position[i].copy()\n                    personal_best_score[i] = new_score\n\n            global_best_index = np.argmin(personal_best_score)\n            global_best_position = personal_best_position[global_best_index].copy()\n\n        return global_best_position, personal_best_score[global_best_index]", "name": "AdaptiveMemeticQuantumPSO", "description": "Adaptive Memetic Quantum Particle Swarm Optimization (AMQPSO) enhances exploration and exploitation by integrating quantum-inspired learning and adaptive local search strategies in a swarm-based framework.", "configspace": "", "generation": 64, "fitness": 0.2854148557140048, "feedback": "The algorithm AdaptiveMemeticQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2854148557140048]}, "mutation_prompt": null}
{"id": "bbb5387e-484e-4b64-bc16-cf4244e5edee", "solution": "import numpy as np\n\nclass EnhancedQuantumHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.harmony_memory_size = self.max_harmony_memory_size\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta_initial = 0.2\n        self.beta_final = 0.05\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.01\n        self.memory_update_frequency = budget // 20\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n        beta = self.beta_initial\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update with dynamic step adjustment\n                if np.random.rand() < beta:\n                    q = np.random.normal(loc=0, scale=(1 - evaluations / self.budget))\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with hybrid memory strategy\n            if evaluations < self.budget and np.random.rand() < beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n            beta = self.beta_initial - (self.beta_initial - self.beta_final) * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                self.harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                self.harmony_memory_size = int(np.clip(self.harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (self.harmony_memory_size, self.dim))\n                scores = np.resize(scores, self.harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumHarmonySearch", "description": "Enhanced Quantum Harmony Search (EQHS) incorporates dynamic quantum step adjustment and hybrid memory strategies for improved exploration and exploitation balance.", "configspace": "", "generation": 65, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {}, "mutation_prompt": null}
{"id": "402884ec-111e-4167-9d86-a57a1e7673ea", "solution": "import numpy as np\n\nclass BioInspiredFireflyAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(15, dim)\n        self.alpha = 0.5  # Randomness parameter\n        self.beta_min = 0.2  # Minimum attraction\n        self.gamma = 1.0  # Light absorption coefficient\n        self.adaptive_rate = 0.01  # Rate of adaptive adjustment of alpha\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        fireflies = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        light_intensity = np.array([func(fireflies[i]) for i in range(self.population_size)])\n        evaluations = self.population_size\n        best_index = np.argmin(light_intensity)\n        best_firefly = fireflies[best_index].copy()\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                for j in range(self.population_size):\n                    if light_intensity[i] > light_intensity[j]:\n                        distance = np.linalg.norm(fireflies[i] - fireflies[j])\n                        beta = self.beta_min + (1 - self.beta_min) * np.exp(-self.gamma * distance**2)\n                        movement = beta * (fireflies[j] - fireflies[i]) + self.alpha * (np.random.rand(self.dim) - 0.5) * (ub - lb)\n                        fireflies[i] = np.clip(fireflies[i] + movement, lb, ub)\n\n            light_intensity = np.array([func(fireflies[i]) for i in range(self.population_size)])\n            evaluations += self.population_size\n\n            current_best_index = np.argmin(light_intensity)\n            if light_intensity[current_best_index] < light_intensity[best_index]:\n                best_index = current_best_index\n                best_firefly = fireflies[best_index].copy()\n\n            # Adaptive randomness reduction\n            self.alpha *= 1 - self.adaptive_rate * (evaluations / self.budget)\n\n        return best_firefly, light_intensity[best_index]", "name": "BioInspiredFireflyAlgorithm", "description": "Bio-Inspired Firefly Algorithm (BIFA) utilizes light intensity-based attraction and adaptive movement to solve complex optimization problems efficiently.", "configspace": "", "generation": 66, "fitness": 0.2815480147766247, "feedback": "The algorithm BioInspiredFireflyAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2815480147766247]}, "mutation_prompt": null}
{"id": "2761556c-d861-4262-a0a5-953a6f68638f", "solution": "import numpy as np\n\nclass QuantumCoherenceSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(30, dim * 2)\n        self.alpha = 0.1  # Exploration factor\n        self.beta = 0.9  # Exploitation factor\n        self.gamma = 0.1  # Quantum coherence factor\n        self.loudness = 0.5  # Loudness of particles\n        self.frequency = 0.5  # Frequency of local search adjustments\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim)) * (ub - lb)\n        scores = np.array([func(p) for p in swarm])\n        personal_best_positions = swarm.copy()\n        personal_best_scores = scores.copy()\n        global_best_index = np.argmin(scores)\n        global_best_position = swarm[global_best_index].copy()\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.alpha * velocities[i] +\n                                 self.beta * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 self.beta * r2 * (global_best_position - swarm[i]))\n                \n                # Quantum coherence update\n                if np.random.rand() < self.gamma:\n                    coherence_factor = np.random.normal(0, self.frequency, self.dim)\n                    velocities[i] += coherence_factor * (global_best_position - personal_best_positions[i])\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                new_score = func(swarm[i])\n                evaluations += 1\n\n                # Update personal and global bests\n                if new_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i].copy()\n                    personal_best_scores[i] = new_score\n\n                if new_score < scores[global_best_index]:\n                    global_best_index = i\n                    global_best_position = swarm[i].copy()\n\n            # Adaptive strategy for quantum coherence\n            self.gamma = max(0.1, self.gamma - 0.01 * (evaluations / self.budget))\n            self.loudness = max(0.1, self.loudness * 0.99)\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumCoherenceSwarmOptimization", "description": "Quantum Coherence Swarm Optimization (QCSO) employs quantum coherence principles and dynamic swarm strategies to balance exploration and exploitation for enhanced optimization.", "configspace": "", "generation": 67, "fitness": 0.2779496302793981, "feedback": "The algorithm QuantumCoherenceSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2779496302793981]}, "mutation_prompt": null}
{"id": "3f477fd0-7a85-472f-b5c8-1938cd17029e", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.25  # Further increased quantum learning rate\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.02  # Further increase adaptive rate for rapid adjustments\n        self.memory_update_frequency = budget // 30  # More frequent harmony memory size adjustment\n        self.differential_weight = 0.5  # Added differential weight for perturbation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update with differential perturbation\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.5)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n                    # Differential perturbation\n                    rand_indices = np.random.choice(harmony_memory_size, 2, replace=False)\n                    new_harmony[i] += self.differential_weight * (harmony_memory[rand_indices[0], i] - harmony_memory[rand_indices[1], i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumEnhancedAdaptiveHarmonySearch", "description": "Quantum-Enhanced Adaptive Harmony Search (QEAHS) integrates adaptive quantum jumps and differential perturbations to balance exploration and exploitation, enhancing convergence rates.", "configspace": "", "generation": 68, "fitness": 0.3094395773694364, "feedback": "The algorithm QuantumEnhancedAdaptiveHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3094395773694364]}, "mutation_prompt": null}
{"id": "17c2c571-34bd-4879-b64e-bb54bf1cc3e8", "solution": "import numpy as np\n\nclass QuantumCohortEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.cohort_size = max(10, dim)\n        self.quantum_rate = 0.15  # Quantum adjustment probability\n        self.mutation_rate = 0.1  # Mutation rate for exploration\n        self.evolution_step_size = 0.05  # Step size for cohort evolution\n        self.min_cohort_size = max(5, dim // 2)\n        self.max_cohort_size = max(10, dim)\n        self.cohort_adjustment_frequency = budget // 25\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        cohort = np.random.uniform(lb, ub, (self.cohort_size, self.dim))\n        fitness = np.array([func(cohort[i]) for i in range(self.cohort_size)])\n        best_index = np.argmin(fitness)\n        best_position = cohort[best_index].copy()\n        evaluations = self.cohort_size\n\n        while evaluations < self.budget:\n            candidate = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.quantum_rate:\n                    candidate[i] = best_position[i] + np.random.normal(0, 0.5) * (ub[i] - lb[i])\n                else:\n                    cohort_choice = np.random.randint(self.cohort_size)\n                    candidate[i] = cohort[cohort_choice, i] + np.random.uniform(-self.evolution_step_size, self.evolution_step_size) * (ub[i] - lb[i])\n                if np.random.rand() < self.mutation_rate:\n                    candidate[i] += np.random.uniform(-self.mutation_rate, self.mutation_rate) * (ub[i] - lb[i])\n            candidate = np.clip(candidate, lb, ub)\n\n            candidate_score = func(candidate)\n            evaluations += 1\n\n            if candidate_score < fitness.max():\n                worst_index = np.argmax(fitness)\n                cohort[worst_index] = candidate\n                fitness[worst_index] = candidate_score\n\n            if candidate_score < fitness[best_index]:\n                best_index = np.argmin(fitness)\n                best_position = cohort[best_index].copy()\n\n            if evaluations % self.cohort_adjustment_frequency == 0:\n                self.cohort_size = self.min_cohort_size + (self.max_cohort_size - self.min_cohort_size) * (1 - evaluations / self.budget)\n                self.cohort_size = int(np.clip(self.cohort_size, self.min_cohort_size, self.max_cohort_size))\n                cohort = np.resize(cohort, (self.cohort_size, self.dim))\n                fitness = np.resize(fitness, self.cohort_size)\n\n        return best_position, fitness[best_index]", "name": "QuantumCohortEvolutionaryAlgorithm", "description": "Quantum-Cohort Evolutionary Algorithm (QCEA) combines cohort intelligence and quantum-inspired adjustments for enhanced diversity and convergence in optimization.", "configspace": "", "generation": 69, "fitness": 0.2913806314621846, "feedback": "The algorithm QuantumCohortEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2913806314621846]}, "mutation_prompt": null}
{"id": "80db2fb2-c1d0-42ca-ba9b-15998e150703", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.3  # Further increased quantum learning rate for enhanced exploration\n        self.gamma = 0.5  # Adaptive quantum perturbation factor\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.02  # Increased adaptive rate for more dynamic parameter updates\n        self.memory_update_frequency = budget // 15  # More frequent memory size adjustments\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=self.gamma * (1 - evaluations / self.budget))  # Adaptive quantum step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Enhanced explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) introduces adaptive quantum-inspired perturbations and dynamic parameter tuning to improve exploration and convergence efficiency across diverse dimensional spaces.", "configspace": "", "generation": 70, "fitness": 0.3152370261392956, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3152370261392956]}, "mutation_prompt": null}
{"id": "c381eaff-e7eb-442c-8248-9866ec4dbd13", "solution": "import numpy as np\n\nclass QuantumEnhancedFireflyAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(15, dim * 2)\n        self.alpha = 0.5  # Base step size\n        self.beta0 = 1.0  # Base attractiveness\n        self.gamma = 1.0  # Absorption coefficient\n        self.quantum_step_scale = 0.1\n        self.exploration_probability = 0.2  # Probability to perform a quantum jump\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(individual) for individual in population])\n        evaluations = self.population_size\n        global_best_index = np.argmin(scores)\n        global_best_position = population[global_best_index].copy()\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                for j in range(self.population_size):\n                    if scores[i] > scores[j]:\n                        r = np.linalg.norm(population[i] - population[j])\n                        beta = self.beta0 * np.exp(-self.gamma * r**2)\n                        step = self.alpha * (np.random.rand(self.dim) - 0.5) * (ub - lb)\n                        movement = beta * (population[j] - population[i]) + step\n                        population[i] = np.clip(population[i] + movement, lb, ub)\n                        if np.random.rand() < self.exploration_probability:\n                            # Perform quantum-inspired jump\n                            q_step = np.random.normal(0, self.quantum_step_scale, self.dim) * (ub - lb)\n                            population[i] = np.clip(global_best_position + q_step, lb, ub)\n\n                new_score = func(population[i])\n                evaluations += 1\n                if new_score < scores[i]:\n                    scores[i] = new_score\n                    if new_score < scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = population[i].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumEnhancedFireflyAlgorithm", "description": "Quantum-Enhanced Firefly Algorithm (QEFA) combines quantum dynamics with firefly-inspired attraction mechanisms to enable efficient exploration and exploitation in high-dimensional spaces.", "configspace": "", "generation": 71, "fitness": 0.28621645267103735, "feedback": "The algorithm QuantumEnhancedFireflyAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.28621645267103735]}, "mutation_prompt": null}
{"id": "1066b8b6-55ac-4cd8-9aae-3f7e4e0afd3d", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)  # A larger population for diversity\n        self.scaling_factor = 0.8  # Differential weight\n        self.crossover_rate = 0.9  # Crossover probability\n        self.quantum_rate = 0.2  # Quantum perturbation frequency\n        self.adaptive_rate = 0.1  # For adaptive mutation strategy\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(individual) for individual in population])\n        global_best_index = np.argmin(scores)\n        global_best_position = population[global_best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.scaling_factor * (b - c), lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, population[i])\n\n                # Quantum perturbation\n                if np.random.rand() < self.quantum_rate:\n                    q = np.random.normal(loc=0, scale=0.5, size=self.dim)\n                    trial += q * (ub - lb)\n                    trial = np.clip(trial, lb, ub)\n\n                trial_score = func(trial)\n                evaluations += 1\n\n                if trial_score < scores[i]:\n                    population[i] = trial\n                    scores[i] = trial_score\n\n                    if trial_score < scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = trial\n\n            # Adaptive mutation strategy\n            if evaluations < self.budget:\n                self.scaling_factor = 0.5 + 0.5 * (1 - evaluations / self.budget)\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumEnhancedAdaptiveDifferentialEvolution", "description": "Quantum-Enhanced Adaptive Differential Evolution (QE-ADE) employs quantum perturbations and adaptive mutation strategies to accelerate convergence and improve exploration in complex search spaces.", "configspace": "", "generation": 72, "fitness": 0.2769826695102542, "feedback": "The algorithm QuantumEnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2769826695102542]}, "mutation_prompt": null}
{"id": "5dd1c4d6-c13b-43c3-b4ba-d7028a31ecf2", "solution": "import numpy as np\n\nclass FractalSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_temp = 1.0\n        self.cooling_rate = 0.99\n        self.fractal_perturbation = 0.5\n        self.perturbation_decay = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        current_solution = np.random.uniform(lb, ub, self.dim)\n        current_score = func(current_solution)\n        best_solution = current_solution.copy()\n        best_score = current_score\n        temperature = self.initial_temp\n        evaluations = 1\n\n        while evaluations < self.budget:\n            # Fractal perturbation based candidate generation\n            perturbation = np.power(self.fractal_perturbation, np.random.normal(size=self.dim))\n            candidate_solution = current_solution + perturbation * (ub - lb)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_score = func(candidate_solution)\n            evaluations += 1\n            \n            # Acceptance logic based on simulated annealing\n            if candidate_score < current_score or \\\n               np.random.rand() < np.exp((current_score - candidate_score) / temperature):\n                current_solution = candidate_solution\n                current_score = candidate_score\n\n                if current_score < best_score:\n                    best_solution = current_solution\n                    best_score = current_score\n\n            # Update temperature and fractal perturbation\n            temperature *= self.cooling_rate\n            self.fractal_perturbation *= self.perturbation_decay\n\n        return best_solution, best_score", "name": "FractalSimulatedAnnealing", "description": "Fractal Simulated Annealing (FSA) combines fractal perturbations with a simulated annealing framework to enhance exploration and avoid local optima in complex search spaces.", "configspace": "", "generation": 73, "fitness": 0.26115625190321123, "feedback": "The algorithm FractalSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.26115625190321123]}, "mutation_prompt": null}
{"id": "d57eb4e3-34db-48ab-921b-d4341e5b9dd7", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(10, 2 * dim)\n        self.inertia_weight = 0.9\n        self.cognitive_acceleration = 2.0\n        self.social_acceleration = 2.0\n        self.quantum_probability = 0.1\n        self.inertia_damping = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim)) * (ub - lb)\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_acceleration * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.social_acceleration * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Quantum-inspired position update\n                if np.random.rand() < self.quantum_probability:\n                    quantum_step = np.random.normal(0, 0.5, self.dim)\n                    positions[i] = global_best_position + quantum_step * (ub - lb)\n                    positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n\n            # Update inertia weight\n            self.inertia_weight *= self.inertia_damping\n\n        return global_best_position, global_best_score", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Adaptive Quantum Particle Swarm Optimization (AQPSO) enhances exploration and exploitation balance with dynamic parameter tuning and quantum-inspired position updates.", "configspace": "", "generation": 74, "fitness": 0.2840094889901811, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2840094889901811]}, "mutation_prompt": null}
{"id": "a5f0e97e-9f12-4441-ae66-f11ef3b8c823", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.95  # Higher chance to consider harmony memory\n        self.initial_par = 0.2\n        self.beta = 0.25  # Balanced quantum learning rate\n        self.mutation_strength = 0.05  # Slightly reduced for finer perturbations\n        self.adaptive_rate = 0.015  # Slightly increased adaptive rate\n        self.memory_update_frequency = budget // 15  # More frequent updates\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    quantum_step = np.random.normal(loc=0, scale=0.3)  # More focused quantum step\n                    new_harmony[i] = global_best_position[i] + quantum_step * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Enhanced replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2\n                explorative_position += np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredHarmonySearch", "description": "Enhanced Quantum-Inspired Harmony Search (EQIHS) integrates adaptive parameter control and a targeted quantum leap mechanism for improved exploration and convergence in high-dimensional spaces.", "configspace": "", "generation": 75, "fitness": 0.2875834905680992, "feedback": "The algorithm EnhancedQuantumInspiredHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2875834905680992]}, "mutation_prompt": null}
{"id": "c12606a8-bda3-40d4-8745-936ccc15eb35", "solution": "import numpy as np\n\nclass EnhancedQuantumOptimizedGreyWolfOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.n_wolves = max(5, dim + 2)\n        self.alpha, self.beta, self.delta = None, None, None\n        self.qbeta = 0.25  # Quantum behavior probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        wolves = np.random.uniform(lb, ub, (self.n_wolves, self.dim))\n        scores = np.array([func(wolves[i]) for i in range(self.n_wolves)])\n        evaluations = self.n_wolves\n\n        while evaluations < self.budget:\n            sorted_indices = np.argsort(scores)\n            self.alpha, self.beta, self.delta = wolves[sorted_indices[0]], wolves[sorted_indices[1]], wolves[sorted_indices[2]]\n\n            a = 2 - evaluations * (2 / self.budget)  # Linearly decreases from 2 to 0\n\n            new_wolves = np.empty_like(wolves)\n            for i in range(self.n_wolves):\n                A1, C1 = 2 * a * np.random.random(self.dim) - a, 2 * np.random.random(self.dim)\n                A2, C2 = 2 * a * np.random.random(self.dim) - a, 2 * np.random.random(self.dim)\n                A3, C3 = 2 * a * np.random.random(self.dim) - a, 2 * np.random.random(self.dim)\n\n                D_alpha = np.abs(C1 * self.alpha - wolves[i])\n                D_beta = np.abs(C2 * self.beta - wolves[i])\n                D_delta = np.abs(C3 * self.delta - wolves[i])\n\n                X1 = self.alpha - A1 * D_alpha\n                X2 = self.beta - A2 * D_beta\n                X3 = self.delta - A3 * D_delta\n\n                new_position = (X1 + X2 + X3) / 3\n\n                # Quantum-inspired update\n                if np.random.rand() < self.qbeta:\n                    q = np.random.randn(self.dim) * 0.1  # Controlled quantum step\n                    new_position += q * (ub - lb)\n\n                new_position = np.clip(new_position, lb, ub)\n                new_wolves[i] = new_position\n\n            new_scores = np.array([func(new_wolves[i]) for i in range(self.n_wolves)])\n            evaluations += self.n_wolves\n\n            improved = new_scores < scores\n            wolves[improved] = new_wolves[improved]\n            scores[improved] = new_scores[improved]\n\n        best_index = np.argmin(scores)\n        return wolves[best_index], scores[best_index]", "name": "EnhancedQuantumOptimizedGreyWolfOptimizer", "description": "Enhanced Quantum-Optimized Grey Wolf Optimizer (EQOGWO) integrates quantum behavior into the Grey Wolf hunting strategy for intensified exploration and exploitation, adapting dynamically to problem landscapes.", "configspace": "", "generation": 76, "fitness": 0.29001999042911764, "feedback": "The algorithm EnhancedQuantumOptimizedGreyWolfOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.29001999042911764]}, "mutation_prompt": null}
{"id": "5798dc8f-00d5-4a97-863a-083ad944b06c", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.2\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.01\n        self.memory_update_frequency = budget // 20\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.5)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            # Gradient-based refinement\n            if evaluations < self.budget:\n                grad_step = 1e-5 * (ub - lb)\n                gradient = np.zeros(self.dim)\n                for i in range(self.dim):\n                    pos_plus = np.copy(global_best_position)\n                    pos_plus[i] += grad_step[i]\n                    pos_plus = np.clip(pos_plus, lb, ub)\n                    gradient[i] = (func(pos_plus) - scores[global_best_index]) / grad_step[i]\n                refinement_position = global_best_position - 0.01 * gradient\n                refinement_position = np.clip(refinement_position, lb, ub)\n                refinement_score = func(refinement_position)\n                evaluations += 1\n                if refinement_score < scores[global_best_index]:\n                    global_best_position = refinement_position\n                    scores[global_best_index] = refinement_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredHarmonySearch", "description": "Enhanced Quantum-Inspired Harmony Search with Gradient-Based Refinement integrates adaptive memory and quantum exploration with gradient refinement for improved convergence.", "configspace": "", "generation": 77, "fitness": 0.2857665256463616, "feedback": "The algorithm EnhancedQuantumInspiredHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2857665256463616]}, "mutation_prompt": null}
{"id": "540c54e2-2e40-4452-b1fd-d1bf4ceadf43", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.25  # Further increased quantum learning rate for greater exploration\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.015  # Enhanced adaptive rate for more dynamic adjustment\n        self.memory_update_frequency = budget // 15  # More frequent updates for harmony memory size\n        self.global_learning_rate = 0.2  # New global update influence rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.5)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Global best position update\n            if new_score < scores[global_best_index]:\n                global_best_position = (1 - self.global_learning_rate) * global_best_position + self.global_learning_rate * new_harmony\n                scores[global_best_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumEnhancedAdaptiveHarmonySearch", "description": "Quantum Enhanced Adaptive Harmony Search (QEAHS) enhances convergence by integrating quantum-inspired exploratory mechanisms with adaptive learning rates and memory size adjustments, tailored for complex high-dimensional functions.", "configspace": "", "generation": 78, "fitness": 0.3072922904146759, "feedback": "The algorithm QuantumEnhancedAdaptiveHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3072922904146759]}, "mutation_prompt": null}
{"id": "63358d09-d9d3-45b7-86b2-80f6382cd3c3", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.95\n        self.initial_par = 0.4\n        self.beta = 0.3  # Adjusted quantum learning rate for balanced exploration\n        self.mutation_strength = 0.05\n        self.adaptive_rate = 0.02  # Adjusted adaptive rate for finer dynamic adjustments\n        self.memory_update_frequency = budget // 15  # More frequent memory size adjustments\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.3)  # More controlled quantum step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with enhanced quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) incorporates guided exploration and exploitation phases to improve robustness and convergence speed in complex optimization landscapes.", "configspace": "", "generation": 79, "fitness": 0.3029979255441221, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3029979255441221]}, "mutation_prompt": null}
{"id": "ab513e1d-3d3a-47d7-853a-2302c7851f31", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.25  # Increased quantum influence for improved exploration\n        self.mutation_strength = 0.05\n        self.evolutionary_rate = 0.1  # Evolutionary rate for diversity control\n        self.memory_update_frequency = budget // 20  # Regular memory adjustments\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.3)  # Refined quantum step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            if evaluations < self.budget and np.random.rand() < self.evolutionary_rate:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            hmcr = self.initial_hmcr - self.evolutionary_rate * (evaluations / self.budget)\n            par = self.initial_par + self.evolutionary_rate * (evaluations / self.budget)\n\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredHarmonySearch", "description": "Enhanced Quantum-Inspired Harmony Search (EQIHS) improves convergence through dynamic global best exploitation and adaptive diversity control.", "configspace": "", "generation": 80, "fitness": 0.30861161428660633, "feedback": "The algorithm EnhancedQuantumInspiredHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.30861161428660633]}, "mutation_prompt": null}
{"id": "095c4e26-1b2b-478a-b3b9-748f05db28ea", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, dim * 2)\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w_max = 0.9  # initial inertia weight\n        self.w_min = 0.4  # final inertia weight\n        self.beta = 0.3  # quantum update probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim)) * (ub - lb) / 10\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        global_best_score = personal_best_scores[global_best_index]\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) + \n                                 self.c2 * r2 * (global_best_position - positions[i]))\n\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(0, 0.1, self.dim)\n                    positions[i] = global_best_position + q * (ub - lb)\n                else:\n                    positions[i] += velocities[i]\n                    positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i].copy()\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i].copy()\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Adaptive Quantum Particle Swarm Optimization (A-QPSO) utilizes dynamic swarm behavior and quantum-inspired position updates to efficiently explore complex search spaces.", "configspace": "", "generation": 81, "fitness": 0.28248342008719474, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.28248342008719474]}, "mutation_prompt": null}
{"id": "0ed4ec8c-0559-4686-b31b-6ea62ee068e0", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.85\n        self.initial_par = 0.35\n        self.beta = 0.25  # Further enhanced quantum influence for exploration\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.015  # Adjusted adaptive rate for finer control\n        self.memory_update_frequency = budget // 15  # More frequent harmony memory evaluation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Enhanced Quantum-inspired update using quantum walks\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.3)  # Quantum walk step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy with adaptive memory\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Multi-phase explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta * 0.5:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning for diverse exploration\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment based on performance\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                if harmony_memory.shape[0] > harmony_memory_size:\n                    worst_indices = scores.argsort()[-(harmony_memory.shape[0] - harmony_memory_size):]\n                    harmony_memory = np.delete(harmony_memory, worst_indices, axis=0)\n                    scores = np.delete(scores, worst_indices)\n                elif harmony_memory.shape[0] < harmony_memory_size:\n                    additional_harmonies = np.random.uniform(lb, ub, (harmony_memory_size - harmony_memory.shape[0], self.dim))\n                    harmony_memory = np.vstack((harmony_memory, additional_harmonies))\n                    additional_scores = np.array([func(additional_harmonies[i]) for i in range(additional_harmonies.shape[0])])\n                    scores = np.concatenate((scores, additional_scores))\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) integrates a multi-phase memory selection with quantum walks and adaptive learning for improved exploration-exploitation balance.", "configspace": "", "generation": 82, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {}, "mutation_prompt": null}
{"id": "3e22a963-6d2f-4eaf-8e53-40e10e0d841e", "solution": "import numpy as np\n\nclass QuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.2\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.01\n        self.memory_update_frequency = budget // 20\n        self.gradient_step_size = 0.01  # Gradient-based intensification step size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.5)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            if np.random.rand() < 0.5:  # Apply gradient-based intensification\n                gradient = self.estimate_gradient(func, new_harmony, lb, ub)\n                new_harmony = new_harmony - self.gradient_step_size * gradient\n                new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]\n\n    def estimate_gradient(self, func, position, lb, ub):\n        gradient = np.zeros(self.dim)\n        epsilon = 1e-5\n        for i in range(self.dim):\n            pos_plus = position.copy()\n            pos_minus = position.copy()\n            pos_plus[i] = min(pos_plus[i] + epsilon, ub[i])\n            pos_minus[i] = max(pos_minus[i] - epsilon, lb[i])\n            gradient[i] = (func(pos_plus) - func(pos_minus)) / (2 * epsilon)\n        return gradient", "name": "QuantumInspiredDynamicHarmonySearch", "description": "Quantum-Inspired Dynamic Harmony Search with Gradient-Based Intensification integrates local gradient information to enhance precision in exploitation phases and refine solutions efficiently.", "configspace": "", "generation": 83, "fitness": 0.27507247873927676, "feedback": "The algorithm QuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.27507247873927676]}, "mutation_prompt": null}
{"id": "9537fa02-9663-457d-8ad2-7c03180952dc", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.25  # Enhanced quantum learning rate for more powerful exploration\n        self.mutation_strength = 0.15\n        self.adaptive_rate = 0.015  # Optimized adaptive rate for finer dynamic adjustments\n        self.memory_update_frequency = budget // 15  # More frequent memory size updates\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        def hierarchical_quantum_entanglement(pos, best_pos):\n            # Hierarchical approach for quantum entanglement\n            q_factor = np.random.normal(loc=0, scale=0.5)\n            return pos + q_factor * (best_pos - pos) * (ub - lb)\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update with hierarchical entanglement\n                if np.random.rand() < self.beta:\n                    new_harmony[i] = hierarchical_quantum_entanglement(new_harmony[i], global_best_position[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with enhanced quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search with Hierarchical Quantum Entanglement for diversified exploration and improved convergence.", "configspace": "", "generation": 84, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {}, "mutation_prompt": null}
{"id": "73376bd6-b3c0-436f-8cbc-571ab61bc394", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, dim * 2)\n        self.inertia_weight = 0.7  # Initial inertia weight\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.quantum_coeff = 0.2  # Quantum enhancement factor\n        self.adaptive_rate = 0.01  # Adaptive parameter change rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = positions.copy()\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i]\n                                 + self.cognitive_coeff * r1 * (personal_best_positions[i] - positions[i])\n                                 + self.social_coeff * r2 * (global_best_position - positions[i]))\n                # Quantum-inspired update\n                if np.random.rand() < self.quantum_coeff:\n                    q = np.random.normal(loc=0, scale=0.5)\n                    velocities[i] += q * (ub - lb)\n\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                    if score < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = positions[i]\n\n            # Adapt inertia weight based on evaluations\n            self.inertia_weight = 0.9 - (0.5 * evaluations / self.budget)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumEnhancedAdaptivePSO", "description": "Quantum-Enhanced Adaptive Particle Swarm Optimization (QEAPSO) combines particle swarm intelligence with quantum-inspired explorative dynamics and adaptive parameter control for robust global optimization.", "configspace": "", "generation": 85, "fitness": 0.2811674446436512, "feedback": "The algorithm QuantumEnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2811674446436512]}, "mutation_prompt": null}
{"id": "07c4c05c-6a49-4cd2-b65b-31fb48a41ad4", "solution": "import numpy as np\n\nclass AdaptiveQuantumDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)  # Scale population size according to the problem dimensionality\n        self.f_cr_initial = (0.5, 0.9)  # Initial crossover rate range\n        self.f_min, self.f_max = 0.5, 1.0  # Differential weight range\n        self.beta = 0.2  # Quantum perturbation factor\n        self.adaptive_rate = 0.005  # Rate of adaptation for control parameters\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(individual) for individual in population])\n        evaluations = self.population_size\n        f_cr = np.random.uniform(*self.f_cr_initial)\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Mutation - DE/rand/1\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = population[indices]\n                mutant = a + np.random.uniform(self.f_min, self.f_max) * (b - c)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < f_cr\n                trial = np.where(crossover, mutant, population[i])\n\n                # Quantum-inspired perturbation\n                if np.random.rand() < self.beta:\n                    q_step = np.random.normal(0, 0.5, self.dim)\n                    trial += q_step * (ub - lb)\n\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                evaluations += 1\n\n                # Selection\n                if trial_score < scores[i]:\n                    population[i] = trial\n                    scores[i] = trial_score\n\n            # Update best solution\n            best_index = np.argmin(scores)\n            best_individual = population[best_index].copy()\n\n            # Adapt control parameters\n            f_cr = max(self.f_cr_initial[0], f_cr - self.adaptive_rate)\n            self.beta = min(1.0, self.beta + self.adaptive_rate * (1 - evaluations / self.budget))\n\n        return best_individual, scores[best_index]", "name": "AdaptiveQuantumDifferentialEvolution", "description": "Adaptive Quantum Differential Evolution (AQDE) combines the exploration power of quantum-inspired adaptation with the robust convergence properties of differential evolution to enhance global search capabilities in photonic structure optimization.", "configspace": "", "generation": 86, "fitness": 0.2785812847155572, "feedback": "The algorithm AdaptiveQuantumDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2785812847155572]}, "mutation_prompt": null}
{"id": "5f86b413-20ad-4f5d-81f5-7cc4192ccde8", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.25  # Enhanced quantum learning for increased exploration\n        self.mutation_strength = 0.05  # Reduced mutation strength for refined local search\n        self.adaptive_rate = 0.02  # Faster convergence with adaptive parameter tuning\n        self.memory_update_frequency = budget // 15  # More frequent memory size adjustments\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Enhanced quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.5)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n                    # Quantum tunneling for potential global escapes\n                    if np.random.rand() < 0.1:\n                        new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n        \n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search uses adaptive quantum tunneling and dynamic mutation for robust global exploration and local exploitation.", "configspace": "", "generation": 87, "fitness": 0.3177023335507786, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3177023335507786]}, "mutation_prompt": null}
{"id": "d81272f2-b5fe-4f2d-88cd-00bfc4bfe1d1", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.harmony_memory_size = self.max_harmony_memory_size\n        self.initial_hmcr = 0.95\n        self.initial_par = 0.3\n        self.beta_initial = 0.3  # Start with a higher exploration rate\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.01\n        self.memory_update_frequency = budget // 10  # More frequent updates for adaptability\n        self.memory_shrink_factor = 0.9  # Factor to reduce memory size progressively\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = np.random.uniform(lb, ub, (self.harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(self.harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = self.harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n        beta = self.beta_initial\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update with adaptive quantum step\n                if np.random.rand() < beta:\n                    q = np.random.normal(loc=0, scale=0.5) * (1 - evaluations / self.budget)\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            if evaluations < self.budget and np.random.rand() < beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n            beta = self.beta_initial * (1 - evaluations / self.budget)\n\n            if evaluations % self.memory_update_frequency == 0:\n                self.harmony_memory_size = int(np.clip(\n                    self.harmony_memory_size * self.memory_shrink_factor, self.min_harmony_memory_size, self.max_harmony_memory_size\n                ))\n                harmony_memory = np.resize(harmony_memory, (self.harmony_memory_size, self.dim))\n                scores = np.resize(scores, self.harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) incorporates adaptive quantum step tuning and multi-level memory management for improved exploration and exploitation balance.", "configspace": "", "generation": 88, "fitness": 0.32289648301070495, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.32289648301070495]}, "mutation_prompt": null}
{"id": "dfcec73e-35c8-40be-9c85-5a6cf6885bda", "solution": "import numpy as np\n\nclass BioInspiredDynamicParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.inertia_decay = 0.99\n        self.min_inertia = 0.4\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        swarm_velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        personal_best_scores = np.array([func(p) for p in swarm_positions])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1, r2 = np.random.rand(2, self.dim)\n                swarm_velocities[i] = (\n                    self.inertia_weight * swarm_velocities[i] +\n                    self.cognitive_coeff * r1 * (personal_best_positions[i] - swarm_positions[i]) +\n                    self.social_coeff * r2 * (global_best_position - swarm_positions[i])\n                )\n                # Update position\n                swarm_positions[i] += swarm_velocities[i]\n                swarm_positions[i] = np.clip(swarm_positions[i], lb, ub)\n\n                # Evaluate new position\n                score = func(swarm_positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm_positions[i].copy()\n\n                # Update global best\n                if score < personal_best_scores[global_best_index]:\n                    global_best_index = i\n                    global_best_position = personal_best_positions[i].copy()\n\n            # Decay inertia\n            self.inertia_weight = max(self.min_inertia, self.inertia_weight * self.inertia_decay)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "BioInspiredDynamicParticleSwarmOptimization", "description": "Bio-Inspired Dynamic Particle Swarm Optimization (BIDPSO) uses a dynamic adaptation of swarm inertia and cognitive factors to balance exploration and exploitation for enhanced optimization in complex landscapes.", "configspace": "", "generation": 89, "fitness": 0.2848104066565287, "feedback": "The algorithm BioInspiredDynamicParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2848104066565287]}, "mutation_prompt": null}
{"id": "5d6b08b8-fc89-4c7a-8935-5db07a5ae871", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.3  # Increased quantum learning rate for more exploration\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.01  # Adaptive rate for dynamic adjustments\n        self.memory_update_frequency = budget // 20  # Adjust harmony memory size more frequently\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        dynamic_mutation_strength = self.mutation_strength * (1 - evaluations / self.budget)\n                        new_harmony[i] += np.random.uniform(-dynamic_mutation_strength, dynamic_mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update with adaptive influence\n                if np.random.rand() < self.beta:\n                    global_influence = np.random.rand() * (1 - evaluations / self.budget)\n                    q = np.random.normal(loc=0, scale=0.5)\n                    new_harmony[i] = global_best_position[i] + global_influence * q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (EQIDHS) incorporates adaptive global best influence and dynamic mutation scaling to balance exploration and exploitation effectively.", "configspace": "", "generation": 90, "fitness": 0.2957216567058796, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2957216567058796]}, "mutation_prompt": null}
{"id": "f64ce68d-5a24-4adf-974c-e2f10c75f31c", "solution": "import numpy as np\n\nclass QuantumAnnealingInspiredDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, dim * 5)\n        self.initial_cr = 0.9  # Crossover probability\n        self.initial_f = 0.8   # Differential weight\n        self.adaptive_rate = 0.01  # Adaptive rate for tuning parameters\n        self.temperature = 1.0  # Initial temperature for simulated annealing\n        self.alpha = 0.95  # Cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(scores)\n        global_best_position = population[global_best_index].copy()\n        evaluations = self.population_size\n        cr = self.initial_cr\n        f = self.initial_f\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                idxs = list(range(self.population_size))\n                idxs.remove(i)\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                \n                mutant = np.clip(a + f * (b - c), lb, ub)\n                crossover = np.random.rand(self.dim) < cr\n                trial = np.where(crossover, mutant, population[i])\n                \n                trial_score = func(trial)\n                evaluations += 1\n                \n                if trial_score < scores[i] or np.exp((scores[i] - trial_score) / self.temperature) > np.random.rand():\n                    population[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = trial.copy()\n\n            self.temperature *= self.alpha  # Cool down\n            cr = self.initial_cr - self.adaptive_rate * (evaluations / self.budget)\n            f = self.initial_f + self.adaptive_rate * (evaluations / self.budget)\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumAnnealingInspiredDifferentialEvolution", "description": "Quantum Annealing-Inspired Adaptive Differential Evolution (QAIDE) utilizes quantum annealing concepts and adaptive scaling to enhance exploration and convergence in complex optimization landscapes.", "configspace": "", "generation": 91, "fitness": 0.27748851523039975, "feedback": "The algorithm QuantumAnnealingInspiredDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.27748851523039975]}, "mutation_prompt": null}
{"id": "e6af8113-bc66-4e0f-b5dc-94ba2756f4a6", "solution": "import numpy as np\n\nclass QuantumInspiredVariableNeighborhoodHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.85\n        self.initial_par = 0.4\n        self.beta = 0.25  # Quantum learning rate for exploration\n        self.mutation_strength = 0.15\n        self.adaptive_rate = 0.015  # Adaptive rate for dynamic parameter adjustment\n        self.memory_update_frequency = budget // 15  # More frequent memory updates\n        self.neighborhood_radius = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.3)  # Controlled quantum step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy with neighborhood exploration\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            # Variable neighborhood search\n            if np.random.rand() < self.neighborhood_radius:\n                neighborhood_position = global_best_position + np.random.normal(0, self.neighborhood_radius, self.dim) * (ub - lb)\n                neighborhood_position = np.clip(neighborhood_position, lb, ub)\n                neighborhood_score = func(neighborhood_position)\n                evaluations += 1\n                if neighborhood_score < scores[global_best_index]:\n                    global_best_position = neighborhood_position\n                    scores[global_best_index] = neighborhood_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n        \n        return global_best_position, scores[global_best_index]", "name": "QuantumInspiredVariableNeighborhoodHarmonySearch", "description": "Quantum-Inspired Variable Neighborhood Harmony Search (QIVNHS) integrates dynamic neighborhood structures and quantum-inspired updates to enhance exploration and exploitation balance for global optimization.", "configspace": "", "generation": 92, "fitness": 0.3225077106642643, "feedback": "The algorithm QuantumInspiredVariableNeighborhoodHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3225077106642643]}, "mutation_prompt": null}
{"id": "30c4cbea-734b-4ca5-9099-a9595841c1b1", "solution": "import numpy as np\n\nclass EnhancedQuantumAdaptiveMemorySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.15  # Adjusted quantum learning rate for balanced exploration\n        self.mutation_strength = 0.05  # Reduced for more precise local search\n        self.adaptive_rate = 0.02  # More responsive adaptive rate\n        self.memory_update_frequency = budget // 10  # More frequent updates\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.3)  # Controlled quantum step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + int((self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumAdaptiveMemorySearch", "description": "Enhanced Quantum-inspired Adaptive Memory Search (EQAMS) uses an improved memory update strategy and adaptive parameter control for more efficient exploration and exploitation.", "configspace": "", "generation": 93, "fitness": 0.31443060907660814, "feedback": "The algorithm EnhancedQuantumAdaptiveMemorySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.31443060907660814]}, "mutation_prompt": null}
{"id": "c23ae44b-dc5b-4289-a658-37452a35aa42", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(10, dim)\n        self.initial_hmcr = 0.9\n        self.initial_par = 0.3\n        self.beta = 0.3  # Enhanced quantum learning rate for better exploration\n        self.mutation_strength = 0.1\n        self.adaptive_rate = 0.02  # Increased adaptive rate for more dynamic tuning\n        self.memory_update_frequency = budget // 15  # More frequent updates for reactive memory size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Enhanced quantum-inspired update\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.3)  # More precise quantum step\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Updated evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Advanced explorative search with quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Adaptive parameter tuning\n            hmcr = self.initial_hmcr - self.adaptive_rate * (evaluations / self.budget)\n            par = self.initial_par + self.adaptive_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = int(self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget))\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                if harmony_memory_size < len(harmony_memory):\n                    harmony_memory = harmony_memory[:harmony_memory_size]\n                    scores = scores[:harmony_memory_size]\n                else:\n                    additional_memory = np.random.uniform(lb, ub, (harmony_memory_size - len(harmony_memory), self.dim))\n                    harmony_memory = np.vstack((harmony_memory, additional_memory))\n                    additional_scores = np.array([func(additional_memory[i]) for i in range(additional_memory.shape[0])])\n                    scores = np.concatenate((scores, additional_scores))\n                    evaluations += additional_memory.shape[0]\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredDynamicHarmonySearch", "description": "Enhanced Quantum-Inspired Dynamic Harmony Search (E-QIDHS) integrates adaptive quantum perturbation and dynamic memory reshaping to boost convergence and solution variety.", "configspace": "", "generation": 94, "fitness": 0.3251136133392998, "feedback": "The algorithm EnhancedQuantumInspiredDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.3251136133392998]}, "mutation_prompt": null}
{"id": "76af4ee5-1ed9-4be7-8822-3b3207ebf52d", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(10, 2 * dim)\n        self.beta = 0.3  # Quantum exploration parameter\n        self.c1, self.c2 = 2.0, 2.0  # Cognitive and social coefficients\n        self.inertia_weight = 0.7\n        self.inertia_decay = 0.99  # Decay for inertia weight\n        self.velocity_clamp = 0.1  # Clamp for velocity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        # Initialize swarm\n        position = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocity = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.swarm_size, self.dim))\n        personal_best_position = position.copy()\n        personal_best_score = np.array([func(pos) for pos in position])\n        global_best_index = np.argmin(personal_best_score)\n        global_best_position = personal_best_position[global_best_index].copy()\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocities\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.c1 * r1 * (personal_best_position[i] - position[i]) +\n                               self.c2 * r2 * (global_best_position - position[i]))\n\n                # Clamp velocity\n                velocity[i] = np.clip(velocity[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update positions\n                position[i] += velocity[i]\n\n                # Quantum-inspired exploration\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(0, 0.5, self.dim)  # Quantum step\n                    position[i] = global_best_position + q * (ub - lb)\n\n                # Boundary handling\n                position[i] = np.clip(position[i], lb, ub)\n\n                # Evaluate new positions\n                score = func(position[i])\n                evaluations += 1\n\n                # Update personal bests\n                if score < personal_best_score[i]:\n                    personal_best_position[i] = position[i].copy()\n                    personal_best_score[i] = score\n\n            # Update global best\n            current_best_index = np.argmin(personal_best_score)\n            if personal_best_score[current_best_index] < personal_best_score[global_best_index]:\n                global_best_index = current_best_index\n                global_best_position = personal_best_position[global_best_index].copy()\n\n            # Adapt inertia weight\n            self.inertia_weight *= self.inertia_decay\n\n        return global_best_position, personal_best_score[global_best_index]", "name": "QuantumInspiredAdaptivePSO", "description": "Quantum-Inspired Adaptive Particle Swarm Optimization (QIAPSO) employs dynamic parameter adaptation and quantum-centric exploration to enhance convergence efficiency and solution accuracy.", "configspace": "", "generation": 95, "fitness": 0.2757711706240893, "feedback": "The algorithm QuantumInspiredAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2757711706240893]}, "mutation_prompt": null}
{"id": "47e92ae3-18fc-4e2d-b684-8230ca796eda", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.min_harmony_memory_size = max(5, dim // 2)\n        self.max_harmony_memory_size = max(15, dim)\n        self.initial_hmcr = 0.95\n        self.initial_par = 0.25\n        self.beta = 0.3  # Strengthened quantum learning rate for adaptive exploration\n        self.mutation_strength = 0.05\n        self.feedback_rate = 0.05  # Feedback rate to dynamically adjust parameters\n        self.memory_update_frequency = budget // 15  # More frequent memory size updates\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = self.max_harmony_memory_size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        scores = np.array([func(harmony_memory[i]) for i in range(harmony_memory_size)])\n        global_best_index = np.argmin(scores)\n        global_best_position = harmony_memory[global_best_index].copy()\n        evaluations = harmony_memory_size\n        hmcr = self.initial_hmcr\n        par = self.initial_par\n\n        while evaluations < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < hmcr:\n                    selected = np.random.randint(harmony_memory_size)\n                    new_harmony[i] = harmony_memory[selected, i]\n                    if np.random.rand() < par:\n                        new_harmony[i] += np.random.uniform(-self.mutation_strength, self.mutation_strength) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n                # Quantum-inspired perturbation\n                if np.random.rand() < self.beta:\n                    q = np.random.normal(loc=0, scale=0.4)  # Controlled quantum variation\n                    new_harmony[i] = global_best_position[i] + q * (ub[i] - lb[i])\n\n            new_score = func(new_harmony)\n            evaluations += 1\n\n            # Enhanced evolutionary replacement strategy\n            if new_score < scores.max():\n                worst_index = np.argmax(scores)\n                harmony_memory[worst_index] = new_harmony\n                scores[worst_index] = new_score\n\n            # Strategic explorative search with focused quantum leap\n            if evaluations < self.budget and np.random.rand() < self.beta:\n                explorative_position = (global_best_position + new_harmony) / 2 + np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                explorative_position = np.clip(explorative_position, lb, ub)\n                explorative_score = func(explorative_position)\n                evaluations += 1\n                if explorative_score < scores[global_best_index]:\n                    global_best_position = explorative_position\n                    scores[global_best_index] = explorative_score\n\n            global_best_index = np.argmin(scores)\n            global_best_position = harmony_memory[global_best_index].copy()\n\n            # Dynamic parameter feedback tuning\n            hmcr = self.initial_hmcr - self.feedback_rate * (evaluations / self.budget)\n            par = self.initial_par + self.feedback_rate * (evaluations / self.budget)\n\n            # Dynamic memory size adjustment\n            if evaluations % self.memory_update_frequency == 0:\n                harmony_memory_size = self.min_harmony_memory_size + (self.max_harmony_memory_size - self.min_harmony_memory_size) * (1 - evaluations / self.budget)\n                harmony_memory_size = int(np.clip(harmony_memory_size, self.min_harmony_memory_size, self.max_harmony_memory_size))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                scores = np.resize(scores, harmony_memory_size)\n\n        return global_best_position, scores[global_best_index]", "name": "EnhancedQuantumInspiredHarmonySearch", "description": "Enhanced Quantum-Inspired Harmony Search utilizes adaptive quantum perturbations and dynamic feedback mechanisms for superior convergence in photonic structure optimization.", "configspace": "", "generation": 96, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 7 is out of bounds for axis 0 with size 7').", "error": "IndexError('index 7 is out of bounds for axis 0 with size 7')", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {}, "mutation_prompt": null}
{"id": "f2ea800e-aeab-46b9-9f02-52c1e1500106", "solution": "import numpy as np\n\nclass QuantumGradientSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(10, dim * 2)\n        self.alpha = 0.5  # Quantum influence factor\n        self.beta = 0.1  # Gradient influence factor\n        self.omega = 0.5  # Inertia weight\n        self.phi_p = 0.5  # Personal attraction\n        self.phi_g = 0.5  # Global attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        swarm_velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = swarm_positions.copy()\n        scores = np.array([func(swarm_positions[i]) for i in range(self.swarm_size)])\n        personal_best_scores = scores.copy()\n        global_best_index = np.argmin(scores)\n        global_best_position = personal_best_positions[global_best_index].copy()\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                gradient = np.zeros(self.dim)\n                for j in range(self.dim):\n                    delta = (ub[j] - lb[j]) * 1e-8\n                    original_value = swarm_positions[i, j]\n                    swarm_positions[i, j] = original_value + delta\n                    score_up = func(swarm_positions[i])\n                    swarm_positions[i, j] = original_value - delta\n                    score_down = func(swarm_positions[i])\n                    swarm_positions[i, j] = original_value\n                    gradient[j] = (score_up - score_down) / (2 * delta)\n                evaluations += 2 * self.dim\n\n                swarm_velocities[i] = (\n                    self.omega * swarm_velocities[i]\n                    + self.phi_p * np.random.rand(self.dim) * (personal_best_positions[i] - swarm_positions[i])\n                    + self.phi_g * np.random.rand(self.dim) * (global_best_position - swarm_positions[i])\n                    - self.beta * gradient\n                    + self.alpha * np.random.normal(0, 1, self.dim)\n                )\n                swarm_positions[i] = np.clip(swarm_positions[i] + swarm_velocities[i], lb, ub)\n                new_score = func(swarm_positions[i])\n                evaluations += 1\n\n                if new_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm_positions[i]\n                    personal_best_scores[i] = new_score\n                    if new_score < personal_best_scores[global_best_index]:\n                        global_best_position = swarm_positions[i]\n                        global_best_index = i\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumGradientSwarmOptimization", "description": "Quantum Gradient Swarm Optimization (QGSO) combines quantum-inspired updates with swarm intelligence by incorporating gradient information to balance exploration and exploitation dynamically.", "configspace": "", "generation": 97, "fitness": 0.2737901315493769, "feedback": "The algorithm QuantumGradientSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2737901315493769]}, "mutation_prompt": null}
{"id": "25a53c5e-a979-428d-9d7f-4fdce7112643", "solution": "import numpy as np\n\nclass QuantumLeapParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(10, dim * 2)\n        self.c1 = 1.49618  # Cognitive coefficient\n        self.c2 = 1.49618  # Social coefficient\n        self.w = 0.7298    # Inertia weight\n        self.quantum_rate = 0.1\n        self.mutation_strength = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim)) * (ub - lb)\n        scores = np.array([func(pos) for pos in positions])\n        personal_best_positions = positions.copy()\n        personal_best_scores = scores.copy()\n        global_best_index = np.argmin(scores)\n        global_best_position = positions[global_best_index].copy()\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.swarm_size, self.dim), np.random.rand(self.swarm_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, lb, ub)\n\n            if np.random.rand() < self.quantum_rate:\n                quantum_jump = np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                positions += quantum_jump\n\n            new_scores = np.array([func(pos) for pos in positions])\n            evaluations += self.swarm_size\n\n            for i in range(self.swarm_size):\n                if new_scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = new_scores[i]\n                    personal_best_positions[i] = positions[i].copy()\n            \n            new_global_best_index = np.argmin(new_scores)\n            if new_scores[new_global_best_index] < scores[global_best_index]:\n                global_best_index = new_global_best_index\n                global_best_position = positions[global_best_index].copy()\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "QuantumLeapParticleSwarmOptimization", "description": "Quantum Leap Particle Swarm Optimization (QLPSO) combines traditional PSO with quantum-inspired position updates for enhanced exploration and exploitation in complex search spaces.", "configspace": "", "generation": 98, "fitness": 0.28072489187465033, "feedback": "The algorithm QuantumLeapParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.28072489187465033]}, "mutation_prompt": null}
{"id": "4f23d6c1-f4f7-44c9-8047-47713daf1eb1", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveSwarmAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = max(20, dim * 5)\n        self.alpha = 0.5  # Initial weight for exploitation\n        self.beta = 0.3   # Initial weight for exploration\n        self.gamma = 0.1  # Quantum influence factor\n        self.mutation_strength = 0.05\n        self.adaptive_factor = 0.01  # Adaptive adjustment rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.1, 0.1, (self.swarm_size, self.dim))\n        scores = np.array([func(p) for p in swarm])\n        global_best_index = np.argmin(scores)\n        global_best_position = swarm[global_best_index].copy()\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocities with quantum-inspired perturbation\n                velocities[i] = (self.alpha * velocities[i]\n                                + self.beta * (global_best_position - swarm[i])\n                                + self.gamma * np.random.normal(0, 1, self.dim) * (ub - lb))\n                \n                # Update positions\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Quantum-inspired mutation\n                if np.random.rand() < self.gamma:\n                    swarm[i] += np.random.normal(0, self.mutation_strength, self.dim) * (ub - lb)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate new position\n                new_score = func(swarm[i])\n                evaluations += 1\n                if new_score < scores[i]:\n                    scores[i] = new_score\n\n                # Update global best\n                if new_score < scores[global_best_index]:\n                    global_best_index = i\n                    global_best_position = swarm[i].copy()\n\n            # Adaptive parameter tuning\n            self.alpha += self.adaptive_factor * (1 - evaluations / self.budget)\n            self.beta -= self.adaptive_factor * (1 - evaluations / self.budget)\n            self.gamma *= 1 + self.adaptive_factor * np.sin(2 * np.pi * evaluations / self.budget)\n\n        return global_best_position, scores[global_best_index]", "name": "QuantumEnhancedAdaptiveSwarmAlgorithm", "description": "Quantum-Enhanced Adaptive Swarm Algorithm (QEASA) integrates quantum-inspired search with adaptive swarm intelligence to dynamically enhance exploration and exploitation.", "configspace": "", "generation": 99, "fitness": 0.2810333555624255, "feedback": "The algorithm QuantumEnhancedAdaptiveSwarmAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "02e98837-8eee-4e4b-9248-3202cf00b110", "metadata": {"aucs": [0.2810333555624255]}, "mutation_prompt": null}

{"id": "2812aa88-df69-4deb-a5e7-d67719f5d65b", "solution": "import numpy as np\n\nclass HybridGA_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50  # Size of population\n        self.c1 = 1.5  # Cognitive constant\n        self.c2 = 1.5  # Social constant\n        self.inertia = 0.5  # Inertia weight\n        self.mutation_rate = 0.1  # Mutation rate for GA\n        self.mutation_strength = 0.1  # Mutation strength\n        self.velocity = np.zeros((self.population_size, dim))\n        self.history = []  # Keep track of best solutions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_personal = pop.copy()\n        best_personal_fitness = fitness.copy()\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions (PSO Step)\n            r1, r2 = np.random.rand(2)\n            self.velocity = (self.inertia * self.velocity +\n                             self.c1 * r1 * (best_personal - pop) +\n                             self.c2 * r2 * (best_global - pop))\n            pop += self.velocity\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate the new population\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            # Update personal and global best\n            update_mask = fitness < best_personal_fitness\n            best_personal[update_mask] = pop[update_mask]\n            best_personal_fitness[update_mask] = fitness[update_mask]\n\n            if np.min(fitness) < func(best_global):\n                best_global = pop[np.argmin(fitness)]\n\n            # Apply genetic algorithm operators\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    pop[i] += np.random.normal(0, self.mutation_strength, self.dim)\n                    pop[i] = np.clip(pop[i], lb, ub)\n\n            # Save the history of best solutions\n            self.history.append(best_global)\n\n        return best_global", "name": "HybridGA_PSO", "description": "This algorithm is a blend of Genetic Algorithm and Particle Swarm Optimization, leveraging crossover and mutation from GA with velocity and position updates from PSO for diverse exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.2829690413376793, "feedback": "The algorithm HybridGA_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.2829690413376793]}, "mutation_prompt": null}
{"id": "1a66cc1e-b9e3-486b-a051-e40d9a8c28e5", "solution": "import numpy as np\n\nclass QuantumInspiredEvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.alpha = 0.5  # Coefficient for quantum rotation\n        self.beta = 0.9   # Coefficient for quantum mutation\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        quantum_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in quantum_population])\n        best_global = quantum_population[np.argmin(fitness)]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Quantum rotation step\n            rotation_matrix = self.alpha * (best_global - quantum_population)\n            quantum_population += rotation_matrix\n            quantum_population = np.clip(quantum_population, lb, ub)\n\n            # Quantum mutation step\n            quantum_population += self.beta * np.random.uniform(-1, 1, quantum_population.shape)\n\n            # Ensure population stays within bounds\n            quantum_population = np.clip(quantum_population, lb, ub)\n\n            # Evaluate the new population\n            fitness = np.array([func(x) for x in quantum_population])\n            evaluations += self.population_size\n\n            # Update the global best\n            current_best_index = np.argmin(fitness)\n            if fitness[current_best_index] < func(best_global):\n                best_global = quantum_population[current_best_index]\n\n            # Save the history of best solutions\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumInspiredEvolutionaryAlgorithm", "description": "Quantum-Inspired Evolutionary Algorithm: This algorithm integrates principles from quantum computing such as quantum superposition and entanglement with evolutionary strategies to enhance exploratory capabilities and ensure diverse solution spaces.", "configspace": "", "generation": 1, "fitness": 0.2814014799550244, "feedback": "The algorithm QuantumInspiredEvolutionaryAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "2812aa88-df69-4deb-a5e7-d67719f5d65b", "metadata": {"aucs": [0.2814014799550244]}, "mutation_prompt": null}
{"id": "99b7c646-6927-4c28-8c75-60f1183d0b83", "solution": "import numpy as np\n\nclass EnhancedHybridGA_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive constant\n        self.c2 = 1.5  # Social constant\n        self.inertia = 0.9  # Initial inertia weight \n        self.final_inertia = 0.4  # Final inertia weight\n        self.mutation_rate = 0.1\n        self.mutation_strength = 0.1\n        self.velocity = np.zeros((self.population_size, dim))\n        self.history = []\n        self.generations = self.budget // self.population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_personal = pop.copy()\n        best_personal_fitness = fitness.copy()\n\n        evaluations = self.population_size\n\n        for gen in range(self.generations):\n            # Dynamically update inertia weight\n            inertia = self.final_inertia + (self.inertia - self.final_inertia) * ((self.generations - gen) / self.generations)\n\n            # Update velocities and positions (PSO Step)\n            r1, r2 = np.random.rand(2)\n            self.velocity = (inertia * self.velocity +\n                             self.c1 * r1 * (best_personal - pop) +\n                             self.c2 * r2 * (best_global - pop))\n            pop += self.velocity\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate the new population\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            # Update personal and global best\n            update_mask = fitness < best_personal_fitness\n            best_personal[update_mask] = pop[update_mask]\n            best_personal_fitness[update_mask] = fitness[update_mask]\n\n            if np.min(fitness) < func(best_global):\n                best_global = pop[np.argmin(fitness)]\n\n            # Tournament selection for genetic algorithm\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    candidates = np.random.choice(self.population_size, size=3, replace=False)\n                    winner = candidates[np.argmin(fitness[candidates])]\n                    pop[i] = pop[winner] + np.random.normal(0, self.mutation_strength, self.dim)\n                    pop[i] = np.clip(pop[i], lb, ub)\n\n            # Save the history of best solutions\n            self.history.append(best_global)\n\n        return best_global", "name": "EnhancedHybridGA_PSO", "description": "This algorithm enhances the exploration-exploitation balance by dynamically updating inertia and introducing a tournament selection mechanism for robust global searching.", "configspace": "", "generation": 2, "fitness": 0.27979596437615795, "feedback": "The algorithm EnhancedHybridGA_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "2812aa88-df69-4deb-a5e7-d67719f5d65b", "metadata": {"aucs": [0.27979596437615795]}, "mutation_prompt": null}
{"id": "8b669362-f954-4130-8211-c6f918fd672a", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.alpha = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.history = []  # Keep track of best solutions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            for i in range(self.population_size):\n                # Quantum-inspired superposition\n                r1, r2, r3 = np.random.choice(self.population_size, 3, replace=False)\n                mutant_vector = pop[r1] + self.alpha * (pop[r2] - pop[r3])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                # Entanglement and crossover\n                trial_vector = np.copy(pop[i])\n                crossover_indices = np.random.rand(self.dim) < self.CR\n                trial_vector[crossover_indices] = mutant_vector[crossover_indices]\n\n                # Selection\n                trial_fitness = func(trial_vector)\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial_vector\n                    fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < func(best_global):\n                    best_global = trial_vector\n\n            pop = new_pop\n            evaluations += self.population_size\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumInspiredEA", "description": "Quantum-Inspired Evolutionary Algorithm (QIEA): A hybrid optimization approach leveraging quantum-inspired superposition and entanglement with classical differential evolution for enhanced exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.27809322741332754, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "2812aa88-df69-4deb-a5e7-d67719f5d65b", "metadata": {"aucs": [0.27809322741332754]}, "mutation_prompt": null}
{"id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "solution": "import numpy as np\n\nclass ImprovedHybridGA_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50  # Size of population\n        self.c1 = 1.5  # Cognitive constant\n        self.c2 = 1.5  # Social constant\n        self.inertia_max = 0.9  # Maximum inertia weight\n        self.inertia_min = 0.4  # Minimum inertia weight\n        self.mutation_rate = 0.1  # Initial mutation rate for GA\n        self.mutation_strength = 0.1  # Initial mutation strength\n        self.velocity = np.zeros((self.population_size, dim))\n        self.history = []  # Keep track of best solutions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_personal = pop.copy()\n        best_personal_fitness = fitness.copy()\n\n        evaluations = self.population_size\n        inertia = self.inertia_max\n\n        while evaluations < self.budget:\n            # Dynamically update inertia\n            inertia = self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n            \n            # Update velocities and positions (PSO Step)\n            r1, r2 = np.random.rand(2)\n            self.velocity = (inertia * self.velocity +\n                             self.c1 * r1 * (best_personal - pop) +\n                             self.c2 * r2 * (best_global - pop))\n            pop += self.velocity\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate the new population\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            # Update personal and global best\n            update_mask = fitness < best_personal_fitness\n            best_personal[update_mask] = pop[update_mask]\n            best_personal_fitness[update_mask] = fitness[update_mask]\n\n            if np.min(fitness) < func(best_global):\n                best_global = pop[np.argmin(fitness)]\n\n            # Adaptive mutation based on fitness improvement\n            avg_fitness = np.mean(fitness)\n            if np.min(fitness) < avg_fitness:\n                self.mutation_rate = max(0.01, self.mutation_rate * 0.9)\n                self.mutation_strength *= 0.9\n            else:\n                self.mutation_rate = min(0.2, self.mutation_rate * 1.1)\n                self.mutation_strength *= 1.1\n\n            # Apply genetic algorithm operators\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    pop[i] += np.random.normal(0, self.mutation_strength, self.dim)\n                    pop[i] = np.clip(pop[i], lb, ub)\n\n            # Save the history of best solutions\n            self.history.append(best_global)\n\n        return best_global", "name": "ImprovedHybridGA_PSO", "description": "A hybrid of Genetic Algorithm and Particle Swarm Optimization with adaptive mutation and dynamic inertial weight to balance exploration and exploitation effectively.", "configspace": "", "generation": 4, "fitness": 0.28474088637073625, "feedback": "The algorithm ImprovedHybridGA_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "2812aa88-df69-4deb-a5e7-d67719f5d65b", "metadata": {"aucs": [0.28474088637073625]}, "mutation_prompt": null}
{"id": "53005ec2-bc60-4651-beab-7d026c4526b4", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # Cognitive constant\n        self.c2 = 2.0  # Social constant\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.velocity = np.zeros((self.population_size, dim))\n        self.history = []\n        self.quantum_prob = 0.05  # Probability of applying quantum jump\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_personal = pop.copy()\n        best_personal_fitness = fitness.copy()\n\n        evaluations = self.population_size\n        inertia = self.inertia_max\n\n        while evaluations < self.budget:\n            inertia = self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n            \n            r1, r2 = np.random.rand(2)\n            self.velocity = (inertia * self.velocity +\n                             self.c1 * r1 * (best_personal - pop) +\n                             self.c2 * r2 * (best_global - pop))\n            pop += self.velocity\n            pop = np.clip(pop, lb, ub)\n\n            # Quantum-inspired jump\n            quantum_jump_mask = np.random.rand(self.population_size) < self.quantum_prob\n            for idx in np.where(quantum_jump_mask)[0]:\n                pop[idx] = best_global + np.random.normal(0, 0.1, self.dim)\n                pop[idx] = np.clip(pop[idx], lb, ub)\n\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            update_mask = fitness < best_personal_fitness\n            best_personal[update_mask] = pop[update_mask]\n            best_personal_fitness[update_mask] = fitness[update_mask]\n\n            if np.min(fitness) < func(best_global):\n                best_global = pop[np.argmin(fitness)]\n\n            # Adaptive quantum probability based on entropy of fitness distribution\n            fitness_entropy = -np.sum((fitness / np.sum(fitness)) * np.log(fitness / np.sum(fitness) + 1e-9))\n            self.quantum_prob = 0.05 + 0.1 * (1 - fitness_entropy / np.log(self.population_size))\n\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumInspiredPSO", "description": "Quantum-Inspired Particle Swarm Optimization with Adaptive Entropy Reduction to seamlessly integrate quantum mechanics principles for enhanced global exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.27977871596963655, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.27977871596963655]}, "mutation_prompt": null}
{"id": "7fead5c9-6dfe-436d-b6c2-cb3de7d86956", "solution": "import numpy as np\n\nclass AdvancedHybridGA_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.velocity = np.zeros((self.population_size, dim))\n        self.crossover_rate = 0.7\n        self.mutation_rate = 0.1\n        self.mutation_strength = 0.1\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_personal = pop.copy()\n        best_personal_fitness = fitness.copy()\n        evaluations = self.population_size\n        inertia = self.inertia_max\n\n        while evaluations < self.budget:\n            inertia = self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n            r1, r2 = np.random.rand(2)\n            self.velocity = (inertia * self.velocity +\n                             self.c1 * r1 * (best_personal - pop) +\n                             self.c2 * r2 * (best_global - pop))\n            pop += self.velocity\n            pop = np.clip(pop, lb, ub)\n\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            update_mask = fitness < best_personal_fitness\n            best_personal[update_mask] = pop[update_mask]\n            best_personal_fitness[update_mask] = fitness[update_mask]\n\n            if np.min(fitness) < func(best_global):\n                best_global = pop[np.argmin(fitness)]\n\n            # Adaptive mutation and crossover based on diversity\n            diversity = np.std(pop)\n            if diversity < 0.1 * (ub - lb):\n                self.crossover_rate = min(0.9, self.crossover_rate * 1.1)\n                self.mutation_rate = max(0.01, self.mutation_rate * 0.9)\n                self.mutation_strength *= 0.9\n            else:\n                self.crossover_rate = max(0.5, self.crossover_rate * 0.9)\n                self.mutation_rate = min(0.2, self.mutation_rate * 1.1)\n                self.mutation_strength *= 1.1\n\n            # Genetic Algorithm: Crossover\n            for i in range(0, self.population_size, 2):\n                if np.random.rand() < self.crossover_rate:\n                    parent1, parent2 = pop[i], pop[i+1]\n                    alpha = np.random.rand(self.dim)\n                    child1 = alpha * parent1 + (1 - alpha) * parent2\n                    child2 = alpha * parent2 + (1 - alpha) * parent1\n                    pop[i], pop[i+1] = np.clip(child1, lb, ub), np.clip(child2, lb, ub)\n\n            # Genetic Algorithm: Mutation\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    pop[i] += np.random.normal(0, self.mutation_strength, self.dim)\n                    pop[i] = np.clip(pop[i], lb, ub)\n\n            self.history.append(best_global)\n\n        return best_global", "name": "AdvancedHybridGA_PSO", "description": "A sophisticated hybrid Genetic Algorithm with Particle Swarm Optimization integrating self-adjusting crossover and mutation strategies based on population diversity to enhance convergence speed and robustness.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {}, "mutation_prompt": null}
{"id": "c65aed93-c779-48c4-9b21-5b871295bd6d", "solution": "import numpy as np\n\nclass QuantumInspiredDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_solution = pop[np.argmin(fitness)]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(self.population_size):\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[idxs]\n                mutant = self.quantum_superposition(a, b, c, lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(crossover, mutant, pop[i])\n                \n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(best_solution):\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n            self.history.append(best_solution)\n            if evaluations >= self.budget:\n                break\n\n        return best_solution\n\n    def quantum_superposition(self, a, b, c, lb, ub):\n        # Generate random coefficients for quantum-inspired linear superposition\n        alpha, beta, gamma = np.random.rand(3)\n        total = alpha + beta + gamma\n        alpha, beta, gamma = alpha/total, beta/total, gamma/total\n        \n        # Create superposition of vectors a, b, c\n        superposed = alpha * a + beta * b + gamma * c\n        superposed += self.mutation_factor * (b - c)\n        \n        # Clip to bounds and return\n        return np.clip(superposed, lb, ub)", "name": "QuantumInspiredDE", "description": "A novel Quantum-inspired Differential Evolution (QDE) algorithm integrating quantum superposition concepts to enhance diversity and convergence speed in high-dimensional photonic structure optimization.", "configspace": "", "generation": 7, "fitness": 0.27775094667606703, "feedback": "The algorithm QuantumInspiredDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.27775094667606703]}, "mutation_prompt": null}
{"id": "82f38371-0242-4c2e-b20e-d665dd053fc5", "solution": "import numpy as np\n\nclass EnhancedHybridDE_PSO_GA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.mutation_rate = 0.1\n        self.mutation_strength = 0.1\n        self.velocity = np.zeros((self.population_size, dim))\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_personal = pop.copy()\n        best_personal_fitness = fitness.copy()\n\n        evaluations = self.population_size\n        inertia = self.inertia_max\n        \n        F = 0.5  # Differential Evolution mutation factor\n        CR = 0.7  # Crossover probability\n\n        while evaluations < self.budget:\n            inertia = self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n            \n            # Differential Evolution step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = np.clip(x1 + F * (x2 - x3), lb, ub)\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, pop[i])\n                trial_fitness = func(trial)\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(best_global):\n                        best_global = trial\n\n            # PSO Step\n            r1, r2 = np.random.rand(2)\n            self.velocity = (inertia * self.velocity +\n                             self.c1 * r1 * (best_personal - pop) +\n                             self.c2 * r2 * (best_global - pop))\n            pop += self.velocity\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate the new population\n            new_fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            # Update personal and global best\n            update_mask = new_fitness < best_personal_fitness\n            best_personal[update_mask] = pop[update_mask]\n            best_personal_fitness[update_mask] = new_fitness[update_mask]\n\n            if np.min(new_fitness) < func(best_global):\n                best_global = pop[np.argmin(new_fitness)]\n\n            # Adaptive mutation\n            avg_fitness = np.mean(new_fitness)\n            if np.min(new_fitness) < avg_fitness:\n                self.mutation_rate = max(0.01, self.mutation_rate * 0.9)\n                self.mutation_strength *= 0.9\n            else:\n                self.mutation_rate = min(0.2, self.mutation_rate * 1.1)\n                self.mutation_strength *= 1.1\n\n            # Apply genetic algorithm operators\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    pop[i] += np.random.normal(0, self.mutation_strength, self.dim)\n                    pop[i] = np.clip(pop[i], lb, ub)\n\n            # Save the history of best solutions\n            self.history.append(best_global)\n\n        return best_global", "name": "EnhancedHybridDE_PSO_GA", "description": "Enhanced hybrid algorithm integrating Differential Evolution with PSO and GA to improve convergence speed and solution precision by adaptively focusing on promising regions.", "configspace": "", "generation": 8, "fitness": 0.28089616519399296, "feedback": "The algorithm EnhancedHybridDE_PSO_GA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.28089616519399296]}, "mutation_prompt": null}
{"id": "56341d27-8668-4217-b3e1-482bebc464fd", "solution": "import numpy as np\n\nclass AdvancedHybridGA_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.mutation_rate = 0.1\n        self.mutation_strength = 0.1\n        self.velocity = np.zeros((self.population_size, dim))\n        self.history = []\n        self.chaos_factor = 0.5  # Initial value for chaotic sequence\n\n    def chaotic_map(self):\n        # Simple logistic map for chaotic sequence generation\n        self.chaos_factor = 4 * self.chaos_factor * (1 - self.chaos_factor)\n        return self.chaos_factor\n\n    def levy_flight(self, L, d):\n        # Lévy flight step size calculation\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, d)\n        v = np.random.normal(0, 1, d)\n        step = u / np.abs(v)**(1 / beta)\n        return L * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_personal = pop.copy()\n        best_personal_fitness = fitness.copy()\n\n        evaluations = self.population_size\n        inertia = self.inertia_max\n\n        while evaluations < self.budget:\n            inertia = (self.inertia_max - ((self.inertia_max - self.inertia_min) * \n                      (evaluations / self.budget)) * self.chaotic_map())\n\n            r1, r2 = np.random.rand(2)\n            self.velocity = (inertia * self.velocity +\n                             self.c1 * r1 * (best_personal - pop) +\n                             self.c2 * r2 * (best_global - pop))\n            pop += self.velocity\n            pop = np.clip(pop, lb, ub)\n\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            update_mask = fitness < best_personal_fitness\n            best_personal[update_mask] = pop[update_mask]\n            best_personal_fitness[update_mask] = fitness[update_mask]\n\n            if np.min(fitness) < func(best_global):\n                best_global = pop[np.argmin(fitness)]\n\n            avg_fitness = np.mean(fitness)\n            if np.min(fitness) < avg_fitness:\n                self.mutation_rate = max(0.01, self.mutation_rate * 0.9)\n                self.mutation_strength *= 0.9\n            else:\n                self.mutation_rate = min(0.2, self.mutation_rate * 1.1)\n                self.mutation_strength *= 1.1\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    pop[i] += np.random.normal(0, self.mutation_strength, self.dim)\n                    pop[i] = np.clip(pop[i], lb, ub)\n\n                if np.random.rand() < 0.1:\n                    L = 0.01  # Lévy flight scaling factor\n                    pop[i] += self.levy_flight(L, self.dim)\n                    pop[i] = np.clip(pop[i], lb, ub)\n\n            self.history.append(best_global)\n\n        return best_global", "name": "AdvancedHybridGA_PSO", "description": "An advanced hybrid GA-PSO with chaotic map-based parameter tuning for enhanced exploration and exploitation balance, incorporating Lévy flight for diverse solution generation.", "configspace": "", "generation": 9, "fitness": 0.28107603839097794, "feedback": "The algorithm AdvancedHybridGA_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.28107603839097794]}, "mutation_prompt": null}
{"id": "d53ada69-a0db-48ed-abdd-b0ecea6a10fb", "solution": "import numpy as np\n\nclass AdaptiveDE_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.temp_max = 1.0\n        self.temp_min = 0.1\n        self.temp = self.temp_max\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_global_fitness = np.min(fitness)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            temp_schedule = (self.temp_max - self.temp_min) * (1 - evaluations / self.budget) + self.temp_min\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = pop[a] + self.mutation_factor * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial_fitness = func(trial)\n\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / temp_schedule):\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n            evaluations += self.population_size\n\n            if np.min(fitness) < best_global_fitness:\n                best_global = pop[np.argmin(fitness)]\n                best_global_fitness = np.min(fitness)\n\n            self.history.append(best_global)\n\n        return best_global", "name": "AdaptiveDE_SA", "description": "A multi-objective optimization inspired by Differential Evolution and Simulated Annealing, incorporating adaptive temperature control and differential evolution to balance exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.2781112288256403, "feedback": "The algorithm AdaptiveDE_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.2781112288256403]}, "mutation_prompt": null}
{"id": "dceea88c-c561-4393-86b5-a3e9607ff6fc", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50  # Quantum bit individuals\n        self.quantum_prob = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.evaluations = 0\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        def evaluate_and_update(population):\n            fitness = np.array([func(x) for x in population])\n            min_fitness_idx = np.argmin(fitness)\n            nonlocal self\n            if fitness[min_fitness_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_fitness_idx]\n                self.best_solution = population[min_fitness_idx].copy()\n            return fitness\n\n        def generate_population():\n            population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            for i in range(self.population_size):\n                for j in range(self.dim):\n                    if np.random.rand() < abs(self.quantum_prob[i][j]):\n                        population[i][j] = ub[j]\n                    else:\n                        population[i][j] = lb[j]\n            return np.clip(population, lb, ub)\n\n        while self.evaluations < self.budget:\n            population = generate_population()\n            fitness = evaluate_and_update(population)\n            self.evaluations += self.population_size\n\n            # Adaptive quantum gate application\n            for i in range(self.population_size):\n                for j in range(self.dim):\n                    if np.random.rand() < 0.5:  # Adaptive decision influenced by solution quality\n                        theta = np.arccos(self.quantum_prob[i][j])\n                        if fitness[i] < np.mean(fitness):\n                            self.quantum_prob[i][j] = np.cos(theta + np.random.uniform(0, np.pi/4))\n                        else:\n                            self.quantum_prob[i][j] = np.cos(theta - np.random.uniform(0, np.pi/4))\n\n            # Record the history of best solutions\n            self.history.append(self.best_solution)\n\n        return self.best_solution", "name": "QuantumInspiredEA", "description": "Quantum-Inspired Evolutionary Algorithm (QEA) enhanced with adaptive quantum gate applications to dynamically balance exploration and exploitation.", "configspace": "", "generation": 11, "fitness": 0.26682585352532784, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.26682585352532784]}, "mutation_prompt": null}
{"id": "88d46e4c-cbb3-4b84-a57a-fe7bf6916cf9", "solution": "import numpy as np\n\nclass QuantumInspiredDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50  # Size of population\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.quantum_rotation_angle = np.pi / 4  # Quantum rotation angle\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            for i in range(self.population_size):\n                # Mutation operation\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = pop[a] + self.F * (pop[b] - pop[c])\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover operation\n                trial = np.copy(pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                # Evaluate the trial solution\n                f_trial = func(trial)\n                if f_trial < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = f_trial\n\n                # Quantum-inspired update using superposition principle\n                phi = self.quantum_rotation_angle\n                for d in range(self.dim):\n                    theta = np.random.rand() * 2 * np.pi\n                    if np.random.rand() < 0.5:\n                        new_pop[i, d] = pop[i, d] * np.cos(phi) + best_global[d] * np.sin(phi)\n                    else:\n                        new_pop[i, d] = pop[i, d] * np.cos(phi) - best_global[d] * np.sin(phi)\n\n                new_pop[i] = np.clip(new_pop[i], lb, ub)\n                fitness[i] = func(new_pop[i])\n                \n                # Update the global best\n                if fitness[i] < func(best_global):\n                    best_global = new_pop[i]\n\n            pop = new_pop\n            evaluations += self.population_size\n\n        return best_global", "name": "QuantumInspiredDE", "description": "Quantum-Inspired Differential Evolution (QIDE) utilizes quantum superposition principles with differential evolution strategies to enhance exploration and exploitation through a novel quantum rotation gate mechanism.", "configspace": "", "generation": 12, "fitness": 0.2796358300733096, "feedback": "The algorithm QuantumInspiredDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.2796358300733096]}, "mutation_prompt": null}
{"id": "7bbe15a9-fa66-4cb3-81c7-d5d67a990d2b", "solution": "import numpy as np\n\nclass MultiLevelAdaptive_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.mutation_rate = 0.1\n        self.mutation_strength = 0.1\n        self.velocity = np.zeros((self.population_size, dim))\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_personal = pop.copy()\n        best_personal_fitness = fitness.copy()\n\n        evaluations = self.population_size\n        inertia = self.inertia_max\n        temperature = 1.0  # Initial temperature for simulated annealing\n\n        while evaluations < self.budget:\n            # Update inertia\n            inertia = self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n            \n            # Update velocities and positions (PSO Step)\n            r1, r2 = np.random.rand(2)\n            self.velocity = (inertia * self.velocity +\n                             self.c1 * r1 * (best_personal - pop) +\n                             self.c2 * r2 * (best_global - pop))\n            pop += self.velocity\n            pop = np.clip(pop, lb, ub)\n\n            # Evaluate the new population\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            # Update personal and global best\n            update_mask = fitness < best_personal_fitness\n            best_personal[update_mask] = pop[update_mask]\n            best_personal_fitness[update_mask] = fitness[update_mask]\n\n            # Simulated Annealing based acceptance\n            for i in range(self.population_size):\n                delta = fitness[i] - func(best_global)\n                if delta < 0 or np.random.rand() < np.exp(-delta / temperature):\n                    best_global = pop[i]\n            \n            # Adaptive mutation based on fitness improvement\n            avg_fitness = np.mean(fitness)\n            if np.min(fitness) < avg_fitness:\n                self.mutation_rate = max(0.01, self.mutation_rate * 0.9)\n                self.mutation_strength *= 0.9\n            else:\n                self.mutation_rate = min(0.2, self.mutation_rate * 1.1)\n                self.mutation_strength *= 1.1\n\n            # Apply genetic algorithm operators\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    pop[i] += np.random.normal(0, self.mutation_strength, self.dim)\n                    pop[i] = np.clip(pop[i], lb, ub)\n\n            # Cooling schedule for simulated annealing\n            temperature *= 0.99\n\n            # Save the history of best solutions\n            self.history.append(best_global)\n\n        return best_global", "name": "MultiLevelAdaptive_Hybrid", "description": "Multi-level Adaptive Hybrid Algorithm combining Particle Swarm Optimization, Genetic Algorithm, and Simulated Annealing for enhanced exploration and exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.28095729373499456, "feedback": "The algorithm MultiLevelAdaptive_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.28095729373499456]}, "mutation_prompt": null}
{"id": "e5b1b758-e588-4a31-9738-7895dcf1a68f", "solution": "import numpy as np\n\nclass EnhancedHybridGA_PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive constant\n        self.c2 = 1.5  # Social constant\n        self.inertia_max = 0.9\n        self.inertia_min = 0.4\n        self.mutation_rate = 0.1\n        self.mutation_strength = 0.1\n        self.velocity = np.zeros((self.population_size, dim))\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_personal = pop.copy()\n        best_personal_fitness = fitness.copy()\n\n        evaluations = self.population_size\n        inertia = self.inertia_max\n        neighborhood_size = 5  # Consider a small neighborhood\n\n        while evaluations < self.budget:\n            inertia = self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n            r1, r2 = np.random.rand(2)\n\n            # Update velocities and positions (PSO Step)\n            for i in range(self.population_size):\n                # Select neighborhood\n                neighbors = np.random.choice(self.population_size, size=neighborhood_size, replace=False)\n                best_neighbor = pop[neighbors[np.argmin(fitness[neighbors])]]\n\n                # Neighborhood influence alongside global influence\n                self.velocity[i] = (inertia * self.velocity[i] +\n                                    self.c1 * r1 * (best_personal[i] - pop[i]) +\n                                    self.c2 * r2 * (best_global - pop[i]) +\n                                    self.c2 * r2 * (best_neighbor - pop[i]) * 0.5)\n\n            pop += self.velocity\n            pop = np.clip(pop, lb, ub)\n\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            # Update personal and global best\n            update_mask = fitness < best_personal_fitness\n            best_personal[update_mask] = pop[update_mask]\n            best_personal_fitness[update_mask] = fitness[update_mask]\n\n            if np.min(fitness) < func(best_global):\n                best_global = pop[np.argmin(fitness)]\n\n            avg_fitness = np.mean(fitness)\n            if np.min(fitness) < avg_fitness:\n                self.mutation_rate = max(0.01, self.mutation_rate * 0.9)\n                self.mutation_strength *= 0.9\n            else:\n                self.mutation_rate = min(0.2, self.mutation_rate * 1.1)\n                self.mutation_strength *= 1.1\n\n            # Apply genetic algorithm operators\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    pop[i] += np.random.normal(0, self.mutation_strength, self.dim)\n                    pop[i] = np.clip(pop[i], lb, ub)\n\n            self.history.append(best_global)\n\n        return best_global", "name": "EnhancedHybridGA_PSO", "description": "Incorporates a neighborhood-based learning mechanism within the hybrid GA-PSO framework to enhance convergence by leveraging local best solutions in addition to the global best.", "configspace": "", "generation": 14, "fitness": 0.28338668432846637, "feedback": "The algorithm EnhancedHybridGA_PSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.28338668432846637]}, "mutation_prompt": null}
{"id": "9424d5b0-466c-4c8e-bbbb-e34a48697bed", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.mutation_rate = 0.1\n        self.mutation_strength = 0.1\n        self.history = []\n        self.qubit_population = np.ones((self.population_size, self.dim, 2)) / np.sqrt(2)  # Initialize in superposition\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evaluations = 0\n        best_solution = None\n        best_fitness = np.inf\n\n        while evaluations < self.budget:\n            # Measure quantum population to get candidate solutions\n            pop = np.array([np.random.choice([lb[i], ub[i]], p=qubit[:, 0]**2) for qubit in self.qubit_population])\n\n            # Evaluate current population\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            # Update best solution\n            if best_solution is None or np.min(fitness) < best_fitness:\n                best_fitness = np.min(fitness)\n                best_solution = pop[np.argmin(fitness)]\n\n            # Calculate probabilities based on fitness improvement\n            avg_fitness = np.mean(fitness)\n            improvement = np.maximum(0, avg_fitness - best_fitness)\n            probability_update = improvement / (avg_fitness + 1e-8)\n\n            # Adaptive mutation based on improvement\n            self.mutation_rate = max(0.01, self.mutation_rate * (1 - probability_update))\n            self.mutation_strength = np.clip(self.mutation_strength * (1 + probability_update), 0.01, 1.0)\n\n            # Quantum Rotation based on success probability\n            for i in range(self.population_size):\n                angle_update = np.random.normal(0, self.mutation_strength, self.dim)\n                for j in range(self.dim):\n                    rotation_matrix = np.array([[np.cos(angle_update[j]), -np.sin(angle_update[j])],\n                                                [np.sin(angle_update[j]), np.cos(angle_update[j])]])\n                    self.qubit_population[i, j] = rotation_matrix @ self.qubit_population[i, j]\n\n            self.history.append(best_solution)\n\n        return best_solution", "name": "AdaptiveQuantumInspiredEA", "description": "Adaptive Quantum-Inspired Evolutionary Algorithm (AQIEA) that combines quantum superposition principles with adaptive mutation to enhance exploration and exploitation for global optimization.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"cannot access free variable 'i' where it is not associated with a value in enclosing scope\").", "error": "NameError(\"cannot access free variable 'i' where it is not associated with a value in enclosing scope\")", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {}, "mutation_prompt": null}
{"id": "d4ca7515-35ef-4405-9541-8218ef520e1d", "solution": "import numpy as np\n\nclass ReinforcementLearningDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.mutation_strategies = [0.5, 0.7, 1.0]\n        self.strategy_probs = np.ones(len(self.mutation_strategies)) / len(self.mutation_strategies)\n        self.cross_prob = 0.7\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx].copy()\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n            new_fitness = np.zeros(self.population_size)\n\n            for i in range(self.population_size):\n                # Select mutation strategy using RL policy-based probabilities\n                strategy_idx = np.random.choice(len(self.mutation_strategies), p=self.strategy_probs)\n                F = self.mutation_strategies[strategy_idx]\n\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.cross_prob\n                trial = np.where(crossover_mask, mutant, pop[i])\n\n                # Evaluate trial vector\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    new_fitness[i] = trial_fitness\n                    # Reward the chosen strategy\n                    self.strategy_probs[strategy_idx] += 0.1\n                else:\n                    new_pop[i] = pop[i]\n                    new_fitness[i] = fitness[i]\n\n            # Normalize strategy probabilities\n            self.strategy_probs /= np.sum(self.strategy_probs)\n\n            # Update population and fitness\n            pop, fitness = new_pop, new_fitness\n\n            # Update global best\n            best_idx = np.argmin(fitness)\n            if fitness[best_idx] < func(best_global):\n                best_global = pop[best_idx].copy()\n\n            # Save the history of best solutions\n            self.history.append(best_global)\n\n        return best_global", "name": "ReinforcementLearningDE", "description": "Reinforcement Learning-enhanced Differential Evolution (RL-DE) that dynamically adjusts mutation strategies based on past performance to improve exploration and exploitation.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('probabilities do not sum to 1').", "error": "ValueError('probabilities do not sum to 1')", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {}, "mutation_prompt": null}
{"id": "d887a38c-275d-4748-92b6-d2fb690c3d77", "solution": "import numpy as np\n\nclass EnhancedHybridGA_PSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50  # Size of population\n        self.c1 = 1.5  # Cognitive constant\n        self.c2 = 1.5  # Social constant\n        self.inertia_max = 0.9  # Maximum inertia weight\n        self.inertia_min = 0.4  # Minimum inertia weight\n        self.mutation_rate = 0.1  # Initial mutation rate for GA\n        self.mutation_strength = 0.1  # Initial mutation strength\n        self.cr = 0.9  # Crossover rate for DE\n        self.F = 0.8  # Differential weight\n        self.velocity = np.zeros((self.population_size, dim))\n        self.history = []  # Keep track of best solutions\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_global = pop[np.argmin(fitness)]\n        best_personal = pop.copy()\n        best_personal_fitness = fitness.copy()\n\n        evaluations = self.population_size\n        inertia = self.inertia_max\n\n        while evaluations < self.budget:\n            # Dynamically update inertia\n            inertia = self.inertia_max - ((self.inertia_max - self.inertia_min) * (evaluations / self.budget))\n            \n            # Update velocities and positions (PSO Step)\n            r1, r2 = np.random.rand(2)\n            self.velocity = (inertia * self.velocity +\n                             self.c1 * r1 * (best_personal - pop) +\n                             self.c2 * r2 * (best_global - pop))\n            pop += self.velocity\n            pop = np.clip(pop, lb, ub)\n\n            # Apply Differential Evolution operators\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, lb, ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                if func(trial) < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = func(trial)\n\n            # Evaluate the new population\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            # Update personal and global best\n            update_mask = fitness < best_personal_fitness\n            best_personal[update_mask] = pop[update_mask]\n            best_personal_fitness[update_mask] = fitness[update_mask]\n\n            if np.min(fitness) < func(best_global):\n                best_global = pop[np.argmin(fitness)]\n\n            # Adaptive mutation based on fitness improvement\n            avg_fitness = np.mean(fitness)\n            if np.min(fitness) < avg_fitness:\n                self.mutation_rate = max(0.01, self.mutation_rate * 0.9)\n                self.mutation_strength *= 0.9\n            else:\n                self.mutation_rate = min(0.2, self.mutation_rate * 1.1)\n                self.mutation_strength *= 1.1\n\n            # Apply genetic algorithm operators\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    pop[i] += np.random.normal(0, self.mutation_strength, self.dim)\n                    pop[i] = np.clip(pop[i], lb, ub)\n\n            # Save the history of best solutions\n            self.history.append(best_global)\n\n        return best_global", "name": "EnhancedHybridGA_PSO_DE", "description": "An enhanced hybrid algorithm combining Genetic Algorithm, Particle Swarm Optimization, and Differential Evolution with adaptive techniques for mutation, crossover, and inertia weight to improve convergence speed and solution quality.", "configspace": "", "generation": 17, "fitness": 0.28251839339105, "feedback": "The algorithm EnhancedHybridGA_PSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.28251839339105]}, "mutation_prompt": null}
{"id": "85015545-def6-4f46-abd5-9802cd8b992d", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize quantum bits\n        qbits = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Measure population from quantum bits\n            pop = np.sign(np.random.uniform(-1, 1, (self.population_size, self.dim))) * qbits\n            pop = np.clip(pop, lb, ub)\n            fitness = np.array([func(x) for x in pop])\n            evaluations += self.population_size\n\n            # Update best solution\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < self.best_fitness:\n                self.best_fitness = fitness[min_idx]\n                self.best_solution = pop[min_idx]\n\n            # Adaptive quantum rotation gates\n            avg_fitness = np.mean(fitness)\n            rotation_angles = 0.1 * np.pi * (fitness - avg_fitness) / (np.max(fitness) - avg_fitness + 1e-9)\n            qbits += rotation_angles[:, np.newaxis] * np.sign(pop - self.best_solution)\n\n            # Dynamic population control\n            diversity = np.mean(np.std(pop, axis=0))\n            if diversity < 0.1:\n                qbits = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n            # Save the history of best solutions\n            self.history.append(self.best_solution)\n        \n        return self.best_solution", "name": "QuantumInspiredEA", "description": "Quantum-Inspired Evolutionary Algorithm with Adaptive Quantum Rotation Gates and Dynamic Population Control for Enhanced Exploration and Exploitation. ", "configspace": "", "generation": 18, "fitness": 0.2664968712099389, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.2664968712099389]}, "mutation_prompt": null}
{"id": "206fea15-a190-4289-9ef3-6128dffd14da", "solution": "import numpy as np\n\nclass MSADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5   # Scaling factor\n        self.CR = 0.9  # Crossover rate\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                if np.random.rand() < 0.5:\n                    # DE/rand/1 strategy\n                    mutant = x0 + self.F * (x1 - x2)\n                else:\n                    # DE/best/1 strategy\n                    mutant = best_global + self.F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "MSADE", "description": "Multi-Strategy Adaptive Differential Evolution (MSADE) uses a dynamic selection of mutation strategies and adaptive control of parameters to enhance convergence and diversity.", "configspace": "", "generation": 19, "fitness": 0.28513638532285734, "feedback": "The algorithm MSADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "526784df-7d81-49d4-8cd7-168c6f2df0b5", "metadata": {"aucs": [0.28513638532285734]}, "mutation_prompt": null}
{"id": "1a8a0f8d-3ee0-4aff-a25d-41dd98d2613e", "solution": "import numpy as np\n\nclass EMSADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9  # Dynamic scaling factor range\n        self.CR = 0.9  # Crossover rate\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.initial_population_size\n        population_size = self.initial_population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            F = self.F_min + (self.F_max - self.F_min) * (1 - evaluations / self.budget)\n\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                if np.random.rand() < 0.5:\n                    # DE/rand/1 strategy\n                    mutant = x0 + F * (x1 - x2)\n                else:\n                    # DE/best/1 strategy\n                    mutant = best_global + F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            # Update population size adaptively\n            population_size = int(self.initial_population_size * (1 - evaluations / self.budget))\n            population_size = max(10, population_size)  # Ensure a minimum population size\n\n            pop = next_pop[:population_size]\n            fitness = fitness[:population_size]\n            self.history.append(best_global)\n\n        return best_global", "name": "EMSADE", "description": "Enhanced Multi-Strategy Differential Evolution (EMSADE) leverages adaptive population size and dynamic scaling to boost exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.284271705461848, "feedback": "The algorithm EMSADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "206fea15-a190-4289-9ef3-6128dffd14da", "metadata": {"aucs": [0.284271705461848]}, "mutation_prompt": null}
{"id": "03768e2c-3ee2-4a14-8906-d890252a468a", "solution": "import numpy as np\n\nclass DNPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.9\n        self.cognitive_component = 2.0\n        self.social_component = 2.0\n        self.max_velocity = 0.1 * (func.bounds.ub - func.bounds.lb)\n        self.min_velocity = -self.max_velocity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(self.min_velocity, self.max_velocity, (self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_fitness = np.array([func(x) for x in personal_best_positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_fitness)]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i, particle in enumerate(pop):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (\n                    self.inertia_weight * velocities[i]\n                    + self.cognitive_component * r1 * (personal_best_positions[i] - particle)\n                    + self.social_component * r2 * (global_best_position - particle)\n                )\n                velocities[i] = np.clip(velocities[i], self.min_velocity, self.max_velocity)\n\n                pop[i] = np.clip(particle + velocities[i], lb, ub)\n                current_fitness = func(pop[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = pop[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < np.min(personal_best_fitness):\n                        global_best_position = pop[i]\n\n            self.inertia_weight = max(0.4, 0.9 - 0.5 * (evaluations / self.budget))\n        \n        return global_best_position", "name": "DNPSO", "description": "Dynamic Neighborhood Particle Swarm Optimization (DNPSO) adaptively adjusts neighborhood structures and inertia weight for enhanced exploration and exploitation in high-dimensional search spaces.", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "206fea15-a190-4289-9ef3-6128dffd14da", "metadata": {}, "mutation_prompt": null}
{"id": "602b92e2-7c88-417a-8f97-38c22749ae4b", "solution": "import numpy as np\n\nclass QIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.alpha = 0.75  # Coefficient of the quantum potential\n        self.best_global = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best = np.copy(particles)\n        personal_best_fitness = np.array([func(p) for p in particles])\n        best_idx = np.argmin(personal_best_fitness)\n        self.best_global = personal_best[best_idx]\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = r1 * velocities[i] + r2 * (self.best_global - particles[i])\n\n                # Apply Quantum-inspired update\n                quantum_potential = np.random.normal(0, self.alpha, self.dim)\n                particles[i] += 0.5 * velocities[i] + quantum_potential\n\n                particles[i] = np.clip(particles[i], lb, ub)\n\n                fitness = func(particles[i])\n                evaluations += 1\n\n                if fitness < personal_best_fitness[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_fitness[i] = fitness\n\n                    if fitness < personal_best_fitness[best_idx]:\n                        best_idx = i\n                        self.best_global = personal_best[best_idx]\n\n        return self.best_global", "name": "QIPSO", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) integrates quantum computing principles with particle dynamics to enhance exploration and convergence in complex landscapes.", "configspace": "", "generation": 22, "fitness": 0.2828009702397829, "feedback": "The algorithm QIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "206fea15-a190-4289-9ef3-6128dffd14da", "metadata": {"aucs": [0.2828009702397829]}, "mutation_prompt": null}
{"id": "9a939a99-f2c9-4f90-9cf7-807d1f03fe72", "solution": "import numpy as np\n\nclass EMSADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.F = 0.5   # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n        \n        evaluations = self.initial_population_size\n        population_size = self.initial_population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            \n            # Dynamically adjust population size\n            if evaluations % (self.budget // 5) == 0:\n                population_size = max(5, population_size // 2)\n                pop = pop[:population_size]\n                fitness = fitness[:population_size]\n                next_pop = next_pop[:population_size]\n\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n\n                # Adaptive mutation strategy\n                if np.random.rand() < 0.5:\n                    mutant = x0 + self.F * (x1 - x2)\n                else:\n                    mutant = best_global + self.F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n                    \n            # Dynamic adaptive control of parameters\n            success_rate = np.count_nonzero(fitness < np.min(fitness)) / float(population_size)\n            self.F = 0.5 + 0.3 * success_rate\n            self.CR = 0.9 - 0.3 * success_rate\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "EMSADE", "description": "Enhanced Multi-Strategy Adaptive Differential Evolution (EMSADE) integrates adaptive mutation strategies with dynamic population size adjustment for improved convergence and diversity.", "configspace": "", "generation": 23, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 35 is out of bounds for axis 0 with size 25').", "error": "IndexError('index 35 is out of bounds for axis 0 with size 25')", "parent_id": "206fea15-a190-4289-9ef3-6128dffd14da", "metadata": {}, "mutation_prompt": null}
{"id": "41098edf-0078-40fc-bedf-53d7474d6a8b", "solution": "import numpy as np\n\nclass EMSADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_base = 0.5\n        self.CR_base = 0.9\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                # Adaptive parameter adjustment\n                F = self.F_base + np.random.rand() * 0.3  # F ranges from 0.5 to 0.8\n                CR = max(self.CR_base - np.std(fitness) / np.mean(fitness), 0.1)  # dynamic CR based on population diversity\n\n                if np.random.rand() < 0.5:\n                    # DE/rand/1 strategy\n                    mutant = x0 + F * (x1 - x2)\n                else:\n                    # DE/best/1 strategy\n                    mutant = best_global + F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            # Diversity mechanism\n            if evaluations % (self.population_size * 10) == 0:\n                diversity_metric = np.std(pop, axis=0)\n                if np.min(diversity_metric) < 1e-3:  # if diversity is too low\n                    pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    fitness = np.array([func(x) for x in pop])\n                    best_idx = np.argmin(fitness)\n                    best_global = pop[best_idx]\n                    evaluations += self.population_size\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "EMSADE", "description": "Enhanced Multi-Strategy Adaptive Differential Evolution (EMSADE) employs adaptive parameter tuning and a diversity mechanism to balance exploration and exploitation, improving convergence on complex landscapes.", "configspace": "", "generation": 24, "fitness": 0.2846851004751665, "feedback": "The algorithm EMSADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "206fea15-a190-4289-9ef3-6128dffd14da", "metadata": {"aucs": [0.2846851004751665]}, "mutation_prompt": null}
{"id": "2545457a-dc71-48a5-8792-89eaa409ebec", "solution": "import numpy as np\n\nclass QIPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.global_best = None\n        self.global_best_fitness = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.zeros_like(positions)\n        personal_best = positions.copy()\n        personal_best_fitness = np.array([func(x) for x in personal_best])\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - positions[i]) +\n                                 self.c2 * r2 * (self.global_best - positions[i] if self.global_best is not None else np.zeros(self.dim)))\n\n                # Quantum-inspired exploration: apply random phase shifts\n                quantum_shift = np.random.uniform(-np.pi, np.pi, self.dim)\n                quantum_positions = positions[i] + np.sin(quantum_shift) * (ub - lb)\n                quantum_positions = np.clip(quantum_positions, lb, ub)\n\n                # Evaluate both classical and quantum positions\n                trial_fitness = func(quantum_positions)\n                evaluations += 1\n\n                if trial_fitness < personal_best_fitness[i]:\n                    personal_best[i] = quantum_positions\n                    personal_best_fitness[i] = trial_fitness\n\n                if trial_fitness < self.global_best_fitness:\n                    self.global_best = quantum_positions\n                    self.global_best_fitness = trial_fitness\n\n                # Update position\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n        return self.global_best", "name": "QIPSO", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) leverages quantum superposition principles to enhance exploration and maintain diversity, optimizing convergence speed and solution quality.", "configspace": "", "generation": 25, "fitness": 0.2750963845051667, "feedback": "The algorithm QIPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "206fea15-a190-4289-9ef3-6128dffd14da", "metadata": {"aucs": [0.2750963845051667]}, "mutation_prompt": null}
{"id": "97994ee6-a306-4b5d-b155-e64e49aa15ac", "solution": "import numpy as np\n\nclass PSO_QIM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5 # cognitive coefficient\n        self.c2 = 1.5 # social coefficient\n        self.mutation_prob = 0.1\n        self.history = []\n\n    def quantum_mutation(self, particle, lb, ub):\n        alpha = np.random.uniform(0, 1, self.dim)\n        beta = np.random.uniform(0, 1, self.dim)\n        mutated = lb + (ub - lb) * alpha * np.sin(2 * np.pi * beta)\n        return np.clip(mutated, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(pop)\n        personal_best_fitness = np.array([func(x) for x in pop])\n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], lb, ub)\n\n                if np.random.rand() < self.mutation_prob:\n                    pop[i] = self.quantum_mutation(pop[i], lb, ub)\n\n                fitness = func(pop[i])\n                evaluations += 1\n\n                if fitness < personal_best_fitness[i]:\n                    personal_best[i] = pop[i]\n                    personal_best_fitness[i] = fitness\n\n            global_best_idx = np.argmin(personal_best_fitness)\n            global_best = personal_best[global_best_idx]\n            self.history.append(global_best)\n\n        return global_best", "name": "PSO_QIM", "description": "Particle Swarm Optimization with Quantum-Inspired Mutation (PSO-QIM) explores the search space with particle swarms and introduces quantum-inspired mutation to enhance diversity and convergence speed.", "configspace": "", "generation": 26, "fitness": 0.28158560329363247, "feedback": "The algorithm PSO_QIM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "206fea15-a190-4289-9ef3-6128dffd14da", "metadata": {"aucs": [0.28158560329363247]}, "mutation_prompt": null}
{"id": "265e5bf9-e946-4c49-b9f3-8ee0af930108", "solution": "import numpy as np\n\nclass QIEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.alpha = 0.5  # angle of quantum rotation\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Initialize quantum bits with equal probability of being 0 or 1\n        q_population = np.random.rand(self.population_size, self.dim, 2)\n        q_population /= np.linalg.norm(q_population, axis=2, keepdims=True)\n\n        pop = self.measure(q_population, lb, ub)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_q_population = np.zeros_like(q_population)\n            next_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                # Quantum rotation gate mechanism\n                delta_theta = self.alpha * (np.random.rand(self.dim) - 0.5)\n                rotation_matrix = np.array([[np.cos(delta_theta), -np.sin(delta_theta)],\n                                            [np.sin(delta_theta), np.cos(delta_theta)]])\n\n                # Update quantum bit representation\n                rotated_q_bits = q_population[i] @ rotation_matrix\n                next_q_population[i] = rotated_q_bits / np.linalg.norm(rotated_q_bits, axis=1, keepdims=True)\n\n                # Measure to get candidate solution\n                candidate = self.measure(next_q_population[i][np.newaxis, ...], lb, ub).flatten()\n                candidate_fitness = func(candidate)\n                evaluations += 1\n\n                if candidate_fitness < fitness[i]:\n                    next_pop[i] = candidate\n                    fitness[i] = candidate\n                    if candidate_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = candidate\n                else:\n                    next_pop[i] = pop[i]\n\n            q_population = next_q_population\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global\n\n    def measure(self, q_population, lb, ub):\n        # Measure quantum bits to obtain classical solutions\n        binary_representation = np.random.rand(*q_population.shape[:-1]) < q_population[..., 0]\n        return lb + (ub - lb) * (binary_representation / (2**np.arange(self.dim)))\n", "name": "QIEA", "description": "Quantum-Inspired Evolutionary Algorithm (QIEA) uses quantum bit representation and quantum-inspired operators to explore and exploit the search space efficiently.", "configspace": "", "generation": 27, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (2,10,10) into shape (10,2)').", "error": "ValueError('could not broadcast input array from shape (2,10,10) into shape (10,2)')", "parent_id": "206fea15-a190-4289-9ef3-6128dffd14da", "metadata": {}, "mutation_prompt": null}
{"id": "96f87d61-2692-442a-b272-a732ce963215", "solution": "import numpy as np\n\nclass EMSDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5   # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.success_rates = [0.5, 0.5] # To track success of strategies\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]  # To track the number of successes for each strategy\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                # Select strategy based on success rates\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    mutant = x0 + self.F * (x1 - x2)  # DE/rand/1 strategy\n                else:\n                    mutant = best_global + self.F * (x1 - x2)  # DE/best/1 strategy\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            # Update success rates for strategies\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            # Adapt F and CR based on success or failure\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "EMSDE", "description": "Enhanced Multi-Strategy Adaptive Differential Evolution (EMSDE) integrates adaptive learning of parameter F and CR based on success rates to improve convergence speed and solution quality.", "configspace": "", "generation": 28, "fitness": 0.2853787596362145, "feedback": "The algorithm EMSDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "206fea15-a190-4289-9ef3-6128dffd14da", "metadata": {"aucs": [0.2853787596362145]}, "mutation_prompt": null}
{"id": "78b8ea6c-4aea-470f-918c-e6beb55379a9", "solution": "import numpy as np\n\nclass ASDDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.F = 0.5   # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.success_rates = [0.5, 0.5] # To track success of strategies\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            population_size = int(self.initial_population_size * (1 - evaluations / self.budget))\n            next_pop = np.zeros((population_size, self.dim))\n            successes = [0, 0]  # To track the number of successes for each strategy\n\n            for i in range(population_size):\n                indices = np.random.choice(range(self.initial_population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                # Select strategy based on success rates\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    mutant = x0 + self.F * (x1 - x2)  # DE/rand/1 strategy\n                else:\n                    mutant = best_global + self.F * (x1 - x2)  # DE/best/1 strategy\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            # Update success rates for strategies\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            # Adapt F and CR based on success or failure\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n\n            # Reduce the population size over time for intensification\n            self.initial_population_size = population_size\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "ASDDE", "description": "Adaptive Success-Driven Differential Evolution (ASDDE) introduces dynamic adjustment of population size and employs adaptive parameter control based on success metrics to enhance exploration-exploitation balance.", "configspace": "", "generation": 29, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "96f87d61-2692-442a-b272-a732ce963215", "metadata": {}, "mutation_prompt": null}
{"id": "233a10ba-cf8d-4498-9900-3e4800bf44f1", "solution": "import numpy as np\n\nclass QIGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.alpha = 0.02  # Rotation angle for quantum gate\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        q_population = np.random.uniform(0, np.pi, (self.population_size, self.dim))\n        evaluations = 0\n\n        def decode(q_individual):\n            return lb + (ub - lb) * (np.sin(q_individual) ** 2)\n        \n        def evaluate_population(q_pop):\n            return np.array([func(decode(q_individual)) for q_individual in q_pop])\n        \n        fitness = evaluate_population(q_population)\n        best_idx = np.argmin(fitness)\n        best_global = decode(q_population[best_idx])\n\n        evaluations += self.population_size\n\n        while evaluations < self.budget:\n            next_q_population = np.zeros_like(q_population)\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 2, replace=False)\n                parent1, parent2 = q_population[indices]\n\n                # Quantum crossover (average of quantum states)\n                child = (parent1 + parent2) / 2\n                \n                # Quantum mutation (rotation gate)\n                rotation = self.alpha * (np.random.rand(self.dim) - 0.5)\n                child = (child + rotation) % np.pi\n                \n                # Decode and evaluate\n                decoded_child = decode(child)\n                child_fitness = func(decoded_child)\n                evaluations += 1\n\n                # Selection: replace if better\n                if child_fitness < fitness[i]:\n                    next_q_population[i] = child\n                    fitness[i] = child_fitness\n                    if child_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = decoded_child\n                else:\n                    next_q_population[i] = q_population[i]\n\n            q_population = next_q_population\n            self.history.append(best_global)\n\n        return best_global", "name": "QIGA", "description": "Quantum-Inspired Genetic Algorithm (QIGA) leverages quantum bit representation and rotation gates to enhance exploration and avoid local optima in complex search spaces.", "configspace": "", "generation": 30, "fitness": 0.281444607950202, "feedback": "The algorithm QIGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "96f87d61-2692-442a-b272-a732ce963215", "metadata": {"aucs": [0.281444607950202]}, "mutation_prompt": null}
{"id": "a0b84468-1232-40c0-8fa2-b68eb1c1fbcd", "solution": "import numpy as np\n\nclass DualAdaptationDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5   # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.success_rates = [0.5, 0.5]  # To track success of strategies\n        self.history = []\n        self.diversity_factor = 0.2  # Initial diversity factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]  # To track the number of successes for each strategy\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                # Select strategy based on success rates\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    # Introduce diversity by adding random noise\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mutant = x0 + self.F * (x1 - x2) + noise  # DE/rand/1 strategy with noise\n                else:\n                    mutant = best_global + self.F * (x1 - x2)  # DE/best/1 strategy\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            # Update success rates for strategies\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            # Adapt F, CR, and diversity factor based on success or failure\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "DualAdaptationDE", "description": "Dual-Adaptation Differential Evolution optimizes convergence by dynamically adapting both mutation strategy and population diversity using a dual adaptation mechanism.", "configspace": "", "generation": 31, "fitness": 0.2881172659833581, "feedback": "The algorithm DualAdaptationDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "96f87d61-2692-442a-b272-a732ce963215", "metadata": {"aucs": [0.2881172659833581]}, "mutation_prompt": null}
{"id": "fe1a9556-94b5-4186-9526-09d18e218039", "solution": "import numpy as np\n\nclass AdaptiveQuantumDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5   # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.success_rates = [0.5, 0.5]  # To track success of strategies\n        self.history = []\n        self.diversity_factor = 0.2  # Initial diversity factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]  # To track the number of successes for each strategy\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                # Select strategy based on success rates\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    # Quantum-inspired mechanism to diversify population\n                    angle = np.random.uniform(0, 2 * np.pi, self.dim)\n                    noise = self.diversity_factor * np.cos(angle) * (ub - lb) * 0.5\n                    mutant = x0 + self.F * (x1 - x2) + noise  # Quantum-inspired mutation\n                else:\n                    # Adaptive DE/best/1 strategy\n                    adaptive_factor = (1 - self.success_rates[1]) * 0.5\n                    mutant = best_global + adaptive_factor * self.F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            # Update success rates for strategies\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            # Adapt F, CR, and diversity factor based on success or failure\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "AdaptiveQuantumDE", "description": "Adaptive Quantum-Inspired Differential Evolution enhances exploration and exploitation by integrating quantum-inspired mechanisms and adaptive strategies for mutation and crossover operations.", "configspace": "", "generation": 32, "fitness": 0.28626834457428185, "feedback": "The algorithm AdaptiveQuantumDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "a0b84468-1232-40c0-8fa2-b68eb1c1fbcd", "metadata": {"aucs": [0.28626834457428185]}, "mutation_prompt": null}
{"id": "7a36f82b-abd8-4300-a8de-bf3fd8403b61", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.eta = 0.1  # quantum movement factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        personal_best = pop.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = pop[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best - pop[i]))\n\n                # Add quantum inspired movement\n                quantum_move = self.eta * np.random.normal(size=self.dim) * np.sign(global_best - pop[i])\n                new_position = pop[i] + velocities[i] + quantum_move\n                new_position = np.clip(new_position, lb, ub)\n\n                new_fitness = func(new_position)\n                evaluations += 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best[i] = new_position\n                    personal_best_fitness[i] = new_fitness\n\n                    if new_fitness < personal_best_fitness[global_best_idx]:\n                        global_best_idx = i\n                        global_best = new_position\n\n                pop[i] = new_position\n\n        return global_best", "name": "QuantumInspiredPSO", "description": "Quantum-inspired Particle Swarm Optimization enhances exploration and exploitation by integrating quantum movements with dynamic social learning.", "configspace": "", "generation": 33, "fitness": 0.2877100759686293, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "a0b84468-1232-40c0-8fa2-b68eb1c1fbcd", "metadata": {"aucs": [0.2877100759686293]}, "mutation_prompt": null}
{"id": "f0dd91a7-fb9a-4c6f-975b-70ce9f5b0f4b", "solution": "import numpy as np\n\nclass QIPSO_AI:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.9  # Initial inertia weight\n        self.w_min = 0.4\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        p_best = pop.copy()\n        p_best_fitness = fitness.copy()\n        g_best_idx = np.argmin(fitness)\n        g_best = pop[g_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update particle velocity and position\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (p_best[i] - pop[i]) +\n                                 self.c2 * r2 * (g_best - pop[i]))\n\n                # Quantum-inspired position update\n                new_position = pop[i] + velocities[i] + np.random.randn(self.dim) * 0.1\n                new_position = np.clip(new_position, lb, ub)\n\n                new_fitness = func(new_position)\n                evaluations += 1\n\n                # Update personal best and global best\n                if new_fitness < p_best_fitness[i]:\n                    p_best[i] = new_position\n                    p_best_fitness[i] = new_fitness\n                    if new_fitness < fitness[g_best_idx]:\n                        g_best_idx = i\n                        g_best = new_position\n\n                pop[i] = new_position\n\n            # Adapt inertia weight\n            self.w = max(self.w_min, self.w - 0.001)\n\n        return g_best", "name": "QIPSO_AI", "description": "Quantum-Inspired Particle Swarm Optimization with Adaptive Inertia (QIPSO-AI) leverages a quantum-inspired particle position update and dynamically adapts inertia weight to balance exploration and exploitation.", "configspace": "", "generation": 34, "fitness": 0.277699802810757, "feedback": "The algorithm QIPSO_AI got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a0b84468-1232-40c0-8fa2-b68eb1c1fbcd", "metadata": {"aucs": [0.277699802810757]}, "mutation_prompt": null}
{"id": "a12ff75f-8db9-4f82-8970-576d8fee9766", "solution": "import numpy as np\n\nclass QuantumInspiredDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5  # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.alpha = np.pi / 4  # Initial quantum rotation angle\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n\n                # Quantum-inspired rotation\n                theta = self.alpha * np.random.uniform(-1, 1, self.dim)\n                quantum_mutant = x0 + self.F * (x1 - x2) * np.cos(theta) + np.sin(theta) * (best_global - x0)\n\n                # Quantum crossover\n                r = np.random.rand(self.dim)\n                quantum_trial = np.where(r < self.CR, quantum_mutant, pop[i])\n                quantum_trial = np.clip(quantum_trial, lb, ub)\n                quantum_fitness = func(quantum_trial)\n                evaluations += 1\n\n                if quantum_fitness < fitness[i]:\n                    next_pop[i] = quantum_trial\n                    fitness[i] = quantum_fitness\n                    if quantum_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = quantum_trial\n                else:\n                    next_pop[i] = pop[i]\n\n            # Adapt F and CR\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n            # Adapt quantum rotation angle\n            self.alpha = np.clip(self.alpha + 0.05 * (np.random.rand() - 0.5), np.pi/6, np.pi/3)\n\n            pop = next_pop\n\n        return best_global", "name": "QuantumInspiredDE", "description": "Quantum-Inspired DE uses quantum principles to enhance exploration by generating candidate solutions in a probabilistic manner with quantum-based rotation and crossover.", "configspace": "", "generation": 35, "fitness": 0.2806229318922375, "feedback": "The algorithm QuantumInspiredDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a0b84468-1232-40c0-8fa2-b68eb1c1fbcd", "metadata": {"aucs": [0.2806229318922375]}, "mutation_prompt": null}
{"id": "60f7365a-0ceb-412a-9616-5706dede3f93", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.alpha = 0.1  # Quantum parameter for enhanced exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(personal_best_fitness)\n        best_global_position = personal_best_positions[best_idx]\n        best_global_fitness = personal_best_fitness[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities and positions using quantum inspired approach\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity_cognitive = self.c1 * r1 * (personal_best_positions[i] - pop[i])\n                velocity_social = self.c2 * r2 * (best_global_position - pop[i])\n                quantum_step = self.alpha * (np.random.rand(self.dim) * 2 - 1)\n                velocities[i] = self.w * velocities[i] + velocity_cognitive + velocity_social + quantum_step\n                \n                # Update position\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], lb, ub)\n                \n                # Evaluate fitness\n                current_fitness = func(pop[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = pop[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    # Update global best\n                    if current_fitness < best_global_fitness:\n                        best_global_position = pop[i]\n                        best_global_fitness = current_fitness\n\n            # Adaptive inertia weight for convergence refinement\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)\n\n        return best_global_position", "name": "QuantumInspiredPSO", "description": "Quantum-inspired Particle Swarm Optimization uses quantum behavior of particles for enhanced exploration and adaptive convergence control for exploitation.", "configspace": "", "generation": 36, "fitness": 0.2792417856473385, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a0b84468-1232-40c0-8fa2-b68eb1c1fbcd", "metadata": {"aucs": [0.2792417856473385]}, "mutation_prompt": null}
{"id": "a81e7e86-70bc-45ef-8639-1bda1f35c6ad", "solution": "import numpy as np\n\nclass QuantumInspiredEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.rotation_angle = 0.1\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        quantum_pop = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = self.quantum_to_real(quantum_pop, lb, ub)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_quantum_pop = np.zeros_like(quantum_pop)\n\n            for i in range(self.population_size):\n                # Select partner for quantum rotation\n                partner_indices = list(range(self.population_size))\n                partner_indices.remove(i)\n                partner_idx = np.random.choice(partner_indices)\n                partner = quantum_pop[partner_idx]\n\n                # Calculate rotation direction\n                direction = np.sign(partner - quantum_pop[i])\n\n                # Apply quantum rotation\n                next_quantum_pop[i] = quantum_pop[i] + direction * self.rotation_angle\n                next_quantum_pop[i] = np.clip(next_quantum_pop[i], 0, 1)\n\n            # Convert quantum population to real values\n            next_pop = self.quantum_to_real(next_quantum_pop, lb, ub)\n            next_fitness = np.array([func(x) for x in next_pop])\n            evaluations += self.population_size\n\n            # Select survivors\n            for i in range(self.population_size):\n                if next_fitness[i] < fitness[i]:\n                    fitness[i] = next_fitness[i]\n                    quantum_pop[i] = next_quantum_pop[i]\n                    if next_fitness[i] < fitness[best_idx]:\n                        best_idx = i\n                        best_global = next_pop[i]\n\n            self.history.append(best_global)\n\n        return best_global\n\n    def quantum_to_real(self, quantum_pop, lb, ub):\n        scale = ub - lb\n        return lb + quantum_pop * scale", "name": "QuantumInspiredEA", "description": "Quantum-Inspired Evolutionary Algorithm (QIEA) leverages quantum-inspired representation and rotation gates to enhance population diversity and accelerate the convergence in optimization.", "configspace": "", "generation": 37, "fitness": 0.2819324963093891, "feedback": "The algorithm QuantumInspiredEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a0b84468-1232-40c0-8fa2-b68eb1c1fbcd", "metadata": {"aucs": [0.2819324963093891]}, "mutation_prompt": null}
{"id": "06137397-9a99-4c9e-aae9-9694fae0052f", "solution": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5   # Initial scaling factor\n        self.CR = 0.9  # Initial crossover rate\n        self.success_history = [0.5, 0.5, 0.5]  # Three strategies\n        self.diversity_factor = 0.2  # Initial diversity factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0, 0]  # Successes for each strategy\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                # Select strategy based on success history\n                strategy = np.random.choice([0, 1, 2], p=np.array(self.success_history) / sum(self.success_history))\n                if strategy == 0:\n                    # DE/rand/1 with noise\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mutant = x0 + self.F * (x1 - x2) + noise\n                elif strategy == 1:\n                    # DE/best/1\n                    mutant = best_global + self.F * (x1 - x2)\n                else:\n                    # DE/current-to-best/1\n                    mutant = x0 + self.F * (best_global - x0) + self.F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            # Update success history for strategies\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_history = [s / total_successes for s in successes]\n\n            # Adapt F, CR, and diversity factor based on success\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n\n        return best_global", "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Dynamic Strategy Selection utilizes a dynamic strategy selection mechanism to switch between multiple mutation strategies based on their historical performance, enhancing exploration and exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.2861301976047059, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "a0b84468-1232-40c0-8fa2-b68eb1c1fbcd", "metadata": {"aucs": [0.2861301976047059]}, "mutation_prompt": null}
{"id": "f40dad16-a60d-4c1c-b734-b7306d9c33da", "solution": "import numpy as np\n\nclass MultilevelAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        # Initialize F and CR with a broader range to allow more adaptability\n        self.F = np.random.uniform(0.4, 0.9, self.population_size)\n        self.CR = np.random.uniform(0.7, 1.0, self.population_size)\n        self.history = []\n        self.diversity_factor = 0.2  # Initial diversity factor\n        self.success_archive = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            next_F = np.zeros_like(self.F)\n            next_CR = np.zeros_like(self.CR)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                # DE/rand/1 strategy with adaptive parameters\n                mutant = x0 + self.F[i] * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                    self.success_archive.append((self.F[i], self.CR[i]))\n                else:\n                    next_pop[i] = pop[i]\n\n                # Multilevel adaptation of F and CR\n                if len(self.success_archive) > 0:\n                    self.F[i], self.CR[i] = self._adapt_parameters()\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global\n\n    def _adapt_parameters(self):\n        mean_F = np.mean([f for f, _ in self.success_archive])\n        mean_CR = np.mean([cr for _, cr in self.success_archive])\n        # Random perturbation around historical mean\n        new_F = np.clip(mean_F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n        new_CR = np.clip(mean_CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n        return new_F, new_CR", "name": "MultilevelAdaptiveDE", "description": "Multilevel Adaptive Differential Evolution incorporates multilevel learning for parameters F and CR, leveraging historical success to adaptively fine-tune the exploration-exploitation trade-off.", "configspace": "", "generation": 39, "fitness": 0.281573742483877, "feedback": "The algorithm MultilevelAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a0b84468-1232-40c0-8fa2-b68eb1c1fbcd", "metadata": {"aucs": [0.281573742483877]}, "mutation_prompt": null}
{"id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "solution": "import numpy as np\n\nclass AdaptiveQuantumDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5\n        self.CR = 0.9\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.diversity_factor = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mutant = x0 + self.F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + self.F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "AdaptiveQuantumDE", "description": "Adaptive Quantum-Inspired Differential Evolution enhances exploration with quantum-inspired representation and dynamic adaptation of parameters to improve convergence in photonic structure optimization.", "configspace": "", "generation": 40, "fitness": 0.2895386913558258, "feedback": "The algorithm AdaptiveQuantumDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "a0b84468-1232-40c0-8fa2-b68eb1c1fbcd", "metadata": {"aucs": [0.2895386913558258]}, "mutation_prompt": null}
{"id": "b0ebc393-aa38-48a4-ac2e-f074f48c09b3", "solution": "import numpy as np\n\nclass EnhancedQuantumDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.F = 0.5\n        self.CR = 0.9\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.diversity_factor = 0.2\n        self.population_decrease_factor = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population_quantum = np.random.uniform(0, 1, (population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mutant = x0 + self.F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + self.F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n            # Adaptive population sizing for enhanced exploitation\n            population_size = int(self.initial_population_size * (self.population_decrease_factor ** (evaluations // self.initial_population_size)))\n\n        return best_global", "name": "EnhancedQuantumDE", "description": "Enhanced Quantum Differential Evolution with Adaptive Population Sizing and Feedback Mechanism to focus on exploitation in the later stages for improved photonic structure optimization.", "configspace": "", "generation": 41, "fitness": 0.2870145885674027, "feedback": "The algorithm EnhancedQuantumDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2870145885674027]}, "mutation_prompt": null}
{"id": "2e6b71ad-4220-4a41-9c6f-67567140429f", "solution": "import numpy as np\n\nclass QuantumFirefly:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.alpha = 0.5  # Randomness reduction factor\n        self.gamma = 1.0  # Light absorption coefficient\n        self.beta_min = 0.2  # Minimum attractiveness\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                for j in range(self.population_size):\n                    if fitness[i] > fitness[j]:\n                        r = np.linalg.norm(pop[i] - pop[j])\n                        beta = self.beta_min + (1 - self.beta_min) * np.exp(-self.gamma * r ** 2)\n                        \n                        # Quantum-inspired update\n                        noise = np.random.uniform(-0.5, 0.5, self.dim)\n                        step = beta * (pop[j] - pop[i]) + self.alpha * noise * (ub - lb)\n                        pop[i] += step\n                        pop[i] = np.clip(pop[i], lb, ub)\n\n                        current_fitness = func(pop[i])\n                        evaluations += 1\n\n                        if current_fitness < fitness[i]:\n                            fitness[i] = current_fitness\n                            if current_fitness < fitness[best_idx]:\n                                best_idx = i\n                                best_global = pop[i]\n\n            self.alpha *= 0.99  # Reduce randomness\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumFirefly", "description": "Quantum Firefly Algorithm combines quantum-inspired position updates with firefly-inspired light intensity-based attraction to balance exploration and exploitation for optimizing photonic structures.", "configspace": "", "generation": 42, "fitness": 0.2758934350358849, "feedback": "The algorithm QuantumFirefly got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2758934350358849]}, "mutation_prompt": null}
{"id": "83168f1e-242d-4df7-9be4-82cbe17ccbfc", "solution": "import numpy as np\n\nclass EnhancedAdaptiveQuantumDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5\n        self.CR = 0.9\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.diversity_factor = 0.2\n        self.adaptive_learning_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mid_point = (x1 + x2) / 2\n                    mutant = x0 + self.F * (mid_point - x0) + noise\n                else:\n                    weighted_mid = (x1 + x2 + best_global) / 3\n                    mutant = best_global + self.F * (weighted_mid - x0)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.F = np.clip(self.F + self.adaptive_learning_rate * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + self.adaptive_learning_rate * (np.random.rand() - 0.5), 0.7, 1.0)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "EnhancedAdaptiveQuantumDE", "description": "Enhanced Adaptive Quantum-Inspired Differential Evolution with Dual-Layer Mutation and Adaptive Learning for improved convergence in photonic structure optimization.", "configspace": "", "generation": 43, "fitness": 0.27800844071585507, "feedback": "The algorithm EnhancedAdaptiveQuantumDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.27800844071585507]}, "mutation_prompt": null}
{"id": "dc3a86cc-cbe8-450d-a15c-b920b52f9382", "solution": "import numpy as np\n\nclass QuantumGuidedADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.F = self.F_min\n        self.CR = self.CR_max\n        self.success_rates = [0.5, 0.5]\n        self.diversity_factor = 0.2\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mutant = x0 + self.F * (x1 - x2) + noise\n                else:\n                    historical_best = self.history[-1] if self.history else best_global\n                    mutant = best_global + self.F * (x1 - x2) + 0.1 * (historical_best - x0)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), self.F_min, self.F_max)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), self.CR_min, self.CR_max)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumGuidedADE", "description": "Quantum-Guided Adaptive Differential Evolution enhances solution diversity and convergence by integrating quantum-inspired initialization, adaptive parameter control, and a guided mutation strategy based on historical best solutions.", "configspace": "", "generation": 44, "fitness": 0.28065569194813866, "feedback": "The algorithm QuantumGuidedADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.28065569194813866]}, "mutation_prompt": null}
{"id": "a6a207c9-a559-450c-922f-6f55d3e0d2ce", "solution": "import numpy as np\n\nclass QuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w = 0.5\n        self.eta = 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = lb + (ub - lb) * np.random.rand(self.swarm_size, self.dim)\n        velocities = np.random.rand(self.swarm_size, self.dim) * (ub - lb) * 0.1\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - swarm[i]) + \\\n                                self.c2 * r2 * (global_best_position - swarm[i])\n                \n                quantum_displacement = np.random.normal(0, self.eta, self.dim)\n                swarm[i] = swarm[i] + velocities[i] + quantum_displacement\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                score = func(swarm[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n                    \n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n        \n        return global_best_position", "name": "QuantumPSO", "description": "Quantum Particle Swarm Optimization (QPSO) leverages quantum behavior principles combined with particle swarm strategies to enhance the exploration and exploitation balance in photonic structure optimization.", "configspace": "", "generation": 45, "fitness": 0.2855505849571496, "feedback": "The algorithm QuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2855505849571496]}, "mutation_prompt": null}
{"id": "a322c804-2cef-4a34-8700-f67fa28e8639", "solution": "import numpy as np\n\nclass QuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.max_velocity = 0.2\n        self.adapt_rate = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        velocity = np.random.uniform(-self.max_velocity, self.max_velocity, (self.swarm_size, self.dim))\n        position_quantum = np.random.uniform(0, 1, (self.swarm_size, self.dim))\n        position = lb + (ub - lb) * np.sin(np.pi * position_quantum)\n        personal_best_position = np.copy(position)\n        personal_best_fitness = np.array([func(x) for x in position])\n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_position[global_best_idx]\n        global_best_fitness = personal_best_fitness[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (self.w * velocity[i] +\n                               self.c1 * r1 * (personal_best_position[i] - position[i]) +\n                               self.c2 * r2 * (global_best_position - position[i]))\n                velocity[i] = np.clip(velocity[i], -self.max_velocity, self.max_velocity)\n                position[i] = position[i] + velocity[i]\n                position[i] = np.clip(position[i], lb, ub)\n\n                current_fitness = func(position[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = current_fitness\n                    personal_best_position[i] = position[i]\n\n                    if current_fitness < global_best_fitness:\n                        global_best_fitness = current_fitness\n                        global_best_position = position[i]\n\n            self.w = np.clip(self.w + self.adapt_rate * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.c1 = np.clip(self.c1 + self.adapt_rate * (np.random.rand() - 0.5), 1.0, 2.0)\n            self.c2 = np.clip(self.c2 + self.adapt_rate * (np.random.rand() - 0.5), 1.0, 2.0)\n            self.max_velocity = np.clip(self.max_velocity + self.adapt_rate * (np.random.rand() - 0.5), 0.1, 0.3)\n\n        return global_best_position", "name": "QuantumAdaptivePSO", "description": "Quantum Adaptive Particle Swarm Optimization (QAPSO) combines quantum-inspired particle swarm dynamics with adaptive parameter control to enhance convergence and diversity in photonic structure optimization.", "configspace": "", "generation": 46, "fitness": 0.27389658978299314, "feedback": "The algorithm QuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.27389658978299314]}, "mutation_prompt": null}
{"id": "49e72587-ad38-44f0-9a57-6dcb507bea85", "solution": "import numpy as np\n\nclass QuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.5\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_alpha = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        lb, ub = np.array(lb), np.array(ub)\n\n        particles = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = particles.copy()\n        personal_best_scores = np.array([func(p) for p in particles])\n        \n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Quantum-inspired velocity update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.c2 * r2 * (global_best_position - particles[i]))\n\n                # Quantum-inspired position update\n                delta = np.random.uniform(0, 1, self.dim)\n                quantum_flip = np.random.rand(self.dim) < self.quantum_alpha\n                quantum_positions = np.where(quantum_flip, \n                                             lb + (ub - lb) * np.sin(np.pi * delta), \n                                             particles[i] + velocities[i])\n\n                # Particle position update and boundary handling\n                particles[i] = np.clip(quantum_positions, lb, ub)\n\n                # Evaluate fitness\n                particle_score = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if particle_score < personal_best_scores[i]:\n                    personal_best_positions[i] = particles[i]\n                    personal_best_scores[i] = particle_score\n\n                # Update global best\n                if particle_score < global_best_score:\n                    global_best_position = particles[i]\n                    global_best_score = particle_score\n\n        return global_best_position", "name": "QuantumPSO", "description": "Quantum Particle Swarm Optimization integrates quantum-inspired updates with particle swarm dynamics for enhanced exploration and faster convergence in photonic structure optimization.", "configspace": "", "generation": 47, "fitness": 0.2808483323060563, "feedback": "The algorithm QuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2808483323060563]}, "mutation_prompt": null}
{"id": "90de650f-08ac-4ed4-8936-8d3a5f14b136", "solution": "import numpy as np\n\nclass EnhancedAdaptiveQuantumDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 50\n        self.F = 0.5\n        self.CR = 0.9\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.diversity_factor = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.base_population_size\n        population_quantum = np.random.uniform(0, 1, (population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mutant = x0 + self.F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + self.F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            # Dynamic adjustment of population size\n            if evaluations < self.budget / 2:\n                population_size = min(self.base_population_size + (evaluations // 100), self.budget - evaluations)\n            else:\n                population_size = max(self.base_population_size, self.base_population_size - (evaluations // 100))\n\n            pop = next_pop[:population_size]\n            fitness = fitness[:population_size]\n            self.history.append(best_global)\n\n        return best_global", "name": "EnhancedAdaptiveQuantumDE", "description": "Enhanced Adaptive Quantum-Inspired Differential Evolution incorporates dynamic population sizing and adaptive crossover to improve convergence and diversity in photonic structure optimization.", "configspace": "", "generation": 48, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {}, "mutation_prompt": null}
{"id": "cb036074-4d82-4e24-8c24-064d2d15b410", "solution": "import numpy as np\n\nclass QuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # cognitive coefficient\n        self.c2 = 1.5  # social coefficient\n        self.w = 0.7   # inertia weight\n        self.quantum_radius = 0.1\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = np.copy(population)\n        personal_best_fitness = np.array([func(x) for x in personal_best])\n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                \n                # Update velocity using cognitive and social components\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best[i] - population[i]) +\n                                 self.c2 * r2 * (global_best - population[i]))\n                \n                # Quantum behavior: add randomness to explore\n                quantum_bounce = np.random.uniform(-self.quantum_radius, self.quantum_radius, self.dim)\n                velocities[i] += quantum_bounce\n\n                # Update position\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Evaluate fitness\n                fitness = func(population[i])\n                evaluations += 1\n\n                # Update personal best\n                if fitness < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness\n\n                    # Update global best\n                    if fitness < personal_best_fitness[global_best_idx]:\n                        global_best_idx = i\n                        global_best = population[i]\n\n            # Adaptive inertia weight\n            self.w = 0.9 - (0.5 * evaluations / self.budget)\n\n            self.history.append(global_best)\n\n        return global_best", "name": "QuantumParticleSwarmOptimization", "description": "Quantum Particle Swarm Optimization leverages quantum superposition principles and adaptive neighborhood learning to enhance convergence and diversity balance in photonic structure optimization.", "configspace": "", "generation": 49, "fitness": 0.2874958145216806, "feedback": "The algorithm QuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2874958145216806]}, "mutation_prompt": null}
{"id": "31412c89-d1e4-4db6-ae78-c8f7026e1d4b", "solution": "import numpy as np\n\nclass AdaptiveQuantumSelfAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.diversity_factor = 0.2\n        # Initialize control parameters\n        self.Fs = np.random.uniform(0.4, 0.9, self.population_size)\n        self.CRs = np.random.uniform(0.7, 1.0, self.population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mutant = x0 + self.Fs[i] * (x1 - x2) + noise\n                else:\n                    mutant = best_global + self.Fs[i] * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CRs[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            # Self-adapt F and CR based on successes\n            self.Fs = np.clip(self.Fs + 0.1 * (np.random.rand(self.population_size) - 0.5), 0.4, 0.9)\n            self.CRs = np.clip(self.CRs + 0.1 * (np.random.rand(self.population_size) - 0.5), 0.7, 1.0)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "AdaptiveQuantumSelfAdaptiveDE", "description": "Adaptive Quantum-Self-Adaptive Differential Evolution with Enhanced Selection refines the search by incorporating self-adaptation of control parameters and a dynamic selection mechanism to improve convergence in photonic structure optimization.", "configspace": "", "generation": 50, "fitness": 0.284409580745691, "feedback": "The algorithm AdaptiveQuantumSelfAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.284409580745691]}, "mutation_prompt": null}
{"id": "3760afc0-cfa8-44bf-ab27-dcd55ec996c3", "solution": "import numpy as np\n\nclass QuantumHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 50\n        self.hmcr = 0.9\n        self.par = 0.3\n        self.bw = 0.05\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_quantum = np.random.uniform(0, 1, (self.harmony_memory_size, self.dim))\n        harmony_memory = lb + (ub - lb) * np.sin(np.pi * harmony_memory_quantum)\n        fitness = np.array([func(x) for x in harmony_memory])\n        best_idx = np.argmin(fitness)\n        best_global = harmony_memory[best_idx]\n\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            new_harmony = np.zeros(self.dim)\n\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = harmony_memory[idx, i]\n                    if np.random.rand() < self.par:\n                        delta = np.random.uniform(-self.bw, self.bw)\n                        new_harmony[i] += delta * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_fitness = func(new_harmony)\n            evaluations += 1\n\n            if new_fitness < fitness[best_idx]:\n                worst_idx = np.argmax(fitness)\n                harmony_memory[worst_idx] = new_harmony\n                fitness[worst_idx] = new_fitness\n                best_idx = np.argmin(fitness)\n                best_global = harmony_memory[best_idx]\n\n            self.history.append(best_global)\n\n            # Adaptively adjusting parameters\n            self.hmcr = np.clip(self.hmcr + 0.05 * (np.random.rand() - 0.5), 0.7, 0.95)\n            self.par = np.clip(self.par + 0.05 * (np.random.rand() - 0.5), 0.1, 0.5)\n            self.bw = np.clip(self.bw + 0.01 * (np.random.rand() - 0.5), 0.01, 0.1)\n\n        return best_global", "name": "QuantumHarmonySearch", "description": "Quantum Harmony Search (QHS) blends quantum-inspired representation and harmony memory with adaptive pitch adjustment for enhanced convergence in photonic structure optimization.", "configspace": "", "generation": 51, "fitness": 0.2783114404584781, "feedback": "The algorithm QuantumHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2783114404584781]}, "mutation_prompt": null}
{"id": "6cad7c59-2ac8-4c88-a6d7-ca3075db7674", "solution": "import numpy as np\n\nclass QuantumPSOAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.w = 0.5\n        self.quantum_factor = 0.5\n        self.entropy_factor = 0.1\n        self.velocity_clamp = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize positions and velocities\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = self.c1 * r1 * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * r2 * (global_best_position - swarm[i])\n                velocities[i] = (self.w * velocities[i] + cognitive + social +\n                                 self.entropy_factor * np.random.uniform(-1, 1, self.dim))\n\n                # Clamp velocity\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                # Update position\n                swarm[i] += velocities[i]\n                \n                # Quantum-inspired update\n                quantum_jump = self.quantum_factor * np.random.uniform(lb, ub, self.dim)\n                swarm[i] = (swarm[i] + np.sin(np.pi * quantum_jump)) / 2\n                \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate new position\n                score = func(swarm[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = np.copy(swarm[i])\n\n                    # Update global best\n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = np.copy(swarm[i])\n\n            # Adjust parameters\n            self.w = np.clip(self.w + 0.05 * (np.random.rand() - 0.5), 0.3, 0.7)\n            self.entropy_factor = np.clip(self.entropy_factor + 0.01 * (np.random.rand() - 0.5), 0.05, 0.15)\n            self.quantum_factor = np.clip(self.quantum_factor + 0.01 * (np.random.rand() - 0.5), 0.3, 0.7)\n\n        return global_best_position", "name": "QuantumPSOAdaptive", "description": "Quantum Particle Swarm Optimization with Adaptive Velocity and Entropy-Inspired Exploration balances global and local search by integrating adaptive velocity updates and entropy-based exploration for robust optimization of photonic structures.", "configspace": "", "generation": 52, "fitness": 0.27267717934137703, "feedback": "The algorithm QuantumPSOAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.27267717934137703]}, "mutation_prompt": null}
{"id": "d9cec25c-c816-4ae8-9d6d-d1238bdda41f", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive parameter\n        self.c2 = 1.5  # Social parameter\n        self.w = 0.5   # Inertia weight\n        self.diversity_factor = 0.1\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        p_best = np.copy(pop)\n        p_best_fitness = np.array([func(x) for x in pop])\n        g_best_idx = np.argmin(p_best_fitness)\n        g_best = pop[g_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                rp = np.random.rand(self.dim)\n                rg = np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * rp * (p_best[i] - pop[i]) +\n                                 self.c2 * rg * (g_best - pop[i]))\n\n                quantum_noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                pop[i] += velocities[i] + quantum_noise\n                pop[i] = np.clip(pop[i], lb, ub)\n\n                fitness = func(pop[i])\n                evaluations += 1\n\n                if fitness < p_best_fitness[i]:\n                    p_best[i] = pop[i]\n                    p_best_fitness[i] = fitness\n\n                if fitness < p_best_fitness[g_best_idx]:\n                    g_best_idx = i\n                    g_best = pop[i]\n\n            self.history.append(g_best)\n            if evaluations >= self.budget:\n                break\n\n            # Update inertia weight and diversity factor dynamically\n            self.w = np.clip(self.w + 0.05 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.02 * (np.random.rand() - 0.5), 0.05, 0.2)\n\n        return g_best", "name": "QuantumInspiredPSO", "description": "Quantum-Inspired Particle Swarm Optimization employs quantum mechanics principles and adaptive diversity control to improve convergence and exploration in photonic structure optimization.", "configspace": "", "generation": 53, "fitness": 0.28698918927687744, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.28698918927687744]}, "mutation_prompt": null}
{"id": "9304e46a-8c06-4d20-8c33-e5f61fcd24f6", "solution": "import numpy as np\n\nclass EnhancedQuantumDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5\n        self.CR = 0.9\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.diversity_factor = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mutant = x0 + self.F * (x1 - x2) + noise\n                    # Enhanced local exploratory mutation\n                    local_explore = np.random.uniform(-np.abs(x0 - best_global), np.abs(x0 - best_global), self.dim)\n                    mutant += local_explore\n                else:\n                    mutant = best_global + self.F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            # Selective diversity enhancement based on successes\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.15, 0.35)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "EnhancedQuantumDE", "description": "Enhanced Quantum-Inspired Differential Evolution integrates adaptive local exploration and a selective mutation process focused on population diversity to improve photonic structure optimization.", "configspace": "", "generation": 54, "fitness": 0.28129975715948885, "feedback": "The algorithm EnhancedQuantumDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.28129975715948885]}, "mutation_prompt": null}
{"id": "355e2224-9adf-4649-8f89-c60323f86d5d", "solution": "import numpy as np\n\nclass QuantumHybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.omega = 0.5\n        self.phi_p = 0.5\n        self.phi_g = 0.5\n        self.mutation_rate = 0.1\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        position = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = position.copy()\n        personal_best_fitness = np.array([func(x) for x in position])\n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best = personal_best[global_best_idx].copy()\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r_p, r_g = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (self.omega * velocity[i] +\n                               self.phi_p * r_p * (personal_best[i] - position[i]) +\n                               self.phi_g * r_g * (global_best - position[i]))\n                \n                position[i] += velocity[i]\n                position[i] = np.clip(position[i], lb, ub)\n                \n                # Apply quantum-inspired update\n                quantum_position = position[i] + np.random.uniform(-1, 1, self.dim)\n                quantum_position = np.clip(quantum_position, lb, ub)\n                \n                # Genetic-inspired mutation\n                if np.random.rand() < self.mutation_rate:\n                    mutation_index = np.random.randint(self.dim)\n                    quantum_position[mutation_index] = np.random.uniform(lb[mutation_index], ub[mutation_index])\n                \n                fitness = func(quantum_position)\n                evaluations += 1\n                \n                if fitness < personal_best_fitness[i]:\n                    personal_best[i] = quantum_position\n                    personal_best_fitness[i] = fitness\n                    if fitness < personal_best_fitness[global_best_idx]:\n                        global_best_idx = i\n                        global_best = quantum_position\n        \n        return global_best", "name": "QuantumHybridPSO", "description": "Quantum Hybrid Particle Swarm with Genetic Operators integrates quantum particle swarm optimization and genetic operators to enhance diversity and convergence in photonic structure optimization.", "configspace": "", "generation": 55, "fitness": 0.2850691171559858, "feedback": "The algorithm QuantumHybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2850691171559858]}, "mutation_prompt": null}
{"id": "3f4968b4-d692-4ecd-8896-4646cf09ed39", "solution": "import numpy as np\n\nclass QuantumGradientDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5\n        self.CR = 0.9\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.diversity_factor = 0.2\n        self.epsilon = 1e-5  # Small step size for gradient estimation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mutant = x0 + self.F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + self.F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Gradient-based local refinement\n                grad = self.estimate_gradient(func, trial, lb, ub)\n                refined_trial = trial - self.epsilon * grad\n                refined_trial = np.clip(refined_trial, lb, ub)\n                refined_fitness = func(refined_trial)\n                evaluations += 1\n\n                if refined_fitness < trial_fitness:\n                    trial = refined_trial\n                    trial_fitness = refined_fitness\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.4, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.7, 1.0)\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global\n    \n    def estimate_gradient(self, func, x, lb, ub):\n        grad = np.zeros(self.dim)\n        fx = func(x)\n        for d in range(self.dim):\n            x_step = np.copy(x)\n            x_step[d] += self.epsilon\n            x_step = np.clip(x_step, lb, ub)\n            grad[d] = (func(x_step) - fx) / self.epsilon\n        return grad", "name": "QuantumGradientDE", "description": "Quantum-Inspired Differential Evolution with Gradient-Enhanced Local Search leverages quantum-inspired representation for global search while integrating gradient-based local refinement to optimize photonic structures more effectively.", "configspace": "", "generation": 56, "fitness": 0.27591130723309654, "feedback": "The algorithm QuantumGradientDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.27591130723309654]}, "mutation_prompt": null}
{"id": "ddc6072a-61f2-4994-8818-279eafdf8245", "solution": "import numpy as np\n\nclass QuantumGradientAssistedEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = 0.5\n        self.CR = 0.9\n        self.gradient_weight = 0.1\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        def approximate_gradient(x):\n            epsilon = 1e-5\n            grad = np.zeros_like(x)\n            for j in range(self.dim):\n                x_eps = np.copy(x)\n                x_eps[j] += epsilon\n                grad[j] = (func(x_eps) - func(x)) / epsilon\n            return grad\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n\n                mutant = x0 + self.F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n\n                gradient = approximate_gradient(trial)\n                trial = trial - self.gradient_weight * gradient\n                \n                trial = np.clip(trial, lb, ub)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumGradientAssistedEA", "description": "Quantum Gradient-Assisted Evolutionary Algorithm (QGAEA) combines quantum-inspired representation with gradient approximation to enhance local search capabilities and accelerate convergence in photonic structure optimization.", "configspace": "", "generation": 57, "fitness": 0.2710846932868316, "feedback": "The algorithm QuantumGradientAssistedEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2710846932868316]}, "mutation_prompt": null}
{"id": "62efd3f1-a36f-4483-8346-dcf5a5115196", "solution": "import numpy as np\n\nclass QuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.5\n        self.cognitive_const = 1.5\n        self.social_const = 1.5\n        self.phi = 0.1  # Quantum potential factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        velocity = np.random.randn(self.population_size, self.dim) * 0.1\n        p_best = np.copy(position)\n        p_best_fitness = np.array([func(x) for x in position])\n        \n        g_best_idx = np.argmin(p_best_fitness)\n        g_best = p_best[g_best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_velocity = self.cognitive_const * r1 * (p_best[i] - position[i])\n                social_velocity = self.social_const * r2 * (g_best - position[i])\n                \n                velocity[i] = (self.inertia_weight * velocity[i] + \n                               cognitive_velocity + \n                               social_velocity)\n                \n                # Quantum-inspired update\n                potential = np.random.uniform(-self.phi, self.phi, self.dim)\n                quantum_step = potential * (position[i] - g_best)\n                position[i] = position[i] + velocity[i] + quantum_step\n                position[i] = np.clip(position[i], lb, ub)\n                \n                fitness = func(position[i])\n                evaluations += 1\n                \n                if fitness < p_best_fitness[i]:\n                    p_best[i] = position[i]\n                    p_best_fitness[i] = fitness\n                    if fitness < p_best_fitness[g_best_idx]:\n                        g_best_idx = i\n                        g_best = position[i]\n\n        return g_best", "name": "QuantumPSO", "description": "Quantum Particle Swarm Optimization (QPSO) integrates quantum-inspired mechanics into particle swarm optimization to enhance global search and convergence for optimizing photonic structures.", "configspace": "", "generation": 58, "fitness": 0.2894355799260552, "feedback": "The algorithm QuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2894355799260552]}, "mutation_prompt": null}
{"id": "d221a515-5ffb-4cab-9e07-d23879e66228", "solution": "import numpy as np\n\nclass QuantumGeneticPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.inertia_weight = 0.7\n        self.cognitive_comp = 1.5\n        self.social_comp = 1.5\n        self.mutation_rate = 0.1\n        self.quantum_prob = 0.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        position = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        velocity = np.random.rand(self.population_size, self.dim) * 0.1\n        personal_best_position = np.copy(position)\n        personal_best_score = np.array([func(x) for x in personal_best_position])\n        global_best_idx = np.argmin(personal_best_score)\n        global_best_position = personal_best_position[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.cognitive_comp * r1 * (personal_best_position[i] - position[i]) +\n                               self.social_comp * r2 * (global_best_position - position[i]))\n                \n                position[i] += velocity[i]\n                position[i] = np.clip(position[i], lb, ub)\n\n                if np.random.rand() < self.quantum_prob:\n                    quantum_bit_flip = np.random.rand(self.dim) < self.mutation_rate\n                    position[i][quantum_bit_flip] = lb[quantum_bit_flip] + (ub[quantum_bit_flip] - lb[quantum_bit_flip]) * np.random.rand(len(quantum_bit_flip[quantum_bit_flip]))\n\n                score = func(position[i])\n                evaluations += 1\n\n                if score < personal_best_score[i]:\n                    personal_best_score[i] = score\n                    personal_best_position[i] = position[i]\n\n                    if score < personal_best_score[global_best_idx]:\n                        global_best_idx = i\n                        global_best_position = position[i]\n\n        return global_best_position", "name": "QuantumGeneticPSO", "description": "Quantum Genetic Particle Swarm Optimization combines the strengths of quantum computing, genetic algorithms, and particle swarm optimization to enhance diversity and convergence for global optimization of photonic structures.", "configspace": "", "generation": 59, "fitness": 0.2796272313405709, "feedback": "The algorithm QuantumGeneticPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2796272313405709]}, "mutation_prompt": null}
{"id": "4866fbbc-fa77-4b4e-b3a9-36f8eafea8e1", "solution": "import numpy as np\n\nclass QuantumHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.harmony_memory_size = 30\n        self.harmony_memory_consideration_rate = 0.95\n        self.pitch_adjustment_rate = 0.7\n        self.bw = 0.1\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_quantum = np.random.uniform(0, 1, (self.harmony_memory_size, self.dim))\n        harmony_memory = lb + (ub - lb) * np.sin(np.pi * harmony_memory_quantum)\n        fitness = np.array([func(x) for x in harmony_memory])\n        best_idx = np.argmin(fitness)\n        best_global = harmony_memory[best_idx]\n\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.harmony_memory_consideration_rate:\n                    new_harmony[i] = harmony_memory[np.random.randint(0, self.harmony_memory_size), i]\n                    if np.random.rand() < self.pitch_adjustment_rate:\n                        new_harmony[i] += self.bw * (np.random.rand() - 0.5) * (ub[i] - lb[i])\n                else:\n                    new_harmony[i] = lb[i] + np.random.rand() * (ub[i] - lb[i])\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_fitness = func(new_harmony)\n            evaluations += 1\n\n            if new_fitness < np.max(fitness):\n                worst_idx = np.argmax(fitness)\n                harmony_memory[worst_idx] = new_harmony\n                fitness[worst_idx] = new_fitness\n                if new_fitness < fitness[best_idx]:\n                    best_idx = worst_idx\n                    best_global = new_harmony\n\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumHarmonySearch", "description": "Quantum Harmony Search blends quantum-inspired representation with harmony search principles to dynamically adapt the convergence process for photonic structure optimization.", "configspace": "", "generation": 60, "fitness": 0.28599957687266886, "feedback": "The algorithm QuantumHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.28599957687266886]}, "mutation_prompt": null}
{"id": "126db62a-ddae-48df-ac51-51d4ab1f6a53", "solution": "import numpy as np\n\nclass QuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.w = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.quantum_factor = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        lb, ub = np.array(lb), np.array(ub)\n\n        pos = lb + np.random.rand(self.swarm_size, self.dim) * (ub - lb)\n        vel = np.random.rand(self.swarm_size, self.dim) * 0.1 * (ub - lb)\n        pbest_pos = np.copy(pos)\n        pbest_val = np.array([func(x) for x in pos])\n        gbest_idx = np.argmin(pbest_val)\n        gbest_pos = np.copy(pbest_pos[gbest_idx])\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                # Quantum-inspired update\n                quantum_position = np.random.rand(self.dim) * self.quantum_factor\n                vel[i] = (self.w * vel[i] \n                          + self.c1 * r1 * (pbest_pos[i] - pos[i]) \n                          + self.c2 * r2 * (gbest_pos - pos[i])) + quantum_position\n                \n                pos[i] = np.clip(pos[i] + vel[i], lb, ub)\n                f_value = func(pos[i])\n                evaluations += 1\n\n                if f_value < pbest_val[i]:\n                    pbest_pos[i] = np.copy(pos[i])\n                    pbest_val[i] = f_value\n                    if f_value < pbest_val[gbest_idx]:\n                        gbest_idx = i\n                        gbest_pos = np.copy(pbest_pos[gbest_idx])\n\n            self.w = np.clip(self.w * 0.99 + 0.01 * np.random.rand(), 0.4, 0.9)\n            self.c1 = np.clip(self.c1 * 0.99 + 0.01 * np.random.rand(), 1.4, 2.0)\n            self.c2 = np.clip(self.c2 * 0.99 + 0.01 * np.random.rand(), 1.4, 2.0)\n            self.quantum_factor = np.clip(self.quantum_factor * 0.95 + 0.05 * np.random.rand(), 0.01, 0.2)\n\n        return gbest_pos", "name": "QuantumPSO", "description": "Quantum-Inspired Particle Swarm Optimization with Dynamic Adaptation leverages quantum superposition principles in particles' positions along with adaptive velocity and inertia updates for enhanced convergence in photonic structure optimization.", "configspace": "", "generation": 61, "fitness": 0.2880272436401218, "feedback": "The algorithm QuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2880272436401218]}, "mutation_prompt": null}
{"id": "749908c5-7ada-49ed-80db-f96a99fe45f7", "solution": "import numpy as np\n\nclass QuantumAssistedSelfAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F = np.full(self.population_size, 0.5)\n        self.CR = np.full(self.population_size, 0.9)\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.diversity_factor = 0.2\n        self.tau1 = 0.1  # Probability for adapting F\n        self.tau2 = 0.1  # Probability for adapting CR\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.sin(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.tau1:\n                    self.F[i] = np.random.uniform(0.4, 0.9)\n                if np.random.rand() < self.tau2:\n                    self.CR[i] = np.random.uniform(0.7, 1.0)\n\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    noise = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n                    mutant = x0 + self.F[i] * (x1 - x2) + noise\n                else:\n                    mutant = best_global + self.F[i] * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR[i]\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.diversity_factor = np.clip(self.diversity_factor + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumAssistedSelfAdaptiveDE", "description": "Quantum-Assisted Self-Adaptive Differential Evolution (QASADE) leverages quantum superposition and self-adaptive strategies to enhance exploration and exploitation balance for better convergence in photonic structure optimization.", "configspace": "", "generation": 62, "fitness": 0.28391630269035373, "feedback": "The algorithm QuantumAssistedSelfAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.28391630269035373]}, "mutation_prompt": null}
{"id": "ff4c1299-1c53-4863-9b5a-3a1de7d7b10b", "solution": "import numpy as np\n\nclass QuantumTunedDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 60\n        self.F = 0.6\n        self.CR = 0.85\n        self.mutation_scaling = 0.2\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum / 2)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                if strategy == 0:\n                    noise = np.random.uniform(-self.mutation_scaling, self.mutation_scaling, self.dim)\n                    mutant = x0 + self.F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + self.F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.F = np.clip(self.F + 0.1 * (np.random.rand() - 0.5), 0.5, 0.9)\n            self.CR = np.clip(self.CR + 0.1 * (np.random.rand() - 0.5), 0.75, 1.0)\n            self.mutation_scaling = np.clip(self.mutation_scaling + 0.05 * (np.random.rand() - 0.5), 0.1, 0.3)\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumTunedDE", "description": "Quantum-Tuned Differential Evolution uses advanced quantum probability adaptation and dynamic diversity control to enhance convergence and robustness in optimizing photonic structures.", "configspace": "", "generation": 63, "fitness": 0.2860876485564742, "feedback": "The algorithm QuantumTunedDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.2860876485564742]}, "mutation_prompt": null}
{"id": "c44ae842-0354-41dd-90e6-37ea0e0c891d", "solution": "import numpy as np\n\nclass QuantumHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 50\n        self.harmony_consideration_rate = 0.8\n        self.pitch_adjustment_rate = 0.3\n        self.scale = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_quantum = np.random.uniform(0, 1, (self.harmony_memory_size, self.dim))\n        harmony_memory = lb + (ub - lb) * np.sin(np.pi * harmony_memory_quantum)\n        fitness = np.array([func(x) for x in harmony_memory])\n        best_idx = np.argmin(fitness)\n        best_solution = harmony_memory[best_idx]\n\n        evaluations = self.harmony_memory_size\n\n        while evaluations < self.budget:\n            new_harmony = np.zeros(self.dim)\n\n            for i in range(self.dim):\n                if np.random.rand() < self.harmony_consideration_rate:\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size)][i]\n                    if np.random.rand() < self.pitch_adjustment_rate:\n                        new_harmony[i] += self.scale * (np.random.rand() - 0.5)\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_fitness = func(new_harmony)\n            evaluations += 1\n\n            if new_fitness < fitness[best_idx]:\n                best_idx = np.argmax(fitness)\n                harmony_memory[best_idx] = new_harmony\n                fitness[best_idx] = new_fitness\n                if new_fitness < fitness[best_idx]:\n                    best_solution = new_harmony\n\n            self.harmony_consideration_rate = np.clip(self.harmony_consideration_rate + 0.01 * (np.random.rand() - 0.5), 0.7, 0.9)\n            self.pitch_adjustment_rate = np.clip(self.pitch_adjustment_rate + 0.01 * (np.random.rand() - 0.5), 0.2, 0.4)\n\n        return best_solution", "name": "QuantumHarmonySearch", "description": "Quantum Harmony Search (QHS) combines harmony search principles with quantum-inspired initialization and adaptive parameter tuning to enhance global optimization of photonic structures.", "configspace": "", "generation": 64, "fitness": 0.27626356040724886, "feedback": "The algorithm QuantumHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.27626356040724886]}, "mutation_prompt": null}
{"id": "64614803-e298-43ec-9112-0c37bc539ba5", "solution": "import numpy as np\n\nclass QuantumGuidedSelfAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim)\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "QuantumGuidedSelfAdaptiveDE", "description": "Quantum-Guided Self-Adaptive Differential Evolution optimizes photonic structures by integrating quantum probability distributions and self-adaptive parameter tuning for improved global exploration and convergence.", "configspace": "", "generation": 65, "fitness": 0.29487791807883224, "feedback": "The algorithm QuantumGuidedSelfAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "b423b48f-c9ff-4d62-8c17-cc5117592976", "metadata": {"aucs": [0.29487791807883224]}, "mutation_prompt": null}
{"id": "5a7c741a-f0da-4b6a-9d40-b4a925c2e10a", "solution": "import numpy as np\n\nclass AdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 50\n        self.w_min, self.w_max = 0.4, 0.9\n        self.c1, self.c2 = 2.0, 2.0\n        self.quantum_prob = 0.05\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = lb + (ub - lb) * np.random.rand(self.num_particles, self.dim)\n        velocities = np.zeros_like(positions)\n        personal_best_positions = np.copy(positions)\n        personal_best_fitness = np.array([func(x) for x in positions])\n        \n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_fitness = personal_best_fitness[global_best_idx]\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n           \n            for i in range(self.num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] \n                                + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                                + self.c2 * r2 * (global_best_position - positions[i]))\n                \n                if np.random.rand() < self.quantum_prob:\n                    quantum_delta = np.random.uniform(-0.5, 0.5, self.dim)\n                    positions[i] = global_best_position + quantum_delta * (ub - lb)\n                else:\n                    positions[i] += velocities[i]\n                \n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                fitness = func(positions[i])\n                evaluations += 1\n\n                if fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness\n                    personal_best_positions[i] = positions[i]\n\n                    if fitness < global_best_fitness:\n                        global_best_fitness = fitness\n                        global_best_position = positions[i]\n\n        return global_best_position", "name": "AdaptiveQuantumPSO", "description": "Adaptive Quantum Particle Swarm Optimization combines quantum position updates with an adaptive inertia factor to enhance exploration and exploitation in high-dimensional photonic structure optimization.", "configspace": "", "generation": 66, "fitness": 0.2809716593757412, "feedback": "The algorithm AdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.2809716593757412]}, "mutation_prompt": null}
{"id": "4362a25a-ca00-4962-9be4-3a376e9dd2d7", "solution": "import numpy as np\n\nclass AdaptiveQuantumGuidedFireflyDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.alpha = 0.5  # Randomness scaling factor\n        self.beta_min, self.beta_max = 0.2, 1.0  # Attraction coefficient scaling\n        self.gamma = 1.0  # Light absorption coefficient\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                \n                for j in range(self.population_size):\n                    if fitness[i] > fitness[j]:\n                        distance = np.linalg.norm(pop[i] - pop[j])\n                        beta = self.beta_min + (self.beta_max - self.beta_min) * np.exp(-self.gamma * distance**2)\n                        attraction = beta * (pop[j] - pop[i]) + self.alpha * (np.random.rand(self.dim) - 0.5)\n                        pop[i] = pop[i] + attraction\n                \n                indices = np.random.choice(range(self.population_size), 2, replace=False)\n                x1, x2 = pop[indices]\n                \n                mutant = pop[i] + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[0] += 1  # Track success\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "AdaptiveQuantumGuidedFireflyDE", "description": "Adaptive Quantum-Guided Firefly Differential Evolution combines firefly attractiveness with quantum probability enhancements for improved convergence in complex search spaces.", "configspace": "", "generation": 67, "fitness": 0.2933909196934348, "feedback": "The algorithm AdaptiveQuantumGuidedFireflyDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.2933909196934348]}, "mutation_prompt": null}
{"id": "e3698652-913f-4a81-b0bb-ea1be5cff2ce", "solution": "import numpy as np\n\nclass QuantumInspiredDynamicSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 60\n        self.q_factor = 0.8\n        self.c1, self.c2 = 1.5, 1.5  # cognitive and social components\n        self.inertia_weight = 0.7\n        self.velocity_clamp = 0.1 * (dim ** 0.5)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        position_quantum = np.random.uniform(0, 1, (self.swarm_size, self.dim))\n        positions = lb + (ub - lb) * np.cos(np.pi * position_quantum)\n        velocities = np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_fitness = np.array([func(x) for x in positions])\n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                                 + self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n\n                positions[i] = positions[i] + velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                quantum_shift = self.q_factor * (np.random.rand(self.dim) - 0.5)\n                positions[i] += quantum_shift\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                fitness = func(positions[i])\n                evaluations += 1\n\n                if fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_fitness[i] = fitness\n                    if fitness < personal_best_fitness[global_best_idx]:\n                        global_best_idx = i\n                        global_best_position = positions[i]\n\n        return global_best_position", "name": "QuantumInspiredDynamicSwarmOptimization", "description": "Quantum-Inspired Dynamic Swarm Optimization (QIDSO) integrates quantum superposition principles and dynamically adaptive swarm behavior to enhance exploration and convergence in complex photonic structure optimization.", "configspace": "", "generation": 68, "fitness": 0.2933909196934348, "feedback": "The algorithm QuantumInspiredDynamicSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.2933909196934348]}, "mutation_prompt": null}
{"id": "ae0f8721-b9b5-4fa2-bf5f-d988230d5383", "solution": "import numpy as np\n\nclass QuantumParticleSwarmEnhancedDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.6, 0.9\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        velocity = np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(x) for x in population])\n        personal_best_pos = np.copy(population)\n        personal_best_fitness = np.copy(fitness)\n        best_global_idx = np.argmin(fitness)\n        best_global_pos = population[best_global_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity and position\n                velocity[i] = (self.inertia_weight * velocity[i] +\n                               self.cognitive_coeff * np.random.rand(self.dim) * (personal_best_pos[i] - population[i]) +\n                               self.social_coeff * np.random.rand(self.dim) * (best_global_pos - population[i]))\n                \n                population[i] += velocity[i]\n                population[i] = np.clip(population[i], lb, ub)\n\n                # Quantum-inspired mutation\n                quantum_mutation = population[i] + np.random.uniform(-1, 1, self.dim) * (best_global_pos - population[i])\n                quantum_mutation = np.clip(quantum_mutation, lb, ub)\n\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, quantum_mutation)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best_pos[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n\n                        if trial_fitness < fitness[best_global_idx]:\n                            best_global_idx = i\n                            best_global_pos = trial\n\n        return best_global_pos", "name": "QuantumParticleSwarmEnhancedDE", "description": "Quantum Particle Swarm-Enhanced Differential Evolution combines particle swarm intelligence with differential evolution and quantum-inspired mutation for superior exploration and convergence.", "configspace": "", "generation": 69, "fitness": 0.28393111483288214, "feedback": "The algorithm QuantumParticleSwarmEnhancedDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.28393111483288214]}, "mutation_prompt": null}
{"id": "93df5399-135a-4abd-bb56-875445d9c9ec", "solution": "import numpy as np\n\nclass QuantumInspiredMultiStrategyDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_threshold = 0.2\n        self.adaptive_factor = 0.1\n        self.history = []\n\n    def compute_diversity(self, population):\n        center = np.mean(population, axis=0)\n        diversity = np.mean(np.linalg.norm(population - center, axis=1))\n        return diversity\n\n    def adapt_strategy(self, diversity):\n        if diversity < self.diversity_threshold:\n            return 1  # Exploitation phase\n        else:\n            return 0  # Exploration phase\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.abs(np.sin(np.pi * population_quantum / 2))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            diversity = self.compute_diversity(pop)\n            strategy = self.adapt_strategy(diversity)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n\n                if strategy == 0:\n                    noise = np.random.uniform(-self.adaptive_factor, self.adaptive_factor, self.dim)\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    j_rand = np.random.randint(0, self.dim)\n                    mutant = np.copy(best_global)\n                    for j in range(self.dim):\n                        if np.random.rand() < CR or j == j_rand:\n                            mutant[j] = x0[j] + F * (best_global[j] - x0[j])\n\n                mutant = np.clip(mutant, lb, ub)\n\n                trial_fitness = func(mutant)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = mutant\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = mutant\n                else:\n                    next_pop[i] = pop[i]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "QuantumInspiredMultiStrategyDE", "description": "Quantum-Inspired Multi-Strategy Differential Evolution enhances exploration and exploitation by incorporating quantum potential fields and dynamically adapting strategy selection based on population diversity.", "configspace": "", "generation": 70, "fitness": 0.27796966944428947, "feedback": "The algorithm QuantumInspiredMultiStrategyDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.27796966944428947]}, "mutation_prompt": null}
{"id": "3b92f99e-7b6b-48d7-8eae-0eb22a3b42a5", "solution": "import numpy as np\n\nclass QuantumInspiredMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = 3\n        self.swarm_size = 20\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.quantum_influence = 0.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarms = [np.random.uniform(lb, ub, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        velocities = [np.random.uniform(-1, 1, (self.swarm_size, self.dim)) for _ in range(self.num_swarms)]\n        pbest_positions = [swarm.copy() for swarm in swarms]\n        pbest_fitness = [np.array([func(p) for p in swarm]) for swarm in swarms]\n        gbest_fitness = [np.min(pbf) for pbf in pbest_fitness]\n        gbest_positions = [swarm[np.argmin(pbf)] for swarm, pbf in zip(swarms, pbest_fitness)]\n\n        evaluations = self.num_swarms * self.swarm_size\n\n        while evaluations < self.budget:\n            for swarm_idx in range(self.num_swarms):\n                swarm = swarms[swarm_idx]\n                velocity = velocities[swarm_idx]\n                pbest_pos = pbest_positions[swarm_idx]\n                gbest_pos = gbest_positions[swarm_idx]\n\n                r1 = np.random.rand(self.swarm_size, self.dim)\n                r2 = np.random.rand(self.swarm_size, self.dim)\n                velocity = (self.inertia_weight * velocity +\n                            self.cognitive_coeff * r1 * (pbest_pos - swarm) +\n                            self.social_coeff * r2 * (gbest_pos - swarm))\n\n                quantum_jump = np.random.uniform(-self.quantum_influence, self.quantum_influence, (self.swarm_size, self.dim))\n                velocity += quantum_jump\n\n                swarm += velocity\n                swarm = np.clip(swarm, lb, ub)\n\n                fitness = np.array([func(p) for p in swarm])\n                evaluations += self.swarm_size\n\n                improved = fitness < pbest_fitness[swarm_idx]\n                pbest_positions[swarm_idx][improved] = swarm[improved]\n                pbest_fitness[swarm_idx][improved] = fitness[improved]\n\n                if np.min(fitness) < gbest_fitness[swarm_idx]:\n                    gbest_fitness[swarm_idx] = np.min(fitness)\n                    gbest_positions[swarm_idx] = swarm[np.argmin(fitness)]\n\n            # Cooperative behavior by exchanging gbest among swarms\n            for i in range(self.num_swarms):\n                for j in range(i + 1, self.num_swarms):\n                    if gbest_fitness[i] < gbest_fitness[j]:\n                        gbest_positions[j] = gbest_positions[i]\n                        gbest_fitness[j] = gbest_fitness[i]\n                    elif gbest_fitness[j] < gbest_fitness[i]:\n                        gbest_positions[i] = gbest_positions[j]\n                        gbest_fitness[i] = gbest_fitness[j]\n\n        # Return the best global solution found across all swarms\n        global_best_idx = np.argmin(gbest_fitness)\n        return gbest_positions[global_best_idx]", "name": "QuantumInspiredMultiSwarmPSO", "description": "Quantum-Inspired Multi-Swarm Particle Swarm Optimization leverages quantum superposition and multi-swarm cooperation to enhance search diversity and convergence in optimizing photonic structures.", "configspace": "", "generation": 71, "fitness": 0.28583502043671993, "feedback": "The algorithm QuantumInspiredMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.28583502043671993]}, "mutation_prompt": null}
{"id": "ce9c1a26-725c-4f47-bc8a-1fe20b2320c4", "solution": "import numpy as np\n\nclass AdaptiveHarmonySearchQuantum:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.hms = 50  # Harmony Memory Size\n        self.hmcr = 0.9  # Harmony Memory Consideration Rate\n        self.par_min, self.par_max = 0.1, 0.5  # Pitch Adjustment Rate\n        self.bandwidth_min, self.bandwidth_max = 0.01, 0.1  # Bandwidth\n        self.quantum_factor = 0.05  # Quantum-inspired mutation factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory = lb + (ub - lb) * np.random.rand(self.hms, self.dim)\n        fitness = np.array([func(harmony) for harmony in harmony_memory])\n        best_idx = np.argmin(fitness)\n        best_harmony = harmony_memory[best_idx]\n\n        evaluations = self.hms\n\n        while evaluations < self.budget:\n            new_harmony = np.zeros(self.dim)\n\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    idx = np.random.randint(0, self.hms)\n                    new_harmony[i] = harmony_memory[idx, i]\n                    if np.random.rand() < np.random.uniform(self.par_min, self.par_max):\n                        bw = np.random.uniform(self.bandwidth_min, self.bandwidth_max)\n                        new_harmony[i] += bw * (np.random.rand() - 0.5)\n                else:\n                    new_harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            # Quantum-inspired mutation\n            if np.random.rand() < self.quantum_factor:\n                mutation_scale = np.random.uniform(0.1, 0.3)\n                quantum_mutation = mutation_scale * (ub - lb) * np.random.rand(self.dim)\n                new_harmony += quantum_mutation\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_fitness = func(new_harmony)\n            evaluations += 1\n\n            if new_fitness < fitness[best_idx]:\n                best_harmony = new_harmony\n                best_idx = np.argmax(fitness)\n                harmony_memory[best_idx] = new_harmony\n                fitness[best_idx] = new_fitness\n\n        return best_harmony", "name": "AdaptiveHarmonySearchQuantum", "description": "Adaptive Harmony Search with Quantum-Inspired Mutation optimizes black box functions by harmonizing adaptive pitch adjustment and quantum-inspired mutation for dynamic exploration and exploitation.", "configspace": "", "generation": 72, "fitness": 0.2786137081200063, "feedback": "The algorithm AdaptiveHarmonySearchQuantum got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.2786137081200063]}, "mutation_prompt": null}
{"id": "5c24bc9e-80c7-4901-86f0-845aaf03dfed", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w_min, self.w_max = 0.4, 0.9\n        self.c1_min, self.c1_max = 1.5, 2.5\n        self.c2_min, self.c2_max = 1.5, 2.5\n        self.alpha_min, self.alpha_max = 0.5, 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        position_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        positions = lb + (ub - lb) * np.cos(np.pi * position_quantum)\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim)) * (ub - lb) * 0.1\n        fitness = np.array([func(x) for x in positions])\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_fitness = np.copy(fitness)\n        \n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                w = np.random.uniform(self.w_min, self.w_max)\n                c1 = np.random.uniform(self.c1_min, self.c1_max)\n                c2 = np.random.uniform(self.c2_min, self.c2_max)\n                alpha = np.random.uniform(self.alpha_min, self.alpha_max)\n\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 c2 * r2 * (global_best_position - positions[i]))\n\n                quantum_shift = np.random.uniform(-alpha, alpha, self.dim)\n                new_position = positions[i] + velocities[i] + quantum_shift\n\n                new_position = np.clip(new_position, lb, ub)\n                new_fitness = func(new_position)\n                evaluations += 1\n\n                if new_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = new_position\n                    personal_best_fitness[i] = new_fitness\n                    if new_fitness < personal_best_fitness[global_best_idx]:\n                        global_best_idx = i\n                        global_best_position = new_position\n\n            positions += velocities\n\n        return global_best_position", "name": "AdaptiveQuantumInspiredPSO", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization leverages quantum-inspired position updating and dynamic parameter adaptation for efficient and robust exploration of photonic structure design spaces.", "configspace": "", "generation": 73, "fitness": 0.2933909196934348, "feedback": "The algorithm AdaptiveQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.2933909196934348]}, "mutation_prompt": null}
{"id": "4d725a5c-8e45-4b7c-bcbd-662bc0f5271e", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.success_rates = [0.5, 0.5]\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.swarm_size, self.dim))\n        positions = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        velocities = np.random.uniform(-1, 1, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_fitness = np.array([func(x) for x in positions])\n        global_best_idx = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) + \n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] = positions[i] + velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                fitness = func(positions[i])\n                evaluations += 1\n\n                if fitness < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness\n                    personal_best_positions[i] = positions[i]\n                    if fitness < personal_best_fitness[global_best_idx]:\n                        global_best_idx = i\n                        global_best_position = positions[i]\n\n        return global_best_position", "name": "QuantumEnhancedAdaptivePSO", "description": "The Quantum-Enhanced Adaptive Particle Swarm Optimization integrates quantum-inspired initialization and self-tuning inertia to enhance global exploration and convergence for photonic structure optimization.", "configspace": "", "generation": 74, "fitness": 0.2933909196934348, "feedback": "The algorithm QuantumEnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.2933909196934348]}, "mutation_prompt": null}
{"id": "eb421a6b-8d9f-4d62-ae38-96600a456c31", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_base = 0.5\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n        evaluations = self.population_size\n        last_improvement = 0\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n            progress = evaluations / self.budget\n            F_dynamic = self.F_base + (1 - progress) * (1 - self.F_base)  # Dynamic scaling of F\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_base, F_dynamic)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n\n                if strategy == 0:\n                    mutant = x0 + F * (x1 - x2)\n                else:\n                    mutant = best_global + F * (x1 - x2)\n\n                mutant = np.clip(mutant, lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                        last_improvement = evaluations\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            if evaluations - last_improvement > self.population_size:\n                break  # Terminate early if no improvement\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "QuantumInspiredAdaptiveDE", "description": "Quantum-Inspired Adaptive Differential Evolution with Dynamic Mutation Adjustments uses quantum probability distributions combined with dynamic mutation scaling based on convergence progress to enhance global exploration and solution refinement.", "configspace": "", "generation": 75, "fitness": 0.2935035766815599, "feedback": "The algorithm QuantumInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.2935035766815599]}, "mutation_prompt": null}
{"id": "59405e74-299e-4f39-a9f6-62ac8206a525", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive constant\n        self.c2 = 1.5  # Social constant\n        self.q_factor = 0.2  # Quantum factor to introduce randomness\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        particles = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in particles])\n        personal_best = particles.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = particles[global_best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(2)\n                cognitive_component = self.c1 * r1 * (personal_best[i] - particles[i])\n                social_component = self.c2 * r2 * (global_best - particles[i])\n                quantum_noise = self.q_factor * np.random.normal(0, 1, self.dim)\n\n                velocity[i] = (self.w * velocity[i] + cognitive_component + social_component + quantum_noise)\n                particles[i] = np.clip(particles[i] + velocity[i], lb, ub)\n\n                current_fitness = func(particles[i])\n                evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_fitness[i] = current_fitness\n\n                    if current_fitness < personal_best_fitness[global_best_idx]:\n                        global_best_idx = i\n                        global_best = particles[i]\n\n        return global_best", "name": "QuantumInspiredPSO", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) leverages quantum-inspired position updates for particles to enhance diversity and convergence in optimizing photonic structures.", "configspace": "", "generation": 76, "fitness": 0.29186300440089574, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.29186300440089574]}, "mutation_prompt": null}
{"id": "59ab21c9-897e-42c7-9ffd-09ab2b2e57c4", "solution": "import numpy as np\n\nclass QuantumInspiredLevyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "QuantumInspiredLevyFlightDE", "description": "Quantum-Inspired Levy Flight Differential Evolution enhances global exploration of photonic structures by integrating Levy flight distributions with quantum probability and self-adaptive mechanisms for robust convergence.", "configspace": "", "generation": 77, "fitness": 0.29889505575653597, "feedback": "The algorithm QuantumInspiredLevyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "64614803-e298-43ec-9112-0c37bc539ba5", "metadata": {"aucs": [0.29889505575653597]}, "mutation_prompt": null}
{"id": "e27b2c9a-11ad-4565-bc8f-4af06528b700", "solution": "import numpy as np\n\nclass QuantumParticleSwarmAdaptiveTunneling:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1, self.c2 = 1.5, 1.5\n        self.w_min, self.w_max = 0.4, 0.9\n        self.tunneling_prob = 0.1\n        self.history = []\n\n    def adaptive_tunneling(self, position, best_global, lb, ub):\n        tunnel = np.random.uniform(-0.1, 0.1, self.dim)\n        if np.random.rand() < self.tunneling_prob:\n            new_position = position + tunnel * (best_global - position)\n            return np.clip(new_position, lb, ub)\n        return position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_individual = pop.copy()\n        best_individual_fitness = fitness.copy()\n        best_global_idx = np.argmin(fitness)\n        best_global = pop[best_global_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (best_individual[i] - pop[i]) +\n                                 self.c2 * r2 * (best_global - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n                pop[i] = self.adaptive_tunneling(pop[i], best_global, lb, ub)\n\n                current_fitness = func(pop[i])\n                evaluations += 1\n\n                if current_fitness < best_individual_fitness[i]:\n                    best_individual[i] = pop[i]\n                    best_individual_fitness[i] = current_fitness\n                    if current_fitness < fitness[best_global_idx]:\n                        best_global_idx = i\n                        best_global = pop[i]\n\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumParticleSwarmAdaptiveTunneling", "description": "Quantum Particle Swarm Optimization with Adaptive Quantum Tunneling combines quantum-inspired particle swarm optimization with adaptive tunneling mechanisms for efficient exploration and convergence in photonic structure optimization.", "configspace": "", "generation": 78, "fitness": 0.2818713547679371, "feedback": "The algorithm QuantumParticleSwarmAdaptiveTunneling got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "59ab21c9-897e-42c7-9ffd-09ab2b2e57c4", "metadata": {"aucs": [0.2818713547679371]}, "mutation_prompt": null}
{"id": "f49aaf93-3ace-4328-9808-a5ab01bc035b", "solution": "import numpy as np\n\nclass EntangledQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.alpha = 0.5  # Weight for cognitive component\n        self.beta = 0.3  # Weight for social component\n        self.gamma = 0.2  # Weight for quantum entanglement\n        self.history = []\n\n    def quantum_entanglement(self, particles, best_global):\n        entangled_particles = []\n        for particle in particles:\n            delta = np.random.uniform(-1, 1, self.dim)\n            entangled_particle = particle + self.gamma * delta * (best_global - particle)\n            entangled_particles.append(entangled_particle)\n        return np.array(entangled_particles)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-0.1, 0.1, (self.swarm_size, self.dim))\n        personal_best = particles.copy()\n        personal_best_fitness = np.array([func(x) for x in personal_best])\n        best_idx = np.argmin(personal_best_fitness)\n        best_global = personal_best[best_idx]\n\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            entangled_particles = self.quantum_entanglement(particles, best_global)\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.uniform(size=2)\n                velocities[i] = (self.alpha * velocities[i]\n                                 + self.beta * r1 * (personal_best[i] - particles[i])\n                                 + self.beta * r2 * (best_global - particles[i]))\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n\n                fitness = func(particles[i])\n                evaluations += 1\n\n                if fitness < personal_best_fitness[i]:\n                    personal_best[i] = particles[i]\n                    personal_best_fitness[i] = fitness\n                    if fitness < personal_best_fitness[best_idx]:\n                        best_idx = i\n                        best_global = particles[i]\n\n            # Quantum entangled update\n            particles = (1 - self.gamma) * particles + self.gamma * entangled_particles\n\n            self.history.append(best_global)\n\n        return best_global", "name": "EntangledQuantumPSO", "description": "Entangled Quantum Particle Swarm Optimization synergizes quantum entanglement and particle swarm dynamics to enhance cooperative exploration and exploitation for optimizing photonic structures.", "configspace": "", "generation": 79, "fitness": 0.2820973868192942, "feedback": "The algorithm EntangledQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "59ab21c9-897e-42c7-9ffd-09ab2b2e57c4", "metadata": {"aucs": [0.2820973868192942]}, "mutation_prompt": null}
{"id": "c6ae6639-4cbb-4174-907d-fc6bb0f0f57a", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveDEDynamicPop:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50  # Initial population size\n        self.min_population_size = 20\n        self.max_population_size = 100\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def dynamic_population_size(self, evaluations):\n        # Adjust population size dynamically based on the remaining budget\n        remaining_budget = self.budget - evaluations\n        return max(self.min_population_size, \n                   min(self.max_population_size, \n                       int(self.population_size * (remaining_budget / self.budget) + self.min_population_size)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            current_pop_size = self.dynamic_population_size(evaluations)\n            next_pop = np.zeros((current_pop_size, self.dim))\n            successes = [0, 0]\n\n            for i in range(current_pop_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i % self.population_size])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % self.population_size]:\n                    next_pop[i] = trial\n                    fitness[i % self.population_size] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % self.population_size\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % self.population_size]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "QuantumEnhancedAdaptiveDEDynamicPop", "description": "Quantum-Enhanced Adaptive DE with Dynamic Population leverages quantum population initialization and adaptive differential evolution with dynamic population sizing for enhanced convergence in photonic structure optimization.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 49 is out of bounds for axis 0 with size 49').", "error": "IndexError('index 49 is out of bounds for axis 0 with size 49')", "parent_id": "59ab21c9-897e-42c7-9ffd-09ab2b2e57c4", "metadata": {}, "mutation_prompt": null}
{"id": "38edbc32-a5bc-4918-8d68-e940c02c3b33", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredLevyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.min_population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.6, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.05, 0.25\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = self.initial_population_size\n        population_quantum = np.random.uniform(0, 1, (pop_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = pop_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n\n            for i in range(pop_size):\n                indices = np.random.choice(range(pop_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n            # Dynamically adjust population size based on diversity\n            pop_variance = np.var(pop, axis=0).mean()\n            if pop_variance < 0.1 and pop_size > self.min_population_size:\n                pop_size = max(self.min_population_size, pop_size // 2)\n                pop = pop[:pop_size]\n                fitness = fitness[:pop_size]\n\n        return best_global", "name": "AdaptiveQuantumInspiredLevyFlightDE", "description": "Adaptive Quantum-Inspired Levy Flight Differential Evolution enhances convergence by dynamically adjusting population size and integrating quantum-inspired interactions with Levy flight and fitness diversity metrics.", "configspace": "", "generation": 81, "fitness": 0.29346595442391865, "feedback": "The algorithm AdaptiveQuantumInspiredLevyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "59ab21c9-897e-42c7-9ffd-09ab2b2e57c4", "metadata": {"aucs": [0.29346595442391865]}, "mutation_prompt": null}
{"id": "b1edd418-71cf-4eb8-83f0-31be98c4ef5d", "solution": "import numpy as np\n\nclass QuantumHamiltonianOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.alpha_min, self.alpha_max = 0.5, 1.0\n        self.beta_min, self.beta_max = 0.3, 0.8\n        self.crossover_rate = 0.9\n        self.history = []\n\n    def quantum_walk(self, alpha=0.7):\n        step = np.random.normal(0, alpha, self.dim)\n        return step\n\n    def adaptive_learning_rate(self, fitness):\n        return np.exp(-fitness / np.max(fitness))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(x) for x in population])\n        best_idx = np.argmin(fitness)\n        best_global = population[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = np.zeros_like(population)\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = population[indices]\n\n                alpha = np.random.uniform(self.alpha_min, self.alpha_max)\n                beta = np.random.uniform(self.beta_min, self.beta_max)\n                quantum_step = self.quantum_walk(alpha)\n                learning_rate = self.adaptive_learning_rate(fitness[i])\n\n                mutant = x0 + beta * (x1 - x2) + quantum_step * learning_rate\n                mutant = np.clip(mutant, lb, ub)\n\n                crossover = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(crossover, mutant, population[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    new_population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    new_population[i] = population[i]\n\n            self.history.append(best_global)\n            population = new_population\n\n        return best_global", "name": "QuantumHamiltonianOptimization", "description": "Quantum Hamiltonian Optimization leverages quantum walks coupled with adaptive learning rates and genetic crossover to achieve efficient global optimization of photonic structures.", "configspace": "", "generation": 82, "fitness": 0.2780946421117275, "feedback": "The algorithm QuantumHamiltonianOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "59ab21c9-897e-42c7-9ffd-09ab2b2e57c4", "metadata": {"aucs": [0.2780946421117275]}, "mutation_prompt": null}
{"id": "d12de98a-e7d9-44b8-97e9-0c625f9a639b", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptiveLevyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.diversity_threshold = 0.1\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def calculate_diversity(self, population):\n        mean = np.mean(population, axis=0)\n        diversity = np.mean(np.linalg.norm(population - mean, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros_like(pop)\n            successes = [0, 0]\n            diversity = self.calculate_diversity(pop)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                if diversity < self.diversity_threshold:\n                    F = self.F_max\n                    CR = self.CR_max\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    next_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "QuantumInspiredAdaptiveLevyFlightDE", "description": "Quantum-Inspired Adaptive Levy Flight DE with Dynamic Parameter Adjustment improves exploitation and exploration by dynamically adjusting control parameters based on population diversity and historical success rates.", "configspace": "", "generation": 83, "fitness": 0.29889505575653597, "feedback": "The algorithm QuantumInspiredAdaptiveLevyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "59ab21c9-897e-42c7-9ffd-09ab2b2e57c4", "metadata": {"aucs": [0.29889505575653597]}, "mutation_prompt": null}
{"id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredLevyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0]\n\n            for i in range(cur_population_size):\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i % len(pop)])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "EnhancedQuantumInspiredLevyFlightDE", "description": "Enhanced Quantum-Inspired Levy Flight Differential Evolution with Adaptive Population Dynamics for improved convergence in photonic structure optimization.", "configspace": "", "generation": 84, "fitness": 0.33374832664574616, "feedback": "The algorithm EnhancedQuantumInspiredLevyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.00.", "error": "", "parent_id": "59ab21c9-897e-42c7-9ffd-09ab2b2e57c4", "metadata": {"aucs": [0.33374832664574616]}, "mutation_prompt": null}
{"id": "2c376976-f23c-4a3b-94bb-1ec12587e981", "solution": "import numpy as np\n\nclass AdaptiveQuantumPSOLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1, self.c2 = 2.0, 2.0\n        self.w_min, self.w_max = 0.4, 0.9\n        self.alpha = 0.5\n        self.beta = 1.5\n\n    def levy_flight(self):\n        sigma = (np.math.gamma(1 + self.beta) * np.sin(np.pi * self.beta / 2) /\n                 (np.math.gamma((1 + self.beta) / 2) * self.beta * 2 ** ((self.beta - 1) / 2))) ** (1 / self.beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / self.beta)\n        return 0.01 * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        positions = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]) +\n                                 self.alpha * self.levy_flight())\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                if current_score < personal_best_scores[global_best_idx]:\n                    global_best_idx = i\n                    global_best_position = positions[i]\n\n        return global_best_position", "name": "AdaptiveQuantumPSOLevy", "description": "Adaptive Quantum-Inspired Particle Swarm Optimization with Levy Flight Mutation for enhanced exploration and exploitation in photonic structure optimization.", "configspace": "", "generation": 85, "fitness": 0.28188346225463845, "feedback": "The algorithm AdaptiveQuantumPSOLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.28188346225463845]}, "mutation_prompt": null}
{"id": "167db366-fb3b-4926-a0c7-8a7d5e4d5314", "solution": "import numpy as np\n\nclass QuantumInspiredDynamicAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1, self.c2 = 1.5, 1.5\n        self.w_min, self.w_max = 0.4, 0.9\n        self.success_rate_threshold = 0.2\n        self.particles = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        self.personal_best_positions = np.copy(self.particles)\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_fitness = np.inf\n        self.success_rates = [0.5, 0.5]\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evaluations = 0\n        inertia_weight = self.w_max\n\n        while evaluations < self.budget:\n            successes = [0, 0]\n            for i in range(self.population_size):\n                # Evaluate current fitness\n                fitness = func(self.particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if fitness < self.personal_best_fitness[i]:\n                    self.personal_best_fitness[i] = fitness\n                    self.personal_best_positions[i] = self.particles[i]\n\n                # Update global best\n                if fitness < self.global_best_fitness:\n                    self.global_best_fitness = fitness\n                    self.global_best_position = self.particles[i]\n\n            # Update inertia weight\n            inertia_weight = self.w_max - ((self.w_max - self.w_min) * (evaluations / self.budget))\n\n            for i in range(self.population_size):\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                r1, r2 = np.random.uniform(0, 1, 2)\n                levy_step = self.levy_flight()\n\n                if strategy == 0:\n                    velocity = (inertia_weight * self.velocities[i] +\n                                self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                self.c2 * r2 * (self.global_best_position - self.particles[i]) + levy_step)\n                else:\n                    velocity = (inertia_weight * self.velocities[i] +\n                                self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                levy_step)\n\n                self.velocities[i] = np.clip(velocity, lb - self.particles[i], ub - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n                # Evaluate success rate\n                new_fitness = func(self.particles[i])\n                evaluations += 1\n                if new_fitness < fitness:\n                    successes[strategy] += 1\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n                self.success_rates = [max(rate, self.success_rate_threshold) for rate in self.success_rates]\n\n        return self.global_best_position", "name": "QuantumInspiredDynamicAdaptivePSO", "description": "Quantum-Inspired Dynamic Adaptive Particle Swarm Optimization with Levy Flights for enhanced exploration and exploitation in optimizing photonic structures.", "configspace": "", "generation": 86, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('probabilities do not sum to 1').", "error": "ValueError('probabilities do not sum to 1')", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {}, "mutation_prompt": null}
{"id": "be2e4560-4355-45be-9fdf-6e11d3958319", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredLevyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def adaptive_diversity_factor(self, evaluations):\n        return self.diversity_factor_min + (self.diversity_factor_max - self.diversity_factor_min) * (1 - evaluations / self.budget)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0]\n            adaptive_div_factor = self.adaptive_diversity_factor(evaluations)\n\n            for i in range(cur_population_size):\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-adaptive_div_factor, adaptive_div_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i % len(pop)])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "EnhancedQuantumInspiredLevyFlightDE", "description": "A Quantum-Inspired Levy Flight Differential Evolution algorithm enhanced with Adaptive Diversity-driven Strategies for improved convergence in photonic structure optimization.", "configspace": "", "generation": 87, "fitness": 0.2933909196934348, "feedback": "The algorithm EnhancedQuantumInspiredLevyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.2933909196934348]}, "mutation_prompt": null}
{"id": "93952b30-18f5-4924-9ed3-bb7dd41cc8b4", "solution": "import numpy as np\n\nclass AdaptiveQuantumLevyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.crossover_strategy = 0  # 0 for binomial, 1 for exponential\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.initial_population_size * (1 - evaluations / self.budget)))\n\n    def crossover(self, target, mutant, CR):\n        if self.crossover_strategy == 0:  # Binomial Crossover\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            return np.where(cross_points, mutant, target)\n        else:  # Exponential Crossover\n            n = np.random.randint(0, self.dim)\n            L = np.random.geometric(CR)\n            j = np.arange(self.dim)\n            cross_points = (j >= n) & (j < n + L)\n            return np.where(cross_points, mutant, target)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.initial_population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0]\n\n            for i in range(cur_population_size):\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n\n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = self.crossover(pop[i % len(pop)], mutant, CR)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "AdaptiveQuantumLevyFlightDE", "description": "Adaptive Quantum-Inspired Levy Flight Differential Evolution with Enhanced Crossover Strategy for robust optimization of photonic structures.", "configspace": "", "generation": 88, "fitness": 0.33374832664574616, "feedback": "The algorithm AdaptiveQuantumLevyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.33374832664574616]}, "mutation_prompt": null}
{"id": "6ee3177f-1cb5-49d4-8dcd-b3db3e656581", "solution": "import numpy as np\n\nclass HybridQuantumInspiredPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.w_min, self.w_max = 0.5, 0.9\n        self.c1, self.c2 = 1.5, 1.5\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0]\n\n            for i in range(cur_population_size):\n                x0 = pop[i % len(pop)]\n                velocity = velocities[i % len(pop)]\n\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                w = np.random.uniform(self.w_min, self.w_max)\n                levy_step = self.levy_flight()\n\n                if strategy == 0:\n                    # PSO-inspired update\n                    personal_best = x0\n                    inertia = w * velocity\n                    cog = self.c1 * np.random.random(self.dim) * (personal_best - x0)\n                    soc = self.c2 * np.random.random(self.dim) * (best_global - x0)\n                    velocity = inertia + cog + soc + levy_step\n                    mutant = x0 + velocity\n                else:\n                    # DE-inspired update\n                    indices = np.random.choice(range(len(pop)), 3, replace=False)\n                    _, x1, x2 = pop[indices]\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, x0)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    velocities[i % len(pop)] = velocity\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = x0\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "HybridQuantumInspiredPSO_DE", "description": "Hybrid Quantum-Inspired Particle Swarm and Differential Evolution with Adaptive Levy Flight for enhanced global search and convergence in photonic structure optimization.", "configspace": "", "generation": 89, "fitness": 0.2933909196934348, "feedback": "The algorithm HybridQuantumInspiredPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.2933909196934348]}, "mutation_prompt": null}
{"id": "1e3a8c0d-7568-4ec6-9f81-655ad31093b0", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.min_population_size = 20\n        self.F_range = (0.4, 0.9)\n        self.CR_range = (0.7, 1.0)\n        self.diversity_factor_range = (0.1, 0.3)\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(self.min_population_size, int(self.initial_population_size * (1 - evaluations / self.budget)))\n\n    def stochastic_restart(self, evaluations):\n        return np.random.rand() < (evaluations / self.budget) ** 2  # Higher chance to restart as evaluations increase\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.initial_population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            if self.stochastic_restart(evaluations):\n                population_quantum = np.random.uniform(0, 1, (self.initial_population_size, self.dim))\n                pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n                fitness = np.array([func(x) for x in pop])\n                best_idx = np.argmin(fitness)\n                best_global = pop[best_idx]\n\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0]\n\n            for i in range(cur_population_size):\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(*self.F_range)\n                CR = np.random.uniform(*self.CR_range)\n                diversity_factor = np.random.uniform(*self.diversity_factor_range)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i % len(pop)])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "QuantumInspiredAdaptiveDE", "description": "Quantum-Inspired Adaptive Differential Evolution with Stochastic Restart Mechanism and Levy Flights for accelerated convergence in complex photonic structure optimization.", "configspace": "", "generation": 90, "fitness": 0.3189194487463243, "feedback": "The algorithm QuantumInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.3189194487463243]}, "mutation_prompt": null}
{"id": "c7744b95-1621-4442-8f94-33f398b495c3", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptiveOBLDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.7, 0.9\n        self.history = []\n\n    def quantum_position(self, lb, ub):\n        quantum_particles = np.random.uniform(0, 1, (self.population_size, self.dim))\n        return lb + (ub - lb) * np.cos(np.pi * quantum_particles)\n\n    def opposition_based_learning(self, x, lb, ub):\n        return lb + ub - x\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = self.quantum_position(lb, ub)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            next_pop = np.zeros((self.population_size, self.dim))\n\n            for i in range(self.population_size):\n                indices = np.random.choice(range(self.population_size), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n\n                mutant = x0 + F * (x1 - x2)\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_obl = self.opposition_based_learning(trial, lb, ub)\n                trial_fitness = func(trial)\n                trial_obl_fitness = func(trial_obl)\n                evaluations += 2\n\n                if trial_fitness < fitness[i] or trial_obl_fitness < fitness[i]:\n                    if trial_fitness < trial_obl_fitness:\n                        next_pop[i] = trial\n                        fitness[i] = trial_fitness\n                    else:\n                        next_pop[i] = trial_obl\n                        fitness[i] = trial_obl_fitness\n\n                    if fitness[i] < fitness[best_idx]:\n                        best_idx = i\n                        best_global = next_pop[i]\n                else:\n                    next_pop[i] = pop[i]\n\n            pop = next_pop\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumInspiredAdaptiveOBLDE", "description": "Quantum-Inspired Adaptive Opposition-Based Learning Differential Evolution integrates quantum principles with opposition-based learning for enhanced exploration and convergence.", "configspace": "", "generation": 91, "fitness": 0.29491582837040464, "feedback": "The algorithm QuantumInspiredAdaptiveOBLDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.29491582837040464]}, "mutation_prompt": null}
{"id": "f35a8859-739a-412e-8920-e3d47cb1025b", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptiveMSDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.33, 0.33, 0.34]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0, 0]\n\n            for i in range(cur_population_size):\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1, 2], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                elif strategy == 1:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n                else:\n                    mutant = x0 + F * (best_global - x0) + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i % len(pop)])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "QuantumInspiredAdaptiveMSDE", "description": "Quantum-Inspired Adaptive Multi-Strategy Differential Evolution with Dynamic Levy Flight for enhanced exploration-exploitation balance in photonic structure optimization.", "configspace": "", "generation": 92, "fitness": 0.31800717494586783, "feedback": "The algorithm QuantumInspiredAdaptiveMSDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.31800717494586783]}, "mutation_prompt": null}
{"id": "aaddb8fe-8861-4c3f-b9d3-167e98355774", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredLevyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def opposition_based_learning(self, current_pop, lb, ub):\n        return lb + ub - current_pop\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0]\n\n            for i in range(cur_population_size):\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n\n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i % len(pop)])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                opposition_solution = self.opposition_based_learning(trial, lb, ub)\n                opposition_fitness = func(np.clip(opposition_solution, lb, ub))\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)] or opposition_fitness < fitness[i % len(pop)]:\n                    if opposition_fitness < trial_fitness:\n                        trial = opposition_solution\n                        trial_fitness = opposition_fitness\n\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "EnhancedQuantumInspiredLevyFlightDE", "description": "Enhanced Quantum-Inspired Levy Flight DE with Adaptive Mutation Strategies and Opposition-Based Learning for improved exploration-exploitation balance in photonic structure optimization.", "configspace": "", "generation": 93, "fitness": 0.2933909196934348, "feedback": "The algorithm EnhancedQuantumInspiredLevyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.2933909196934348]}, "mutation_prompt": null}
{"id": "b7ed691c-6209-4a3d-98ab-46582385b0d4", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredLevyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def adaptive_f_cr(self):\n        F = np.random.uniform(self.F_min, self.F_max)\n        CR = np.random.uniform(self.CR_min, self.CR_max)\n        return F, CR\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0]\n\n            for i in range(cur_population_size):\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F, CR = self.adaptive_f_cr()\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i % len(pop)])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "EnhancedQuantumInspiredLevyFlightDE", "description": "Enhanced Quantum-Inspired Levy Flight Differential Evolution with Adaptive Control of Mutation and Crossover using Historical Success Metrics for optimized convergence in photonic structure optimization.", "configspace": "", "generation": 94, "fitness": 0.33374832664574616, "feedback": "The algorithm EnhancedQuantumInspiredLevyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.33374832664574616]}, "mutation_prompt": null}
{"id": "d72dd5c7-6dac-4877-8684-c6a638c9214c", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredLevyFlightDESelfAdaptive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def self_adaptive_params(self, F, CR, strategy_success):\n        tau1, tau2 = 0.1, 0.1\n        if np.random.rand() < tau1:\n            F = self.F_min + np.random.rand() * (self.F_max - self.F_min)\n        if np.random.rand() < tau2:\n            CR = self.CR_min + np.random.rand() * (self.CR_max - self.CR_min)\n        if np.random.rand() < 0.5:\n            strategy_success[0], strategy_success[1] = strategy_success[1], strategy_success[0]\n        return F, CR\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0]\n\n            for i in range(cur_population_size):\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n\n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                F, CR = self.self_adaptive_params(F, CR, successes)\n\n                levy_step = self.levy_flight()\n\n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i % len(pop)])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            pop = next_pop\n\n        return best_global", "name": "EnhancedQuantumInspiredLevyFlightDESelfAdaptive", "description": "Enhanced Quantum-Inspired Levy Flight Differential Evolution with Self-Adaptive Parameters for improved robustness in exploring and exploiting the search space in photonic structure optimization.", "configspace": "", "generation": 95, "fitness": 0.29603935720616736, "feedback": "The algorithm EnhancedQuantumInspiredLevyFlightDESelfAdaptive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.29603935720616736]}, "mutation_prompt": null}
{"id": "acc7c829-7840-44de-afc2-7d03f03a16c4", "solution": "import numpy as np\n\nclass QuantumInspiredBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.A = 0.5  # Loudness\n        self.r_min, self.r_max = 0.0, 1.0  # Pulse rate bounds\n        self.q_min, self.q_max = 0.0, 2.0  # Frequency bounds\n        self.alpha = 0.9  # Loudness reduction factor\n        self.gamma = 0.9  # Pulse rate increase factor\n        self.history = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n        pulse_rate = np.random.uniform(self.r_min, self.r_max, self.population_size)\n        frequency = np.random.uniform(self.q_min, self.q_max, self.population_size)\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                beta = np.random.rand()\n                frequency[i] = self.q_min + (self.q_max - self.q_min) * beta\n                velocity[i] = velocity[i] + (pop[i] - best_global) * frequency[i]\n                candidate = pop[i] + velocity[i]\n\n                if np.random.rand() > pulse_rate[i]:\n                    candidate = best_global + 0.001 * np.random.normal(size=self.dim)\n\n                candidate = np.clip(candidate, lb, ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n\n                if candidate_fitness < fitness[i] and np.random.rand() < self.A:\n                    pop[i] = candidate\n                    fitness[i] = candidate_fitness\n                    pulse_rate[i] = self.r_min + (self.r_max - self.r_min) * self.gamma\n                    self.A *= self.alpha\n\n                    if candidate_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best_global = candidate\n\n            self.history.append(best_global)\n\n        return best_global", "name": "QuantumInspiredBatAlgorithm", "description": "Quantum-Inspired Bat Algorithm with Adaptive Pulse Rate and Loudness for enhanced exploration-exploitation balance in complex photonic structure optimization.", "configspace": "", "generation": 96, "fitness": 0.2933909196934348, "feedback": "The algorithm QuantumInspiredBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.2933909196934348]}, "mutation_prompt": null}
{"id": "aa8e9bb2-a615-42bc-9873-14c05f1041b3", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredLevyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.33, 0.33, 0.34]  # Three strategies\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0, 0]\n\n            for i in range(cur_population_size):\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1, 2], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                elif strategy == 1:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n                else:\n                    centroid = np.mean(pop, axis=0)\n                    mutant = centroid + F * (x0 - x1) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i % len(pop)])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(best_global)\n            pop = next_pop\n\n        return best_global", "name": "EnhancedQuantumInspiredLevyFlightDE", "description": "Enhanced Quantum-Inspired Levy Flight Differential Evolution with Multi-Strategy Adaptation for Diverse Exploration and Exploitation Balancing in photonic structure optimization.", "configspace": "", "generation": 97, "fitness": 0.30480763769063457, "feedback": "The algorithm EnhancedQuantumInspiredLevyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.30480763769063457]}, "mutation_prompt": null}
{"id": "878fafca-db59-496b-aec4-3f6f703336d7", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredLevyFlightDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def exponential_crossover(self, target, mutant, CR):\n        n = len(target)\n        j_rand = np.random.randint(0, n)\n        cross_points = np.zeros(n, dtype=bool)\n        for j in range(n):\n            if np.random.rand() < CR or j == j_rand:\n                cross_points[j] = True\n        return np.where(cross_points, mutant, target)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n        historical_best_global = best_global\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0]\n\n            for i in range(cur_population_size):\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = historical_best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                trial = self.exponential_crossover(pop[i % len(pop)], mutant, CR)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                        if trial_fitness < func(historical_best_global):\n                            historical_best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            total_successes = sum(successes)\n            if total_successes > 0:\n                self.success_rates = [s / total_successes for s in successes]\n\n            self.history.append(historical_best_global)\n            pop = next_pop\n\n        return historical_best_global", "name": "EnhancedQuantumInspiredLevyFlightDE", "description": "Enhanced Quantum-Inspired Levy Flight DE with Adaptive Historical Memory and Exponential Crossover for faster convergence in photonic structure optimization.", "configspace": "", "generation": 98, "fitness": 0.2933909196934348, "feedback": "The algorithm EnhancedQuantumInspiredLevyFlightDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.2933909196934348]}, "mutation_prompt": null}
{"id": "1f89ef54-39d8-4032-b585-013b8394ebfd", "solution": "import numpy as np\n\nclass AdaptiveMultiStratumQuantumLevyDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.F_min, self.F_max = 0.4, 0.9\n        self.CR_min, self.CR_max = 0.7, 1.0\n        self.diversity_factor_min, self.diversity_factor_max = 0.1, 0.3\n        self.success_rates = [0.5, 0.5]\n        self.history = []\n        self.stratum_levels = 3\n\n    def levy_flight(self, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return 0.01 * step\n\n    def adapt_population_size(self, evaluations):\n        return max(20, int(self.population_size * (1 - evaluations / self.budget)))\n\n    def dynamic_success_rate_rebalancing(self, successes):\n        total_successes = sum(successes)\n        if total_successes > 0:\n            return [s / total_successes for s in successes]\n        return self.success_rates\n\n    def preserve_diversity(self, population, lb, ub):\n        diversity_offsets = np.random.uniform(-0.05, 0.05, population.shape)\n        return np.clip(population + diversity_offsets, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_quantum = np.random.uniform(0, 1, (self.population_size, self.dim))\n        pop = lb + (ub - lb) * np.cos(np.pi * population_quantum)\n        fitness = np.array([func(x) for x in pop])\n        best_idx = np.argmin(fitness)\n        best_global = pop[best_idx]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            cur_population_size = self.adapt_population_size(evaluations)\n            stratum_size = cur_population_size // self.stratum_levels\n            next_pop = np.zeros((cur_population_size, self.dim))\n            successes = [0, 0]\n\n            for i in range(cur_population_size):\n                stratum = i // stratum_size\n                indices = np.random.choice(range(len(pop)), 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                \n                strategy = np.random.choice([0, 1], p=self.success_rates)\n                F = np.random.uniform(self.F_min, self.F_max)\n                CR = np.random.uniform(self.CR_min, self.CR_max)\n                diversity_factor = np.random.uniform(self.diversity_factor_min, self.diversity_factor_max)\n\n                levy_step = self.levy_flight()\n                \n                if strategy == 0:\n                    noise = np.random.uniform(-diversity_factor, diversity_factor, self.dim) + levy_step\n                    mutant = x0 + F * (x1 - x2) + noise\n                else:\n                    mutant = best_global + F * (x1 - x2) + levy_step\n\n                mutant = np.clip(mutant, lb, ub)\n\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i % len(pop)])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i % len(pop)]:\n                    next_pop[i] = trial\n                    fitness[i % len(pop)] = trial_fitness\n                    successes[strategy] += 1\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i % len(pop)\n                        best_global = trial\n                else:\n                    next_pop[i] = pop[i % len(pop)]\n\n            self.success_rates = self.dynamic_success_rate_rebalancing(successes)\n            pop = self.preserve_diversity(next_pop, lb, ub)\n            self.history.append(best_global)\n\n        return best_global", "name": "AdaptiveMultiStratumQuantumLevyDE", "description": "Adaptive Multi-Stratum Quantum-Inspired Levy Flight DE with Dynamic Success Rate Rebalancing and Diversity Preservation for enhanced photonic structure optimization.", "configspace": "", "generation": 99, "fitness": 0.2933909196934348, "feedback": "The algorithm AdaptiveMultiStratumQuantumLevyDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "66d3492d-e015-4010-b0b5-7f1735f9ac42", "metadata": {"aucs": [0.2933909196934348]}, "mutation_prompt": null}

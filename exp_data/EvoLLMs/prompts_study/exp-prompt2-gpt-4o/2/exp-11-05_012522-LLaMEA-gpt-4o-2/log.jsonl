{"id": "5450019b-04da-49ed-a6d0-580d228b4bba", "solution": "", "name": "", "description": "", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "No code was extracted.", "error": "", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 1, "fitness": 0.04539964264268405, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.05 with standard deviation 0.05.", "error": "", "parent_id": "5450019b-04da-49ed-a6d0-580d228b4bba", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "7989b914-7c57-4153-8cb4-1cd9fd8e9d6a", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "ad858891-3766-497f-bdee-a6eb0d0d915a", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "a2c6c696-9723-428e-a098-71264ae5583d", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "edd7d6ce-8671-4a16-8af7-3c802bcd17be", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "0a0de6fa-997f-4ae8-a99e-be6b8b963b37", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "4c30c5ac-9c0c-4b57-9401-da91b5f3983d", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "fb4a0d0d-61bd-459d-8f28-ba8030bee891", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "bff1cb8f-f581-4b1a-9f31-66129655d59c", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "b2973504-b0af-4e32-84f7-683b53b10304", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "005a5715-9245-48a3-ab0f-3082f41dfce7", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "cffacfe7-c9c5-427a-93ba-9525d7011649", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "60cf8cca-589d-4655-bf97-394e6856c548", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "46667e81-2057-4740-899b-a9889347491b", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / np.linalg.norm(trial - population[i])\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Gradient-Inspired Adaptive Differential Evolution combines differential evolution with adaptive steps based on quasi-gradient approximations for efficient exploration.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.11860917256239101, 0.08099573939876048, 0.100609238516145, 0.0942217514195951, 0.107410762746187, 0.11033114211644335, 0.09975734614470277, 0.09931891186792252, 0.0791400990384098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014572254733962064, 0.005275638633511881, 0.010544468052148481, 0.006493004426635696, 0.006570620486303191, 0.018150078853237606, 0.007693168839173259, 0.010575797721399605, 0.0, 0.0, 0.0, 0.019501673109847295, 0.00039528563299850994, 0.0, 0.014664865741570998, 0.0, 0.0, 0.0586156020135693, 0.04529032155668278, 0.04278205048616679, 0.07872714727482433, 0.056586617818649265, 0.037332462972905156, 0.06905108907452762, 0.05508659418267503, 0.040576766581731705, 0.06265423285317917, 0.0, 0.0, 0.0, 0.00021551809509001707, 0.0, 0.0, 0.011194453811883442, 0.0, 0.10018685869141841, 0.0821548355402063, 0.05973037536276371, 0.06661749824786911, 0.07275849405212154, 0.0, 0.026181922062049168, 0.05921649636366433, 0.0362902258601947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879119250399583, 0.15748132322754993, 0.14829537673711224, 0.11826639483027501, 0.10265315387628593, 0.12263907014781539, 0.16104568613219816, 0.09707379230406277, 0.12096781838999704, 0.020502135086924, 0.0, 0.021886321886607996, 0.0325721299095072, 0.0, 0.01750168379108641, 0.0, 0.0, 0.02666833626569931, 0.08484849337016565, 0.08600231476351294, 0.11833361437130174, 0.09846289938816155, 0.10844057434014065, 0.10789794917811235, 0.08799080449358876, 0.08090029113184061, 0.07717165476235766, 0.09597227240618145, 0.10454213726846207, 0.16130937881362284, 0.13792052181401182, 0.1137187550761597, 0.10435826762181499, 0.12019368026040644, 0.17369512487615557, 0.11374251144952907, 0.059761631126171944, 0.033911540361439396, 0.08389423256590178, 0.05686290050998832, 0.06397588396999376, 0.06333484497577446, 0.08364015581209894, 0.09968109929816105, 0.06403167692626899, 0.1193455890418943, 0.09379139630447497, 0.13336421106438578, 0.11026790024335642, 0.08771080209608828, 0.10887980745480197, 0.12237199858757519, 0.07863718186214741, 0.12610897469223925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10942794826650037, 0.07457348599177183, 0.08157840845421893, 0.11368001314310328, 0.12070353966556191, 0.0665206661762211, 0.10692837481480588, 0.10502535409825287, 0.06926818844989102, 0.11031370369950688, 0.10258192672273381, 0.06922728298844594, 0.07631154935099294, 0.03728632333816162, 0.05909326144378779, 0.06706807913950963, 0.04009445607431428, 0.04133833534605069, 0.13471522306136374, 0.14203972751788496, 0.1475449842687161, 0.11590646924167103, 0.1590951401420554, 0.13224602528921636, 0.14961211855402412, 0.12597574652475974, 0.14680476350940774, 0.01351929609764324, 0.015817976510868692, 0.03129662407793532, 0.02691798931623468, 0.03415436066354671, 0.019947514614564676, 0.01612999899170031, 0.03793735337628057, 0.0181425315871262]}, "mutation_prompt": null}
{"id": "a7b62e5d-8936-445c-8264-bef48d268d77", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 15, "fitness": 0.13324531892820632, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.22.", "error": "", "parent_id": "db0f02d9-e2f1-4220-97b0-3136d5509801", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "26cf4961-2e2b-4860-bed0-266058118598", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "eea9651b-06f7-4d58-914d-1e38a41ac360", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "050ac104-d7a9-4f23-b09f-a7625165c3cf", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "16a20c01-9c1d-4cf8-8d5e-b00947c6c5a5", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "58956ae4-8ad1-4362-b927-c5fe4d01b2c3", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "dda4b589-c912-4ef3-a0c6-8abf6d8ea93b", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "fa0af08b-2ecf-497d-bdb3-489ef5f18b97", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with dynamic adjustment\n                crossover_prob = 0.8 + (0.95 - 0.8) * (fitness.min() / (fitness.max() + 1e-8))\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Dynamic Crossover Adjustment for improved exploration.", "configspace": "", "generation": 22, "fitness": 0.12652723255597043, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.22.", "error": "", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.44487694338362394, 0.45312925765555034, 0.3969150792673408, 0.6190250609544274, 0.6031417533652577, 0.5566324210859805, 0.5440840749770408, 0.5680117671932735, 0.5835725499166876, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008055743096100576, 0.01467079663371329, 0.02081540681619931, 0.010643411704069683, 0.006592353378601756, 0.006669962766643223, 0.018248263482334326, 0.013745259228990836, 0.015757274581284175, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9664050888148001, 0.9629122296772569, 0.9756866727377435, 0.9064219556039079, 0.9294594951350681, 0.9605336264993302, 0.9529204680753568, 0.9842743404545433, 0.9755232696132371, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.03430776336702179, 0.04223118998415265, 0.05931056463008866, 0.06033130437999101, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15858496211176576, 0.45194310973722474, 0.1533448634484783, 0.11835455572806985, 0.46123536282114597, 0.3941445202524668, 0.44732090497503774, 0.45581244624405826, 0.492931621950332, 0.036546519227756424, 0.03723515251228271, 0.04169545298513622, 0.03266886175302153, 0.011665815624912645, 0.01759993274736349, 0.005147823319083589, 9.999999999998899e-05, 0.0267656688986897, 0.12931569791719866, 0.1406557683129993, 0.15007141848607441, 0.1106850658852343, 0.15589007022119672, 0.1479342139530665, 0.11667910333536324, 0.13221541286871596, 0.14546456936411545, 0.1487338926121804, 0.1782316833307297, 0.1613932299901244, 0.21309654885678042, 0.21872057076946605, 0.21248631367879545, 0.24209788297800672, 0.2590329905622176, 0.2546919479258126, 0.09566245908167825, 0.0748284288336114, 0.08398582550377798, 0.11247175305051005, 0.09453284648111471, 0.09042623513518644, 0.08837413426422736, 0.12327424749591753, 0.09494876028449417, 0.1300195328098276, 0.10691447779918728, 0.1611595969487375, 0.15956676688992333, 0.15621497583090171, 0.15781873252718215, 0.1661131184323722, 0.14526745663577034, 0.16185067716847845, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15122989117914787, 0.2047639262291603, 0.1496153830643807, 0.11020255205574736, 0.15710355135353749, 0.14763838228268544, 0.20107417157921592, 0.15566692450156827, 0.1312956551997818, 0.1125234799947229, 0.17282490807112594, 0.1334170918833334, 0.0787570004142204, 0.09374714898594627, 0.10482550608119068, 0.15397372019892286, 0.13906952030167974, 0.10930038347733662, 0.18960952471580195, 0.191033791087049, 0.17963912256081438, 0.17509767928556974, 0.1820789858123717, 0.18973561006173978, 0.17574601569090353, 0.1977571705515897, 0.18060218473220557, 0.026344689197692395, 0.035194593661627915, 0.031393493129599714, 0.03631043434263792, 0.03425093938292756, 0.03383449623584478, 0.03552005012660209, 0.03803354422653826, 0.03231640700445737]}, "mutation_prompt": null}
{"id": "9262de8c-ccad-4047-ad73-1df45f976262", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "cd039eb7-9768-4c6f-8487-5b97f51617f0", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n            # Adaptive Population Size Adjustment\n            if eval_count % (self.population_size * 2) == 0:\n                if fitness.min() > np.median(fitness):\n                    self.population_size = min(self.population_size + 1, self.budget // self.dim)\n                    new_individual = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    population = np.vstack((population, new_individual))\n                    fitness = np.append(fitness, func(new_individual))\n                    eval_count += 1\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation, Modified Crossover, and Adaptive Population Size for improved exploration.", "configspace": "", "generation": 24, "fitness": 0.13324531892820632, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.22.", "error": "", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "8663b79c-a3cf-41a5-be1e-c609d93140ef", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "fc6c3cad-e88d-4668-9cf7-041833dc356a", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "33558f4e-5122-499e-a5fd-9098b0c56e29", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                fitness_variance = np.var(fitness)  # Calculate fitness variance\n                dynamic_F = self.F + 0.2 * np.clip(fitness_variance, 0, 1)  # Adjust F based on variance\n                mutant = x1 + dynamic_F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduces a dynamic adjustment of the differential weight `F` based on fitness variance for enhanced convergence in Adaptive DE.", "configspace": "", "generation": 27, "fitness": 0.12274753167862283, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.21.", "error": "", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.1956922779889364, 0.14739255810941343, 0.15116322143925787, 0.5544846394517433, 0.5806451083711783, 0.545009733272781, 0.5306343143381647, 0.4884067244344664, 0.47337670981818514, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01467079663371329, 0.005375109906600173, 0.010643411704069683, 0.013913325313189118, 0.006669962766643223, 0.018248263482334326, 0.020049591142952572, 0.010674738340807233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9802503599691201, 0.9824813295138116, 0.9832058004674231, 0.9703730258694966, 0.9625307443093678, 0.9737805612417315, 0.9443858752770664, 0.9898193421554384, 0.9827321824114797, 0.06274794416174423, 0.0076140864774207895, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031549654350837564, 0.06422283074924673, 0.023679223707468333, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.028408693743681934, 0.044211164755830534, 0.060713120681501254, 0.044486387295083474, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05536121838078323, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.37361398267158663, 0.35633565219895347, 0.34325249463771523, 0.3542966799802181, 0.3894032114682797, 0.4011269001523614, 0.32419794555385617, 0.3954402524291383, 0.3761126379558324, 0.03215054081173019, 0.03015346085638393, 0.028880492094393917, 0.03266886175302153, 0.00042645745344382924, 0.01759993274736349, 0.011757521158984097, 9.999999999998899e-05, 0.0267656688986897, 0.14301669106168846, 0.136930650910147, 0.14798480431482874, 0.1762148987739618, 0.13933790197163765, 0.13962088084777502, 0.12218413932603112, 0.13136210422664263, 0.15106586386584764, 0.17111816094602605, 0.18591257205983058, 0.18147865254289397, 0.1620122481415105, 0.16391053978161052, 0.1774309126218755, 0.2318574692490296, 0.24188435148481235, 0.21653579858103478, 0.07202791628209126, 0.09031167844486021, 0.08398582550377798, 0.08687743408422521, 0.08313183963848136, 0.09532223544910867, 0.0837317855149382, 0.0997711199450243, 0.11988196592591172, 0.15888619637218748, 0.15319873361338232, 0.14374179378890928, 0.1572729758703053, 0.14314128581277874, 0.14569937075459383, 0.15271873659692792, 0.15662349635377792, 0.1644827681639658, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15393920408436956, 0.15699303024879407, 0.14634540257389383, 0.14265788624971898, 0.12099943766531163, 0.10737453631547722, 0.11653058576242381, 0.11549079501516812, 0.12402240072174953, 0.11040265245322212, 0.12196209937347646, 0.13374564474260364, 0.11183252562818202, 0.08278947361315636, 0.13439933907286272, 0.19569131293413844, 0.18736311313069376, 0.1958214774414676, 0.1748851004971903, 0.19592980095318802, 0.18881100333326062, 0.19024263814709308, 0.19464352557103903, 0.1886980287663096, 0.182549302174837, 0.18918928419324388, 0.17495632036932385, 0.049420457032314125, 0.030429488613374578, 0.031393493129599714, 0.031245610758741327, 0.03425093938292756, 0.03120472053332557, 0.026533525883877696, 0.03803354422653826, 0.022211531179071042]}, "mutation_prompt": null}
{"id": "03fcaeff-df75-4024-b1b4-11ab6fa1140c", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with refined dynamic adjustment\n                crossover_prob = np.random.uniform(0.7, 0.95) * (1 - eval_count / self.budget)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Refined adaptive step with more precise gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-10)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with dynamic crossover adjustment and refined gradient approximation for improved convergence.", "configspace": "", "generation": 28, "fitness": 0.1270995018853583, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.22.", "error": "", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.46704876805287887, 0.36595363783537915, 0.5407697821159152, 0.6159101280158892, 0.6474368052904114, 0.6479585384303065, 0.6256325466733101, 0.62890235122541, 0.5941630490511073, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0034949719918753175, 0.01467079663371329, 0.006398715974074376, 0.010643411704069683, 0.006592353378601756, 0.006669962766643223, 0.018248263482334326, 0.007792397052521438, 0.010674738340807233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9647327984824566, 0.9680386066736919, 0.9697793164081778, 0.9577258869767923, 0.9584082334241174, 0.9510028511862814, 0.9739980679866825, 0.9543019589025069, 0.9710906321352208, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 0.009902704151547037, 0.005994021760462376, 9.999999999998899e-05, 0.015512309637186306, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.04010500669014161, 0.10926621274628212, 0.05931056463008866, 0.05143343849892812, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.3813558345787804, 0.35400504371038277, 0.1514381035692398, 0.1661693133071771, 0.3912773869835169, 0.33634362274016594, 0.39433207332201536, 0.3901714432789193, 0.3694841163951076, 0.017047988254921598, 0.049156740000415255, 0.02198412468535549, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.020229629588233156, 9.999999999998899e-05, 0.0267656688986897, 0.14869529119228286, 0.13782405103545703, 0.12333520959361899, 0.1475535641115262, 0.15918861212668456, 0.16161075212677445, 0.1522823155731834, 0.14202725932645333, 0.11590550661241172, 0.19797820570656166, 0.20906745066473864, 0.19386589359931217, 0.1948977087534538, 0.17318411606040118, 0.20080905899166235, 0.2527044515250676, 0.23112762262359532, 0.22464028906386202, 0.06144404201595022, 0.057284187390015506, 0.08398582550377798, 0.08630569145691225, 0.0920546615011546, 0.07841252917155739, 0.08659749096438996, 0.0997711199450243, 0.09001626970388932, 0.14590841599994508, 0.15953826549410866, 0.1717475311165979, 0.14688950123669509, 0.16652475234528663, 0.17130318941934985, 0.14830015335828195, 0.15775795117055935, 0.14625706151533413, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12148659249177074, 0.15751995261508034, 0.2525609393881717, 0.11221087828861676, 0.1207914665021157, 0.13806282921975488, 0.1070176662487543, 0.11095641913011112, 0.11600478859695396, 0.11040265245322212, 0.12137213694470195, 0.09755220172717238, 0.09560279680764483, 0.10355619754652767, 0.10378033954912991, 0.17590963589478725, 0.15794247009032147, 0.17020819215070293, 0.16932207624833262, 0.17741370166662596, 0.1804320463847775, 0.21636508918463282, 0.176917148853178, 0.17062292042419702, 0.19674462757703282, 0.17466612742404564, 0.18664718290929372, 0.04590263498258251, 0.025523548061740065, 0.031393493129599714, 0.037581630697400614, 0.03425093938292756, 0.030598490419710855, 0.021217920064998674, 0.03803354422653826, 0.035474149362403895]}, "mutation_prompt": null}
{"id": "4fabae3c-35db-45df-8aff-3160b0656146", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "a36478ff-e222-470a-9337-021ec85d5969", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "ee5bbd81-e458-4ae3-84b5-1fa54601a68f", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n                # Dynamic population adjustment\n                self.population_size = int(10 * self.dim * (1 - (eval_count / self.budget)))\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation, Modified Crossover, and Dynamic Population for improved exploration.", "configspace": "", "generation": 31, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {}, "mutation_prompt": null}
{"id": "98d3b985-fa48-4185-99e0-37d5eed634a9", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "2aed61f7-adce-4e7b-b84b-f9158392c295", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "40b311b0-1b60-403a-9c6d-302c1d8523b2", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "86686a15-0d1e-431c-b3df-e9052460c2a6", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "d529f46e-85d1-4032-856c-e2f3fc6bfc71", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "efe84c7c-0677-4d4f-932e-6d279c6a5c2b", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "b85859ef-eae9-4c06-ba81-9f7fd846324a", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhanced Differential Evolution with Quasi-Gradient Adaptation and Modified Crossover for improved exploration.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.37432946077593865, 0.15804801397138435, 0.42568846952421935, 0.6084820445409236, 0.6344775149588708, 0.5944138893626935, 0.5923571353667453, 0.5740034617477354, 0.6221969990739308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011217119504398965, 0.01467079663371329, 0.006398715974074376, 0.01295144909202206, 0.006592353378601756, 0.006669962766643223, 0.020599990696951176, 0.02158575168079513, 0.011169485145817615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9462034040702694, 0.9704417997023972, 0.9830264562975857, 0.9288335883217852, 0.9498761475479817, 0.9642797563962923, 0.9498354624555003, 0.9760440829051091, 0.9794713267199622, 0.06274794416174423, 0.015947792607833633, 9.999999999998899e-05, 9.999999999998899e-05, 0.005994021760462376, 0.06523752695187668, 0.017767770905089075, 0.03904321923099563, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06987991504875501, 0.07285119553694963, 0.06656497958209506, 0.056198290572831655, 0.06282094980074615, 0.05471524724338028, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007933191934826556, 9.999999999998899e-05, 9.999999999998899e-05, 0.011097711233281737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4453509666314027, 0.43142810824598044, 0.38103118709172223, 0.3649324698796431, 0.4457517630186316, 0.4178309600457637, 0.4316441080596132, 0.4396075881834872, 0.43998774328185064, 0.026961489721882614, 0.0391963480784705, 0.023764282272672577, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 0.0010806450441552817, 9.999999999998899e-05, 0.0267656688986897, 0.14210915686333958, 0.13577672883015035, 0.1373641325198578, 0.15976371443274928, 0.11545272065534862, 0.13146970095081323, 0.134220491179053, 0.13166710208451582, 0.1250637985429972, 0.19529012319761052, 0.22796147287775925, 0.20371893995406598, 0.20182818536923997, 0.23082757460567194, 0.19326642911510994, 0.2531234017052487, 0.25603384988070854, 0.25641029414309546, 0.10851779598102806, 0.06514754968396341, 0.08398582550377798, 0.09218359564812195, 0.10770065289295794, 0.09540487260722041, 0.09728735084168294, 0.10880882297948535, 0.11360665885607146, 0.15801576541117468, 0.1650967376839062, 0.162712684273559, 0.15878269427252578, 0.1643414015897735, 0.15944736511108715, 0.15699046461549737, 0.15858101332881525, 0.1565234533185501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13678492748300286, 0.16505034266076457, 0.3148068966076639, 0.1607667376325833, 0.12463334309904894, 0.11427651863822597, 0.1591127558497032, 0.13346917965237592, 0.15324421769656205, 0.11470140576655974, 0.14312866601589236, 0.14700102310937324, 0.07569216059944595, 0.10986118819545954, 0.10715739549286551, 0.4833611595900834, 0.20391855587988406, 0.19554689997682695, 0.17932280567073555, 0.18640184695754847, 0.1926657956240535, 0.18291545155495403, 0.1758624151117194, 0.18564103059867965, 0.1849971569570512, 0.2098728060631796, 0.1850780370315791, 0.029254660488912898, 0.03484729948210985, 0.03207402012649252, 0.0322873145221827, 0.03425093938292756, 0.038010106997693804, 0.03434174375261645, 0.040514246324535264, 0.03208261527951106]}, "mutation_prompt": null}
{"id": "81f75acf-0bcf-437d-b6ab-f5b5b215820c", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)  # Random differential weight\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introducing random uniform scaling to the differential weight F for enhanced diversity in the solution space.", "configspace": "", "generation": 39, "fitness": 0.14383827294432186, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.24.", "error": "", "parent_id": "a7b62e5d-8936-445c-8264-bef48d268d77", "metadata": {"aucs": [0.6535215594052826, 0.6431484729883874, 0.6274164358768165, 0.7055959105898051, 0.7054498487435859, 0.6763565352938692, 0.6914002453605297, 0.6634246417773633, 0.6940405739250263, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006411293967932941, 0.01467079663371329, 0.012386445869355112, 0.010643411704069683, 0.006592353378601756, 0.013045382922772242, 0.018248263482334326, 0.020706689420918023, 0.013054989388521232, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9556373577866808, 0.9680231851543654, 0.9464461554298844, 0.9600561206474104, 0.9362795938071418, 0.9554077488648961, 0.9785698426807137, 0.938805703153456, 0.9810104107779757, 0.06274794416174423, 0.02081213589069497, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06774728012944853, 0.07432382740840171, 0.04681048540084831, 0.061961040602338424, 0.05989547953521779, 0.06931635586218032, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002810384041631031, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5105902072232102, 0.4758900571346242, 0.42476484746594334, 0.4925144562688587, 0.4822986756343882, 0.5218093501069123, 0.5304841082700175, 0.5341119310747297, 0.5304828519788389, 0.03417782080463694, 0.03544589894689265, 0.024541828095870355, 0.03266886175302153, 0.0059155819368647, 0.01759993274736349, 0.006655178970549014, 0.0023315870989876197, 0.0267656688986897, 0.1370574852990758, 0.1436941037553794, 0.1390141528192742, 0.14273997566753538, 0.14409459101375144, 0.11900054574606889, 0.12902195530642402, 0.142390038272996, 0.12689594516226266, 0.2607209803506604, 0.2774352761807066, 0.28536347281582397, 0.26344597730613617, 0.24368977983224183, 0.2532527383590686, 0.28914861778910295, 0.3105225023012709, 0.30303402223231724, 0.09496791082618694, 0.08847394609469339, 0.08843858948745253, 0.12796004288997354, 0.11088706726467312, 0.0841047479773801, 0.12292341730118428, 0.16015137470042207, 0.1064974840407873, 0.17080240936053526, 0.1616524206398301, 0.17641908157176933, 0.15528301285537438, 0.1772180430783432, 0.17545364238502903, 0.15866301013922113, 0.18613477533311928, 0.1662226726421362, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1897203357130558, 0.15552344269388718, 0.18079733619676863, 0.16173335537031075, 0.1207914665021157, 0.12956749998664985, 0.1082667265823557, 0.12973798112971602, 0.12622463279480634, 0.12014479058450311, 0.14548803869053195, 0.11638309028322313, 0.10568693874269608, 0.07485516371621526, 0.10813906509062576, 0.1996907100174976, 0.19945045734528422, 0.20699837059348947, 0.18062116625063518, 0.19039219817387243, 0.17708499660111665, 0.17361285159937667, 0.22548532021099654, 0.20269529237672002, 0.17744589261642962, 0.19503842906336366, 0.19079343510548574, 0.051762367796220676, 0.03439642013735045, 0.031393493129599714, 0.034741528747948336, 0.03425093938292756, 0.02779575531519962, 0.02712297991321977, 0.03803354422653826, 0.025586374806567225]}, "mutation_prompt": null}
{"id": "8513c02f-3c2b-485e-9108-0ab1db4d89bd", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)  # Random differential weight\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introducing random uniform scaling to the differential weight F for enhanced diversity in the solution space.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "81f75acf-0bcf-437d-b6ab-f5b5b215820c", "metadata": {"aucs": [0.6535215594052826, 0.6431484729883874, 0.6274164358768165, 0.7055959105898051, 0.7054498487435859, 0.6763565352938692, 0.6914002453605297, 0.6634246417773633, 0.6940405739250263, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006411293967932941, 0.01467079663371329, 0.012386445869355112, 0.010643411704069683, 0.006592353378601756, 0.013045382922772242, 0.018248263482334326, 0.020706689420918023, 0.013054989388521232, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9556373577866808, 0.9680231851543654, 0.9464461554298844, 0.9600561206474104, 0.9362795938071418, 0.9554077488648961, 0.9785698426807137, 0.938805703153456, 0.9810104107779757, 0.06274794416174423, 0.02081213589069497, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06774728012944853, 0.07432382740840171, 0.04681048540084831, 0.061961040602338424, 0.05989547953521779, 0.06931635586218032, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002810384041631031, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5105902072232102, 0.4758900571346242, 0.42476484746594334, 0.4925144562688587, 0.4822986756343882, 0.5218093501069123, 0.5304841082700175, 0.5341119310747297, 0.5304828519788389, 0.03417782080463694, 0.03544589894689265, 0.024541828095870355, 0.03266886175302153, 0.0059155819368647, 0.01759993274736349, 0.006655178970549014, 0.0023315870989876197, 0.0267656688986897, 0.1370574852990758, 0.1436941037553794, 0.1390141528192742, 0.14273997566753538, 0.14409459101375144, 0.11900054574606889, 0.12902195530642402, 0.142390038272996, 0.12689594516226266, 0.2607209803506604, 0.2774352761807066, 0.28536347281582397, 0.26344597730613617, 0.24368977983224183, 0.2532527383590686, 0.28914861778910295, 0.3105225023012709, 0.30303402223231724, 0.09496791082618694, 0.08847394609469339, 0.08843858948745253, 0.12796004288997354, 0.11088706726467312, 0.0841047479773801, 0.12292341730118428, 0.16015137470042207, 0.1064974840407873, 0.17080240936053526, 0.1616524206398301, 0.17641908157176933, 0.15528301285537438, 0.1772180430783432, 0.17545364238502903, 0.15866301013922113, 0.18613477533311928, 0.1662226726421362, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1897203357130558, 0.15552344269388718, 0.18079733619676863, 0.16173335537031075, 0.1207914665021157, 0.12956749998664985, 0.1082667265823557, 0.12973798112971602, 0.12622463279480634, 0.12014479058450311, 0.14548803869053195, 0.11638309028322313, 0.10568693874269608, 0.07485516371621526, 0.10813906509062576, 0.1996907100174976, 0.19945045734528422, 0.20699837059348947, 0.18062116625063518, 0.19039219817387243, 0.17708499660111665, 0.17361285159937667, 0.22548532021099654, 0.20269529237672002, 0.17744589261642962, 0.19503842906336366, 0.19079343510548574, 0.051762367796220676, 0.03439642013735045, 0.031393493129599714, 0.034741528747948336, 0.03425093938292756, 0.02779575531519962, 0.02712297991321977, 0.03803354422653826, 0.025586374806567225]}, "mutation_prompt": null}
{"id": "1affad3e-21a8-4336-9d43-27b298d48ffd", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with slightly adjusted random scaling factor\n                F_rand = np.random.uniform(0.55, 0.95)  # Random differential weight\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.012 * gradient_approx * (fitness.min() - fitness.max())  # Adjusted gradient influence\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Slightly enhance exploration by adjusting the differential weight range and adaptive gradient influence.", "configspace": "", "generation": 41, "fitness": 0.13510574160175604, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.23.", "error": "", "parent_id": "81f75acf-0bcf-437d-b6ab-f5b5b215820c", "metadata": {"aucs": [0.4841388982120389, 0.47870169982313915, 0.15234091864591082, 0.6654512525004871, 0.6676370918745864, 0.6554530310623958, 0.6509962113119391, 0.6364034277760652, 0.6078263751468279, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009150020538097436, 0.01467079663371329, 0.005375109906600173, 0.010643411704069683, 0.013380600408992027, 0.017969798915349222, 0.026820262755723023, 0.012459058379498344, 0.0170017144248773, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.94601508073734, 0.9611525392247422, 0.9272135038144111, 0.9527861644475869, 0.9563579809126194, 0.9698085196644347, 0.9770096121222954, 0.9317753314734706, 0.9810147382177857, 0.06274794416174423, 0.023489190873079324, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06774728012944853, 0.07285119553694963, 0.04578655556259115, 0.050759715689493, 0.05931056463008866, 0.0681660839102235, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004416712751200258, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002614161892866118, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4406757915506794, 0.44309769616522077, 0.3822973263138276, 0.45839749249825623, 0.46172774672700134, 0.4599830540954756, 0.4656695975682138, 0.48564165134712445, 0.5070206536131765, 0.020236844684344057, 0.024643963884579678, 0.029262073139767586, 0.03266886175302153, 0.031020161106285027, 0.01759993274736349, 0.032998361993958114, 0.0006383489559425026, 0.0267656688986897, 0.14862381449753426, 0.16401330252244406, 0.13678617525460446, 0.14062099200471734, 0.13230845385878787, 0.12429966032814155, 0.12970110445925798, 0.12061278682443322, 0.12215518884423782, 0.23687881781629427, 0.2413735482976862, 0.225009789142397, 0.23535599557501197, 0.23545498126336606, 0.2206447183303697, 0.2682499271452746, 0.2567314165690169, 0.2503626695232709, 0.0792279254491467, 0.08762043676472409, 0.12803481962008045, 0.09993190765785354, 0.11045472921114075, 0.08821816586586406, 0.11866732071986685, 0.09983549380368661, 0.11094547100836427, 0.1569724296002989, 0.14431971131775612, 0.16279405687529636, 0.1710064216725301, 0.1628712920496147, 0.14411713252281222, 0.1556573857119189, 0.19534938615868946, 0.1690618965784897, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14690053232984923, 0.1566182996607013, 0.15770367381604844, 0.15137466842690772, 0.1207914665021157, 0.13257813413515107, 0.1445921603549568, 0.10511484148144368, 0.1270317716997077, 0.11783712198329976, 0.10968135835997528, 0.12998953456199525, 0.08343712074507226, 0.0734492459465308, 0.08157327070349507, 0.1961861828590601, 0.3725819566374008, 0.19906043726856937, 0.17459567835227352, 0.19235477940213064, 0.19936731250149653, 0.20072248946296445, 0.18518660775298856, 0.18190278555440398, 0.18667681439871664, 0.19520729711585738, 0.18995697722154925, 0.03150651675872218, 0.03077265457492684, 0.031393493129599714, 0.03318677638651135, 0.03425093938292756, 0.02291047979895433, 0.03378415609393837, 0.03803354422653826, 0.035556985518236384]}, "mutation_prompt": null}
{"id": "f33678fa-a5b9-47c0-8a88-a42be563859f", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)  # Random differential weight\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.8, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * (1 + 0.1 * np.cos(2 * np.pi * eval_count / self.budget)) * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce oscillating scaling to the gradient approximation step for additional exploration and convergence.", "configspace": "", "generation": 42, "fitness": 0.14341346710806058, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.24.", "error": "", "parent_id": "81f75acf-0bcf-437d-b6ab-f5b5b215820c", "metadata": {"aucs": [0.612191821640635, 0.5709667157793428, 0.5636445412072753, 0.7315221173648644, 0.6887164691165472, 0.7028620475932864, 0.661108182501601, 0.6822364529771278, 0.6904212017351803, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01467079663371329, 0.005375109906600173, 0.010643411704069683, 0.006592353378601756, 0.013045382922772242, 0.018248263482334326, 0.015687949577144145, 0.013054989388521232, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9538002596800945, 0.9679801285354523, 0.9341762425470024, 0.9478323271811594, 0.9438600781103934, 0.9555697061252814, 0.9730461916352093, 0.9372622739641594, 0.9810037406570475, 0.06274794416174423, 0.02081213589069497, 9.999999999998899e-05, 9.999999999998899e-05, 0.002484810230975909, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.06774728012944853, 0.07432382740840171, 0.05204823521340751, 0.0767840374018326, 0.05931056463008866, 0.06931635586218032, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002391962213361909, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002774164293391501, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4597057392786229, 0.505587253887377, 0.42997174828434936, 0.46544485083110887, 0.4837325808398589, 0.46317372762853337, 0.5061488025611284, 0.5230392287200589, 0.5241676491996543, 0.02943155608387793, 0.028524675124342314, 0.028962484884018758, 0.03266886175302153, 0.011728467898988515, 0.018942970141900717, 0.014312460605974242, 0.00966915262375767, 0.0267656688986897, 0.14046179441828266, 0.14989493072185378, 0.14487052985188598, 0.13464220114480563, 0.12253092068952953, 0.1441790476999193, 0.15009569005873313, 0.1266658538125932, 0.1835777515726208, 0.260464330134334, 0.27269660153256714, 0.2692537043412746, 0.2648555234876059, 0.25140861054783614, 0.23419876425323516, 0.2816458942772916, 0.27255621234352534, 0.2895126687072965, 0.08544176343372822, 0.08593679214132866, 0.08843858948745253, 0.10606511743427494, 0.0985301524317278, 0.09698338362930825, 0.11750222007316935, 0.11323158083142737, 0.12206526522674044, 0.15018209340220745, 0.17645210188865001, 0.15679934105040738, 0.17084982054917075, 0.15267625982157662, 0.15965045219438512, 0.18658930190249146, 0.17694385159768922, 0.16231731367542745, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16524176767114274, 0.1859359952701214, 0.5446100062368875, 0.1563185235926996, 0.1484554474159404, 0.10264461093878541, 0.1148184663410009, 0.11725899494065195, 0.14055980908531696, 0.1336090019837065, 0.1443556918614438, 0.12075680363811458, 0.10142785948635247, 0.11071722713180188, 0.1066094508869262, 0.20194355403614583, 0.20365539470135152, 0.20472161370383302, 0.19097130284342267, 0.17551191148000433, 0.18282469898221465, 0.17648687034950195, 0.19334678999308486, 0.18050555899107934, 0.17692405798925515, 0.1859012391197099, 0.18190794225457907, 0.045225072989295234, 0.023032064644391337, 0.031393493129599714, 0.027015293023570086, 0.03425093938292756, 0.028000978511561914, 0.03352077104865203, 0.03803354422653826, 0.02371224839671826]}, "mutation_prompt": null}
{"id": "c863323b-1a11-49c0-8633-10dd6cf573d9", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Crossover probability (slightly adjusted)\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)  # Random differential weight\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover with slight adjustment\n                crossover_prob = np.random.uniform(0.75, 0.95)  # Adjusted bounds\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n                \n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhancing exploratory capabilities by adjusting crossover probability bounds for increased solution diversity.", "configspace": "", "generation": 43, "fitness": 0.1430829325984662, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.24.", "error": "", "parent_id": "81f75acf-0bcf-437d-b6ab-f5b5b215820c", "metadata": {"aucs": [0.6584728065173602, 0.632232583819284, 0.6561867790766673, 0.6772812622850422, 0.724590971449822, 0.7142176513287181, 0.6751382853592044, 0.6831702090542235, 0.6795589011208908, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01467079663371329, 0.013366577710384853, 0.010643411704069683, 0.006733145608135982, 0.013045382922772242, 0.018248263482334326, 0.024541877737306983, 0.017151810347976415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9521201815925109, 0.9614579494846162, 0.9533455743048169, 0.9474070137432193, 0.9755021576763504, 0.9591053665057674, 0.970790792250212, 0.9634287568989746, 0.9431135587073423, 0.06274794416174423, 0.00424828113517528, 9.999999999998899e-05, 9.999999999998899e-05, 0.0009777195819040685, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.14782315377769795, 0.07432382740840171, 0.029372498790414148, 0.04733262249459935, 0.05931056463008866, 0.06931635586218032, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00818732875750705, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005225672594707631, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4478546304132419, 0.4942361444142602, 0.44860071173075455, 0.45736523407744656, 0.4673288648994093, 0.4722332593808599, 0.4771834844410817, 0.5218126521331315, 0.5254515079917086, 0.02676636215154027, 0.040355821161831784, 0.02562905115825287, 0.03266886175302153, 0.0053085322177838234, 0.01759993274736349, 0.006655178970549014, 9.999999999998899e-05, 0.0267656688986897, 0.14653357591405713, 0.13541434678392472, 0.1334670426561514, 0.14576572647985964, 0.1206382679133492, 0.15366661710880947, 0.1409643306410009, 0.14924417195737627, 0.12641975064023114, 0.2703410082212938, 0.2576473734740523, 0.2476584538481046, 0.24161833102888464, 0.23843690247853389, 0.27698193971778595, 0.2884515956296251, 0.3030899355583093, 0.29324089570771994, 0.0810579128692942, 0.07807288677509483, 0.08843858948745253, 0.09593123641495638, 0.10806360082326427, 0.12121189675763855, 0.1250917014174916, 0.11141027403843984, 0.09970488822288337, 0.18549121792759005, 0.17524399248060674, 0.17729111619102422, 0.17167476585971908, 0.17400350786005636, 0.17636946188546376, 0.15979586860574924, 0.1633662750105359, 0.17614307614487512, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16366495932953185, 0.1438584994565506, 0.16572197166268232, 0.16782014538285106, 0.12653007639402258, 0.12526085809304421, 0.11608606983063996, 0.11570663632106803, 0.10997926369378763, 0.11497771855799876, 0.16231414801156352, 0.1528742231542799, 0.08959152166536444, 0.1623219586266459, 0.10504562014451657, 0.19784432259639972, 0.1995206197732966, 0.19978535122721663, 0.18558533476122685, 0.20364838012356035, 0.18134162106816154, 0.17805241067450128, 0.18905260574605243, 0.20233249782141716, 0.1756584394010835, 0.19870374382915323, 0.19226674517607367, 0.024293466990436885, 0.03309079964118633, 0.03444495364692046, 0.033690643102453066, 0.03867781441281737, 0.032474776766173274, 0.032626034912812574, 0.03803354422653826, 0.030089678788205454]}, "mutation_prompt": null}
{"id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 44, "fitness": 0.1489678770663797, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.24.", "error": "", "parent_id": "81f75acf-0bcf-437d-b6ab-f5b5b215820c", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "a9811a0b-c2a9-40b0-ac32-af235b28021c", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "b3004c74-cce8-480c-a508-15b9e2f13e95", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "e91ac3d1-5b46-493e-b3a6-14d8c44ed5f8", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n        stagnation_count = np.zeros(self.population_size)  # Track stagnation\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    stagnation_count[i] = 0  # Reset stagnation\n                else:\n                    stagnation_count[i] += 1\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n                # Random reinitialization for stagnation\n                if stagnation_count[i] > 10:  # If stagnating for 10 iterations\n                    population[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    stagnation_count[i] = 0\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce diversity preservation through random reinitialization of stagnating individuals to prevent premature convergence.", "configspace": "", "generation": 47, "fitness": 0.12577633020481258, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.21.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.2129413277247345, 0.2402716323032943, 0.2743093653133267, 0.31400067060876125, 0.6373375616554156, 0.6644226558481586, 0.6603376762774747, 0.295738866367782, 0.3381223971230375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013864500514024436, 0.036402843119275885, 0.02124546998774335, 0.04854797471689376, 0.03001713957911467, 0.022542029952722475, 0.029387687510993188, 0.02932156630768057, 0.05091260032672362, 0.026776391891241702, 9.999999999998899e-05, 0.0019625687973077177, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 0.004776178121513874, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9289719120172185, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 0.011733952478946263, 0.023177268165646137, 0.01884821408553561, 0.014513139245871942, 0.007711711724248338, 0.020590898085119047, 0.014890502740619427, 9.999999999998899e-05, 0.11458398399042291, 0.09023658878933916, 0.09001779085247874, 0.08654116892318231, 0.11225246800393085, 0.10211415973167692, 0.08685543166750143, 0.10182607715611225, 0.08285401769887957, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00799879538680437, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.24049149112984347, 0.33661721647541043, 0.4236502974385564, 0.36933472259588584, 0.24510913852719396, 0.3110182654707544, 0.2686864528617603, 0.2546093344292035, 0.24188005276819047, 0.04261281094330027, 0.04034150508243162, 0.04210506695830685, 0.03266886175302153, 0.026029154082082506, 0.04411785901549847, 0.04415821037472811, 0.02868299831044696, 0.028180357338724704, 0.1421128623871355, 0.14515399391499673, 0.1418967255725896, 0.14830703197352746, 0.13606742112059333, 0.1621213516728769, 0.15968218934464307, 0.14369017458505928, 0.2336766495301491, 0.166655204207377, 0.17200289126422919, 0.18403385239786407, 0.1652886772186516, 0.17790468692979433, 0.17899827940752489, 0.18625529779349714, 0.20545423481222957, 0.1761583422300681, 0.1046317111838827, 0.09842262867645202, 0.11343365999368848, 0.11307209092130266, 0.10138155575466079, 0.10788181920883089, 0.10356706349298161, 0.10343049931139192, 0.1126704806852531, 0.1436171707188758, 0.1476845662894808, 0.15232200674711827, 0.20179217153808315, 0.1648479201323626, 0.17050870940506646, 0.1742708226586145, 0.1590326457480361, 0.1535451701226198, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16020112670630027, 0.31086157891396815, 0.17908181597512518, 0.14652319663744107, 0.1407909559916003, 0.14988139454056748, 0.15295413626232857, 0.18147904474223064, 0.1437199521653707, 0.16035813943814514, 0.18337201897023925, 0.1441944584821342, 0.13919771414677473, 0.11614132310106307, 0.13413798605287208, 0.17655861970435638, 0.18310737979400515, 0.17868119979412989, 0.20926158510965853, 0.18114610203452064, 0.20280288021127246, 0.1888070744724739, 0.20307292138383548, 0.17945728332100408, 0.1832772464902117, 0.18557022449082583, 0.1740311087889338, 0.042048975652433374, 0.051873099881629026, 0.03888394609056145, 0.038655372824748735, 0.040293687227338726, 0.04158903529618818, 0.06089969431974296, 0.04120909843539122, 0.04135301312662998]}, "mutation_prompt": null}
{"id": "580e1465-2676-40f0-b416-230ef87d3930", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "1b547686-9181-40be-a07d-2e5a1518a3ec", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "7dda7149-2ca0-487e-87c8-2df6474b6b15", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with adaptive scaling factor based on population diversity\n                F_rand = np.random.uniform(0.5, 0.9) * (1.0 + np.std(population) / (self.upper_bound - self.lower_bound))\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhance mutation diversity by introducing an adaptive scaling factor based on population diversity to improve exploration.", "configspace": "", "generation": 50, "fitness": 0.12201220295083601, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.21.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.14465657853809166, 0.1939159716825538, 0.13742951713631368, 0.47682163741082906, 0.48541042335435913, 0.5164391770839626, 0.5340323500419184, 0.5311484498531347, 0.5408113288648049, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01467079663371329, 0.0067769007135498605, 0.010643411704069683, 0.006592353378601756, 0.006669962766643223, 0.018248263482334326, 0.007792397052521438, 0.010674738340807233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9720535132031506, 0.9368271036096977, 0.971182064698822, 0.9374571263384422, 0.954212813076569, 0.9422324262000286, 0.9322637508545042, 0.9825212588475029, 0.9904942933012069, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015823976417179697, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.01293287307491342, 0.10909737191383317, 0.05931056463008866, 0.02626260260480706, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4137570542658866, 0.4420991991171883, 0.24392293803176657, 0.34479112323273964, 0.39517882633981916, 0.4127001563968957, 0.44056395922971814, 0.4497206484147527, 0.4290365123985137, 0.016146825411043952, 0.027197433172643115, 0.02927458003981387, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 9.999999999998899e-05, 9.999999999998899e-05, 0.0267656688986897, 0.12899452585627824, 0.15200468779480603, 0.144329830634097, 0.14095103024575206, 0.133651640206635, 0.14964645910714203, 0.12967484806480167, 0.13929124867641074, 0.1370069524999732, 0.2194034321434769, 0.23288834896851107, 0.21529461279247286, 0.17815986714766607, 0.19675221022772316, 0.22013973514929808, 0.2414924011566768, 0.22960325597633557, 0.2430071367518215, 0.05985564337097804, 0.05649955590462197, 0.08398582550377798, 0.09170743201153797, 0.09784856866617031, 0.09870113305133421, 0.09480375880165426, 0.0997711199450243, 0.08794103626380478, 0.16031602967321523, 0.14768539284312865, 0.15492493652290418, 0.13549577069264018, 0.15865818834448042, 0.17335484030349524, 0.13947405901445542, 0.14847710546798754, 0.14637339195251775, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14187114934518164, 0.2463267432060955, 0.1556486266994196, 0.1080923410009953, 0.1207914665021157, 0.10744397053069465, 0.11007167196518874, 0.10511484148144368, 0.11075866579521498, 0.11040265245322212, 0.13419955881714762, 0.10608894032353511, 0.07719605790412498, 0.09391054747145222, 0.09777035995729444, 0.17175342556142492, 0.17158471160116373, 0.17810451965155794, 0.1792329628857553, 0.1872622813173601, 0.18434009176367305, 0.20217426306276254, 0.17901664600295775, 0.1829687912486596, 0.17901812551824425, 0.18008744399766874, 0.19216190378501674, 0.040476660246351104, 0.022978350128562086, 0.031393493129599714, 0.027015293023570086, 0.03425093938292756, 0.03595112025304403, 0.020002670929182953, 0.03803354422653826, 0.030777379125470405]}, "mutation_prompt": null}
{"id": "00e17c5c-9da4-4fe4-9523-a0862787b729", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "f570d837-8c55-46d3-9a2e-92936577ac05", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "c21a94ae-0c91-4627-9dca-9ce84258c489", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "afe42d97-1ae7-4a91-96e2-ebd76dc3259b", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "d9d525b0-c407-493b-841f-966842fdf3f7", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "9b64ed68-a934-497b-abdc-abf89a16f068", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "cc57e982-f6d5-4ad2-978d-d13a7d556f96", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "978447fb-48d3-4524-b895-e27628b745bb", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "5a026c30-de52-4bcd-b9c8-6baad5c4972f", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection incorporating fitness diversity\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                elif trial_fitness < fitness.mean():\n                    population[i] = trial\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "GradientInspiredAdaptiveDE with enhanced selection mechanism incorporating fitness diversity for improved convergence.", "configspace": "", "generation": 59, "fitness": 0.1418123211401835, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.22.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5500036249854368, 0.6078028558319849, 0.5686170712024348, 0.63026771334319, 0.6383905727958848, 0.6257464221073853, 0.6042742048795944, 0.5852827012667392, 0.6303824506659123, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005239612030313201, 0.01467079663371329, 0.005923305958902114, 0.014793696393340716, 0.037863123287933065, 0.016213614441965674, 0.033814250555996295, 0.017565449915636022, 0.011393775517657412, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9613792043439209, 0.9170251599439578, 0.9364928677696118, 0.782979640129341, 0.7873037033568929, 0.8608768703809284, 0.9276086043587196, 0.9611134584143147, 0.9275567257634606, 0.06274794416174423, 0.03282451017640764, 0.06009923547740359, 0.03884662396574423, 0.019025301726932953, 0.017089264170080942, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.12392524433315844, 0.07679583476891916, 0.07285119553694963, 0.05467680879051007, 0.07053235749629094, 0.059440952379421486, 0.07763497309287726, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004019429456145862, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.496670815778119, 0.4885026529923644, 0.5108455705983613, 0.48315472260873826, 0.48686414368958797, 0.5119037066313137, 0.4975092312519731, 0.5144174263055428, 0.5006878335969123, 0.04840800475408502, 0.032088992704581876, 0.04276355453927683, 0.03266886175302153, 0.016443286094577902, 0.01759993274736349, 0.027648155059964097, 9.999999999998899e-05, 0.035419347181350536, 0.1538463099684152, 0.14336632018208384, 0.1456480736893958, 0.1615162022852069, 0.13991852218419376, 0.167440992380965, 0.14342542723996177, 0.1687687649109939, 0.15508157733045114, 0.25564285273389087, 0.27643003185992643, 0.2551932194093326, 0.27322116493442794, 0.24897851613000987, 0.2521604335344041, 0.28198865404648044, 0.28937559591197193, 0.27684081684671247, 0.08291084435143725, 0.0894754286827607, 0.08469420989347165, 0.11405528345540716, 0.12495082360559007, 0.10412018666474487, 0.14424487197333224, 0.11463944286098904, 0.11745801517627408, 0.16120740088365149, 0.15089925691753292, 0.17686371411063861, 0.21333193691692742, 0.16323612743876126, 0.16131238164754813, 0.1674922709384964, 0.16527587318781822, 0.16359818552982508, 0.008083004124703752, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1472379634790717, 0.1554539595252119, 0.1452945140086528, 0.16046786237522026, 0.1702873797226816, 0.16601320749172954, 0.1476815422412936, 0.17129652695390907, 0.15156770049882395, 0.17014694531718288, 0.11040265245322212, 0.19415538905137397, 0.155666737741197, 0.07943239828909388, 0.09148291178884704, 0.09313993740421189, 0.17260909489906884, 0.2002470476738526, 0.20179932993043992, 0.1865669011338137, 0.17599928321862512, 0.18116379354483747, 0.181605492307229, 0.19283094792496747, 0.18592298606013002, 0.2152289230820893, 0.18313599621997445, 0.18764691595156524, 0.036209387166027396, 0.03684892197084477, 0.041232067783570914, 0.027723519223440962, 0.03425093938292756, 0.032217836905996444, 0.03353105575067583, 0.03803354422653826, 0.03884673098523417]}, "mutation_prompt": null}
{"id": "b61c7f5b-0131-4d5e-a730-198c8420af56", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "201dc9b6-3645-4a51-ba12-55fbd722dff1", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "23924c8e-31f9-41a3-be03-5af5e2dfcd8f", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with adaptive scaling factor\n                F_dyn = 0.6 + 0.4 * (fitness.min() / (fitness[i] + 1e-8))\n                mutant = x1 + F_dyn * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce an adaptive strategy for the differential weight F based on convergence rate to enhance diversity and convergence speed.", "configspace": "", "generation": 62, "fitness": 0.11435310876731343, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.11 with standard deviation 0.20.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.1641884204702656, 0.160030153179182, 0.1689715615533598, 0.3892987693049409, 0.35313171006835375, 0.39615109514957003, 0.30258082380106477, 0.3408903998726026, 0.3546208273197339, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01467079663371329, 0.005375109906600173, 0.010643411704069683, 0.006592353378601756, 0.009113938324562865, 0.018248263482334326, 0.007934008512353818, 0.02736833579347131, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9532900283494945, 0.9563036587068819, 0.9722097786226439, 0.9498050499920399, 0.972199285551607, 0.925310559465987, 0.9646014476341681, 0.9719891765140363, 0.9852965780678664, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.09500347718915814, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.047139082635548, 0.049316015966914706, 0.06628977544734405, 0.07624065167869598, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004873522007954656, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.283858162668605, 0.3013337632695353, 0.2562821653733993, 0.31086854243632, 0.31114673754790134, 0.2989526658734778, 0.29972078711428884, 0.328952191287728, 0.3293323145172511, 0.032460070990462, 0.027172494529924318, 0.042871983740104924, 0.03266886175302153, 9.999999999998899e-05, 0.01759993274736349, 9.999999999998899e-05, 0.013712094950184994, 0.02824978537374445, 0.1264711742136445, 0.13848502095518267, 0.16386530560055856, 0.14350087897889952, 0.15789155386579046, 0.14607885173314483, 0.14532552430550805, 0.13546355969209234, 0.12677504669334283, 0.13496369494050908, 0.15082586435234757, 0.1613932299901244, 0.18443891327062434, 0.18863486293033627, 0.17122209438471037, 0.19642275305951296, 0.20838708783817506, 0.2039063906656703, 0.0853902276853361, 0.08712591186857466, 0.09771309606460821, 0.1045374816785547, 0.10846325888500252, 0.09154010966501169, 0.09034043952310766, 0.0997711199450243, 0.09328462673547822, 0.1454848857687181, 0.16759573671837258, 0.16024993315096525, 0.16299802839221034, 0.1542156596306573, 0.1486553085375748, 0.14051819061382775, 0.1612525086143909, 0.1432826609508704, 0.13311663473442947, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1610623647656354, 0.15655055956755282, 0.17541866817589746, 0.16317764416675706, 0.14671468326735282, 0.12160089111339589, 0.11122667078249526, 0.14821310495732687, 0.12396217103887264, 0.13125076453872875, 0.13622374364247103, 0.11377545015468427, 0.08374954012214642, 0.08628373945764034, 0.09440009188835996, 0.16670262092986954, 0.17091086802984778, 0.1515493817934188, 0.18490202520363086, 0.18518068460469173, 0.18074620070662895, 0.17760615621472586, 0.19002201400491836, 0.17942948117596857, 0.18065738330685677, 0.19528243834985282, 0.18886644659511675, 0.03677733540031347, 0.023652265084532553, 0.03159883295179555, 0.027015293023570086, 0.03425093938292756, 0.0334297101233022, 0.028580568122430483, 0.03803354422653826, 0.029640593711566576]}, "mutation_prompt": null}
{"id": "5a37c1d9-2082-41cc-8be3-bc76398f4678", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Adaptive mutation with dynamic scaling factor F\n                diversity = np.std(population, axis=0).mean()\n                F_adapt = self.F + 0.1 * (1.0 - diversity / self.dim)\n                mutant = x1 + F_adapt * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce adaptive differential weight F based on population diversity to enhance exploration in diverse landscapes.", "configspace": "", "generation": 63, "fitness": 0.12628426566339895, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.21.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.31193244800158204, 0.27158774113096973, 0.15272899364662385, 0.4886799957342046, 0.5303248594031165, 0.5033678014974436, 0.4450949400236709, 0.4323151123296911, 0.4327204442617256, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.023168467951937055, 0.01706667172093279, 0.005375109906600173, 0.010643411704069683, 0.02474363706065963, 0.023336145682595788, 0.018248263482334326, 0.04422552387660106, 0.010674738340807233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.011354739030403627, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9536625758112344, 0.9796981274257845, 0.9672143123216717, 0.9543977274867224, 0.9523186324906042, 0.9378024093899883, 0.9662168478589673, 0.9719886096131428, 0.9685328855231832, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.06253180957070525, 0.09718541345375598, 0.07285119553694963, 0.05697870041482833, 0.08650406017020684, 0.09061242364396405, 0.09639379167913598, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.40655872979385166, 0.3776573022278552, 0.35537725930602915, 0.39564594548661625, 0.38345360030237685, 0.3723252970530181, 0.3705782057155026, 0.4037187135927134, 0.3954976084283136, 0.039670335238162435, 0.04535245393622955, 0.03523681754536501, 0.03266886175302153, 0.015807711568815996, 0.03757188786539223, 0.007998962832151624, 0.009439821174404672, 0.032138607680575304, 0.13813966363157726, 0.14538225585301878, 0.14617238631855212, 0.13890580762687843, 0.17410731655248723, 0.14442086187543468, 0.13774423169120542, 0.12052456905684794, 0.13435405685542468, 0.19945736149329163, 0.23261998113950344, 0.196853317046643, 0.2023238774611037, 0.19977833994824334, 0.1953463564554624, 0.22518902308138067, 0.209251686237647, 0.22010153382322173, 0.07729500728585825, 0.07606902040003694, 0.08696285210750543, 0.10127329647533023, 0.09623455729227048, 0.09506538234179629, 0.11119337548880215, 0.11211859087887355, 0.10928044847691021, 0.17133362211508651, 0.15487270458656954, 0.14782853401639573, 0.16243841060519515, 0.18651997976126966, 0.18225008979559354, 0.1494133074714642, 0.1596804805045995, 0.15429368501701668, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.24756561409230238, 0.15325741368509993, 0.1636855403646874, 0.14760907972220538, 0.12398774796667711, 0.14090077580321503, 0.14943427624978978, 0.1440657419753033, 0.15701655686368599, 0.1486738229698189, 0.16129051747454304, 0.13532617031627436, 0.16782069582704173, 0.10289866911946832, 0.0962645498906528, 0.19542796802980278, 0.18872709162512968, 0.19179588244178292, 0.1835045098831809, 0.179209125569334, 0.19445197622368715, 0.18926275903070766, 0.18321943812851715, 0.18729149931232758, 0.19732562023089117, 0.20834128207347968, 0.18395583219312472, 0.022060690200915944, 0.03585626665832675, 0.031393493129599714, 0.03283069071104838, 0.03425093938292756, 0.026131220257555432, 0.0332745692375267, 0.03803354422653826, 0.017643830485487344]}, "mutation_prompt": null}
{"id": "dbf4f74e-95ce-421a-a898-c9bd82a55f24", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "730dc312-a519-411c-91b5-d6eb5fab3a41", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            best_index = np.argmin(fitness)\n            best_vector = population[best_index]\n\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with global best incorporation\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3 + best_vector - population[i])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Refine mutation strategy by incorporating global best vector to enhance convergence speed.", "configspace": "", "generation": 65, "fitness": 0.10458941250511486, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.20.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.14063982696997213, 0.14772210006147912, 0.20282063165847053, 0.21585205596979562, 0.24777444446901886, 0.22887537719478546, 0.18017403979069546, 0.21931636777045904, 0.22908445486696005, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.022639231883957334, 0.01467079663371329, 0.019264953603424173, 0.010643411704069683, 0.006592353378601756, 0.006669962766643223, 0.018248263482334326, 0.007792397052521438, 0.010674738340807233, 9.999999999998899e-05, 9.999999999998899e-05, 0.0020180273228783685, 0.01959972157639278, 0.0004952459975243739, 0.006677246940382964, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.984748540841358, 0.9832810410275388, 0.985613753061233, 0.9879054000629632, 0.9823893982591602, 0.979363497474655, 0.9791116374248527, 0.9944932729642758, 0.9905401258723132, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 0.00032843434665097426, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05133364577005728, 0.048968006538854025, 0.05931056463008866, 0.0416657502729213, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01477402722049903, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.2058950222523087, 0.15756555760738078, 0.14838054695461433, 0.172778780373137, 0.2120539112315688, 0.16762740696087297, 0.16112956940342849, 0.1952677015693668, 0.1845712813684871, 0.015212852272986854, 0.02276614813561606, 0.028097593569869406, 0.03266886175302153, 0.008556037031317132, 0.01759993274736349, 9.999999999998899e-05, 9.999999999998899e-05, 0.0267656688986897, 0.11617400508292008, 0.13359034395801372, 0.14374810169284702, 0.14899122330265036, 0.13121498893595274, 0.13618924189560477, 0.1493410021508813, 0.13841642024423106, 0.1411354096211198, 0.1815119065234826, 0.1782268853459229, 0.1613932299901244, 0.1665439873420741, 0.15749619882433685, 0.15266644374945082, 0.20774537546765248, 0.1916681151698747, 0.21771969007534442, 0.05985564337097804, 0.07829226064403427, 0.08398582550377798, 0.0947187592775075, 0.0933346763512991, 0.08254807211308579, 0.0837317855149382, 0.0997711199450243, 0.07512002163720499, 0.1270795240619187, 0.1696771867633743, 0.14674862513531628, 0.14316027216262395, 0.12863045993590871, 0.14686636814639364, 0.16482188091107564, 0.15849411064300456, 0.1370192604800009, 9.999999999998899e-05, 9.999999999998899e-05, 0.140109762200902, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12355323572233878, 0.16738043108763234, 0.14922687045988714, 0.1165855974281329, 0.1207914665021157, 0.1547373139803141, 0.11167414897662342, 0.10788022884929849, 0.12060088593047569, 0.11040265245322212, 0.11887399783196784, 0.11255124454261312, 0.09124354919767175, 0.08045817179650006, 0.07397314510663455, 0.1793705921016775, 0.17926753718333044, 0.17132715821442857, 0.171352100829114, 0.17638580705547102, 0.17478536317796212, 0.19031202620819476, 0.18642903644276843, 0.18963600011182458, 0.18638104518847376, 0.19174544838584884, 0.2011905653585716, 0.028515710043195752, 0.021738148441522887, 0.031393493129599714, 0.027015293023570086, 0.03425093938292756, 0.023799018777821423, 0.04474490880036208, 0.05055634130343589, 0.02530581973749102]}, "mutation_prompt": null}
{"id": "7e27ff09-5fe9-4b37-b2ef-f12bf3c98b5a", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "04c51bab-440f-460b-ab40-6338b0573064", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "deb57fc1-d38d-446c-9677-cd7e84d2a00b", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "50b28c08-f973-42e2-8c9d-04c2bf117701", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "248043e2-71dc-43ef-b99a-d31dbd947a37", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "96477bea-32d9-4bb2-a7d6-aedb6e561fa9", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "99576fa3-c8a2-4585-89ab-57d4098d86de", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "40317d4b-d72c-4b29-b9d0-f4d04059e731", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "267b7053-efa7-4ea3-a5a0-d96232ac93eb", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "4340f7ec-b2b6-440c-b4c3-8b0cf97c6c04", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "ac14b58c-9e5b-48db-9f47-be12347454de", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "92cc2534-1ee9-4eaa-9ab7-43eaab13fd39", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "6689b055-c089-48fb-8c84-9d48ba921593", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Introduce random perturbation to trial vector\n                perturbation = np.random.uniform(-0.05, 0.05, self.dim)\n                trial += perturbation\n                trial = np.clip(trial, self.lower_bound, self.upper_bound)\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhance exploratory capability by introducing a random perturbation to the trial vector, improving diversity.", "configspace": "", "generation": 78, "fitness": 0.1328297781848016, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.21.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.47876132810295124, 0.4523706747555841, 0.4599192943194559, 0.4705781435675249, 0.5206543559092365, 0.4733864620415751, 0.46892962470531974, 0.4774006306369223, 0.4763952712914955, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014896821717390818, 0.01467079663371329, 0.007407931404652457, 0.012353045464380541, 0.02557251442367947, 0.021332138725608463, 0.02479690706708626, 0.02902348037621616, 0.03692298209021372, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9360260284250697, 0.9359439060643053, 0.8780953085117852, 0.9183107228093127, 0.9542409784776779, 0.8659839112506628, 0.8970184440093868, 0.9176552702397145, 0.8778287661823079, 0.06274794416174423, 0.02722417134996724, 0.028869332240197387, 0.018349846378654888, 0.01310666060338228, 0.013082011377620995, 0.018898657558512277, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.10463982041892217, 0.05017183931107205, 0.09786483155552983, 0.05931056463008866, 0.07876821675853207, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004280103223691767, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0016234438109983262, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.41603852757139526, 0.3951534721032526, 0.41412309740738196, 0.4093742507500211, 0.4269194019379804, 0.39693676640655884, 0.42274965822994937, 0.40509144650570084, 0.41055627997978905, 0.04974680462160197, 0.04244989901093321, 0.040553234215889855, 0.03266886175302153, 0.026183977933660008, 0.02964699566175788, 0.008815519130536797, 0.010581544746091853, 0.03329690452994272, 0.14209515247647764, 0.13653497472385967, 0.14500947750982218, 0.1613414286916517, 0.16100423847125078, 0.1276436830217097, 0.1286328044361873, 0.14204682620094156, 0.14614082640093107, 0.27185287202676955, 0.2581353384513363, 0.2583609665380916, 0.27067450507941704, 0.25529100481409883, 0.2682830550094538, 0.27576877819678614, 0.27914975209695225, 0.2791469937997555, 0.08778395485982493, 0.09587715872272184, 0.08694112387704589, 0.11640549388984178, 0.13293241145175871, 0.11515443232343003, 0.13172741412514533, 0.12285543636686613, 0.15431847258392062, 0.15677752343671092, 0.17860733950525443, 0.1750462532473801, 0.16149548499741595, 0.1709795546504974, 0.18131615284422398, 0.16943061939811432, 0.1568035095208583, 0.16774859920448015, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16795092821375635, 0.17917993183936232, 0.16524850843125038, 0.12434676601738337, 0.151366254288277, 0.1533077656976729, 0.1658066170391408, 0.1673535342336605, 0.12948708920827945, 0.13390858901024927, 0.3276451935352619, 0.11225378059956004, 0.09458219333034035, 0.1002753016593686, 0.11401073193820321, 0.2011888450512549, 0.20290313231518053, 0.2048838016482638, 0.17647047709717156, 0.18212526393313688, 0.1785453184066107, 0.1992168700468221, 0.18387456342667408, 0.1840833362550155, 0.18132146938508786, 0.174731618897085, 0.18251066586028886, 0.038067579845118216, 0.033154432631125164, 0.03698767763453159, 0.03404741367487407, 0.03425093938292756, 0.04817524839805831, 0.029931645561300457, 0.04184710470655595, 0.027667722519394866]}, "mutation_prompt": null}
{"id": "c2d90524-0652-4f64-9934-ca88cb58e4df", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "ed91bf77-d72d-4a69-9ee4-47302f905616", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n                \n                # Dynamic scaling factor based on population diversity\n                diversity = np.std(population, axis=0)\n                F_dyn = np.clip(self.F * (1 + 0.5 * (diversity.mean() / (1e-8 + np.std(diversity)))), 0.5, 0.9)\n                mutant = x1 + F_dyn * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhance exploration by incorporating a dynamic scaling factor F based on population diversity to maintain robustness across diverse functions.", "configspace": "", "generation": 80, "fitness": 0.12137153501732288, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.21.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.15739901622067098, 0.1478639254849835, 0.2569334424529993, 0.5140658746388806, 0.4663658777199272, 0.4945874014913241, 0.4358724820167834, 0.45407583180299527, 0.4077006804783072, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009505223114130823, 0.018765603060067026, 0.005375109906600173, 0.010643411704069683, 0.014421779970302473, 0.006669962766643223, 0.018248263482334326, 0.010413509161328549, 0.017636656480102597, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9650303763687484, 0.9659301651862537, 0.9669064467325434, 0.96187451712186, 0.9608721663373345, 0.949945585537628, 0.9578502904215153, 0.9718745070594756, 0.9852884570040891, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 0.009294934020928625, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.025662650997032355, 0.04889922685212478, 0.05931056463008866, 0.04382311507786396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01743164049297552, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.37070089751208624, 0.36263828966584466, 0.3378760133278188, 0.35376571439994264, 0.35588125421554484, 0.387216092658777, 0.3638219668074858, 0.3957229934183202, 0.36697695230926985, 0.03598955358983369, 0.030639861079878705, 0.022281966034328304, 0.03266886175302153, 0.00032234732913216657, 0.01759993274736349, 0.006896060160239026, 0.00276870442183641, 0.0267656688986897, 0.15427194106031095, 0.13928176761696576, 0.136512889297302, 0.1260173786062012, 0.1474121286447715, 0.1398671608929991, 0.14224437601702133, 0.13172608214447556, 0.14434154044633019, 0.21049868913402692, 0.20790407405898992, 0.210962188673393, 0.1968481754521808, 0.19261453003660245, 0.1894777613072801, 0.21261159715971356, 0.221163441160262, 0.22807704565092657, 0.06967622899193704, 0.07574176359266072, 0.08398582550377798, 0.10617929886278465, 0.10778390998432152, 0.08487544676677938, 0.0837317855149382, 0.0997711199450243, 0.09430129496337525, 0.15691542993640872, 0.17731628454766013, 0.16285821624465824, 0.2089331271467223, 0.17905235579505518, 0.1551535751516322, 0.14837466047646397, 0.14479180270952563, 0.1487127236097101, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16497196979019735, 0.15801799668989258, 0.16118529783879676, 0.1530759766299521, 0.1288105382966902, 0.10911813437719409, 0.14881244455103604, 0.15255402664112006, 0.14525496610391708, 0.14361636661621924, 0.12344537683833168, 0.1293612263007179, 0.09803523321504903, 0.0982945657758677, 0.08490975546569057, 0.19446517696915533, 0.17006525194677324, 0.19029962382574506, 0.184828050801371, 0.2027013506482913, 0.1849323892117386, 0.18132951022471355, 0.18209004739877976, 0.1847227096756826, 0.190396826063716, 0.1867251263918156, 0.1927214461504997, 0.022980515888143205, 0.02774531882785214, 0.031393493129599714, 0.027015293023570086, 0.03425093938292756, 0.020045516730027746, 0.02103971939277194, 0.03803354422653826, 0.02262142106333409]}, "mutation_prompt": null}
{"id": "222ff35c-766f-408c-81b8-9bdf0fc91fe8", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "9f29c811-46b2-42cd-a79e-957b4ddc6535", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation with stochastic perturbation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                stochastic_perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max()) + stochastic_perturbation\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce a stochastic element to the adaptive step to enhance diversity and escape local optima.", "configspace": "", "generation": 82, "fitness": 0.1299755357830157, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.21.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.4295775313621195, 0.42910380377617086, 0.41062445806714254, 0.44177849318379214, 0.4562152102454714, 0.44562290341836164, 0.46774897513430147, 0.4936698123440224, 0.4563793970098885, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02047271308922105, 0.01467079663371329, 0.005389293477455204, 0.010643411704069683, 0.012791322361413449, 0.022370279867511833, 0.018248263482334326, 0.015301041986322317, 0.029455750053725915, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9540363661212662, 0.9472539717130433, 0.9415664333090177, 0.9772332157626344, 0.9761757797343473, 0.9380027749168096, 0.9481936120874652, 0.948952467100574, 0.9223189183364657, 0.06274794416174423, 9.999999999998899e-05, 0.007782950861172089, 0.00631460795666261, 0.00031549654350837564, 9.999999999998899e-05, 0.019178910996247356, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0732687348123825, 0.07285119553694963, 0.04539691890840636, 0.038592368234340424, 0.05931056463008866, 0.07876821675853207, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001736094410065947, 9.999999999998899e-05, 9.999999999998899e-05, 0.0009629382143588883, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004810541837318882, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.4014111514696328, 0.3828100073031492, 0.3767323884687377, 0.3964411419827196, 0.3933189999557609, 0.39261080165720985, 0.41516048047578413, 0.39935950199942183, 0.3916197127772735, 0.03815588224355981, 0.03421220513573897, 0.05274103187118018, 0.03266886175302153, 0.00034117288976809323, 0.03213341239395762, 9.999999999998899e-05, 0.006787515885596118, 0.0267656688986897, 0.166835238809803, 0.14756242957957888, 0.13189772554353218, 0.14381707666645238, 0.14328805999993277, 0.12824744537793353, 0.13855517592935795, 0.12850965941120607, 0.14364916530198846, 0.2697442354989572, 0.2566470207299181, 0.2598966318740298, 0.25185071483619204, 0.26283258823481515, 0.27044301537710647, 0.27338424940790307, 0.27682315416084835, 0.27670922192807845, 0.07563646625216314, 0.06882397263515216, 0.08398582550377798, 0.08917993432784821, 0.10649505782745694, 0.09712825201650688, 0.10984490753978093, 0.136340802266259, 0.11603722944896999, 0.17216676083321103, 0.16965345417275535, 0.1712778156844137, 0.1917858106333339, 0.15230618827177023, 0.15350001144562375, 0.1572901167409385, 0.15675179332649203, 0.1681737840607791, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.17598044565197613, 0.15168523853876703, 0.14763906529897286, 0.1478005205526799, 0.12408219285112487, 0.1246908319580261, 0.15975244579118175, 0.15046626803637353, 0.13887701206544367, 0.13648804668872705, 0.15608018812556346, 0.11687257970083231, 0.09612871257015865, 0.07840544767845947, 0.16693099594591188, 0.19945967029603007, 0.20165098682923976, 0.2792419027912948, 0.18642430943537525, 0.17391364851207058, 0.19191914095176477, 0.18660938909061253, 0.18555379794074844, 0.18370774163731807, 0.19513134596590942, 0.19551673017491, 0.18379535497635957, 0.029590211296487312, 0.02627403862372868, 0.031393493129599714, 0.04199993177544925, 0.03425093938292756, 0.04712575033130817, 0.03356639457300736, 0.039341516520252306, 0.03379451781610132]}, "mutation_prompt": null}
{"id": "a5bba0ba-81d0-4d04-9c0a-ddd0f4ac91b5", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "a14f9172-b509-417d-b9b5-3cfe601daa37", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "b3f0f72e-17bf-4fdb-bd83-fe16f233f6e2", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with fitness-scaled random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9) * (fitness.max() / (fitness[i] + 1e-8))\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Incorporate fitness-based scaling of differential weights to maintain diversity and adapt exploration.", "configspace": "", "generation": 85, "fitness": 0.14687905244035132, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.15 with standard deviation 0.24.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.6047878137979894, 0.6319042852614557, 0.49864969255055125, 0.6506979776184472, 0.6969507212232178, 0.6861209949782043, 0.6820760592984245, 0.6792516715894112, 0.7318630719988195, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.029040903772520554, 0.01467079663371329, 0.013979241128081243, 0.010643411704069683, 0.008350024635023545, 0.006669962766643223, 0.018248263482334326, 0.020243298874401128, 0.011619376944190796, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9846068442600246, 0.9803208758873587, 0.9786619496051596, 0.9497527326412447, 0.9399408736225806, 0.944810528146179, 0.974697531035863, 0.9790538404319836, 0.9793619120224646, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031549654350837564, 0.06440069148459793, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.02719911740704939, 0.05318070397888297, 0.05931056463008866, 0.05293696890512367, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5477418662155527, 0.5620657286155495, 0.5384031117587114, 0.5451947101086536, 0.6026634573652712, 0.5796395421117799, 0.5398731420565877, 0.530560807763629, 0.557922952634521, 0.04538878667371793, 0.03552175011748604, 0.03977437727335131, 0.03266886175302153, 0.017454120622505398, 0.01759993274736349, 0.008621956377178552, 9.999999999998899e-05, 0.0267656688986897, 0.13703913566746506, 0.1400225049611521, 0.14956561159794524, 0.16649241700700934, 0.1407498118273901, 0.16168181562564332, 0.14775183671564718, 0.11759404095711401, 0.12167855324305477, 0.2803468951614645, 0.29641707562105746, 0.2987519556023799, 0.25537971749894295, 0.23797948752813414, 0.2398205320403628, 0.2805460296329376, 0.30682848323820566, 0.31748209543622863, 0.06984966857132169, 0.07037586475973645, 0.08398582550377798, 0.11765689029038617, 0.10371835395395479, 0.10444627188191224, 0.1198665232620999, 0.11938154446312843, 0.12460944724881973, 0.1630716320267629, 0.18622992294704388, 0.15886656393850773, 0.15628424291447296, 0.17216194462634282, 0.16765773147268226, 0.16009860265651732, 0.16571373630383202, 0.15556149409837494, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19883911963331313, 0.30739241423029307, 0.15244029544950188, 0.11866552154182641, 0.13819833328632503, 0.11645649480220654, 0.14091644612652454, 0.13428333079838317, 0.19979848958903745, 0.1239398508277405, 0.12615010133653326, 0.15413331191104118, 0.10088372496995468, 0.10428515488483792, 0.11783724009838537, 0.17735431493016818, 0.17644131374446748, 0.18946925644309454, 0.18952040607113563, 0.18291008204577752, 0.2085788680087347, 0.20712385731424787, 0.18827714300781206, 0.18510287467837683, 0.18494396113138334, 0.19620837046573414, 0.18757847394025007, 0.0330272012734697, 0.034640023137940235, 0.0521889544204841, 0.03775669100349355, 0.03425093938292756, 0.027943410892885767, 0.04334987140871294, 0.03803354422653826, 0.029903229998356262]}, "mutation_prompt": null}
{"id": "8a0f4123-d8eb-4adb-af3d-19b4bae7080c", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "942c4c72-e3ba-4b0e-9fb6-7cd95875d06b", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "f9cbb710-4eab-44c5-892e-c5cdecd18f9e", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "9be2704b-ce2d-4e9c-8892-6be69b4c0ed5", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "ee278b85-b025-4afb-80d9-348c337c946d", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "2b5e3eb2-e6d5-4873-b39e-1e2bc9a8329d", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "52546b7b-2050-47c4-9002-4f980df45e16", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "d7a5ca5c-c57a-4d8c-b086-e800cb580b25", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "b6987923-df8c-4786-9ea4-62ae614988ae", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "1266edd8-cfbb-4d93-8e34-b50d56876dcb", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "ddefe295-dc77-4690-a615-723700bd4a9f", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "dda91257-66e4-4a99-955d-a4e71684a464", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with probability-based scaling factor\n                F_rand = np.random.uniform(0.5, 0.9) if np.random.rand() > 0.5 else self.F\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Enhance exploration by introducing a probability-based dynamic mutation factor in addition to the adaptive crossover.", "configspace": "", "generation": 97, "fitness": 0.1425726204635719, "feedback": "The algorithm GradientInspiredAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.23.", "error": "", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5414918385100491, 0.5594546949986345, 0.564551666022943, 0.6561681753118203, 0.6446957157903099, 0.6684763587374043, 0.6059569016851033, 0.637983631465297, 0.6310287902207263, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007712259834628976, 0.01467079663371329, 0.005375109906600173, 0.010643411704069683, 0.020632555462373192, 0.006669962766643223, 0.018248263482334326, 0.007792397052521438, 0.017696490181088098, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9616529221343005, 0.9440477413927716, 0.9502707629380005, 0.9328630631987544, 0.9589463922902088, 0.9397880177678075, 0.9345861603491636, 0.9614533520524191, 0.9425826839141266, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00031549654350837564, 9.999999999998899e-05, 9.999999999998899e-05, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.12085487017904328, 0.060014717511023496, 0.0667108215001172, 0.07441837608301827, 0.06493231021397483, 0.08201602012220488, 0.059565536725526225, 0.07664589433551772, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01777698929152849, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0007295521173206199, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5216425378686225, 0.4870059477204769, 0.4773482407691432, 0.505318055286234, 0.531908917058177, 0.48294393718291906, 0.5198151849689276, 0.4994871625846852, 0.4972865995913126, 0.0362663635356163, 0.029893258790700594, 0.03894783774706989, 0.03266886175302153, 0.029394596165130515, 0.043867140340497435, 9.999999999998899e-05, 0.0038237344029983245, 0.0267656688986897, 0.1393441060809284, 0.14529274947481574, 0.1439650467499125, 0.13190783605855416, 0.13613652616146588, 0.1611759362350096, 0.13229247798723276, 0.12632380293459922, 0.15629160923292162, 0.2600577946734365, 0.2541588228021856, 0.25730123066678434, 0.222153189120333, 0.22405606934475575, 0.25523883463541663, 0.27686300191120383, 0.24794755155642811, 0.27245993175327954, 0.08171616073640142, 0.0812813239206458, 0.08398582550377798, 0.09030759358266349, 0.09408885485176255, 0.12310828088198578, 0.10635151869407544, 0.0997711199450243, 0.12407907036185684, 0.16294938429953332, 0.16145271857908738, 0.18868405791909004, 0.16414963333183985, 0.15486138121754445, 0.1653837093612357, 0.1591958212080865, 0.15894317943606806, 0.19611214180708747, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15743325775472605, 0.14639473932364466, 0.6426890935233374, 0.15753959840806842, 0.16223595750081077, 0.13019664392059693, 0.12326054624008687, 0.1409040706582404, 0.17586094082088055, 0.14005721083770872, 0.12834045562875962, 0.10870379948432729, 0.10405816407631885, 0.10693238937201055, 0.10199560664114693, 0.17344211535924137, 0.1989708561184228, 0.19741776944729217, 0.17137083977565126, 0.18139945238861788, 0.20030379758054773, 0.20445292728790998, 0.18772123058642376, 0.18756431860979084, 0.18991019872060255, 0.17546753163221407, 0.1709455493804375, 0.035188188397116016, 0.032312255139294255, 0.04112360849594188, 0.027015293023570086, 0.05146464376328075, 0.03769725689472547, 0.029267261154883095, 0.03803354422653826, 0.04734539624663925]}, "mutation_prompt": null}
{"id": "9cabdba6-1bb7-4832-833c-6ff757841b05", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}
{"id": "a9050330-4154-42f4-853c-98f60c398cd8", "solution": "import numpy as np\n\nclass GradientInspiredAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.85  # Initial crossover probability\n\n    def __call__(self, func):\n        # Initialize population\n        population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                if eval_count >= self.budget:\n                    break\n\n                # Select three distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[indices]\n\n                # Mutation with random scaling factor\n                F_rand = np.random.uniform(0.5, 0.9)\n                mutant = x1 + F_rand * (x2 - x3)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Dynamic adjustment of crossover probability\n                crossover_prob_adjust = 0.1 * (fitness.min() / (fitness[i] + 1e-8))\n                crossover_prob = np.clip(self.CR + crossover_prob_adjust, 0.7, 0.95)\n                trial = np.where(np.random.rand(self.dim) < crossover_prob, mutant, population[i])\n\n                # Calculate trial fitness\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Adaptive step inspired by quasi-gradient approximation\n                gradient_approx = (trial - population[i]) / (np.linalg.norm(trial - population[i]) + 1e-8)\n                population[i] += 0.01 * gradient_approx * (fitness.min() - fitness.max())\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "GradientInspiredAdaptiveDE", "description": "Introduce dynamic adjustment of crossover probability CR based on fitness improvement to strike a balance between exploration and exploitation.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8125e611-8a4e-4c57-9231-cd84cf2dcd29", "metadata": {"aucs": [0.5779135066858279, 0.6845376647789543, 0.6412781629175713, 0.6939883971757594, 0.7089971796351728, 0.6756624525004463, 0.6969178434512342, 0.6720079910332665, 0.670489102807402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003813260775191285, 0.01467079663371329, 0.008597931612806309, 0.010643411704069683, 0.011171825950318626, 0.008081312356504555, 0.018248263482334326, 0.02245396823685264, 0.013381582795556457, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01959972157639278, 0.0004952459975243739, 9.999999999998899e-05, 0.014763392921912755, 9.999999999998899e-05, 9.999999999998899e-05, 0.9670436432642897, 0.9431406464831704, 0.9709450796015254, 0.9415456932839592, 0.9292908328946601, 0.9399531693068357, 0.9450486159845315, 0.9534797154634919, 0.9653896536312507, 0.06274794416174423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013787374116120965, 0.00015712844835247264, 0.020590898085119047, 0.011293333694524565, 9.999999999998899e-05, 0.10027683525177622, 0.08224659834595494, 0.059824388882108726, 0.0667108215001172, 0.07285119553694963, 0.05630301384236025, 0.05340839039023271, 0.06013426203556105, 0.07066526698708153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009836872689234943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5242243822288651, 0.5501671141888419, 0.5236523992611004, 0.5712510687212085, 0.5749364958780736, 0.5703826421812861, 0.5505252174908944, 0.54476162047912, 0.5960944856226249, 0.03229073323637999, 0.048151337744904765, 0.05525227570633762, 0.03266886175302153, 0.02092461802103951, 0.01759993274736349, 0.027648519519361647, 9.999999999998899e-05, 0.0267656688986897, 0.13242633870064768, 0.14462293220566536, 0.1537162761821308, 0.14274180166892747, 0.13283486090062546, 0.1621213516728769, 0.14543933739420278, 0.12452757744808063, 0.13768817797701882, 0.2618780256617542, 0.28064661531702273, 0.2493540938776999, 0.2791662479370175, 0.28293747675288505, 0.2825197338221074, 0.2953862038009989, 0.3325045394317644, 0.29712648410009057, 0.09706139579349926, 0.07980694189915283, 0.08398582550377798, 0.10797357335257451, 0.10966214653560491, 0.110858582775618, 0.14507870803916334, 0.11410904548697198, 0.13944322386158492, 0.16468466875020638, 0.1576181081034379, 0.15460323862060465, 0.17514352732145422, 0.1570260113790347, 0.1738982916554329, 0.1625391310758536, 0.16380599140586638, 0.16851394190130375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14589836985408167, 0.520800541069524, 0.14928635027757098, 0.12149875237666852, 0.1207914665021157, 0.11342853671276698, 0.1497796088958936, 0.15156770049882395, 0.15079551893467147, 0.12180875444892136, 0.33255960093313763, 0.14863359084918926, 0.10166384998654465, 0.080171524090622, 0.10557349494622159, 0.18378871943019903, 0.19534947684563198, 0.18855734013075842, 0.18654499005568959, 0.1821817847573307, 0.18630350903678494, 0.1904295171752689, 0.1994557136810483, 0.18503259572672603, 0.19784065069019674, 0.180409799648109, 0.17250778223544583, 0.044549287618789846, 0.051873099881629026, 0.04616574320828426, 0.03221187948900228, 0.03425093938292756, 0.03704885231756705, 0.05371391184604546, 0.03803354422653826, 0.03322245767576093]}, "mutation_prompt": null}

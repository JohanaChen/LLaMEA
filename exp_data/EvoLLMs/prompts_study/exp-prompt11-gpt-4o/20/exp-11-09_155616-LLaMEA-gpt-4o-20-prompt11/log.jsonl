{"id": "0c18ab97-472b-445b-8585-decc541a6892", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.2843497343912691, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.27.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "a6a38bab-568d-4166-8f97-c889387af5ba", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "49798c8a-99b6-489e-a620-58d4afa8b47c", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "bd269fea-4cc9-495d-aedf-95dc2a173175", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "9cb4f7b3-7f8c-4847-90e2-a75eb178b74f", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "31600678-8900-4101-a651-c5ba2a1944c7", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "f2a14e4d-5d06-4f01-8e66-0578e0240fc3", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "e55d8049-56e3-4100-8530-67fcabe1c4c8", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "5f7482e4-5c5e-4019-8b56-c980441f3101", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "1955d5ba-c9d9-4505-9c62-7cac8cd4de57", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "d6cb45b9-7aca-481c-a8a4-8b63656dd692", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "01727fd9-2f7b-4e34-9299-4dcb6a4c599a", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "d035fe39-4edc-4466-a9ef-41cea531a49e", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "fe969810-6739-443c-b5bf-4becee9c95c8", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(20, self.budget // 2)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n\n    def __call__(self, func):\n        # Initialize particles\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        # Evaluate initial particles\n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        # Initialize global best\n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        # Update personal bests\n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Clamp positions within bounds\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            # Evaluate new positions\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            # Update personal bests\n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            # Update global best\n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that adaptively refines search regions using momentum-driven particle movements to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9158054739651612, 0.8947398857306461, 0.9111745840980899, 0.9191430930008543, 0.9146619089981933, 0.9103961116433226, 0.9135632926726931, 0.14372258527849502, 0.9122190046671588, 0.04190471695712694, 0.6411551036449572, 0.7737600475269768, 0.7850735294016032, 0.048399539888556276, 0.7106557982698376, 0.7696731564802295, 0.8108854134390127, 0.8020767580262563, 0.18471850712517346, 0.19137573370096284, 0.13694945482821275, 0.15858801466000527, 0.16019942562430933, 0.15683491466483335, 0.14325261191418537, 0.18099879613788084, 0.1847312317253147, 0.15635512106374738, 0.13273806878086702, 0.15344559856767903, 0.12000469032471173, 0.16024127310345826, 0.15810414872687706, 0.15810046631718377, 0.13165108586205698, 0.11559078644541476, 0.9927951731776428, 0.9852811748201823, 0.9944513201932383, 0.9868581463106867, 0.9908355814319855, 0.9909411338272135, 0.9891228355927848, 0.9910036704277513, 0.9907626025622283, 0.7885382320495676, 0.055557705312883954, 0.8015680584274762, 0.7679197865631764, 0.15371053056025086, 0.6704363881974966, 0.12735029555156085, 0.051876399640121806, 0.7436876418634877, 0.17301390878266087, 0.15435016827162595, 0.2203358396548729, 0.19423181752053242, 0.20815975371549267, 0.19349986762873128, 0.12589951821580891, 0.12693373277112785, 0.2240609124700511, 0.32036100596610095, 0.232958402514843, 0.23976171199145002, 0.24969886970861577, 0.23158938055215772, 0.21181534634148258, 0.24439668360733657, 0.2515298819276064, 0.2507333807446589, 0.13602241869232834, 0.1311909314901223, 0.13170695346620664, 0.13648378221144286, 0.1315907804324925, 0.25765252853360066, 0.2730324981892879, 9.999999999998899e-05, 0.2698772783004437, 9.999999999998899e-05, 9.999999999998899e-05, 0.038181480818222036, 9.999999999998899e-05, 9.999999999998899e-05, 0.028005123588707104, 0.03473155877153655, 0.0001292379701304247, 0.04526017008009986, 0.04988391042880991, 0.03749604363609815, 0.07700140877348183, 0.032218568561280025, 0.009458217471536745, 0.023869563110814118, 0.11778497344230254, 0.12672517948127193, 0.0387513761184165, 0.05231472247171953, 9.999999999998899e-05, 0.151796947221144, 0.08138376206861031, 0.24965908824434835, 0.07907834726332963, 0.27281929300194074, 0.166902093762344, 0.10849806512252202, 0.054993200322625446, 0.0438929412548974, 0.0316344038294345, 0.0381312825457073, 0.0067447013617131235, 0.006745438356910549, 0.29436286925748845, 0.050351979908740074, 0.08486209836933978, 0.6292883423787753, 0.545861681215888, 0.6120549126679226, 0.5699611968114111, 0.5970595870741253, 0.20955147723508583, 0.5877499455993919, 0.5642813987028603, 0.5611509901060692, 0.08616346664527297, 0.05993987934123579, 0.07837757159842473, 0.07982522099807754, 0.0730091311132397, 0.09160585776919283, 0.14426706228752062, 0.11107716643094423, 0.09961209683757366, 0.26168012254445105, 0.1987581546720124, 0.18754149662548258, 0.18583302844457172, 0.47101670187188904, 0.16748755144875827, 0.1795325309644097, 0.3003853376243345, 0.2673405932618613, 0.24382436402605978, 0.2000318992766129, 0.3106469860048252, 0.6472496051035174, 0.3111044790104297, 0.2888530603666082, 0.3785913078174594, 0.37504071680580453, 0.1593480678991478, 0.18045684518999094, 0.21234761187572315, 0.15432784393771204, 0.3852303120331114, 0.10819983608268158, 0.3723018342777611, 0.30035575176998086, 0.3000583890592182, 0.20091312069391531, 0.22200897419639143, 0.2061365345447187, 0.2393668214774214, 0.22190741381730994, 0.22052297409320976, 0.23577814075945658, 0.21136784644505013, 0.2331630191380213, 0.25962853627835114, 0.2196470479793886, 0.19063419992929442, 0.19086322425358038, 0.23710402437203504, 0.20304502311139616, 0.19471950327477938, 0.1830461012260668, 0.18871226792082774, 0.1938144490190712, 0.9300135687605826, 0.17284813354649997, 0.12482409142848194, 0.17324672357154014, 0.20164193794631946, 0.17024418561468224, 0.10017494247776215, 0.17031096412817193, 0.1676968332434855, 0.08348521731334768, 0.2128540262506894, 0.21090653502758672, 0.5271434959727868, 0.16964186421419525, 0.2106791631330347, 0.10422477399566721, 0.844912276580365, 0.7910468112376831, 0.19764636576602024, 0.19626277664631775, 0.19665961121209496, 0.19303821262969634, 0.2137395750003378, 0.19452325665194725, 0.17990444885110068, 0.20636632962586687, 0.2029252415102022, 0.07890152774329251, 0.11987001886334314, 0.10449827933341005, 0.10316133475888523, 0.09468284989775089, 0.12032186646509979, 0.1022654465688978, 0.10033267718957961, 0.11704461993130333]}, "mutation_prompt": null}
{"id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.3090060317450278, "feedback": "The algorithm StochasticAdaptiveParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.29.", "error": "", "parent_id": "0c18ab97-472b-445b-8585-decc541a6892", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "42749968-c620-4f72-93c2-6a0946bcd8dc", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "f9ca23c8-1f10-4deb-b10a-3f00e0d6cdda", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "f398be8e-2bd7-4989-9687-b4fe7bd4c290", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "7f62072b-9c1c-4bb1-b49b-72619dabf831", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "16a927e7-496e-462e-95ac-dfdeadede692", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "5d998269-9ade-459c-8a22-f4c74149b9d4", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "06fc6543-2267-446e-8a19-526569ff2bc5", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "b467f232-a725-4839-8ce5-2b52676bd4c9", "solution": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 3)  # Adjusted population size\n        self.inertia_weight = 0.7  # Adjusted inertia weight for balancing exploration\n        self.cognitive_coeff = 1.5  # Lowered to reduce excessive local search focus\n        self.social_coeff = 2.0  # Increased to leverage global influence\n        self.adaptive_scaling = 0.95  # Enhanced adaptive scaling for refined control\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 7) == 0:  # More frequent adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2.5  # Adjusted elite influence factor\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "EnhancedParticleOptimizer", "description": "A refined particle optimization algorithm with enhanced inertia adaptation and elite-guided convergence to improve convergence speed.", "configspace": "", "generation": 22, "fitness": 0.24824814208341706, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.24.", "error": "", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.8392481975423232, 0.8128719224825808, 0.8242432971202271, 0.30189271162254805, 0.2956865146421165, 0.7500168213575512, 0.8347070078495304, 0.8336838104439994, 0.20947100986366818, 9.999999999998899e-05, 0.6131499374703269, 0.0347910099676747, 9.999999999998899e-05, 0.04565891134080302, 0.6390733361263905, 9.999999999998899e-05, 0.6223189092877746, 9.999999999998899e-05, 0.12654251028836694, 0.44709313535594575, 0.11597194330971106, 0.1858140673880757, 0.12565954696793036, 0.07320436087169258, 0.15207803203111891, 0.11890526168539761, 0.19793017833636284, 0.14349315211367208, 0.12961079077500837, 0.13341453891404365, 0.1319723009233339, 0.12059808807421546, 0.12597770788087492, 0.12765976476232332, 0.13648717597959092, 0.1346305271075835, 0.9913902530048896, 0.9937607531173426, 0.9939408724037891, 0.9856878723911775, 0.9837299260003732, 0.9882800128236294, 0.9910307131227067, 0.991750387019865, 0.9915006003633993, 0.4878911732088519, 0.4605761870901446, 0.47161569031621753, 0.14857559434927148, 0.15235855795822517, 0.15321945424589756, 0.10141802045740167, 0.10116250718643094, 0.073671746746925, 0.34716278574214043, 0.18982437535043017, 0.3506775781585638, 0.27565965732149034, 0.27770917916341775, 0.1925820911216667, 0.6714751892711959, 0.12630809905009233, 0.22588228283860035, 0.30290081306751004, 0.14863350855032187, 0.1286472895081595, 0.18366599126221728, 0.128818284180226, 0.17480413887226987, 0.1896470597772537, 0.14843808764602984, 0.18139445179983105, 0.20643262765148307, 0.02170939939451233, 0.2134612434000004, 0.13113188504128226, 0.21047168320677379, 0.2085360933719157, 0.2277535483274562, 9.999999999998899e-05, 0.22046764224520188, 0.01363606382667748, 9.999999999998899e-05, 0.07001015489101015, 9.999999999998899e-05, 0.01882669584545893, 9.999999999998899e-05, 0.04803697106752458, 9.999999999998899e-05, 9.999999999998899e-05, 0.06877111629973587, 0.06559906292717788, 0.04566504596666199, 0.009619383161534323, 0.002982225459222221, 0.0058143419708096555, 0.15580696470504796, 0.044872305627565945, 0.07370779300156394, 0.04637262371040374, 0.07228662456772894, 0.18573543149733673, 0.06957491047830333, 0.07132963316769603, 0.18111767538058943, 0.08773956152843143, 0.09306188830411266, 0.06917804832162477, 0.18019387189663083, 0.011176582783994693, 0.2734040604006044, 0.11804266317654222, 0.006484871464983222, 0.08700621879954251, 0.08120585961403415, 9.999999999998899e-05, 0.08120165445171623, 0.5560858921835348, 0.5570074568424165, 0.5346224549490107, 0.23912118151093753, 0.5382348850687735, 0.5536031306636107, 0.5319253187481318, 0.14348595804875353, 0.5174666388381586, 0.07465992442386671, 0.06305631019768809, 0.07551718487516357, 0.11235008499479793, 0.12200783468903187, 0.1832830440019576, 0.11353707247832134, 0.10914586940997595, 0.10912043711537134, 0.21768834511631052, 0.17019979695808074, 0.23686269552311756, 0.21768554782747884, 0.37729648609987354, 0.2139053281991986, 0.20018422497175703, 0.3142625354327939, 0.20942548554987583, 0.37726714599419253, 0.18658933070823125, 0.3020723615040114, 0.18654285480602084, 0.33564977241773775, 0.3844569937824558, 0.47548289482710004, 0.47323979830998475, 0.20977312112226743, 0.2584378235786057, 0.1984928505905763, 0.18629063850898797, 0.2331669472924336, 0.1869001274688702, 0.25580466798878454, 0.24762666500512265, 0.2725498188479233, 0.24021307541538062, 0.23947310653342924, 0.14286678372242856, 0.21883554841733854, 0.1917697655152052, 0.18324854192990936, 0.1658538374714681, 0.1944367375437036, 0.2595696247901089, 0.20159753327652374, 0.2061750354426829, 0.21981366324530105, 0.2065733540540614, 0.3041143698211868, 0.1984059186813414, 0.2208904640498075, 0.20417282135630788, 0.2332713784845305, 0.23070885684792342, 0.8494758204131144, 0.12647784287885666, 0.11490130747791949, 0.9140695092714678, 0.2007489156177974, 0.19456979454954137, 0.12282534812619617, 0.16996265291202328, 0.1936985501696984, 0.8125945392602927, 0.15344499689571767, 0.20675236689750354, 0.5118664467120976, 0.22523084616592437, 0.21060574131320164, 0.10404783379587701, 0.19973819761182954, 0.10489901893246201, 0.19306686177859622, 0.19721626979329576, 0.2244964082172295, 0.1945519152864591, 0.21337957378876882, 0.2101249299375254, 0.19311945923738905, 0.20923000904706213, 0.19123784309392755, 0.09534294020262446, 0.08547058476031377, 0.08915265726265276, 0.10050014658742423, 0.08819503276368346, 0.07852394733946089, 0.08678186238670682, 0.0726903989746992, 0.0893606751852003]}, "mutation_prompt": null}
{"id": "e36684b1-c3ab-4cf9-baa3-633dcf7712f4", "solution": "import numpy as np\n\nclass HybridAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.5  # Further reduced for faster convergence\n        self.cognitive_coeff = 1.5  # Adjusted for balance\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Adjusted scaling for adaptation\n        self.de_weight = 0.8  # Differential evolution weight\n        self.de_cross_prob = 0.7  # Crossover probability\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            # Differential Evolution Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = positions[indices]\n                mutant = x1 + self.de_weight * (x2 - x3)\n                crossover = np.random.rand(self.dim) < self.de_cross_prob\n                trial = np.where(crossover, mutant, positions[i])\n                positions[i] = np.clip(trial, self.lower_bound, self.upper_bound)\n            \n            if eval_count % (self.budget // 5) == 0:\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "HybridAdaptiveParticleOptimizer", "description": "A hybridized adaptive particle optimization method incorporating differential evolution crossover for enhanced solution diversity and convergence speed.", "configspace": "", "generation": 23, "fitness": 0.12726408587242644, "feedback": "The algorithm HybridAdaptiveParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.19.", "error": "", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.206421243054276, 0.1650011637561427, 0.19458668745965102, 0.24971927674600325, 0.2188912578039156, 0.22909969607158154, 0.1997148545749683, 0.18722662689832648, 0.19906422546714742, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05562698269918476, 0.04714534329451403, 0.04474413089856644, 0.04750575725170325, 0.058041984138228475, 0.043884356639326105, 0.0486280964637712, 0.04717996431912741, 0.05281999205821708, 0.03032105033878485, 0.023420073435914457, 0.023044848529004236, 0.027479167052766207, 0.027052735953861484, 0.03059574057039971, 0.0318349614404988, 0.028511241199779436, 0.032532173119201424, 0.9898206177735673, 0.9932238727927067, 0.9920433947010538, 0.9910555149310507, 0.9913990706884307, 0.9903545736756194, 0.9908917607923088, 0.9929825086855749, 0.992965956197141, 0.08048460970075555, 0.09095665653855978, 0.09246615316377116, 0.09330142309234668, 0.08884471709192843, 0.09983673221984957, 0.09933119894382958, 0.08560889059471122, 0.10373001333715814, 0.13992789294339836, 0.0770319920017275, 0.10693255849176186, 0.13604954459643848, 0.12855261035505716, 0.12457758789453488, 0.11650003276702192, 0.12083817666123453, 0.1363935011154377, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.023283579292705192, 0.026912828148760504, 0.02443986917879215, 0.0028861747881641087, 0.008048478252423052, 0.005080513649958318, 0.005951117826420549, 0.042587913783339926, 0.02768063819234634, 0.022269152059940844, 0.03772435527015583, 9.999999999998899e-05, 9.999999999998899e-05, 0.014477953249684483, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0313957863020774, 0.029535307748858708, 0.04343641909648743, 0.03176747455232676, 0.003630694154690861, 0.0061628245690203975, 0.03598122643246715, 0.043325745684606565, 0.02060161355425194, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002256182625202552, 0.0007886185761967202, 0.004624867499386509, 0.014734538555964738, 0.0001848262318313587, 9.999999999998899e-05, 0.013500432848589261, 0.019479665563995496, 0.017368078498587458, 0.1887147928997044, 0.18587484187843029, 0.20751909072065233, 0.2157942900499299, 0.19038476319638664, 0.22401403483021842, 0.19203928914428625, 0.20646093565995083, 0.17890168156729747, 0.0640206481699166, 0.07081487487854554, 0.06240427065542431, 0.05324196908539125, 0.05155168027554424, 0.05684121871503467, 0.05171754826456931, 0.04877204666175894, 0.06997919316499523, 0.14277877738786715, 0.12775431664323955, 0.14552093262762578, 0.13308199894206485, 0.14904334878705117, 0.15074973645831047, 0.1384280919500408, 0.13579075652943962, 0.1385831309545692, 0.16544381414521392, 0.16963092620661469, 0.17858819838905038, 0.1763946510611908, 0.15383554358344753, 0.16753128656583938, 0.16179009781627374, 0.17588583299912475, 0.1629214898717779, 0.10497209623652981, 0.12859492150487528, 0.11641509126947824, 0.10759928931601459, 0.10241706336409939, 0.09683001364029187, 0.12608991729314278, 0.12127310433053806, 0.10840604909948581, 0.14189321362438145, 0.13310018137226287, 0.1412012312089388, 0.1474520444253834, 0.1378424147716183, 0.14627284716428934, 0.1454100931733816, 0.14941844092720435, 0.1498267854218056, 0.120457165964856, 0.13407876483218517, 0.15513497715273117, 0.14386960093053036, 0.14714556387918987, 0.13960789543270635, 0.11911988925571038, 0.13281252348675976, 0.11605956312791532, 0.1491031364430745, 0.12861841866221635, 0.13829910212494345, 0.1610173585357435, 0.1409277965120611, 0.13334305590666684, 0.1536300549099484, 0.16769470367243844, 0.15218795460089518, 0.15606600611181676, 0.15816609570524454, 0.15325534056335177, 0.1258091844230237, 0.20216252161028836, 0.09793912927021775, 0.19170755085587132, 0.19559351318001528, 0.19575852344837563, 0.18937212816909077, 0.22087719460594224, 0.17307133886083248, 0.2025277904758146, 0.17362562589702302, 0.17669282982593326, 0.18641761209564855, 0.18232647741355978, 0.19265829827201852, 0.04362056327455177, 0.047313949786452536, 0.05983464665243521, 0.03908985536041709, 0.04420671922920372, 0.059899359182889245, 0.04472278837395549, 0.04454149031206922, 0.041151522007927266]}, "mutation_prompt": null}
{"id": "9f49848f-2bcf-4a2a-8e70-6f8f8c2114d6", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "d2360aba-a6fa-4ec1-b35b-1b2f044ad59a", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "93d7f941-7586-4b8d-90ac-3919b3230e63", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "1b3b15ee-1405-40b2-9ffb-d8ab81cdaf82", "solution": "import numpy as np\n\nclass EnhancedDynamicParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 3)  # Increased population size\n        self.inertia_weight = 0.5  # Further reduced for faster convergence\n        self.cognitive_coeff = 1.8  # Slightly adjusted for balance\n        self.social_coeff = 2.0  # Increased to enhance social learning\n        self.adaptive_scaling = 0.85  # More aggressive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustments\n                self.inertia_weight *= self.adaptive_scaling if np.mean(scores) > global_best_score else 1.0 / self.adaptive_scaling\n                elite_index = np.argsort(scores)[:3]  # Use top 3 instead of top 1 for elite influence\n                elite_positions = positions[elite_index].mean(axis=0)\n                positions = (positions + elite_positions) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "EnhancedDynamicParticleOptimizer", "description": "An enhanced dynamic particle swarm optimizer with adaptive coefficients and elite local search for faster convergence.", "configspace": "", "generation": 27, "fitness": 0.28672416328046685, "feedback": "The algorithm EnhancedDynamicParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.27.", "error": "", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9027350854078897, 0.899343571384669, 0.8940995599125832, 0.1834550505513719, 0.18337208218769907, 0.9130261085268453, 0.9208949785163569, 0.9119637096105302, 0.18257976906087314, 0.7991767777735915, 0.7668956676469075, 0.7242635349755597, 0.7834775893911694, 0.7815145080181403, 0.7713281543167209, 9.999999999998899e-05, 0.8146991116721519, 0.7517187829431725, 0.1521537188783384, 0.17784503110377503, 0.16195663465481103, 0.07412231696350957, 0.11581095546015152, 0.12127276033156409, 0.17523924613257602, 0.18090333678225623, 0.14256958554127996, 0.15730995630349276, 0.09409845412829732, 0.13376578224491154, 0.1802399881721043, 0.1423241171750531, 0.14622663151909543, 0.16874274215193874, 0.1507491539834469, 0.13318441190244812, 0.99135564118369, 0.9937354047265503, 0.9938948888774666, 0.9859265791202199, 0.9862540451278177, 0.9878146793583478, 0.9906968091115348, 0.9904155887065048, 0.991253267951664, 0.060081534794876656, 0.7296282567089547, 0.6078010181409933, 0.15281670726214103, 0.6414368104223228, 0.6065836268733302, 0.08426749538363243, 0.08891094731551819, 0.0886723902537957, 0.8947116614869924, 0.16953977997619263, 0.22763761192368903, 0.22199429046283958, 0.2222944754897389, 0.8735682417495843, 0.12444693153940167, 0.13027692799299218, 0.2208132235376401, 0.24923216703759155, 0.21583304567101114, 0.33026018910252164, 0.20728687676663982, 0.21130314270186168, 0.19923463571468936, 0.123430128303327, 0.1629705719001504, 0.20450574167576374, 0.2367184435419467, 0.02222449734835541, 0.22456067910088084, 0.25248811451527886, 0.33426261658529877, 0.22654513325980774, 0.23527702841300202, 9.999999999998899e-05, 0.2510982101268081, 9.999999999998899e-05, 0.0012465819646897414, 0.04290390188236981, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007390719243389521, 9.999999999998899e-05, 0.05732911405858088, 0.0851787704594229, 0.04949172627878762, 0.08951098131875301, 0.07622381172114234, 0.00722454342494494, 0.027307427376589977, 0.23484361289860667, 0.0993023721318197, 0.028278441906772422, 0.05178697047756009, 0.07802489994558559, 0.2201727031369174, 0.0835912288832682, 0.32375902070481677, 0.07850419690158383, 0.2591914923121462, 0.2432884753870872, 0.07524412587541252, 0.05862945147639653, 9.999999999998899e-05, 0.07364491509094528, 0.006677910061990033, 0.0066372832084833355, 0.11177292229021474, 0.08327551792413701, 0.05015611219327909, 0.08509860252722645, 0.5665069719374006, 0.566160979312152, 0.5509941981635703, 0.5562791628632353, 0.5920804464782667, 0.20942302016935488, 0.5686739853747609, 0.5753116037130674, 0.550778263370596, 0.08757067941625285, 0.05958292582881464, 0.11598276240214567, 0.14488036397734616, 0.07637164401728647, 0.10102444651259535, 0.13138517468856514, 0.121782353840024, 0.11038373105360844, 0.4361634314198237, 0.18700234288735818, 0.18487553839125337, 0.24538873426607177, 0.626569169989275, 0.1857112519664943, 0.339779761780722, 0.2718337501991558, 0.20843372114829828, 0.5665650520825265, 0.4719247500208368, 0.5076355844340599, 0.18844523293500748, 0.3157069134197201, 0.3513347486582743, 0.4082129323853394, 0.4113339432868126, 0.5702009359470748, 0.2598366100162328, 0.17440369777922948, 0.26267323387067365, 0.2628571870487477, 0.2083718482854643, 0.2752817201648462, 0.2886388118288421, 0.26564383979822537, 0.20192240132813466, 0.22234799752080092, 0.1978248664538994, 0.21098063467429906, 0.19621877971314738, 0.28294362541249707, 0.1942444772624674, 0.2853582578546955, 0.2447406185243196, 0.21789492698785096, 0.1970180543354978, 0.2514049943564498, 0.2278447191533166, 0.226380297016904, 0.19364526252385295, 0.19235232445654926, 0.20422875253621886, 0.25338181627298406, 0.23837864389126773, 0.1532862205153922, 0.1664735452115057, 0.152512609283464, 0.17742268452951027, 0.2017825685495508, 0.2005859355086974, 0.12459530396021656, 0.1702000771844392, 0.21436635001316873, 0.5798533970744875, 0.3060611242208868, 0.11221229899812313, 0.691912476630942, 0.7935527565654968, 0.21357278703140758, 0.10419476727113197, 0.10527722700382236, 0.1039484797703748, 0.1872102829739527, 0.207233720183723, 0.22160069133190652, 0.19201092605533343, 0.21061261982123902, 0.19464664590394276, 0.21062028270738709, 0.22509214640564346, 0.220899094332915, 0.10446931647748192, 0.08572896401845775, 0.09796132493504506, 0.08167684932990593, 0.07959168222310942, 0.0707813854109327, 0.15881082676104852, 0.09672982587147161, 0.08221641147860825]}, "mutation_prompt": null}
{"id": "fb2096e4-b9af-4569-bf4d-a01fa758827f", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "86a75679-8dc8-4071-acaf-36818e9f9421", "solution": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increase population size\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.cognitive_coeff = 1.5  # Adjusted to reduce personal bias\n        self.social_coeff = 1.7  # Slightly increased for global influence\n        self.adaptive_scaling = 0.8  # More aggressive scaling\n        self.mutation_prob = 0.1  # Introduce mutation probability\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            mutation_mask = np.random.rand(self.population_size, self.dim) < self.mutation_prob\n            random_mutation = np.random.uniform(-1, 1, (self.population_size, self.dim))\n            positions = np.where(mutation_mask, positions + random_mutation, positions)\n            \n            if eval_count % (self.budget // 5) == 0:  # Adjust inertia dynamically\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.1\n                elite_position = positions[np.argmin(scores)]\n                positions = (positions + 2 * elite_position) / 3  # Refined elite influence\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "EnhancedParticleOptimizer", "description": "A modified particle optimization algorithm with enhanced convergence using dynamic inertia, mutation strategies, and elite utilization.", "configspace": "", "generation": 29, "fitness": 0.16877141856854222, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.19.", "error": "", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.2924828718557462, 0.29163502505329675, 0.29647241386235157, 0.3169570819754687, 0.295728911330118, 0.31357826236568187, 0.29809979696438893, 0.29004753402257766, 0.3281631010335231, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005709418771809971, 9.999999999998899e-05, 9.999999999998899e-05, 0.00624951485174241, 9.999999999998899e-05, 0.08003796413841158, 0.07846779908527857, 0.06617275949137968, 0.07331337884770806, 0.06264943150386248, 0.09648641458165785, 0.07657932992675065, 0.0842354841581302, 0.08084678409929202, 0.0762808735278857, 0.06881441346188988, 0.05507202083299123, 0.0669548405838597, 0.07385996114390547, 0.06906919864561512, 0.07458475650319052, 0.07026056970387162, 0.06776806856639417, 0.9896110228118922, 0.9923192710253107, 0.9933988305371655, 0.9864210641646686, 0.9824167461852538, 0.9890693975490091, 0.9891534844439415, 0.9913424458145152, 0.990936830554197, 0.1681670164633433, 0.1719012211873283, 0.16031211013110824, 0.15720128686903534, 0.18136470868621268, 0.1663740671781334, 0.18935915117494584, 0.1443199737118548, 0.17444811551457062, 0.2199042597470735, 0.18466785603686442, 0.17675074354719122, 0.21338198333355718, 0.1800293001742289, 0.19128823957333863, 0.21343815368840802, 0.25079033519837335, 0.20097252873122695, 0.11324756033142147, 0.08242387270613105, 0.13027417816833808, 0.08586547383391696, 0.1075015860186419, 0.046982756587833685, 0.08826145415346254, 0.05468522213521121, 0.0908384700925643, 0.0888112019611883, 0.06348617385383326, 0.08345435145397095, 0.09456936641637981, 0.10557822080849077, 0.09782226259421445, 0.07356456494973684, 9.999999999998899e-05, 0.10987773882145613, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.025816992828062935, 0.03995834046793589, 0.013184139208323176, 0.06931625487038706, 0.07348347786652354, 9.999999999998899e-05, 0.015384937000153864, 0.057101316260927515, 0.02077947216556897, 0.031240724437309852, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03345790713324681, 0.022156234483605153, 0.03510916017642374, 0.028115713539890952, 0.023358470252312524, 0.04890091148916531, 0.03934272686921869, 0.03214376967740118, 0.04302415393178094, 0.31302285300432564, 0.2950630342481404, 0.29982775965448105, 0.3017908378049585, 0.3076079175087091, 0.2831267473015544, 0.3152113882307169, 0.2922082259918105, 0.2891028948600737, 0.06937860251607597, 0.06406166476946962, 0.0789037883080066, 0.08436124060306716, 0.07071793083680966, 0.07895036670882982, 0.05740588589440754, 0.0644673546609914, 0.06754864690262019, 0.18524240470395836, 0.1752163344470482, 0.17125954068763583, 0.190743384388401, 0.1789381016020276, 0.17312179044930653, 0.14490283305468876, 0.18683123340169272, 0.13160429267425622, 0.23021712614036594, 0.22805422374451623, 0.20556464569616406, 0.22080412364204982, 0.1749066692794955, 0.21586286378406605, 0.21714941286347933, 0.2233232564709533, 0.22428954737000417, 0.1521643375281987, 0.1805700189620013, 0.1503843915955302, 0.12341599107238799, 0.16308593935238969, 0.15481843369738602, 0.1569453000688973, 0.17586883100228456, 0.18160780889063166, 0.1776738432967644, 0.14450326992742957, 0.1871889784411468, 0.18308595607842892, 0.17794562108011924, 0.20270805596677277, 0.1729134751526652, 0.16893470963115087, 0.16824623338983347, 0.17816670440177274, 0.16861168750540523, 0.17024167354450637, 0.17590771525928717, 0.17630209715152811, 0.17088429501959657, 0.1808983934521049, 0.16806624481064758, 0.17956887759867846, 0.40015217541065584, 0.28103368727049505, 0.1519402501639755, 0.32634448466020216, 0.18660808477240742, 0.193953011641953, 0.09892970258115197, 0.16910073284200478, 0.3478493279395508, 0.32758888302804434, 0.19205797502528044, 0.1109144934100077, 0.19535658153429236, 0.24373977638247957, 0.2600700418089935, 0.1816881786026957, 0.325454247723141, 0.1949746483764947, 0.18662878998192478, 0.18499896569945162, 0.18411060484985897, 0.17782498086814702, 0.19760011612465556, 0.19461936224240628, 0.2024583703807401, 0.18238247077675263, 0.19651903154321237, 0.06763609152431072, 0.071925756007995, 0.08085955444973492, 0.0755381440877716, 0.07717208171351464, 0.07192812769017765, 0.07927603943105244, 0.08127565996230224, 0.07498088974802464]}, "mutation_prompt": null}
{"id": "50ccd953-81f2-48e9-a489-44961ef0c137", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "d8d7a1f7-6c61-4437-9fd0-23ca902effd8", "solution": "import numpy as np\n\nclass EnhancedStochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Slight increase in population size\n        self.inertia_weight = 0.5  # Further reduced for faster convergence\n        self.cognitive_coeff = 1.8  # Slightly reduced for balance\n        self.social_coeff = 1.7  # Slightly increased for enhanced social influence\n        self.adaptive_scaling = 0.85  # Adjusted for better scaling dynamics\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Narrower velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            r3 = np.random.rand(self.population_size, self.dim)  # Additional random component for perturbation\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            perturbation = 0.1 * r3 * (np.random.randn(*positions.shape))  # Strategic noise\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component + perturbation\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "EnhancedStochasticAdaptiveParticleOptimizer", "description": "An enhanced stochastic adaptive particle optimizer with diversified velocity update and strategic perturbations to improve convergence speed.", "configspace": "", "generation": 31, "fitness": 0.23232714236280816, "feedback": "The algorithm EnhancedStochasticAdaptiveParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.22.", "error": "", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.48303455147919094, 0.47772771506858314, 0.488315352269018, 0.5111564239323494, 0.4697091247291373, 0.49993119792070206, 0.5067431153349793, 0.4857081630664055, 0.4923607453243265, 0.01476704439142873, 0.026128805425806756, 0.030464467248081717, 0.06355633326644128, 0.03825449236967238, 0.11186777708462137, 0.08794550348698904, 0.05906296847115977, 0.0932343326451075, 0.11300984195233232, 0.14215511825671323, 0.0722266060708393, 0.10755752458332701, 0.12101842204786895, 0.11647168427131216, 0.15360428093772338, 0.12666342164067623, 0.12413027728990345, 0.11553025256374183, 0.11112254904883612, 0.1355946158493, 0.11669701867583848, 0.10613987496679678, 0.1209680532449503, 0.11790409489247444, 0.10569241178182365, 0.14203077966821998, 0.9865063555845612, 0.9917332288646431, 0.9916548510212215, 0.9542828763369213, 0.9732079527057783, 0.9863727696729283, 0.9915819285045698, 0.9890320174101933, 0.9891460602893984, 0.3278400734373952, 0.33223349214793685, 0.3386918935966118, 0.3266824949404238, 0.3389194199203873, 0.3354868370434607, 0.34391681383338946, 0.33267357043120616, 0.34758524247419254, 0.6825448174226674, 0.7044545185287701, 0.2299855031769531, 0.28363005516478756, 0.20299954820384514, 0.21335917349440126, 0.23321295704348755, 0.23681443182041062, 0.6772346360836587, 0.171807280839833, 0.17736646922901478, 0.17311986980415717, 0.1797865976725539, 0.18060034619742205, 0.15268793643615242, 0.19025797237182251, 0.14298955681420444, 0.17621388881148792, 0.16503783093816782, 0.12095786307586909, 0.21734061568985574, 0.25016332369140126, 0.1910747299157618, 0.17936472620802213, 0.19943254581672076, 0.08162207709253144, 0.12434935279309933, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0020927704008231185, 0.012129271745886738, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.027085998176972992, 0.023619046348840267, 0.11932816755926501, 0.08574375606228257, 0.023135396926307283, 0.02780809040571386, 0.15783034058291212, 0.04608084742908647, 0.05288954830064685, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0020200918905837195, 9.999999999998899e-05, 9.999999999998899e-05, 0.013819458312014143, 0.05596919457543903, 0.05948892298701525, 0.12535126931033702, 0.07011567793172557, 0.06584506672410351, 0.08087744534631625, 0.10408408948064518, 0.1292065178892693, 0.08370290133758085, 0.4444006962941548, 0.4426878530266819, 0.4490851783080728, 0.4651117529126514, 0.452214428731723, 0.4326566352457031, 0.44485129490342856, 0.4562449862313628, 0.4572715069760055, 0.10268110356429938, 0.11342097815556695, 0.07696118458551193, 0.11948384295392334, 0.10811974952830916, 0.09936007364614141, 0.10711681372820092, 0.08811240181929703, 0.12131052520367847, 0.19999091385479695, 0.32279668012582086, 0.18051934904472544, 0.17859219045611896, 0.2979047763621252, 0.2187956212904404, 0.3376834810003998, 0.18782217538722512, 0.19832397365210241, 0.2497756789519503, 0.318889540820273, 0.3292125915250175, 0.22749327465595748, 0.31005681919689154, 0.3173025061049206, 0.31081594408645064, 0.31479680629114093, 0.3168995109517986, 0.1683650090925254, 0.25583801469340606, 0.20735833843126206, 0.18989297813468387, 0.15304053207937962, 0.2574340322382054, 0.22826203354274, 0.2692262659673912, 0.23775675078065572, 0.22273271356990498, 0.14732595959859973, 0.2197558199918691, 0.1911722744252916, 0.19780886979325807, 0.19374040081817057, 0.2247899677924503, 0.199230408573431, 0.19259536951496636, 0.24475332466997013, 0.27609336833663023, 0.20764385212884617, 0.24314530156855318, 0.22133035931165634, 0.22252768995380168, 0.19132903079482944, 0.19935304026644118, 0.221189926585873, 0.8123037123796659, 0.1495361903499186, 0.1542576570884947, 0.17345594580664436, 0.20172059479351734, 0.20076377801508138, 0.1316251861976081, 0.17050114345020828, 0.21367445124389062, 0.6269732935317105, 0.29305744911373044, 0.1685224159841502, 0.5623035932412281, 0.49616247786527123, 0.21327292450244784, 0.10529425445916063, 0.1052712861804268, 0.5369123743529144, 0.18124339083608676, 0.17726661439267244, 0.18670420084409667, 0.18131037108196202, 0.18296610576416028, 0.1962816163103448, 0.17991374564034235, 0.19417786631638378, 0.17101228568723004, 0.07773164109484298, 0.07774343761970781, 0.08086086180851104, 0.08110964050547698, 0.0828818982370032, 0.09525422189690957, 0.07975580810231697, 0.09806210398293735, 0.08625842592912081]}, "mutation_prompt": null}
{"id": "5199f127-8fa6-47e2-893f-3151bd4fb841", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 3)  # Slightly increased for diversity\n        self.initial_inertia_weight = 0.7  # Start with a higher inertia weight\n        self.final_inertia_weight = 0.4\n        self.cognitive_coeff = 1.8  # Adjusted for better personal exploration\n        self.social_coeff = 1.6\n        self.dynamic_scaling = 0.95  # Introduced dynamic scaling for velocities\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            inertia_weight = (self.final_inertia_weight + \n                              (self.initial_inertia_weight - self.final_inertia_weight) * \n                              (self.budget - eval_count) / self.budget)\n            \n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = inertia_weight * velocities + cognitive_component + social_component\n            velocities *= self.dynamic_scaling  # Dynamic velocity scaling\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                median_score = np.median(scores)\n                self.dynamic_scaling *= 0.98 if median_score > global_best_score else 1.02\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = positions + (elite_position - positions) * 0.5\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "EnhancedAdaptiveParticleOptimizer", "description": "A modified adaptive particle optimizer that enhances convergence by introducing a variable inertia weight, enhanced swarm diversity, and dynamic velocity scaling.", "configspace": "", "generation": 32, "fitness": 0.3069128842695716, "feedback": "The algorithm EnhancedAdaptiveParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.8895343919074784, 0.8937918967928047, 0.8824705731367012, 0.8995874383268001, 0.9036785148680917, 0.8880714133681971, 0.904767882597492, 0.9000570332849168, 0.8591891717573064, 9.999999999998899e-05, 0.7177768815539349, 9.999999999998899e-05, 0.7368598761355729, 0.04763275161335201, 9.999999999998899e-05, 0.7804240374041316, 0.77524790020509, 0.7621670869425444, 0.1529505183641655, 0.1561956078071648, 0.07623832543854081, 0.15871137882494435, 0.12895211802884787, 0.6440166252277271, 0.18086910647577414, 0.11319336292997972, 0.27844483775523554, 0.13114058537790663, 0.13800410093757454, 0.13486965598618494, 0.1427097769962853, 0.17356361459199776, 0.0937409576974002, 0.13002105620080406, 0.10663842521907141, 0.13241546758716372, 0.9913579812499191, 0.9909301973112998, 0.991323599098686, 0.9861617074807928, 0.9836101600231341, 0.9836237871823909, 0.990583484906886, 0.9892930334005071, 0.9913258269694802, 0.06003965946000189, 0.05923139534396982, 0.7233699585712552, 0.5808004973296612, 0.7616092035624167, 0.6162648118467193, 0.7596777116119748, 0.0882855973522847, 0.08761706045807782, 0.2280526867353051, 0.34425796952159615, 0.8159964576374684, 0.28066097888024555, 0.2740357872600765, 0.21204207060628155, 0.12428302154328685, 0.22353629062096614, 0.1497713765871973, 0.333257421104443, 0.21510813015999153, 0.21694722475436656, 0.2209408391906469, 0.20560500164444995, 0.27610069325060116, 0.1900728934791558, 0.3344783019281099, 0.22002491226622156, 0.22527145314642283, 0.01660811506527038, 0.22677258321895344, 0.23273006248170347, 0.25926488037897455, 0.21408761460368597, 0.11360753923518363, 0.13421281994953005, 0.07547800264365379, 9.999999999998899e-05, 0.029360403588355233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.060999411654994784, 9.999999999998899e-05, 9.999999999998899e-05, 0.05304958523685488, 0.0744362461826702, 0.10700208211534445, 0.06488372393100394, 0.010808162812854016, 0.018565254811552356, 0.15816252548733534, 0.05630122634852708, 0.07043782492302364, 0.04759020466798447, 9.999999999998899e-05, 0.09254093795320018, 0.07815675937315558, 0.0806371827846819, 0.07852061509693053, 0.31117343929976304, 0.1563857174010571, 0.07406973412031326, 0.18903368699855028, 0.043709546595170456, 0.3228840538160893, 0.1805176955472494, 0.25536165389043963, 0.3485838546339748, 0.05034339132599286, 0.0584435446547914, 0.0831492185036603, 0.583644866420379, 0.5406766643638994, 0.6343723830877799, 0.6109275076625102, 0.5877355780165816, 0.5452174950579172, 0.6132840409087446, 0.5519322188211875, 0.5868772521836676, 0.07855291919085883, 0.1611717711751156, 0.15531120316976776, 0.1335777236590362, 0.06906009610280728, 0.11265950245341405, 0.06870300653638683, 0.10695074251950498, 0.08658887366082801, 0.27253083130717237, 0.28465253950051417, 0.19916414481784628, 0.18631858586223593, 0.27561942921477234, 0.1713087475718903, 0.22452228687098397, 0.21420596765534705, 0.17570418688127887, 0.2910905170579179, 0.3678506872252778, 0.3870178024457075, 0.24824656018646618, 0.25606817951792926, 0.43993627529211177, 0.4897684783480801, 0.310560468492449, 0.6376929560738114, 0.1952428665083712, 0.33217981920549833, 0.32441713668746097, 0.2609582965554986, 0.21008372782838614, 0.16962063254274695, 0.2072882712636973, 0.2043497904563315, 0.2819566169404393, 0.2302835514975372, 0.15003809855654782, 0.21032040801344853, 0.18667260321977297, 0.19627189613485407, 0.20083265734077305, 0.20881594669980919, 0.21379880865369882, 0.2403194386203864, 0.20460408388528328, 0.7981414354266441, 0.22416817867695804, 0.22484518621282057, 0.24410802844020185, 0.2073117818369088, 0.21948906558856818, 0.20818649264865552, 0.20961057632837898, 0.9050234881409949, 0.1886684737673695, 0.15296625808687625, 0.9295909677868278, 0.20151426226549352, 0.2013386361290791, 0.1317597480576509, 0.17010267533585088, 0.9380501606452951, 0.7593497969223297, 0.15732193606254719, 0.6266543866012697, 0.30871557095347457, 0.696895791923267, 0.8416181815405663, 0.10530249243181711, 0.19506641121933255, 0.7946151361223615, 0.19823932823587442, 0.21981635514218234, 0.191522443944371, 0.2051002037470413, 0.20259751546534588, 0.20522985543167072, 0.18779704618807058, 0.22376687168500475, 0.19424619408913213, 0.11858687911420407, 0.09747977722691537, 0.08983611453028062, 0.08676113384023953, 0.08689811546355763, 0.09639493806989852, 0.11992963508799681, 0.08977835094888087, 0.08277912879260552]}, "mutation_prompt": null}
{"id": "93a2bea5-8ad5-416b-9686-bd67e45c68ef", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "585681f0-c321-4d74-b11e-cbd784dc4cc1", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "0371c0cb-8b75-4503-b0a7-de960860e67b", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.6  # Reduced for faster convergence\n        self.cognitive_coeff = 2.0  # Increased to emphasize personal best\n        self.social_coeff = 1.5\n        self.adaptive_scaling = 0.9  # New parameter for adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                median_score = np.median(scores)\n                self.inertia_weight *= self.adaptive_scaling if median_score > global_best_score else 1.0 / self.adaptive_scaling\n                top_elite_index = np.argmin(scores)\n                elite_position = positions[top_elite_index]\n                positions = (positions + elite_position) / 2\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "A stochastic adaptive particle optimization method that dynamically adjusts learning parameters and uses an elite-guided search strategy to enhance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.9100263311259822, 0.9221506175145884, 0.9050356756799348, 0.9083758016223796, 0.9187936890058882, 0.9148598124297931, 0.9214065456275129, 0.8979431960598758, 0.9079255377333113, 0.7868925807865743, 0.8008887489601377, 0.7667243997809374, 0.796104461661137, 0.048351527302036845, 0.8211118225291231, 0.679249531151601, 0.8110529425540208, 0.8235757608556881, 0.11698222079004117, 0.17758605264726723, 0.27934814463333224, 0.746206260606023, 0.13347516279351712, 0.806527006247294, 0.13408100824668323, 0.16041620247329424, 0.1549512964315023, 0.17848884971265366, 0.17527278173819427, 0.14595663741180775, 0.10064021525492484, 0.11700251665226058, 0.15884409283604806, 0.1304455839553027, 0.11918038857357338, 0.11131843040123823, 0.9910617556972255, 0.993150160254792, 0.988795149959955, 0.9878236100650324, 0.9882194014400625, 0.9856279167533747, 0.9885752758866323, 0.9881011633007761, 0.9904277182491317, 0.7810883583857536, 0.7726337884054544, 0.7753601367419292, 0.15322614618265418, 0.1539481625681819, 0.6716329068923708, 0.1278193503755396, 0.08908713752896635, 0.7674789100014415, 0.3985665022808089, 0.15686240951371822, 0.14101979353659355, 0.3489416490644016, 0.19366778935959872, 0.1923178898818334, 0.12635733853376663, 0.16722689939646573, 0.16048282940757586, 0.22490511289231518, 0.21380146257679733, 0.2114107155893188, 0.1339670147052493, 9.999999999998899e-05, 0.2363068873936287, 0.21571503449965135, 0.12500945966026922, 0.22614404129894172, 0.22517020259853793, 0.01682284544864887, 0.13502020615973975, 0.25521526575065345, 0.2033230090254059, 0.2205105806174502, 0.13428730328898764, 0.10428214113535028, 0.23721811244064717, 0.06911432112974403, 9.999999999998899e-05, 0.07149630973039534, 0.013146858884566792, 9.999999999998899e-05, 9.999999999998899e-05, 0.0040685040125058025, 9.999999999998899e-05, 0.13776117454499381, 0.12576113344105344, 0.03633783338744179, 0.04433679612170327, 0.09361411035909606, 0.013796678332362866, 0.04205577996216092, 0.12304336923472414, 0.05671439371739251, 0.03443035062045796, 0.05089356949133328, 9.999999999998899e-05, 0.08446761411383885, 0.0795031836692347, 0.09603198105422528, 0.10263505565784004, 0.17924786601096332, 0.270466091261898, 0.07734302726794173, 0.13424086751680275, 0.0441200178411737, 0.16585994486237032, 9.999999999998899e-05, 0.006648821473249744, 0.14598268063590658, 0.08347668369958006, 0.08354178652335742, 0.08705915614397619, 0.6131779914488631, 0.5842341153372912, 0.5955949646317366, 0.5829276276229545, 0.5417688384608721, 0.5471241198696075, 0.5793141703485656, 0.5798371142717815, 0.5937085128525903, 0.07668313798829918, 0.07170534077183255, 0.07654915883471547, 0.15897025264010756, 0.08312915335312887, 0.10597334345110576, 0.14221764129897752, 0.11427407514471344, 0.10840395706187156, 0.2448759151344424, 0.1898896303882378, 0.1864787306542175, 0.35385298907799856, 0.23745862887472102, 0.16556832636133823, 0.20572003089307023, 0.23852499920583825, 0.2760793748680055, 0.2954996934857156, 0.17674096845461096, 0.38549868135056253, 0.24749663705155467, 0.1931549512601094, 0.4921847363052574, 0.3947316275886872, 0.29706443520262005, 0.7848291871242628, 0.1541824910432259, 0.20338232833981995, 0.4926327555918293, 0.18983719894490292, 0.19592751581026902, 0.3172830249159909, 0.2426550897377241, 0.30511094962839946, 0.2302194452087294, 0.1952538279269984, 0.2380574603083383, 0.19550874704036036, 0.22500550197920666, 0.205294150738492, 0.2030097162688762, 0.23516517195171993, 0.21971082448779766, 0.2467996510129049, 0.18970004196486379, 0.2547376468792658, 0.20177565530959818, 0.22123648451971134, 0.20694102907242506, 0.20475608403567547, 0.22679851476650237, 0.2039798311269413, 0.2033519889464941, 0.8530943879125165, 0.1647244930686611, 0.15450524276478939, 0.17860811489599948, 0.20139636990296017, 0.2013863395066141, 0.8737437990552013, 0.17088574958887892, 0.9342608586524089, 0.08290860101444064, 0.15747420607834484, 0.19242188922161474, 0.21287862712145988, 0.7696485685062684, 0.21306379744741055, 0.10533609262299926, 0.832124069634159, 0.781693925765863, 0.19255970302970848, 0.19709471981067195, 0.20184559340918273, 0.20954303893592519, 0.1862517575417948, 0.2100256993444869, 0.20551222583564188, 0.19591326199078296, 0.19653528543180332, 0.09230248353367465, 0.10537296465363744, 0.1006664434892115, 0.09422534586604037, 0.09924674385592913, 0.0992610477491096, 0.10264509436554692, 0.10728640866766515, 0.09560638119388243]}, "mutation_prompt": null}
{"id": "e90bde8c-412e-43bd-8940-587d2561f647", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 36, "fitness": 0.3304703293497984, "feedback": "The algorithm StochasticAdaptiveParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "98bb48f6-ae24-4bd4-8828-ce244defa9ba", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "983c2ffd-eb2d-47e9-b97d-eba4cb25ec6e", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "18215a77-f883-404b-987a-b49ae857a27f", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "a5170992-d17f-4524-97a8-673398f3ae0c", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "0753ba65-be6e-4229-9800-dd27b16e82da", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "7c92e7b3-ac61-40d8-a719-34775284b201", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "d884c134-2b36-4393-9733-039082764595", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "094df8d3-9887-4fe9-a341-06409bd093d6", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "aee25506-c270-48b1-aa4e-cd4f846dd684", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "536c31f4-27f3-4125-83b4-d43d6bf2fe5a", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "44b0c345-6887-4d19-9ef9-8dd8849f68c0", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "0478c12b-7131-4404-887b-6347ef4def7c", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "93dc031a-a288-4f74-a897-4f2a2e21ea2b", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "8e5b4e00-cae8-46ff-93f8-56c4b7dc531e", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "74c6e41e-e1e1-40ce-b1b9-279b12258a7c", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "eb0627ad-f97e-4800-96d7-7e8cc161e291", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "89465d02-7f8b-4571-a416-9ae68c8c5cca", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "4aca0f40-fcb3-4b4a-880b-b3a6d1fe422c", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "7cb921d3-1bcd-4d5e-b79b-ae3a3a5889bd", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "60de46fb-62e9-40f1-a467-ad3ade7073ee", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "a079c762-4e69-4785-ac0e-72c1a039dd4e", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "9fd81edb-f32d-4225-93ac-ae084fdd0949", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "bae4f134-e267-4f2d-8093-a6e882b956cc", "solution": "import numpy as np\n\nclass StochasticAdaptiveParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(25, self.budget // 2)\n        self.inertia_weight = 0.7  # Adjust inertia to balance exploration/exploitation\n        self.cognitive_coeff = 1.8  # Tweaked coefficients for balanced personal/global search\n        self.social_coeff = 1.7\n        self.adaptive_scaling = 0.85  # Slightly more aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Reduced initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            # Velocity clamping to prevent explosions\n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 5) == 0:  # Adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Introduce perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n        return global_best_score, global_best_position", "name": "StochasticAdaptiveParticleOptimizer", "description": "An improved stochastic adaptive particle optimizer with dynamic velocity clamping and perturbation for enhanced convergence speed.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.8798358603219251, 0.8878132255776622, 0.8876461718076417, 0.8750019823291064, 0.8891803281336446, 0.8785862494606638, 0.8847839890572015, 0.8729789317751678, 0.8770257752415508, 0.6897089180666428, 0.6989155158097776, 0.6914413861889617, 0.6720916083668868, 0.718484587244131, 0.7174791453025007, 0.6437569241930756, 0.6610901185481606, 0.7112973556058353, 0.11882477569550265, 0.1611979117634028, 0.15724711489247234, 0.1808352198126678, 0.12747736379490415, 0.6028722643607345, 0.11595389908709874, 0.18788456843663748, 0.1226336576981032, 0.11627902753042141, 0.09676676275623908, 0.14515166312447236, 0.0967738402822812, 0.09985079474222347, 0.14376143002080932, 0.12048166877602962, 0.11663063982018462, 0.10963532294419143, 0.9613847294226016, 0.970594130555269, 0.9704591732049037, 0.9618298430232738, 0.9688772162012509, 0.9729848092311082, 0.9687003300315749, 0.9644235384252567, 0.9620701076539668, 0.6729374303488005, 0.731801055264303, 0.7044517119516417, 0.7275251478126985, 0.637760578363717, 0.6564533635691525, 0.676849552554172, 0.6911262425175241, 0.7082902909131376, 0.22802145843035748, 0.1414139719129489, 0.2297509027918483, 0.21616608837332052, 0.280510714139816, 0.21547288702615885, 0.17871691729724315, 0.23152804833253016, 0.1786198002421886, 0.20584350018083697, 0.20411295137853158, 0.20267372033666675, 0.2145310099258303, 0.13437670922965883, 0.2764821235011201, 0.3921356769743749, 0.20606296642716293, 0.19799909099359314, 0.1346434372395252, 0.22373931512717282, 0.21049020336184388, 0.21417777728121612, 0.19796830824666978, 0.13586013831188903, 0.25373489648766034, 0.25404479832244165, 0.24910601022082823, 0.00825266276783132, 0.006054904089826785, 0.21513327697055729, 0.050804923332084084, 0.018637262657747677, 0.04482859241837689, 0.006643977098470755, 0.008334402998045665, 0.07681313146308899, 0.20926623589973603, 0.065394215131372, 0.11950574123259572, 0.05105882753340196, 0.0017009137251652318, 0.019602479498055936, 0.19805615567102497, 0.07586782258055735, 0.08083343092006867, 0.21649227701188967, 0.18516101906822702, 0.10665803270326846, 0.07857899996379003, 0.19340423211214952, 0.14861589442441558, 0.10010912572965314, 0.20025848115088252, 0.07429666843051941, 0.13643986325993174, 0.17679661655863543, 0.11210785431457448, 0.08317367668989406, 0.10464742811019823, 0.2167950405987319, 0.08413661292601604, 0.13435311955289797, 0.0847403652745723, 0.5425721182895475, 0.5345654706307736, 0.5304034894924894, 0.5465022688004768, 0.5824176697918262, 0.6002960639946846, 0.5855805537595749, 0.5790114228877546, 0.5530588126140712, 0.09709801221367709, 0.09854703712156498, 0.13479582349878616, 0.0702778039506391, 0.08763114348632839, 0.14000300943420485, 0.11037687556824549, 0.16144753015089486, 0.08100008868991959, 0.4547427975893361, 0.16021901821458773, 0.4341901162984415, 0.3857102222192569, 0.2944149548412204, 0.3358084568316483, 0.38336616009740254, 0.22071551044862614, 0.24073928226882912, 0.517076372342113, 0.3792468867323512, 0.3576040512782288, 0.4495866881919969, 0.3604150154683424, 0.29344850807574974, 0.2604994227170473, 0.4272588768079233, 0.2134777618291549, 0.12238044570460915, 0.23336504551156523, 0.31566607870222363, 0.3575980058453836, 0.20350460076272014, 0.2903783468906548, 0.2535421059825598, 0.201595439686312, 0.24481868761024972, 0.24901779796056, 0.22110831731279534, 0.20737936194062256, 0.21487505423477138, 0.2621352695133432, 0.2361288428035302, 0.28094660308373454, 0.23482019267131637, 0.1939732439828934, 0.2268659265975812, 0.2004860671046247, 0.2542517796088941, 0.7022975718728235, 0.25028152140949356, 0.22314798381964007, 0.2258561072551527, 0.20560859133697684, 0.19608324436051539, 0.1267629930586729, 0.1266680717256926, 0.15398897366825404, 0.9443278824662068, 0.20170697157038764, 0.9361639092626041, 0.09986672091226478, 0.9227045581367432, 0.9330782245252007, 0.6624334511935233, 0.15715244761162195, 0.7622651441515769, 0.21222258192121668, 0.16929331713462814, 0.2133387669970661, 0.10520436250937604, 0.8034636170360684, 0.7489916504572016, 0.19871544277502606, 0.19573058296428403, 0.19961565870073883, 0.18873683778297268, 0.18517314715381994, 0.20562929005847774, 0.23966816834567983, 0.21702563607402325, 0.23712010899563207, 0.10629987565534049, 0.08087624102682944, 0.09049706039173322, 0.07859447761574301, 0.10848892248850694, 0.11337315048141972, 0.08203433224345136, 0.1048526284069532, 0.08967546828931594]}, "mutation_prompt": null}
{"id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 59, "fitness": 0.3490816234226132, "feedback": "The algorithm RefinedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.30.", "error": "", "parent_id": "e90bde8c-412e-43bd-8940-587d2561f647", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "8f3498aa-0e42-40cd-b507-44043a00626e", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "0dfe0af1-04f4-4511-ac0b-2c9c6c27092c", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "e75204b4-33b3-465d-b1cf-a54e30cd9a87", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "17d0552a-2b08-4711-bd64-61baaae89fdf", "solution": "import numpy as np\nimport chaotic_maps  # Assuming a library for generating chaotic sequences\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)\n        self.inertia_weight = 0.9  # Start with higher inertia and adapt non-linearly\n        self.inertia_weight_min = 0.4\n        self.cognitive_coeff = 2.0  # Slightly increased for stronger focus on individual learning\n        self.social_coeff = 1.3 \n        self.adaptive_scaling = 0.95\n\n    def __call__(self, func):\n        chaotic_sequence = chaotic_maps.logistic_map(self.population_size * self.dim, 3.9)  # Logistic map for diversity\n        positions = self.lower_bound + (self.upper_bound - self.lower_bound) * chaotic_sequence.reshape(self.population_size, self.dim)\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Expanded initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.2\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n\n            self.inertia_weight = max(self.inertia_weight_min, self.inertia_weight * self.adaptive_scaling)\n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "EnhancedParticleOptimizer", "description": "Enhanced Particle Swarm Optimizer with chaotic maps for initialization and non-linear inertia weight adaptation to improve convergence.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: ModuleNotFoundError(\"No module named 'chaotic_maps'\").", "error": "ModuleNotFoundError(\"No module named 'chaotic_maps'\")", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {}, "mutation_prompt": null}
{"id": "254c3a7d-abde-4729-b0d6-bbb6fd2cf0f6", "solution": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 3)  # Increased initial diversity\n        self.inertia_weight = 0.8  # Adaptive inertia for better exploration-exploitation balance\n        self.cognitive_coeff = 2.0  # Enhanced cognitive component for individual learning\n        self.social_coeff = 1.3  # Adjusted social factor for collective learning\n        self.adaptive_scaling = 0.95  # Smoother adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Broader initial velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.20  # Dynamic velocity clamp heightened\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 8) == 0:  # More frequent inertia adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                mutation = np.random.normal(0, 0.1, positions.shape)  # Slightly increased mutation for exploration\n                positions += mutation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "EnhancedParticleOptimizer", "description": "An enhanced particle swarm optimizer using adaptive inertia and mutation strategies for faster convergence.", "configspace": "", "generation": 64, "fitness": 0.2880924445746287, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.23.", "error": "", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.7025202349980719, 0.7273281803424397, 0.7282598554703812, 0.7460627079906424, 0.7455426373727984, 0.7485005334554939, 0.7427295763089334, 0.7282949073577123, 0.7377337271548654, 0.35744502869675576, 0.2294544117257391, 0.39115561870105153, 0.4229455485985486, 0.40019574557591764, 0.3511218511033636, 0.32567562456411936, 0.39101799262133263, 0.3788218327086448, 0.1679288122869369, 0.1620035726861344, 0.13812119597428374, 0.1355834019301061, 0.19630932094420783, 0.11821454925547004, 0.1348141473816895, 0.3924261385181398, 0.15458933534496244, 0.14457632892552197, 0.2646143759906979, 0.12697134555416956, 0.12794829302993582, 0.13325091850597437, 0.14693598292826282, 0.11729603055491211, 0.11261874387688053, 0.143270713463876, 0.9836779870687232, 0.982860044672943, 0.9824976009303047, 0.9756942428397556, 0.9809215435119717, 0.964489508232788, 0.983701741679845, 0.978136140345861, 0.9828647852441184, 0.3835236407780629, 0.43293731380276035, 0.474748176713674, 0.41091784148575206, 0.41034832825877554, 0.3450018299004436, 0.3929258110236691, 0.419582279913839, 0.38478682897147487, 0.6617156664691819, 0.22241919323045323, 0.47717505308619834, 0.2193496128952519, 0.25116987329376406, 0.2015932087616218, 0.1263721893980403, 0.22592725389818802, 0.25575219630177914, 0.2391180080450389, 0.12748387806141503, 0.16254099982706627, 0.1730973745269725, 0.2018989940024507, 0.12964758239187246, 0.18320911109532922, 0.11436626708369002, 0.17252860689890126, 0.1812232821907055, 0.13230554415001483, 0.17811334013230884, 0.18515022158394967, 0.17273979510554305, 0.1651346396298965, 0.17852506049654726, 0.20250740865795747, 0.20266700847713515, 0.03576068363988527, 0.00864979614548933, 0.005022414435841394, 0.00020541942542573466, 9.999999999998899e-05, 0.003665121601620913, 0.051431986278984154, 9.999999999998899e-05, 0.05020469500805502, 0.11627563940733121, 0.06998876429428436, 0.09830304513982624, 0.09879571887944016, 0.038235964726732186, 0.05089857181011126, 0.2085049478546439, 0.07559390559513612, 0.06947312017448315, 0.18803114137042143, 0.021012171888779685, 0.13114795814772262, 0.05657329415998247, 0.16924113025651133, 0.09081068262137904, 0.08113887429835864, 0.08131603893821993, 0.08715070675709669, 0.15453217649087492, 0.047017451038204316, 0.10724106829667546, 0.042319931504994246, 0.10601266121662689, 0.2655889103209016, 0.14222772220764057, 0.08147535174960341, 0.0811918128698188, 0.4688850401700677, 0.5068752745260312, 0.46944362930125116, 0.5178727065137338, 0.49458376158762063, 0.46821766151785504, 0.5137885594379803, 0.5251523942904688, 0.5030676962992984, 0.09864021527536493, 0.10091324826628356, 0.12941410597497338, 0.1080704879931258, 0.09191085663277876, 0.1440214689444287, 0.09668999080429452, 0.11486791535469243, 0.11201839914825507, 0.2839935028475896, 0.2185721524659432, 0.2132949190978598, 0.2407194973144413, 0.2525508817803961, 0.28428617889336116, 0.25677641769645565, 0.2377500768651697, 0.3444148212428054, 0.2339411171691158, 0.37486623571883504, 0.39230706197287313, 0.38931406804202806, 0.33186635559643207, 0.3909247845400754, 0.4064682602483193, 0.36378538404928096, 0.375988122922724, 0.1912432398935614, 0.23447767382467577, 0.20728165764159034, 0.2735239414410876, 0.22091208385000494, 0.22583636685541197, 0.2390222535919958, 0.29552925866287527, 0.23414146077715237, 0.19667908467175232, 0.21237273907854892, 0.21437227597122865, 0.22626163843341274, 0.22176033606185974, 0.22310017049384956, 0.24073658964709221, 0.23545400597894117, 0.2096559183536867, 0.22864860888506933, 0.45131706712824926, 0.4183303721070464, 0.38306811856774725, 0.35729012847522523, 0.2362707386355123, 0.21282166741039077, 0.24620693158154616, 0.4084938357897955, 0.865394110444817, 0.1780104379648455, 0.15410039579276036, 0.8448513112424401, 0.24967065536794453, 0.19899451546258007, 0.12195814551863582, 0.5058656497488987, 0.8380432809463129, 0.7327595358668699, 0.15589370530961877, 0.45362752938653084, 0.6561681550081158, 0.16962615272986548, 0.634039508220824, 0.5528467208665694, 0.16812756419531072, 0.1679072826723521, 0.18168730352610996, 0.18354278437887916, 0.1704035396568393, 0.17811977206875507, 0.19176704726184068, 0.23095243168608726, 0.21028055249680822, 0.1844797739040004, 0.18627521793738255, 0.11377603254859137, 0.09175754524596047, 0.09007933955303582, 0.0850818482767467, 0.09054897835599607, 0.0883845525713961, 0.11945370841710701, 0.0983427388463699, 0.08322367481496185]}, "mutation_prompt": null}
{"id": "72da85e6-64ec-49b9-b993-054432967b1a", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "e65abb15-80b6-4985-bdc1-dc12a34ced32", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "b53eb608-af90-407a-9d5c-67ffdbb7fd58", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "4699778d-c144-48b2-8478-48b96f1c5375", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "372f9608-8bf6-480a-a06c-c1e48e966553", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "7f9e9f4e-37f1-478c-affe-01e33071fe37", "solution": "import numpy as np\n\nclass EnhancedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(40, self.budget // 2)  # Increased population size for diversity\n        self.inertia_weight = 0.7  # Adjusted inertia weight for balance\n        self.cognitive_coeff = 2.0  # More emphasis on cognitive component\n        self.social_coeff = 1.8  # Slight increase for social component\n        self.adaptive_scaling = 0.85  # More frequent scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.4, 0.4, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.2  # Adjusted velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 6) == 0:  # Increased frequency of adaptation\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.1, positions.shape)  # Increased perturbation for exploration\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "EnhancedParticleOptimizer", "description": "Enhanced Particle Swarm Optimizer with non-linear inertia adaptation and stochastic velocity perturbations for improved convergence speed.", "configspace": "", "generation": 70, "fitness": 0.2915190326017967, "feedback": "The algorithm EnhancedParticleOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.7899823098558638, 0.7895759534353771, 0.7543876841322612, 0.8058469495082193, 0.7685071330353612, 0.7520183449385328, 0.748525706736091, 0.7543307095932907, 0.7828775766456557, 0.4468411932079813, 0.4779562893187994, 0.46232425626035156, 0.41544279961272856, 0.04467305644850861, 0.4670049079578301, 0.3765314345125651, 0.42957539327765426, 0.4856596254024842, 0.11669899515707094, 0.16507740169645657, 0.14486804221019922, 0.12110996938330687, 0.12019185540314647, 0.13475357495115947, 0.24069148644937843, 0.14967758076274207, 0.21127203141396356, 0.16072530644290273, 0.13325215776042987, 0.16880541171005026, 0.13949469896652134, 0.13908858653734624, 0.15908231634462067, 0.1211039359093462, 0.16997544392164254, 0.1367570244136137, 0.9782237209172345, 0.9777060775357933, 0.9783242840314013, 0.9753696319383048, 0.9743886136718195, 0.9748689104759481, 0.9783648897567286, 0.971713391005184, 0.9772271176116992, 0.4551256971780189, 0.37713541898571223, 0.059118256230135335, 0.3541059482369021, 0.4103743122152066, 0.36366907335557375, 0.1263254969933798, 0.39080087976085687, 0.40306957607060023, 0.6888094974547224, 0.29205154463296845, 0.255476421777737, 0.401989064047819, 0.2774855194470206, 0.20326577878005614, 0.46862275763288586, 0.7977259146478508, 0.8798442450252761, 0.24727199179136639, 0.22188798716329372, 0.17315892552613388, 0.17281220247390738, 0.171092902438421, 0.19249107193763182, 0.17671569162234357, 0.3149062687380426, 0.19341922041659032, 0.1796171893275541, 0.168993119538005, 0.1915422047739621, 0.16679517471543182, 0.2553751286745426, 0.1942669931756471, 0.2814326528364308, 0.313113696683602, 0.21948753504115592, 0.1066591867214236, 0.0105926455443347, 0.011409086783666145, 0.05989770461761312, 0.0005998797235584608, 9.999999999998899e-05, 0.07367697254810213, 0.06416629680963781, 0.0026807203566604487, 0.07506169719808709, 0.04487032502824018, 0.06164566419564599, 0.07496166585790454, 0.021539335794600434, 0.07608269803263956, 0.11296920602977623, 0.07052401458319402, 0.08526854515050841, 0.0914277294585929, 0.08976457800054338, 0.13952091950284684, 0.13969979991353887, 0.09190673486025802, 0.08932455244846493, 0.10518482792882333, 0.08420757777403709, 0.06133471875693264, 0.19326682884830348, 0.10044405348190377, 0.06608548123232139, 0.11330450081501808, 0.18853054431734184, 0.12302803497555648, 0.15216933412687517, 0.10343320390072619, 0.08217473775885686, 0.47112396625661224, 0.5095688704219736, 0.5073899635569652, 0.5330662935186199, 0.49358578187714197, 0.5232814259112795, 0.5101803313901112, 0.5173728799494384, 0.5253437692462362, 0.10463566768035759, 0.1527466354728153, 0.09764779028573978, 0.08854011727176281, 0.09589546898305834, 0.1525021088053654, 0.08635318642166023, 0.09196437557226456, 0.11597884143978499, 0.2304535443254596, 0.3278765615082794, 0.18243017764348535, 0.17141052145693503, 0.3065345605632277, 0.23901627227511946, 0.1579834932361961, 0.17235117519277443, 0.2994261894056476, 0.36998527694204, 0.2733801080503113, 0.31248484608059146, 0.39844468976377645, 0.35036916299853305, 0.286878580107931, 0.4207694170522863, 0.4003002304106479, 0.3436741670279849, 0.2486359217761338, 0.29219684247106903, 0.23573386274662778, 0.2485703374307413, 0.18713223963637415, 0.2632275201889174, 0.3295988872568154, 0.25938830512876276, 0.31119837531020134, 0.20868492835618502, 0.24804547903934904, 0.22311031581786334, 0.21604200107811067, 0.1861203766359627, 0.23842488372843507, 0.20383070455416819, 0.22139363533612266, 0.21398931418405132, 0.23116114355303252, 0.22166273226286415, 0.20080475559425703, 0.35891828266077264, 0.22783640631321833, 0.22129131036867944, 0.24052400332723123, 0.23321065569212096, 0.2396635070488764, 0.8549276070268321, 0.1767657990429341, 0.15325969550201135, 0.9087998705258441, 0.20038908383543064, 0.20021071296779103, 0.1426334610979516, 0.8637418186140089, 0.8848601569077861, 0.5713399548388147, 0.21288901002863447, 0.48374465602574135, 0.2110491015275321, 0.1700677149894333, 0.1547231505801976, 0.1050444012059858, 0.10376432489318654, 0.5584759313670294, 0.20096088294841652, 0.20438636228448182, 0.19041524133264343, 0.1827956074152589, 0.19398530825028848, 0.21178351978828647, 0.1926445871471255, 0.18752315840062628, 0.18288309706874895, 0.08711511853160414, 0.09339113754638928, 0.08533945378912489, 0.09260309052695415, 0.09278757511247748, 0.09065666331940314, 0.10350590994094777, 0.11551131936860182, 0.09403043995931015]}, "mutation_prompt": null}
{"id": "991100a1-714c-49b4-a5bc-e7fd91d9ef17", "solution": "import numpy as np\n\nclass EnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(40, self.budget // 2)  # Increased population size\n        self.inertia_weight = 0.7  # Adjusted inertia weight for exploration balance\n        self.cognitive_coeff = 1.4  \n        self.social_coeff = 1.6  # Slightly increased social coefficient\n        self.adaptive_scaling = 0.95  # Adjusted adaptive scaling\n        self.velocity_decay = 0.98  # New velocity decay factor\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Updated dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.velocity_decay * (self.inertia_weight * velocities + cognitive_component + social_component)\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 3) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.03, positions.shape)  # Lower perturbation\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n\n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "EnhancedPSO", "description": "A refined PSO with enhanced convergence by adaptive learning rates and self-organizing velocities.", "configspace": "", "generation": 71, "fitness": 0.32987091676399904, "feedback": "The algorithm EnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.8768856143965598, 0.8796310013373896, 0.8928093900219014, 0.8721444717053392, 0.8728849194229931, 0.8685424602339047, 0.8762724806773866, 0.8660567867390875, 0.8741232715231064, 0.7011422535586729, 0.6897859094072636, 0.6943577282471436, 0.6451769297652704, 0.6595864578334788, 0.699528370685, 0.6711479227594677, 0.6929148832745534, 0.6916500292938481, 0.12353543943198342, 0.14744076121002636, 0.18272012802735849, 0.15787265997593336, 0.14648681685017162, 0.11729379540463492, 0.12126150502261679, 0.15230984676874104, 0.1845409754620686, 0.10751167557574004, 0.1304854716123367, 0.12327758207437978, 0.11923944991584634, 0.08284714600627796, 0.09260625482641405, 0.09291058686615927, 0.10921694605817611, 0.10885679256727909, 0.9604686636646829, 0.959774002376239, 0.958202617756031, 0.9571422962392877, 0.9455915949458242, 0.9431769953267158, 0.9573136505338031, 0.95298513702389, 0.957084218210906, 0.701746008922522, 0.7534364052214815, 0.711592411855716, 0.7217176513198631, 0.7084790686568013, 0.6929068426886633, 0.6690670558788001, 0.7164519299477462, 0.7184031747121773, 0.3939303638213538, 0.22783644096409472, 0.22801363081022596, 0.27986442546758117, 0.38198878475910447, 0.22096813034145624, 0.2358534529833668, 0.1390970214017001, 0.18065248422151148, 0.2567106819253101, 0.169243091077676, 0.21526332917288438, 0.3143343900505877, 0.19122359530274635, 0.20266783399169752, 0.19833822903424914, 0.2910024050973, 0.13355478654074737, 0.19467237330872667, 0.12551199241600175, 0.12515682328106137, 0.13564926444448977, 0.2427160419081661, 0.26130405038989335, 0.26044495715294824, 0.2573702637979661, 0.2418138200791835, 0.07891682336455219, 0.006237133896675573, 0.06089469518550017, 0.04627781358419647, 9.999999999998899e-05, 9.999999999998899e-05, 0.053755060042739555, 9.999999999998899e-05, 0.09765512668385057, 0.14585097276412984, 0.09764048470482012, 0.08516934401766374, 0.06612156896823396, 0.04605840258096883, 0.0008763624833957318, 0.06098353482643293, 0.14046473118067493, 0.0611736790013816, 0.2743336002872049, 0.09929616932160401, 0.1319798628755645, 0.19457932380392662, 0.20260155317734574, 0.17170822781264938, 0.1390028544490326, 0.21996102855250754, 0.07137878183833524, 0.08445036925377791, 0.19027747677125229, 0.14260099284177596, 0.08370946477938579, 0.18871707622078382, 0.1095988500952031, 0.08302847545053005, 0.09524781378643743, 0.13222023491998736, 0.6082620830012606, 0.5244557401099351, 0.5403201215590039, 0.5531169480516036, 0.5625631641512712, 0.5373772647285773, 0.5696129205395742, 0.5951265898024347, 0.5659118864745519, 0.08676446669570792, 0.07726927345780987, 0.07396002200048313, 0.11083659829787162, 0.08026093142742319, 0.11252644726272232, 0.08839606340469963, 0.14368912997447314, 0.13350634898238334, 0.632949853939555, 0.18142234743326857, 0.184981880454683, 0.1928772264176698, 0.43459309661014967, 0.2641870595791167, 0.17109167911575263, 0.2052136057793018, 0.20589668388072324, 0.33810733281809924, 0.33293739767754094, 0.34850580802591546, 0.411176482579411, 0.5531387148685042, 0.47959218508208845, 0.2599890729133718, 0.45062858110322446, 0.2682896320491849, 0.21322204072434725, 0.31508689818318614, 0.2761151196531445, 0.3644356897284803, 0.24197953291600538, 0.30129447330836445, 0.21380170506381513, 0.3427310271558832, 0.1845257254310434, 0.21591570498592672, 0.19389215978772678, 0.2068044114587383, 0.20851632556423239, 0.18224308243314746, 0.23658688171619946, 0.23117211646459335, 0.2070426654392994, 0.22113868902891431, 0.188914425542682, 0.18928957337013108, 0.18964211938421205, 0.20776533884524784, 0.18970121502478277, 0.20993808093275867, 0.22614733052416702, 0.23007293385110128, 0.19954871572266253, 0.9158768542861874, 0.16768674946406303, 0.17773007740752522, 0.9430154344795366, 0.20098544419684672, 0.20011175600718478, 0.14279826008507568, 0.9282341516111677, 0.9269651142504065, 0.9058433509518118, 0.21382818639314938, 0.8571251275260904, 0.6904326008252379, 0.16932081290157275, 0.15458139713142105, 0.1050707609249173, 0.8070599593181905, 0.871367015133441, 0.2095511138874636, 0.22598907231941023, 0.18686821733504289, 0.19791887411219145, 0.18018191258650784, 0.2160259078106126, 0.2006393236711559, 0.19508107990909107, 0.23842369932885454, 0.1272029881032284, 0.09887403616946722, 0.0894232487107336, 0.10033935087332269, 0.10299858772573245, 0.1022966425635814, 0.09730734835527965, 0.08720039312647443, 0.07185955596745719]}, "mutation_prompt": null}
{"id": "a14293a3-d27c-48b4-85ae-0845ff1463f6", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "e92eee8e-8115-4365-ba19-33d8e42708a6", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "3b32bbe2-85d2-45d9-933b-f54a3f8299e8", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "8964f963-55ad-44b4-8149-5e6b7d40eabb", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "97dabcb6-1619-4d16-8646-40ec7c60ea2d", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "4312a1a2-62b5-4149-b5c4-645228ed02e5", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "bed9bc0d-6d13-4302-ac82-646f5abf09d6", "solution": "import numpy as np\n\nclass EnhancedParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)\n        self.inertia_weight = 0.5  # Further decreased inertia for more exploration\n        self.cognitive_coeff = 1.7  # Slightly increased for improved personal exploration\n        self.social_coeff = 1.3  # Slightly decreased to reduce premature convergence\n        self.adaptive_scaling = 0.92  # Adjusted scaling for robust adaptation\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.1  # Reduced dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 3) == 0:  # Adjusted frequency for adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.uniform(-0.05, 0.05, positions.shape)  # Uniform perturbation for exploration\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n\n            # Local search enhancement step\n            if eval_count % (self.budget // 5) == 0:\n                local_search_idx = np.random.randint(self.population_size)\n                candidate = positions[local_search_idx] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                candidate_score = func(candidate)\n                eval_count += 1\n                if candidate_score < personal_best_scores[local_search_idx]:\n                    personal_best_scores[local_search_idx] = candidate_score\n                    personal_best_positions[local_search_idx] = candidate\n                    if candidate_score < global_best_score:\n                        global_best_score = candidate_score\n                        global_best_position = candidate\n                \n        return global_best_score, global_best_position", "name": "EnhancedParticleSwarmOptimizer", "description": "Introducing local search and dynamic adaptive parameters in a refined PSO to enhance convergence speed.", "configspace": "", "generation": 78, "fitness": 0.3137159987954491, "feedback": "The algorithm EnhancedParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9464155438311779, 0.9463041072968528, 0.9423444966016196, 0.9375015662263884, 0.933878731170826, 0.9375101888280643, 0.9379057408005114, 0.9372134669587848, 0.9395085749705959, 0.40323506501172846, 0.30731911529351885, 0.8485381156390082, 0.8345657507241464, 0.8418042268746961, 0.7851510893248417, 0.8124790717164865, 0.3294690922905704, 0.26818104404661036, 0.09823440550595042, 0.13082566427537767, 0.1620052314551904, 0.12371182223440225, 0.13538482600074553, 0.11257387758568382, 0.14680133096197368, 0.14575989661587518, 0.14249134173957723, 0.11930521111679027, 0.11828389954011653, 0.0896586110571308, 0.09783554633824676, 0.12558965470309014, 0.11235258571097184, 0.09276513254177787, 0.08636771600453652, 0.11912857769125518, 0.9403251939933349, 0.9425867529103664, 0.8413689215610806, 0.7578196846916934, 0.9180645283372386, 0.8725692786682597, 0.9279418256240516, 0.7345011749411321, 0.879501901742776, 0.7441782410833477, 0.3778149890514185, 0.5166827280632929, 0.7975276749512188, 0.4133519024829253, 0.75165027415445, 0.8263573395715874, 0.17951746266307944, 0.5683513643207474, 0.30911002334163173, 0.1411368619328759, 0.17111838446366479, 0.22349278339614753, 0.19409674550048994, 0.222465387309692, 0.15218917645947527, 0.13144092068055035, 0.1792098370123314, 0.1957198641825224, 0.12669869676720025, 0.16874447295979844, 0.2891296474213444, 0.2711481675935201, 0.1785419973076523, 0.1687346013398675, 0.13429059910332686, 0.1812269746758851, 0.20432828207959486, 0.1992981970632901, 0.1361353015251474, 0.27674915710540804, 0.24593091341689155, 0.3615932806225305, 0.1503182774338624, 0.1281154508535126, 0.13191894266164128, 0.03564878145554884, 9.999999999998899e-05, 0.07479619129335313, 0.05767810619671887, 0.03641839715581685, 9.999999999998899e-05, 0.0573616877045493, 9.999999999998899e-05, 0.1778077808320917, 0.1248712308394917, 0.051510616503399276, 0.09279828373762211, 0.07143908555521217, 0.01789543930283488, 0.029655235737023777, 0.14701518684522985, 0.12284601255568073, 0.04425697877864965, 0.09347841755390307, 0.13552322414397278, 0.16065776961878786, 0.14065913232490856, 0.14081904767221565, 0.15353380459151156, 0.1812326315199675, 0.30043044329172586, 0.10539488422782628, 0.15835597636929633, 0.0789283899434382, 0.0718130111748907, 0.053757453182951775, 0.0067000227596690776, 0.11442915240403706, 0.10174519259967418, 0.29818215389141955, 0.10566417330377875, 0.5400439983247562, 0.624266165707111, 0.5685704127316151, 0.5620421740433549, 0.566163451961315, 0.6380551986796016, 0.5727429697853553, 0.6025685194893322, 0.6055907380160216, 0.09706400222469569, 0.0831871264377132, 0.08524534369975068, 0.1361580436856311, 0.08059660744598718, 0.08114857749742244, 0.11822488138136122, 0.10201973467389325, 0.08181841147444102, 0.22149250686104482, 0.15344520643466408, 0.31817850763749334, 0.2472383687083819, 0.16377892989690812, 0.2608613935138129, 0.1926875093017295, 0.21008997216338543, 0.40590700899694765, 0.1768899013549533, 0.3377445485897155, 0.2193733577340029, 0.3492129592921488, 0.38496019567607753, 0.21922662473652632, 0.1879455617239083, 0.5243562983956425, 0.2897953230531227, 0.23580428423046118, 0.16721898353004871, 0.2152116379660105, 0.34503108627371604, 0.17077421566797546, 0.3452744015332325, 0.12850339470630823, 0.21578780057083446, 0.2229488703965129, 0.22913010102849085, 0.25903924117914123, 0.19060732673456926, 0.22350917716732732, 0.23526490402642453, 0.20568066457990175, 0.24093859655993255, 0.25460624983936453, 0.21426272921884038, 0.17689043893566903, 0.19916374618923405, 0.1823918415445973, 0.19461803020832358, 0.1953587769648033, 0.21365211809678575, 0.22988940084154852, 0.18357249502420714, 0.19934569826445947, 0.9382625350803212, 0.1263420733325442, 0.14796729254426755, 0.9627252585087673, 0.2022090047600047, 0.9594956592101727, 0.9506929487337288, 0.9524985522541645, 0.9525739544729962, 0.6754989454228716, 0.15681134653279094, 0.7260494455153141, 0.6162146444544598, 0.16877620850141117, 0.6130792721392035, 0.400721708321634, 0.16897353610397292, 0.5220725310690637, 0.22517021010863525, 0.22138954662680843, 0.2083970455390386, 0.20086740863564378, 0.18922878977319602, 0.20216477068918615, 0.22690978017306507, 0.23676716613662208, 0.20900953302661573, 0.0688343054953301, 0.09356458826054026, 0.10558756689382576, 0.09998767904182682, 0.10682687663027013, 0.11223926391228811, 0.09494022515514922, 0.08258281846355497, 0.09905810891500955]}, "mutation_prompt": null}
{"id": "9e7475f0-8211-4e60-aaf1-e64fcaddfae3", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "60f71a63-8959-49dc-aec3-858e306f22f3", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "bdbfc92e-f26b-487e-9d62-61779a0244cc", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "0a2cc740-f13c-41c8-91a3-3121cf738048", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "07c8cec3-6dca-4ee6-b9bb-592de9cde287", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "1b0ab937-d8a8-4403-b135-2c1f1c660d96", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "3d81aa69-370c-4371-91c9-1005c545fd28", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "6f149f26-56a1-428e-817d-4ff4aa3b927b", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "db58bb84-5f33-49c2-885c-692a7c51cae5", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "81744b61-fc80-4dda-89a4-3e32809fd930", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "5233dd70-0928-474d-b727-a4d22a1b538c", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "b0016e7e-c18d-4125-a0ae-7a29ec9b8520", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "050a28ed-5c76-45c6-a205-d0f646dc3548", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "151ff76c-d56d-4b40-b8d2-2df70c022c5a", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "821f4940-4ec3-4d52-939d-0673fc09c5eb", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "d324e29d-b2b1-4e8a-a027-cac73026415a", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "772a2e32-48d2-47f0-b954-42c16ead0472", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "7bbca904-de15-47de-8633-899a092888b8", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "357af69b-e48f-471c-9d74-12782aa148c4", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "57417785-6452-4002-ade8-095aae08e072", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}
{"id": "e8b47b6d-0d02-4b8e-9fb0-912187480b48", "solution": "import numpy as np\n\nclass RefinedParticleOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = min(30, self.budget // 2)  # Increased population size for better diversity\n        self.inertia_weight = 0.6  # Decreased inertia weight for faster convergence\n        self.cognitive_coeff = 1.5  \n        self.social_coeff = 1.5  # Adjusted coefficients for more balanced search\n        self.adaptive_scaling = 0.9  # More aggressive adaptive scaling\n\n    def __call__(self, func):\n        positions = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.3, 0.3, (self.population_size, self.dim))  # Reduced velocity range\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        \n        scores = np.array([func(pos) for pos in positions])\n        eval_count = self.population_size\n        \n        global_best_index = np.argmin(scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n        global_best_score = scores[global_best_index]\n        \n        personal_better_mask = scores < personal_best_scores\n        personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n        personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n\n        velocity_clamp = (self.upper_bound - self.lower_bound) * 0.15  # Adjusted dynamic velocity clamp\n\n        while eval_count < self.budget:\n            r1 = np.random.rand(self.population_size, self.dim)\n            r2 = np.random.rand(self.population_size, self.dim)\n            cognitive_component = self.cognitive_coeff * r1 * (personal_best_positions - positions)\n            social_component = self.social_coeff * r2 * (global_best_position - positions)\n            velocities = self.inertia_weight * velocities + cognitive_component + social_component\n            \n            velocities = np.clip(velocities, -velocity_clamp, velocity_clamp)\n            positions += velocities\n            \n            if eval_count % (self.budget // 4) == 0:  # More frequent adaptive adjustment\n                self.inertia_weight *= self.adaptive_scaling\n                perturbation = np.random.normal(0, 0.05, positions.shape)  # Lower perturbation for fine-tuning\n                positions += perturbation\n            \n            positions = np.clip(positions, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(pos) for pos in positions])\n            eval_count += self.population_size\n            \n            personal_better_mask = scores < personal_best_scores\n            personal_best_scores[personal_better_mask] = scores[personal_better_mask]\n            personal_best_positions[personal_better_mask] = positions[personal_better_mask]\n            \n            current_global_best_index = np.argmin(personal_best_scores)\n            current_global_best_score = personal_best_scores[current_global_best_index]\n            if current_global_best_score < global_best_score:\n                global_best_score = current_global_best_score\n                global_best_position = np.copy(personal_best_positions[current_global_best_index])\n                \n        return global_best_score, global_best_position", "name": "RefinedParticleOptimizer", "description": "A refined particle swarm optimizer with dynamic acceleration coefficients and adaptive neighborhood-based velocity adjustment for improved convergence.", "configspace": "", "generation": 60, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "19363b03-75a4-4d76-8557-0fb51cf2e6c0", "metadata": {"aucs": [0.9234905746467763, 0.9247910977077087, 0.9271473036544184, 0.9189940210261363, 0.9237219876225518, 0.9203993981198124, 0.9239786955909927, 0.9236240462568802, 0.9281727198024574, 0.7687381179661611, 0.7747388401589748, 0.7760952165314896, 0.8288442141710551, 0.818564929431878, 0.8133887177746292, 0.7551991746384847, 0.8123719358807132, 0.7827612027253623, 0.15792321851163993, 0.16419916593930706, 0.18868118354189023, 0.10128262539564747, 0.16103249967411215, 0.12475796929235272, 0.08995240553437689, 0.19168272317168522, 0.16227935456621145, 0.09584799039346092, 0.11226897315048068, 0.12484352117504205, 0.12480275845252253, 0.1042562139925245, 0.16021775448351416, 0.1629374639450747, 0.09748704232136729, 0.11659074642357514, 0.9780943528196917, 0.9728122882304635, 0.9750297222635917, 0.9654557691952415, 0.9700971557652285, 0.9492663226764099, 0.9786119434515324, 0.9702105401668445, 0.9728509122091447, 0.8276296602174511, 0.8118639613663315, 0.7862271377192288, 0.8374067746061736, 0.7837545810050545, 0.8110565832123257, 0.7968869059978162, 0.1545138978347521, 0.8031052703117074, 0.24753052205895365, 0.22134801873914045, 0.16411226616881935, 0.22225821889019926, 0.28190703174061305, 0.21129844452896562, 0.2428161532740769, 0.2369360687683385, 0.23676266107091182, 0.21335236543657843, 0.2609899290251352, 0.2056905536478989, 0.2606441496968507, 0.23315835810067598, 0.34313249692322656, 0.22690557425072877, 0.134017828552091, 0.2456405011289, 0.24740285494474734, 0.24962061123041757, 0.13641267410637736, 0.13558673968611057, 0.2579990624895996, 0.2510394043695806, 0.1280535155359115, 0.2668967398642115, 0.16053072066400675, 0.0015581996148638089, 0.09048044894448815, 0.011042766928239467, 0.05211337518767545, 0.005179140531957116, 9.999999999998899e-05, 0.01019970055783781, 9.999999999998899e-05, 0.1337901816026631, 0.13632754111010692, 0.06559481246577781, 0.12064257619897412, 0.07001694904283251, 0.027079253729730968, 0.007200954021186923, 0.12831523957142876, 0.09543388035154055, 0.0362093703877574, 0.13361474261882889, 0.04107113929556139, 0.19892025437016003, 0.31990594724939536, 0.12217024307279156, 0.2410146420948136, 0.2982195464715953, 0.1328565193244129, 0.0761817724451026, 0.1295718305507546, 0.08628336260492431, 0.0641171458992782, 0.07215256638185275, 0.14986661164579196, 0.14944375259043896, 0.0850133815825187, 0.13186510158751008, 0.08531038296582738, 0.5558871708531303, 0.5881957500351946, 0.5595189583941202, 0.5618728726184432, 0.5851803523275643, 0.6125786058985262, 0.6123807614180228, 0.5901387119707127, 0.5704795094088558, 0.11207709779740649, 0.11195051508613196, 0.19120204519729622, 0.1484082793572763, 0.10537072131228975, 0.10240823371477781, 0.08988910001713013, 0.12573735749379522, 0.08732603656925586, 0.2766640296393602, 0.2332366387233621, 0.45101076352816527, 0.1860192087603625, 0.4255126914036639, 0.3346655830252162, 0.20657959139941995, 0.49620491082059826, 0.29717809483336854, 0.3284666052171694, 0.29784051935546596, 0.5138379242084169, 0.39925489568734196, 0.273325712550186, 0.3058517519921444, 0.2732163479708114, 0.5921003729466756, 0.21107620981168196, 0.2249950670073364, 0.2242984394762476, 0.25740516939423963, 0.3247093124155829, 0.24062413757510592, 0.3683663440614011, 0.18860232704803825, 0.30410432711384894, 0.23642745932489773, 0.2613508744865324, 0.21814920187234543, 0.2553756875701927, 0.27045833714337, 0.23861575051158457, 0.24926554330599837, 0.2537335158168247, 0.24237766665173532, 0.2730287930008013, 0.1824559118707305, 0.20381744954430847, 0.19393308303398094, 0.1946262211726124, 0.19862633515643824, 0.227395345546356, 0.1916893689680098, 0.18437810200857652, 0.19930835190631657, 0.948125496520805, 0.12676249411502738, 0.18854074994856618, 0.9510708553742536, 0.20196300079584018, 0.9448806831624486, 0.12282368175779534, 0.9470724001454487, 0.960160487396827, 0.8271288712943669, 0.15758322478649223, 0.8714777847540649, 0.915118458533596, 0.16947283669001867, 0.805851625081892, 0.8308886768578682, 0.16874969667343032, 0.8229205875967924, 0.20713349455564878, 0.2019527729609133, 0.2001021870847507, 0.22942310529830667, 0.19713164874712463, 0.20893321249358365, 0.24220779153640537, 0.19729173601894412, 0.21642132306659, 0.10762652288906882, 0.09858084676622059, 0.0946008222498258, 0.10264457669925309, 0.09140977075105006, 0.09111800210202559, 0.17404628065205985, 0.09532684444764183, 0.10237967454080732]}, "mutation_prompt": null}

{"id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 0, "fitness": 0.4621309054160245, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.46 with standard deviation 0.29.", "error": "", "parent_id": null, "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "c8f83666-c0aa-4ddf-8df4-39b6c6bdab4f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "01a7ec71-1e89-4a3e-bb40-8311bb27c915", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "c7f33577-1786-430f-a8e9-f17921681b0f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "91191778-c98e-48a0-a430-b82c83e5dacf", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "98d9e8ab-c871-4ee5-8263-5a99e14835ba", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "34211ae5-c761-4a39-8e68-82f52193bf6e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "c088f76e-3057-4d12-81cd-2d819971fa75", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "2ed6d388-e351-479d-a932-df8072018d1b", "solution": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1_init, self.c2_init = 1.5, 1.5\n        self.w_init, self.w_min = 0.9, 0.4  # Adaptive inertia\n        self.f_init = 0.8\n        self.cr_init = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            progress = eval_count / self.budget\n            c1 = self.c1_init - progress * 0.5\n            c2 = self.c2_init + progress * 0.5\n            w = self.w_init - progress * (self.w_init - self.w_min)\n\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - pop) +\n                          c2 * r2 * (global_best_position - pop))\n            pop = np.clip(pop + velocities, self.lower_bound, self.upper_bound)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f_init * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.where(np.random.rand(self.dim) < self.cr_init, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "AdaptiveHybridPSODE", "description": "An adaptive hybrid PSO-DE variant utilizing dynamic parameter tuning and local search intensification to better balance exploration and exploitation across complex fitness landscapes.", "configspace": "", "generation": 8, "fitness": 0.39956764367066916, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.25.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.745648961179021, 0.745648961179021, 0.745648961179021, 0.7465886971182027, 0.7465886971182027, 0.7465886971182027, 0.717418046688088, 0.717418046688088, 0.717418046688088, 0.5271763537611606, 0.5271763537611606, 0.5271763537611606, 0.5359162415204081, 0.5359162415204081, 0.5359162415204081, 0.5594141056586805, 0.5594141056586805, 0.5594141056586805, 0.1345525994473009, 0.1345525994473009, 0.1345525994473009, 0.10732634801968655, 0.10732634801968655, 0.10732634801968655, 0.1284923533355843, 0.1284923533355843, 0.1284923533355843, 0.12780924955513095, 0.12780924955513095, 0.12780924955513095, 0.12075962380757155, 0.12075962380757155, 0.12075962380757155, 0.1117990008235975, 0.1117990008235975, 0.1117990008235975, 0.9868106268011169, 0.9868106268011169, 0.9868106268011169, 0.985885477785211, 0.985885477785211, 0.985885477785211, 0.9828810112487475, 0.9828810112487475, 0.9828810112487475, 0.5898808415103862, 0.5898808415103862, 0.5898808415103862, 0.5831657068262366, 0.5831657068262366, 0.5831657068262366, 0.5816747742154816, 0.5816747742154816, 0.5816747742154816, 0.8132130355668515, 0.8132130355668515, 0.8132130355668515, 0.7998621767928531, 0.7998621767928531, 0.7998621767928531, 0.723517270075118, 0.723517270075118, 0.723517270075118, 0.499173653027178, 0.499173653027178, 0.499173653027178, 0.5050212843104039, 0.5050212843104039, 0.5050212843104039, 0.4959915459435599, 0.4959915459435599, 0.4959915459435599, 0.5104085742419316, 0.5104085742419316, 0.5104085742419316, 0.44914504649754994, 0.44914504649754994, 0.44914504649754994, 0.46157206199866396, 0.46157206199866396, 0.46157206199866396, 0.4798430692999699, 0.4798430692999699, 0.4798430692999699, 0.47417077954344444, 0.47417077954344444, 0.47417077954344444, 0.4788892194721902, 0.4788892194721902, 0.4788892194721902, 0.5915623105958592, 0.5915623105958592, 0.5915623105958592, 0.5552829059625088, 0.5552829059625088, 0.5552829059625088, 0.5446542140199456, 0.5446542140199456, 0.5446542140199456, 0.3030314937477181, 0.3030314937477181, 0.3030314937477181, 0.36544873535337263, 0.36544873535337263, 0.36544873535337263, 0.1719578199182048, 0.1719578199182048, 0.1719578199182048, 0.010732777520783054, 0.010732777520783054, 0.010732777520783054, 0.3523205657236883, 0.3523205657236883, 0.3523205657236883, 0.34657381137421794, 0.34657381137421794, 0.34657381137421794, 0.6928546828010006, 0.6928546828010006, 0.6928546828010006, 0.2084032142814921, 0.2084032142814921, 0.2084032142814921, 0.692098813049979, 0.692098813049979, 0.692098813049979, 0.10231524279829995, 0.10231524279829995, 0.10231524279829995, 0.1266924083725558, 0.1266924083725558, 0.1266924083725558, 0.1437618479543118, 0.1437618479543118, 0.1437618479543118, 0.19232666610304427, 0.19232666610304427, 0.19232666610304427, 0.15428763766317466, 0.15428763766317466, 0.15428763766317466, 0.18940731243075792, 0.18940731243075792, 0.18940731243075792, 0.5342721688827448, 0.5342721688827448, 0.5342721688827448, 0.42965776989009696, 0.42965776989009696, 0.42965776989009696, 0.4014247787424675, 0.4014247787424675, 0.4014247787424675, 0.35248758707757655, 0.35248758707757655, 0.35248758707757655, 0.36304876400897623, 0.36304876400897623, 0.36304876400897623, 0.3493428131661376, 0.3493428131661376, 0.3493428131661376, 0.23174682127287582, 0.23174682127287582, 0.23174682127287582, 0.22841567501817817, 0.22841567501817817, 0.22841567501817817, 0.22955924673672157, 0.22955924673672157, 0.22955924673672157, 0.1989557085767727, 0.1989557085767727, 0.1989557085767727, 0.2315363096639097, 0.2315363096639097, 0.2315363096639097, 0.18457737009019037, 0.18457737009019037, 0.18457737009019037, 0.8399645220996547, 0.8399645220996547, 0.8399645220996547, 0.12972239149800247, 0.12972239149800247, 0.12972239149800247, 0.7772557015489532, 0.7772557015489532, 0.7772557015489532, 0.16829935421019893, 0.16829935421019893, 0.16829935421019893, 0.20268549494432553, 0.20268549494432553, 0.20268549494432553, 0.20330963004250202, 0.20330963004250202, 0.20330963004250202, 0.2786528281438999, 0.2786528281438999, 0.2786528281438999, 0.21181430410249602, 0.21181430410249602, 0.21181430410249602, 0.23095125765355884, 0.23095125765355884, 0.23095125765355884, 0.1054476099589372, 0.1054476099589372, 0.1054476099589372, 0.09098947278312897, 0.09098947278312897, 0.09098947278312897, 0.08703256843363305, 0.08703256843363305, 0.08703256843363305]}, "mutation_prompt": null}
{"id": "fda73863-34be-4648-8fff-d52994a39eef", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "5cf85e07-f287-433e-b2c4-ebee449d9bd7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "6f1c0ae9-0332-4312-900f-d841056a3137", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "e404a95a-3893-4c83-84e9-14389496e90b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "6182b465-8730-4658-a7bd-a7ab84efe6ec", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "71347a47-ada9-4fc5-9adb-e55c394b615d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "07e62e4a-5873-4b8e-b72d-4ee02ff1ad90", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "a1e744d2-15c3-4893-9d49-3fd57beffe8c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "e5e339c2-0210-4781-ae21-ee1cc80fe803", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "b8122532-79d4-4e9f-87e9-ae34664d2876", "solution": "import numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\n\nclass ImprovedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.f = 0.8\n        self.cr = 0.9\n        self.surrogate = RandomForestRegressor(n_estimators=10)\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Train surrogate model\n            self.surrogate.fit(pop, personal_best_scores)\n\n            # Adaptive PSO Update\n            self.w = 0.5 + np.random.rand() / 2  # Modify inertia weight dynamically\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population using surrogate predictions\n            surrogate_scores = self.surrogate.predict(pop)\n            eval_count += self.pop_size\n\n            # Update personal bests using surrogate scores\n            better_mask = surrogate_scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, surrogate_scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n\n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "ImprovedHybridPSODE", "description": "Improved HybridPSODE with adaptive parameters and random forest surrogate to balance exploration-exploitation efficiently.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ModuleNotFoundError(\"No module named 'sklearn'\").", "error": "ModuleNotFoundError(\"No module named 'sklearn'\")", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {}, "mutation_prompt": null}
{"id": "9b99d30e-ce34-4341-98e8-c96682dd5522", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "cd51633b-7cc5-456d-a079-fbb01be47e5c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "31acca60-c416-4347-b5ce-f2c9e9bab9c9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "45c211f1-b1e7-42dc-8870-864194044841", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "1d8e52e4-ecb7-46ca-ab6e-c1bf2fbb01a7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "cf76d14d-4e24-45a0-a2f8-960f737740cb", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "35aef55b-5504-4780-ae5c-8eb452f279fb", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "420374e4-c92d-4972-9b96-a830936e417c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "4ade35c2-c8d0-42ed-a369-ca1b50b3c338", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "0ac72e36-5da4-4406-8e71-7a4bde337ab9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "932bafd5-54f0-4e22-95d2-c433cb6cf0da", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "c291b01b-d832-4006-b43d-acaf2043e5b8", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1 = 1.2  # Reduced cognitive coefficient\n        self.c2 = 1.8  # Increased social coefficient\n        self.w_min = 0.4  # Adaptive inertia weight minimum\n        self.w_max = 0.9  # Adaptive inertia weight maximum\n        self.f = 0.8\n        self.cr = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            inertia_weight = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            r1, r2 = np.random.rand(2)\n            velocities = (inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Leader selection for DE\n            selected_leader_idx = np.random.choice(np.arange(self.pop_size), p=personal_best_scores / personal_best_scores.sum())\n            leader_position = personal_best_positions[selected_leader_idx]\n\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = leader_position + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive mechanisms and leader selection for improved diversity and convergence.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('probabilities are not non-negative').", "error": "ValueError('probabilities are not non-negative')", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {}, "mutation_prompt": null}
{"id": "1cb36dd2-f5a2-490c-b541-94d6edaccabb", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "cace612d-9c3c-4a34-9cce-785c3a981e3a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "9d14f00c-0965-4321-8d9c-b5ab65f2abb9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "9649b731-1e66-420e-a23d-415f491ad2c9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            w = self.w_max - ((self.w_max - self.w_min) * eval_count / self.budget)\n            \n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introducing an adaptive inertia weight in HybridPSODE to balance exploration and exploitation dynamically based on the convergence progress, enhancing performance across diverse optimization tasks.", "configspace": "", "generation": 34, "fitness": 0.40006617918508, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.24.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7320635196697547, 0.7320635196697547, 0.7320635196697547, 0.7149050605241551, 0.7149050605241551, 0.7149050605241551, 0.6991681008717469, 0.6991681008717469, 0.6991681008717469, 0.5401296845839507, 0.5401296845839507, 0.5401296845839507, 0.5082322974680907, 0.5082322974680907, 0.5082322974680907, 0.5268206530767674, 0.5268206530767674, 0.5268206530767674, 0.15264491377403688, 0.15264491377403688, 0.15264491377403688, 0.14670972268528093, 0.14670972268528093, 0.14670972268528093, 0.12356932226367878, 0.12356932226367878, 0.12356932226367878, 0.10403179877749857, 0.10403179877749857, 0.10403179877749857, 0.09284002136628333, 0.09284002136628333, 0.09284002136628333, 0.11972768997839067, 0.11972768997839067, 0.11972768997839067, 0.9868103531951011, 0.9868103531951011, 0.9868103531951011, 0.9858852739855981, 0.9858852739855981, 0.9858852739855981, 0.9828791162675301, 0.9828791162675301, 0.9828791162675301, 0.5715025368036317, 0.5715025368036317, 0.5715025368036317, 0.5555380996015296, 0.5555380996015296, 0.5555380996015296, 0.5336521142201651, 0.5336521142201651, 0.5336521142201651, 0.6729357322282348, 0.6729357322282348, 0.6729357322282348, 0.7382786070055004, 0.7382786070055004, 0.7382786070055004, 0.7238205033928382, 0.7238205033928382, 0.7238205033928382, 0.5254520377064242, 0.5254520377064242, 0.5254520377064242, 0.12323320507888713, 0.12323320507888713, 0.12323320507888713, 0.5052355199818236, 0.5052355199818236, 0.5052355199818236, 0.5516155176471598, 0.5516155176471598, 0.5516155176471598, 0.5368608687760271, 0.5368608687760271, 0.5368608687760271, 0.4474499597321775, 0.4474499597321775, 0.4474499597321775, 0.4183346838991653, 0.4183346838991653, 0.4183346838991653, 0.46684453530386183, 0.46684453530386183, 0.46684453530386183, 0.45457001033420363, 0.45457001033420363, 0.45457001033420363, 0.5331792441225913, 0.5331792441225913, 0.5331792441225913, 0.5273844509679024, 0.5273844509679024, 0.5273844509679024, 0.529735241336067, 0.529735241336067, 0.529735241336067, 0.2320828373859637, 0.2320828373859637, 0.2320828373859637, 0.22952751087174184, 0.22952751087174184, 0.22952751087174184, 0.11365565262817057, 0.11365565262817057, 0.11365565262817057, 0.010972932415001524, 0.010972932415001524, 0.010972932415001524, 0.34246336993120763, 0.34246336993120763, 0.34246336993120763, 0.3987274678076884, 0.3987274678076884, 0.3987274678076884, 0.6510803237305339, 0.6510803237305339, 0.6510803237305339, 0.20838825495869895, 0.20838825495869895, 0.20838825495869895, 0.6784245612470493, 0.6784245612470493, 0.6784245612470493, 0.15879312147208635, 0.15879312147208635, 0.15879312147208635, 0.4703110837654665, 0.4703110837654665, 0.4703110837654665, 0.12732837185477786, 0.12732837185477786, 0.12732837185477786, 0.2392456866541074, 0.2392456866541074, 0.2392456866541074, 0.47405118698198434, 0.47405118698198434, 0.47405118698198434, 0.5606841326278047, 0.5606841326278047, 0.5606841326278047, 0.45722822312867406, 0.45722822312867406, 0.45722822312867406, 0.38810575282897075, 0.38810575282897075, 0.38810575282897075, 0.40491882522337097, 0.40491882522337097, 0.40491882522337097, 0.3457145599182364, 0.3457145599182364, 0.3457145599182364, 0.3436183367502653, 0.3436183367502653, 0.3436183367502653, 0.3549154826302505, 0.3549154826302505, 0.3549154826302505, 0.2172519120174654, 0.2172519120174654, 0.2172519120174654, 0.1940853287156742, 0.1940853287156742, 0.1940853287156742, 0.20789986482328326, 0.20789986482328326, 0.20789986482328326, 0.22041448741424452, 0.22041448741424452, 0.22041448741424452, 0.20165587693542053, 0.20165587693542053, 0.20165587693542053, 0.5105138863543482, 0.5105138863543482, 0.5105138863543482, 0.8392423893156884, 0.8392423893156884, 0.8392423893156884, 0.1910003530555675, 0.1910003530555675, 0.1910003530555675, 0.7463155617395075, 0.7463155617395075, 0.7463155617395075, 0.16787934194036058, 0.16787934194036058, 0.16787934194036058, 0.2032892157059455, 0.2032892157059455, 0.2032892157059455, 0.20188795402506898, 0.20188795402506898, 0.20188795402506898, 0.22343389005341519, 0.22343389005341519, 0.22343389005341519, 0.20176007269233998, 0.20176007269233998, 0.20176007269233998, 0.18006088094350148, 0.18006088094350148, 0.18006088094350148, 0.08798600486888952, 0.08798600486888952, 0.08798600486888952, 0.09924904000616608, 0.09924904000616608, 0.09924904000616608, 0.08856076928077206, 0.08856076928077206, 0.08856076928077206]}, "mutation_prompt": null}
{"id": "afa5ffdc-ef25-4c52-96ce-7cb2ade1029b", "solution": "import numpy as np\n\nclass DynamicHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Dynamic inertia weight adjustment\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n\n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "DynamicHybridPSODE", "description": "A dynamic inertia-weight PSO-DE hybrid optimizer that adapts exploration and exploitation phases by adjusting inertia weight based on convergence speed to enhance performance on varied fitness landscapes.", "configspace": "", "generation": 35, "fitness": 0.40006617918508, "feedback": "The algorithm DynamicHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.24.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7320635196697547, 0.7320635196697547, 0.7320635196697547, 0.7149050605241551, 0.7149050605241551, 0.7149050605241551, 0.6991681008717469, 0.6991681008717469, 0.6991681008717469, 0.5401296845839507, 0.5401296845839507, 0.5401296845839507, 0.5082322974680907, 0.5082322974680907, 0.5082322974680907, 0.5268206530767674, 0.5268206530767674, 0.5268206530767674, 0.15264491377403688, 0.15264491377403688, 0.15264491377403688, 0.14670972268528093, 0.14670972268528093, 0.14670972268528093, 0.12356932226367878, 0.12356932226367878, 0.12356932226367878, 0.10403179877749857, 0.10403179877749857, 0.10403179877749857, 0.09284002136628333, 0.09284002136628333, 0.09284002136628333, 0.11972768997839067, 0.11972768997839067, 0.11972768997839067, 0.9868103531951011, 0.9868103531951011, 0.9868103531951011, 0.9858852739855981, 0.9858852739855981, 0.9858852739855981, 0.9828791162675301, 0.9828791162675301, 0.9828791162675301, 0.5715025368036317, 0.5715025368036317, 0.5715025368036317, 0.5555380996015296, 0.5555380996015296, 0.5555380996015296, 0.5336521142201651, 0.5336521142201651, 0.5336521142201651, 0.6729357322282348, 0.6729357322282348, 0.6729357322282348, 0.7382786070055004, 0.7382786070055004, 0.7382786070055004, 0.7238205033928382, 0.7238205033928382, 0.7238205033928382, 0.5254520377064242, 0.5254520377064242, 0.5254520377064242, 0.12323320507888713, 0.12323320507888713, 0.12323320507888713, 0.5052355199818236, 0.5052355199818236, 0.5052355199818236, 0.5516155176471598, 0.5516155176471598, 0.5516155176471598, 0.5368608687760271, 0.5368608687760271, 0.5368608687760271, 0.4474499597321775, 0.4474499597321775, 0.4474499597321775, 0.4183346838991653, 0.4183346838991653, 0.4183346838991653, 0.46684453530386183, 0.46684453530386183, 0.46684453530386183, 0.45457001033420363, 0.45457001033420363, 0.45457001033420363, 0.5331792441225913, 0.5331792441225913, 0.5331792441225913, 0.5273844509679024, 0.5273844509679024, 0.5273844509679024, 0.529735241336067, 0.529735241336067, 0.529735241336067, 0.2320828373859637, 0.2320828373859637, 0.2320828373859637, 0.22952751087174184, 0.22952751087174184, 0.22952751087174184, 0.11365565262817057, 0.11365565262817057, 0.11365565262817057, 0.010972932415001524, 0.010972932415001524, 0.010972932415001524, 0.34246336993120763, 0.34246336993120763, 0.34246336993120763, 0.3987274678076884, 0.3987274678076884, 0.3987274678076884, 0.6510803237305339, 0.6510803237305339, 0.6510803237305339, 0.20838825495869895, 0.20838825495869895, 0.20838825495869895, 0.6784245612470493, 0.6784245612470493, 0.6784245612470493, 0.15879312147208635, 0.15879312147208635, 0.15879312147208635, 0.4703110837654665, 0.4703110837654665, 0.4703110837654665, 0.12732837185477786, 0.12732837185477786, 0.12732837185477786, 0.2392456866541074, 0.2392456866541074, 0.2392456866541074, 0.47405118698198434, 0.47405118698198434, 0.47405118698198434, 0.5606841326278047, 0.5606841326278047, 0.5606841326278047, 0.45722822312867406, 0.45722822312867406, 0.45722822312867406, 0.38810575282897075, 0.38810575282897075, 0.38810575282897075, 0.40491882522337097, 0.40491882522337097, 0.40491882522337097, 0.3457145599182364, 0.3457145599182364, 0.3457145599182364, 0.3436183367502653, 0.3436183367502653, 0.3436183367502653, 0.3549154826302505, 0.3549154826302505, 0.3549154826302505, 0.2172519120174654, 0.2172519120174654, 0.2172519120174654, 0.1940853287156742, 0.1940853287156742, 0.1940853287156742, 0.20789986482328326, 0.20789986482328326, 0.20789986482328326, 0.22041448741424452, 0.22041448741424452, 0.22041448741424452, 0.20165587693542053, 0.20165587693542053, 0.20165587693542053, 0.5105138863543482, 0.5105138863543482, 0.5105138863543482, 0.8392423893156884, 0.8392423893156884, 0.8392423893156884, 0.1910003530555675, 0.1910003530555675, 0.1910003530555675, 0.7463155617395075, 0.7463155617395075, 0.7463155617395075, 0.16787934194036058, 0.16787934194036058, 0.16787934194036058, 0.2032892157059455, 0.2032892157059455, 0.2032892157059455, 0.20188795402506898, 0.20188795402506898, 0.20188795402506898, 0.22343389005341519, 0.22343389005341519, 0.22343389005341519, 0.20176007269233998, 0.20176007269233998, 0.20176007269233998, 0.18006088094350148, 0.18006088094350148, 0.18006088094350148, 0.08798600486888952, 0.08798600486888952, 0.08798600486888952, 0.09924904000616608, 0.09924904000616608, 0.09924904000616608, 0.08856076928077206, 0.08856076928077206, 0.08856076928077206]}, "mutation_prompt": null}
{"id": "8e14e021-dc1f-481d-bd2f-10b890d92159", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "ccaefb87-5222-4217-a61e-51e4b51f0e55", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive parameter update\n            self.w = 0.9 - 0.5 * (eval_count / self.budget)\n            self.f = 0.5 + 0.3 * np.sin(eval_count / self.budget)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(self.pop_size, self.dim), np.random.rand(self.pop_size, self.dim)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update with Opposition-Based Learning\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.1:  # Elite opposition-based strategy\n                    opposition = self.lower_bound + self.upper_bound - personal_best_positions[i]\n                    opposition = np.clip(opposition, self.lower_bound, self.upper_bound)\n                    trial_score = func(opposition)\n                    eval_count += 1\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = opposition\n                        if trial_score < global_best_score:\n                            global_best_score = trial_score\n                            global_best_position = opposition\n\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameters and elite opposition-based learning for improved convergence on diverse landscapes.", "configspace": "", "generation": 37, "fitness": 0.37310380883970296, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.26.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7744646033121639, 0.7744646033121639, 0.7744646033121639, 0.7847161191513261, 0.7847161191513261, 0.7847161191513261, 0.8094016590858637, 0.8094016590858637, 0.8094016590858637, 0.5530076169738435, 0.5530076169738435, 0.5530076169738435, 0.588481823332367, 0.588481823332367, 0.588481823332367, 0.6066480306579358, 0.6066480306579358, 0.6066480306579358, 0.15524839977204685, 0.15524839977204685, 0.15524839977204685, 0.1360328128042564, 0.1360328128042564, 0.1360328128042564, 0.11613091678112197, 0.11613091678112197, 0.11613091678112197, 0.11561241150691826, 0.11561241150691826, 0.11561241150691826, 0.12371056221178789, 0.12371056221178789, 0.12371056221178789, 0.1396863887194515, 0.1396863887194515, 0.1396863887194515, 0.9903724449953549, 0.9903724449953549, 0.9903724449953549, 0.9916229228754613, 0.9916229228754613, 0.9916229228754613, 0.990752257691892, 0.990752257691892, 0.990752257691892, 0.1148315248178644, 0.1148315248178644, 0.1148315248178644, 0.1506298558211503, 0.1506298558211503, 0.1506298558211503, 0.5661414769703295, 0.5661414769703295, 0.5661414769703295, 0.8174877258116553, 0.8174877258116553, 0.8174877258116553, 0.8090306319317431, 0.8090306319317431, 0.8090306319317431, 0.823712265551076, 0.823712265551076, 0.823712265551076, 0.3717485852962725, 0.3717485852962725, 0.3717485852962725, 0.12076282842356267, 0.12076282842356267, 0.12076282842356267, 0.30450436342160303, 0.30450436342160303, 0.30450436342160303, 0.5474244747709132, 0.5474244747709132, 0.5474244747709132, 0.5554678212784501, 0.5554678212784501, 0.5554678212784501, 0.35638699982396693, 0.35638699982396693, 0.35638699982396693, 0.5158080914580878, 0.5158080914580878, 0.5158080914580878, 0.06917137773847393, 0.06917137773847393, 0.06917137773847393, 0.1668890762763906, 0.1668890762763906, 0.1668890762763906, 0.3886944576684146, 0.3886944576684146, 0.3886944576684146, 0.1694705119234341, 0.1694705119234341, 0.1694705119234341, 0.26629452309414947, 0.26629452309414947, 0.26629452309414947, 0.06301738888869679, 0.06301738888869679, 0.06301738888869679, 0.14321375491227406, 0.14321375491227406, 0.14321375491227406, 0.29701854214124934, 0.29701854214124934, 0.29701854214124934, 0.2787537149010312, 0.2787537149010312, 0.2787537149010312, 0.2900526918866808, 0.2900526918866808, 0.2900526918866808, 0.24904850667563028, 0.24904850667563028, 0.24904850667563028, 0.5891122647347928, 0.5891122647347928, 0.5891122647347928, 0.6636194172944894, 0.6636194172944894, 0.6636194172944894, 0.7281663481051059, 0.7281663481051059, 0.7281663481051059, 0.12236145404650944, 0.12236145404650944, 0.12236145404650944, 0.1296899259036598, 0.1296899259036598, 0.1296899259036598, 0.46349113889203997, 0.46349113889203997, 0.46349113889203997, 0.35865871272329397, 0.35865871272329397, 0.35865871272329397, 0.1431068157361014, 0.1431068157361014, 0.1431068157361014, 0.18923775874070237, 0.18923775874070237, 0.18923775874070237, 0.4197380252941817, 0.4197380252941817, 0.4197380252941817, 0.4436324061225354, 0.4436324061225354, 0.4436324061225354, 0.49107400743158336, 0.49107400743158336, 0.49107400743158336, 0.3323548503768877, 0.3323548503768877, 0.3323548503768877, 0.31366565165390736, 0.31366565165390736, 0.31366565165390736, 0.3302067980699942, 0.3302067980699942, 0.3302067980699942, 0.22601641159908648, 0.22601641159908648, 0.22601641159908648, 0.21257999664052507, 0.21257999664052507, 0.21257999664052507, 0.21149025050668113, 0.21149025050668113, 0.21149025050668113, 0.19647492017689117, 0.19647492017689117, 0.19647492017689117, 0.4351519186430153, 0.4351519186430153, 0.4351519186430153, 0.21740464920021874, 0.21740464920021874, 0.21740464920021874, 0.8831949221449437, 0.8831949221449437, 0.8831949221449437, 0.8654765489752725, 0.8654765489752725, 0.8654765489752725, 0.17972104114600151, 0.17972104114600151, 0.17972104114600151, 0.169613442767086, 0.169613442767086, 0.169613442767086, 0.2089766939604064, 0.2089766939604064, 0.2089766939604064, 0.1560181548647439, 0.1560181548647439, 0.1560181548647439, 0.215267004132357, 0.215267004132357, 0.215267004132357, 0.19923476426013487, 0.19923476426013487, 0.19923476426013487, 0.20241292486421358, 0.20241292486421358, 0.20241292486421358, 0.07525813744605403, 0.07525813744605403, 0.07525813744605403, 0.09510141619836865, 0.09510141619836865, 0.09510141619836865, 0.08451530245194117, 0.08451530245194117, 0.08451530245194117]}, "mutation_prompt": null}
{"id": "1fecf5a2-cdce-4c44-9a65-2f498370b0a0", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = min(50, max(10, dim * 2))  # Dynamic population size based on dimension\n        self.c1 = 2.0  # Increased cognitive coefficient for faster convergence\n        self.c2 = 2.0  # Increased social coefficient for stronger global attraction\n        self.w = 0.9  # Higher initial inertia weight for enhanced exploration\n        self.w_min = 0.4  # Minimum inertia weight for exploitation\n        self.f = 0.9  # Increased DE scaling factor\n        self.cr = 0.7  # Decreased DE crossover probability for diversity\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight decrement\n            self.w = self.w_min + (0.5 * (self.w - self.w_min) * (1 - eval_count / self.budget))\n            \n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameters and dynamic population size to improve exploration-exploitation balance over diverse landscapes.", "configspace": "", "generation": 38, "fitness": 0.2551237278354956, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.27.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.9514027305790733, 0.9514027305790733, 0.9514027305790733, 0.1413574418782908, 0.1413574418782908, 0.1413574418782908, 0.1761991194260223, 0.1761991194260223, 0.1761991194260223, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.8679851219140693, 0.8679851219140693, 0.8679851219140693, 0.8104594198625125, 0.8104594198625125, 0.8104594198625125, 0.1138346754454529, 0.1138346754454529, 0.1138346754454529, 0.10848414833311648, 0.10848414833311648, 0.10848414833311648, 0.16242499391830056, 0.16242499391830056, 0.16242499391830056, 0.07897128713356183, 0.07897128713356183, 0.07897128713356183, 0.05321579439153179, 0.05321579439153179, 0.05321579439153179, 0.10635037338834341, 0.10635037338834341, 0.10635037338834341, 0.9934351773436616, 0.9934351773436616, 0.9934351773436616, 0.993616946958783, 0.993616946958783, 0.993616946958783, 0.9934650441424706, 0.9934650441424706, 0.9934650441424706, 0.8828054100805266, 0.8828054100805266, 0.8828054100805266, 0.8382763012439938, 0.8382763012439938, 0.8382763012439938, 0.08914154347343395, 0.08914154347343395, 0.08914154347343395, 0.17781924222205692, 0.17781924222205692, 0.17781924222205692, 0.1633310043275873, 0.1633310043275873, 0.1633310043275873, 0.021327268337609895, 0.021327268337609895, 0.021327268337609895, 0.41009589304039795, 0.41009589304039795, 0.41009589304039795, 0.3407303643521331, 0.3407303643521331, 0.3407303643521331, 0.4827899587804284, 0.4827899587804284, 0.4827899587804284, 0.14994120519938514, 0.14994120519938514, 0.14994120519938514, 0.5077363385853082, 0.5077363385853082, 0.5077363385853082, 0.36376905623662936, 0.36376905623662936, 0.36376905623662936, 0.041686733897766004, 0.041686733897766004, 0.041686733897766004, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10813532716709173, 0.10813532716709173, 0.10813532716709173, 0.07520192779166357, 0.07520192779166357, 0.07520192779166357, 0.01969965426612197, 0.01969965426612197, 0.01969965426612197, 0.04305918059939562, 0.04305918059939562, 0.04305918059939562, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1255526179574855, 0.1255526179574855, 0.1255526179574855, 0.13336063077736127, 0.13336063077736127, 0.13336063077736127, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0508639603551565, 0.0508639603551565, 0.0508639603551565, 0.694622201455675, 0.694622201455675, 0.694622201455675, 0.16843882573906244, 0.16843882573906244, 0.16843882573906244, 0.6043476169719272, 0.6043476169719272, 0.6043476169719272, 0.04233958039788044, 0.04233958039788044, 0.04233958039788044, 0.1198961662342144, 0.1198961662342144, 0.1198961662342144, 0.11734382132856025, 0.11734382132856025, 0.11734382132856025, 0.35575983036841174, 0.35575983036841174, 0.35575983036841174, 0.2952394016707617, 0.2952394016707617, 0.2952394016707617, 0.10497175591481733, 0.10497175591481733, 0.10497175591481733, 0.27949537147538406, 0.27949537147538406, 0.27949537147538406, 0.1146310857759687, 0.1146310857759687, 0.1146310857759687, 0.3943883949462048, 0.3943883949462048, 0.3943883949462048, 0.10784540691916134, 0.10784540691916134, 0.10784540691916134, 0.2698554252481018, 0.2698554252481018, 0.2698554252481018, 0.04190061210451168, 0.04190061210451168, 0.04190061210451168, 0.23739856117928315, 0.23739856117928315, 0.23739856117928315, 0.25471212100764806, 0.25471212100764806, 0.25471212100764806, 0.25411502028306554, 0.25411502028306554, 0.25411502028306554, 0.21012199948112442, 0.21012199948112442, 0.21012199948112442, 0.21225260639448895, 0.21225260639448895, 0.21225260639448895, 0.22735140001062104, 0.22735140001062104, 0.22735140001062104, 0.11324757238629513, 0.11324757238629513, 0.11324757238629513, 0.1645185521480489, 0.1645185521480489, 0.1645185521480489, 0.15438891774627905, 0.15438891774627905, 0.15438891774627905, 0.05848278391408401, 0.05848278391408401, 0.05848278391408401, 0.21315954901862388, 0.21315954901862388, 0.21315954901862388, 0.0949676690303477, 0.0949676690303477, 0.0949676690303477, 0.19289884074402552, 0.19289884074402552, 0.19289884074402552, 0.21724734771846554, 0.21724734771846554, 0.21724734771846554, 0.1922034696304471, 0.1922034696304471, 0.1922034696304471, 0.10715265767114102, 0.10715265767114102, 0.10715265767114102, 0.07956739913235378, 0.07956739913235378, 0.07956739913235378, 0.09702054670197435, 0.09702054670197435, 0.09702054670197435]}, "mutation_prompt": null}
{"id": "a1ca8438-fd3b-4bcc-a420-206ac1687597", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "8bf6e37d-8c55-4638-ba0e-73f5856a9b27", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "0168c72c-2766-4ff3-8799-901fa3958e45", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "c2fce727-8404-416d-bec8-3ac4fd4fe94f", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.f = 0.8\n        self.cr_min = 0.6\n        self.cr_max = 1.0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            cr = self.cr_max - (self.cr_max - self.cr_min) * (eval_count / self.budget)\n            \n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced PSO-DE optimizer that integrates adaptive inertia and crossover mechanisms to improve convergence speed and accuracy across diverse optimization landscapes.", "configspace": "", "generation": 42, "fitness": 0.3888211406437926, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.24.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7192699837242964, 0.7192699837242964, 0.7192699837242964, 0.7226533915560838, 0.7226533915560838, 0.7226533915560838, 0.726610558995558, 0.726610558995558, 0.726610558995558, 0.5089374226608184, 0.5089374226608184, 0.5089374226608184, 0.49658293062364767, 0.49658293062364767, 0.49658293062364767, 0.5260322818666366, 0.5260322818666366, 0.5260322818666366, 0.13280465576948186, 0.13280465576948186, 0.13280465576948186, 0.1250916453515427, 0.1250916453515427, 0.1250916453515427, 0.5246322666033396, 0.5246322666033396, 0.5246322666033396, 0.10749845183780904, 0.10749845183780904, 0.10749845183780904, 0.11744566710299265, 0.11744566710299265, 0.11744566710299265, 0.11966060831201353, 0.11966060831201353, 0.11966060831201353, 0.983252167963587, 0.983252167963587, 0.983252167963587, 0.983532366766471, 0.983532366766471, 0.983532366766471, 0.9855016378177662, 0.9855016378177662, 0.9855016378177662, 0.5830674250026604, 0.5830674250026604, 0.5830674250026604, 0.5545095217532165, 0.5545095217532165, 0.5545095217532165, 0.5440796440137807, 0.5440796440137807, 0.5440796440137807, 0.22466177616746552, 0.22466177616746552, 0.22466177616746552, 0.7825626911613908, 0.7825626911613908, 0.7825626911613908, 0.7081818930317636, 0.7081818930317636, 0.7081818930317636, 0.5276009614503474, 0.5276009614503474, 0.5276009614503474, 0.5177844462761629, 0.5177844462761629, 0.5177844462761629, 0.48801663907304793, 0.48801663907304793, 0.48801663907304793, 0.5380470850394232, 0.5380470850394232, 0.5380470850394232, 0.5030288268925757, 0.5030288268925757, 0.5030288268925757, 0.5426986511573284, 0.5426986511573284, 0.5426986511573284, 0.3269656892709325, 0.3269656892709325, 0.3269656892709325, 0.427282785210371, 0.427282785210371, 0.427282785210371, 0.3433138313569628, 0.3433138313569628, 0.3433138313569628, 0.5641533385271597, 0.5641533385271597, 0.5641533385271597, 0.47443865531283314, 0.47443865531283314, 0.47443865531283314, 0.5963398180146474, 0.5963398180146474, 0.5963398180146474, 0.09196255013620591, 0.09196255013620591, 0.09196255013620591, 0.19858381792232238, 0.19858381792232238, 0.19858381792232238, 0.05992968860304404, 0.05992968860304404, 0.05992968860304404, 0.2983380450870179, 0.2983380450870179, 0.2983380450870179, 0.32461669256559145, 0.32461669256559145, 0.32461669256559145, 0.30695075248091463, 0.30695075248091463, 0.30695075248091463, 0.6785904242383316, 0.6785904242383316, 0.6785904242383316, 0.5970928045480366, 0.5970928045480366, 0.5970928045480366, 0.6130811716559482, 0.6130811716559482, 0.6130811716559482, 0.1555960296181087, 0.1555960296181087, 0.1555960296181087, 0.11142923690446382, 0.11142923690446382, 0.11142923690446382, 0.15163335333233174, 0.15163335333233174, 0.15163335333233174, 0.2500011205451992, 0.2500011205451992, 0.2500011205451992, 0.16697215132822807, 0.16697215132822807, 0.16697215132822807, 0.1936439633538558, 0.1936439633538558, 0.1936439633538558, 0.3882629614609838, 0.3882629614609838, 0.3882629614609838, 0.38194360292537344, 0.38194360292537344, 0.38194360292537344, 0.4055059180584337, 0.4055059180584337, 0.4055059180584337, 0.3849406882355154, 0.3849406882355154, 0.3849406882355154, 0.2995797001910214, 0.2995797001910214, 0.2995797001910214, 0.3329143113111862, 0.3329143113111862, 0.3329143113111862, 0.24564798808663124, 0.24564798808663124, 0.24564798808663124, 0.2302139406228727, 0.2302139406228727, 0.2302139406228727, 0.2107416098931001, 0.2107416098931001, 0.2107416098931001, 0.22793404807115236, 0.22793404807115236, 0.22793404807115236, 0.191864006334989, 0.191864006334989, 0.191864006334989, 0.22283078390467403, 0.22283078390467403, 0.22283078390467403, 0.8514787074577208, 0.8514787074577208, 0.8514787074577208, 0.17703300791400967, 0.17703300791400967, 0.17703300791400967, 0.19149736595547107, 0.19149736595547107, 0.19149736595547107, 0.1553821736285036, 0.1553821736285036, 0.1553821736285036, 0.8361100468758269, 0.8361100468758269, 0.8361100468758269, 0.15461306802134567, 0.15461306802134567, 0.15461306802134567, 0.21073967868331633, 0.21073967868331633, 0.21073967868331633, 0.18198911073268675, 0.18198911073268675, 0.18198911073268675, 0.20017809690085242, 0.20017809690085242, 0.20017809690085242, 0.08337779194203199, 0.08337779194203199, 0.08337779194203199, 0.11250419253570887, 0.11250419253570887, 0.11250419253570887, 0.09317780862594649, 0.09317780862594649, 0.09317780862594649]}, "mutation_prompt": null}
{"id": "c2399d96-5902-4927-9221-7c0192858f72", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "f96640c8-538a-4d84-8f0c-09769753e697", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "375ba575-ff7a-4592-b20f-8c821f761244", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 25  # Increased population size for diversity\n        self.c1 = 2.0  # Enhanced PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.5  # Reduced inertia weight for faster convergence\n        self.f_min = 0.5  # Dynamic DE scaling factor\n        self.f_max = 0.9\n        self.cr = 0.8  # Slightly reduced DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update with adaptive scaling factor\n            f_dynamic = self.f_min + (self.f_max - self.f_min) * (eval_count / self.budget)\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + f_dynamic * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "A balanced hybrid algorithm enhancing PSO's exploration with adaptive DE mutation strategies, ensuring robust performance across various optimization landscapes.", "configspace": "", "generation": 45, "fitness": 0.4294653351356682, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.43 with standard deviation 0.30.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.8619203595554907, 0.8619203595554907, 0.8619203595554907, 0.8701887756805214, 0.8701887756805214, 0.8701887756805214, 0.8612842022177072, 0.8612842022177072, 0.8612842022177072, 0.6855898168610016, 0.6855898168610016, 0.6855898168610016, 0.6638742930040189, 0.6638742930040189, 0.6638742930040189, 0.6765352388334116, 0.6765352388334116, 0.6765352388334116, 0.1533791928345114, 0.1533791928345114, 0.1533791928345114, 0.15424235091216, 0.15424235091216, 0.15424235091216, 0.1537943939010784, 0.1537943939010784, 0.1537943939010784, 0.12097906969895889, 0.12097906969895889, 0.12097906969895889, 0.13012163488755846, 0.13012163488755846, 0.13012163488755846, 0.1370769240753984, 0.1370769240753984, 0.1370769240753984, 0.9842278550294241, 0.9842278550294241, 0.9842278550294241, 0.984048757656973, 0.984048757656973, 0.984048757656973, 0.9797083801593914, 0.9797083801593914, 0.9797083801593914, 0.723788757050684, 0.723788757050684, 0.723788757050684, 0.6954583698736683, 0.6954583698736683, 0.6954583698736683, 0.0894807952814819, 0.0894807952814819, 0.0894807952814819, 0.8687718927392106, 0.8687718927392106, 0.8687718927392106, 0.19535781261814755, 0.19535781261814755, 0.19535781261814755, 0.11703292594425985, 0.11703292594425985, 0.11703292594425985, 0.6793176199708792, 0.6793176199708792, 0.6793176199708792, 0.13158748795588304, 0.13158748795588304, 0.13158748795588304, 0.6749268042059868, 0.6749268042059868, 0.6749268042059868, 0.6333831465428826, 0.6333831465428826, 0.6333831465428826, 0.6752721453199515, 0.6752721453199515, 0.6752721453199515, 0.7507228131409905, 0.7507228131409905, 0.7507228131409905, 0.3386130489540673, 0.3386130489540673, 0.3386130489540673, 0.6494794080999708, 0.6494794080999708, 0.6494794080999708, 0.00897094913554397, 0.00897094913554397, 0.00897094913554397, 0.6502027683941494, 0.6502027683941494, 0.6502027683941494, 0.5720590401005152, 0.5720590401005152, 0.5720590401005152, 0.6771456791720764, 0.6771456791720764, 0.6771456791720764, 0.27691768136622064, 0.27691768136622064, 0.27691768136622064, 0.19076389018829376, 0.19076389018829376, 0.19076389018829376, 0.0710698186399199, 0.0710698186399199, 0.0710698186399199, 0.44334350217449403, 0.44334350217449403, 0.44334350217449403, 0.03845736655051335, 0.03845736655051335, 0.03845736655051335, 0.08320786848533246, 0.08320786848533246, 0.08320786848533246, 0.8266759408258504, 0.8266759408258504, 0.8266759408258504, 0.7855547610841249, 0.7855547610841249, 0.7855547610841249, 0.7907240191604703, 0.7907240191604703, 0.7907240191604703, 0.0645864926018781, 0.0645864926018781, 0.0645864926018781, 0.09092437135522158, 0.09092437135522158, 0.09092437135522158, 0.1582772006091061, 0.1582772006091061, 0.1582772006091061, 0.7156941189484851, 0.7156941189484851, 0.7156941189484851, 0.7522292431620219, 0.7522292431620219, 0.7522292431620219, 0.6990817933077222, 0.6990817933077222, 0.6990817933077222, 0.5618464827793425, 0.5618464827793425, 0.5618464827793425, 0.5316374121682647, 0.5316374121682647, 0.5316374121682647, 0.5290786285509013, 0.5290786285509013, 0.5290786285509013, 0.24647208688816014, 0.24647208688816014, 0.24647208688816014, 0.25236657180033806, 0.25236657180033806, 0.25236657180033806, 0.3898527128629087, 0.3898527128629087, 0.3898527128629087, 0.2327192311802646, 0.2327192311802646, 0.2327192311802646, 0.2255325040568943, 0.2255325040568943, 0.2255325040568943, 0.2513464645191812, 0.2513464645191812, 0.2513464645191812, 0.22305074956148396, 0.22305074956148396, 0.22305074956148396, 0.21174383139499242, 0.21174383139499242, 0.21174383139499242, 0.24827065130525394, 0.24827065130525394, 0.24827065130525394, 0.9381278097229061, 0.9381278097229061, 0.9381278097229061, 0.15936855708641784, 0.15936855708641784, 0.15936855708641784, 0.9071165811439946, 0.9071165811439946, 0.9071165811439946, 0.1690315550287239, 0.1690315550287239, 0.1690315550287239, 0.21211849052277465, 0.21211849052277465, 0.21211849052277465, 0.1685095828077232, 0.1685095828077232, 0.1685095828077232, 0.215337301083955, 0.215337301083955, 0.215337301083955, 0.20648843846635812, 0.20648843846635812, 0.20648843846635812, 0.20249462685303088, 0.20249462685303088, 0.20249462685303088, 0.10488821882281463, 0.10488821882281463, 0.10488821882281463, 0.1033913737781248, 0.1033913737781248, 0.1033913737781248, 0.09466348911569089, 0.09466348911569089, 0.09466348911569089]}, "mutation_prompt": null}
{"id": "934dd59d-e460-427b-b594-e0afd6845c7b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "a6caaeb7-78f6-41c1-b96d-811a7cb0f24c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "274474dc-a15b-4420-a295-1ada6c099c3b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "9d79555e-937c-402f-ada1-a81d5eb7ea6e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "4a7e4e1a-7f04-4b01-a534-177f03fb39a2", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "72e515cb-c6ad-4ea9-9729-9c7e571d0705", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.epsilon = 1e-5  # Fitness-sharing threshold\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n        \n        # Adaptive PSO coefficients\n        c1_initial, c2_initial = self.c1, self.c2\n        c1_final, c2_final = 0.5, 2.0\n\n        while eval_count < self.budget:\n            # Update adaptive PSO coefficients\n            progress = eval_count / self.budget\n            self.c1 = c1_initial * (1 - progress) + c1_final * progress\n            self.c2 = c2_initial * (1 - progress) + c2_final * progress\n            \n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests with fitness sharing\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Apply fitness sharing to maintain diversity\n            distances = np.linalg.norm(pop[:, np.newaxis] - pop[np.newaxis, :], axis=2)\n            sharing_func = np.maximum(0, 1 - (distances / self.epsilon))\n            personal_best_scores += np.sum(sharing_func, axis=1)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "An enhanced PSO-DE hybrid with adaptive coefficients and fitness-sharing mechanism for improved diversity and convergence.", "configspace": "", "generation": 51, "fitness": 0.3050100879477264, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.20.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.3957764514257196, 0.3957764514257196, 0.3957764514257196, 0.38461710779368086, 0.38461710779368086, 0.38461710779368086, 0.39157636151362174, 0.39157636151362174, 0.39157636151362174, 0.3365276945280644, 0.3365276945280644, 0.3365276945280644, 0.3179826070044133, 0.3179826070044133, 0.3179826070044133, 0.3046419952815407, 0.3046419952815407, 0.3046419952815407, 0.12130286703434345, 0.12130286703434345, 0.12130286703434345, 0.13574347114053453, 0.13574347114053453, 0.13574347114053453, 0.13058957696083873, 0.13058957696083873, 0.13058957696083873, 0.15025581602748295, 0.15025581602748295, 0.15025581602748295, 0.13319585796256472, 0.13319585796256472, 0.13319585796256472, 0.130879432032031, 0.130879432032031, 0.130879432032031, 0.9868363086837815, 0.9868363086837815, 0.9868363086837815, 0.9753834764186143, 0.9753834764186143, 0.9753834764186143, 0.9835966503529238, 0.9835966503529238, 0.9835966503529238, 0.37112806978316826, 0.37112806978316826, 0.37112806978316826, 0.3688444389469062, 0.3688444389469062, 0.3688444389469062, 0.1263731171998943, 0.1263731171998943, 0.1263731171998943, 0.5585058585987117, 0.5585058585987117, 0.5585058585987117, 0.5293515951349357, 0.5293515951349357, 0.5293515951349357, 0.8571869270664318, 0.8571869270664318, 0.8571869270664318, 0.3480674569104957, 0.3480674569104957, 0.3480674569104957, 0.3793769852022112, 0.3793769852022112, 0.3793769852022112, 0.3012508402334795, 0.3012508402334795, 0.3012508402334795, 0.28934867663551556, 0.28934867663551556, 0.28934867663551556, 0.3077601545629496, 0.3077601545629496, 0.3077601545629496, 0.13290366999386793, 0.13290366999386793, 0.13290366999386793, 0.07067116239825899, 0.07067116239825899, 0.07067116239825899, 0.34779471006143114, 0.34779471006143114, 0.34779471006143114, 0.31295542578718205, 0.31295542578718205, 0.31295542578718205, 0.31618687142928525, 0.31618687142928525, 0.31618687142928525, 0.2977775207980964, 0.2977775207980964, 0.2977775207980964, 0.3371629993144043, 0.3371629993144043, 0.3371629993144043, 0.11442429935217513, 0.11442429935217513, 0.11442429935217513, 0.25249539187439296, 0.25249539187439296, 0.25249539187439296, 0.12189307426661722, 0.12189307426661722, 0.12189307426661722, 0.2490758146428791, 0.2490758146428791, 0.2490758146428791, 0.246948582846936, 0.246948582846936, 0.246948582846936, 0.2505102954741373, 0.2505102954741373, 0.2505102954741373, 0.37605269675940367, 0.37605269675940367, 0.37605269675940367, 0.3526559614485919, 0.3526559614485919, 0.3526559614485919, 0.38431711755975173, 0.38431711755975173, 0.38431711755975173, 0.1082492672474562, 0.1082492672474562, 0.1082492672474562, 0.10684793984516872, 0.10684793984516872, 0.10684793984516872, 0.13533082730694734, 0.13533082730694734, 0.13533082730694734, 0.20011121463718073, 0.20011121463718073, 0.20011121463718073, 0.3674965024541894, 0.3674965024541894, 0.3674965024541894, 0.331187966794247, 0.331187966794247, 0.331187966794247, 0.2784442582480159, 0.2784442582480159, 0.2784442582480159, 0.289532967618196, 0.289532967618196, 0.289532967618196, 0.2880749283267199, 0.2880749283267199, 0.2880749283267199, 0.26241718060171937, 0.26241718060171937, 0.26241718060171937, 0.256978398732544, 0.256978398732544, 0.256978398732544, 0.25220211378282675, 0.25220211378282675, 0.25220211378282675, 0.21429678654887174, 0.21429678654887174, 0.21429678654887174, 0.2207584908231336, 0.2207584908231336, 0.2207584908231336, 0.21136195208292452, 0.21136195208292452, 0.21136195208292452, 0.30966001836930745, 0.30966001836930745, 0.30966001836930745, 0.23025144436074108, 0.23025144436074108, 0.23025144436074108, 0.22049687306075016, 0.22049687306075016, 0.22049687306075016, 0.6006645784347125, 0.6006645784347125, 0.6006645784347125, 0.16837613513234884, 0.16837613513234884, 0.16837613513234884, 0.5877444622913905, 0.5877444622913905, 0.5877444622913905, 0.155277440050808, 0.155277440050808, 0.155277440050808, 0.20920954906721034, 0.20920954906721034, 0.20920954906721034, 0.5817157793924213, 0.5817157793924213, 0.5817157793924213, 0.20113271425161272, 0.20113271425161272, 0.20113271425161272, 0.18122912725982143, 0.18122912725982143, 0.18122912725982143, 0.1991632690531413, 0.1991632690531413, 0.1991632690531413, 0.10218546237731385, 0.10218546237731385, 0.10218546237731385, 0.09550503844734337, 0.09550503844734337, 0.09550503844734337, 0.11489825719497238, 0.11489825719497238, 0.11489825719497238]}, "mutation_prompt": null}
{"id": "c089934b-a10c-4abb-a285-80c62b3bd502", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "96a5755c-0c29-42e5-ac0e-e6d24897f272", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "91475b45-c562-4596-a57c-d523e43c835f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "b299bca4-e8a3-4804-b097-2f30f5ed76b9", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 2.0  # Adaptive PSO cognitive coefficient\n        self.c2 = 2.0  # Adaptive PSO social coefficient\n        self.w = 0.9  # Adaptive inertia weight\n        self.f = 0.5  # DE scaling factor\n        self.cr = 0.7  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive Particle Swarm Optimization Update\n            self.w = 0.9 - 0.5 * (eval_count / self.budget)\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update with chaotic exploration\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                # Chaotic exploration modification\n                chaos_factor = np.tan(np.random.uniform(-np.pi/2, np.pi/2, self.dim))\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant + chaos_factor, pop[i])\n                trial = np.clip(trial, self.lower_bound, self.upper_bound)\n                \n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive learning rates and chaotic exploration to improve convergence and diversity in complex fitness landscapes.", "configspace": "", "generation": 55, "fitness": 0.2128185170930042, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.21.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.5184551714350714, 0.5184551714350714, 0.5184551714350714, 0.5121554659159371, 0.5121554659159371, 0.5121554659159371, 0.4920542184450485, 0.4920542184450485, 0.4920542184450485, 0.0971119253829682, 0.0971119253829682, 0.0971119253829682, 0.1554765138210762, 0.1554765138210762, 0.1554765138210762, 0.1202245999426268, 0.1202245999426268, 0.1202245999426268, 0.10352988191419266, 0.10352988191419266, 0.10352988191419266, 0.11164765328953441, 0.11164765328953441, 0.11164765328953441, 0.13166175981334416, 0.13166175981334416, 0.13166175981334416, 0.08738305174520067, 0.08738305174520067, 0.08738305174520067, 0.09227102579146851, 0.09227102579146851, 0.09227102579146851, 0.08617143550343431, 0.08617143550343431, 0.08617143550343431, 0.9884615658946101, 0.9884615658946101, 0.9884615658946101, 0.987800301492637, 0.987800301492637, 0.987800301492637, 0.9940759926070708, 0.9940759926070708, 0.9940759926070708, 0.3348025510125665, 0.3348025510125665, 0.3348025510125665, 0.24445067508883522, 0.24445067508883522, 0.24445067508883522, 0.23730508169270803, 0.23730508169270803, 0.23730508169270803, 0.167047477901331, 0.167047477901331, 0.167047477901331, 0.16418840937340085, 0.16418840937340085, 0.16418840937340085, 0.2101391173818652, 0.2101391173818652, 0.2101391173818652, 0.12606813681739892, 0.12606813681739892, 0.12606813681739892, 0.095571954071491, 0.095571954071491, 0.095571954071491, 0.14444437432528012, 0.14444437432528012, 0.14444437432528012, 0.1063345370903227, 0.1063345370903227, 0.1063345370903227, 0.12703810892740441, 0.12703810892740441, 0.12703810892740441, 0.11570885266665953, 0.11570885266665953, 0.11570885266665953, 0.05969069799733129, 0.05969069799733129, 0.05969069799733129, 0.035046369478156314, 0.035046369478156314, 0.035046369478156314, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14280625215948672, 0.14280625215948672, 0.14280625215948672, 0.08345675166921229, 0.08345675166921229, 0.08345675166921229, 0.08769680961548088, 0.08769680961548088, 0.08769680961548088, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03424954062516483, 0.03424954062516483, 0.03424954062516483, 0.043545060554563086, 0.043545060554563086, 0.043545060554563086, 0.1775237581296194, 0.1775237581296194, 0.1775237581296194, 0.07545314121022673, 0.07545314121022673, 0.07545314121022673, 0.06992691694673736, 0.06992691694673736, 0.06992691694673736, 0.3882622691856389, 0.3882622691856389, 0.3882622691856389, 0.42356365796966844, 0.42356365796966844, 0.42356365796966844, 0.4176733725712828, 0.4176733725712828, 0.4176733725712828, 0.09336194956233068, 0.09336194956233068, 0.09336194956233068, 0.09383334192685311, 0.09383334192685311, 0.09383334192685311, 0.07896140309488242, 0.07896140309488242, 0.07896140309488242, 0.20470660069197788, 0.20470660069197788, 0.20470660069197788, 0.19960905465704704, 0.19960905465704704, 0.19960905465704704, 0.1580565979906614, 0.1580565979906614, 0.1580565979906614, 0.24565165727363836, 0.24565165727363836, 0.24565165727363836, 0.21578115575705237, 0.21578115575705237, 0.21578115575705237, 0.3044366801947752, 0.3044366801947752, 0.3044366801947752, 0.22368929815658, 0.22368929815658, 0.22368929815658, 0.16827408025442037, 0.16827408025442037, 0.16827408025442037, 0.1623969390103992, 0.1623969390103992, 0.1623969390103992, 0.1957083145690508, 0.1957083145690508, 0.1957083145690508, 0.1899331710796982, 0.1899331710796982, 0.1899331710796982, 0.21265087590459397, 0.21265087590459397, 0.21265087590459397, 0.21334193055592476, 0.21334193055592476, 0.21334193055592476, 0.1843776504678859, 0.1843776504678859, 0.1843776504678859, 0.1823476493608347, 0.1823476493608347, 0.1823476493608347, 0.7191773578056474, 0.7191773578056474, 0.7191773578056474, 0.1706736226054727, 0.1706736226054727, 0.1706736226054727, 0.1598363116567596, 0.1598363116567596, 0.1598363116567596, 0.15476296556580016, 0.15476296556580016, 0.15476296556580016, 0.2009422371564238, 0.2009422371564238, 0.2009422371564238, 0.19991916937747056, 0.19991916937747056, 0.19991916937747056, 0.17936705540545939, 0.17936705540545939, 0.17936705540545939, 0.1978641827230848, 0.1978641827230848, 0.1978641827230848, 0.18040086340724104, 0.18040086340724104, 0.18040086340724104, 0.07927150248592274, 0.07927150248592274, 0.07927150248592274, 0.07602881255619809, 0.07602881255619809, 0.07602881255619809, 0.0868963619861628, 0.0868963619861628, 0.0868963619861628]}, "mutation_prompt": null}
{"id": "5d80d1f5-84d3-4267-867d-4128ee342248", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Starting population size\n        self.c1_start = 1.5  # Initial PSO cognitive coefficient\n        self.c2_start = 1.5  # Initial PSO social coefficient\n        self.w_start = 0.9  # Initial inertia weight\n        self.f_start = 0.8  # Initial DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        # Adaptive parameters\n        c1 = self.c1_start\n        c2 = self.c2_start\n        w = self.w_start\n        f = self.f_start\n\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive coefficients update\n            progress_ratio = eval_count / self.budget\n            c1 = self.c1_start - progress_ratio * 0.5\n            c2 = self.c2_start + progress_ratio * 0.5\n            w = self.w_start - progress_ratio * 0.5\n            f = self.f_start - progress_ratio * 0.3\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - pop) +\n                          c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n\n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n\n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n\n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n\n                if eval_count >= self.budget:\n                    break\n\n            # Dynamic population adjustment (e.g., reduce population size for exploitation)\n            if eval_count % (self.budget // 10) == 0 and self.pop_size > 10:\n                self.pop_size -= 1\n                pop = pop[:self.pop_size]\n                velocities = velocities[:self.pop_size]\n                personal_best_positions = personal_best_positions[:self.pop_size]\n                personal_best_scores = personal_best_scores[:self.pop_size]\n\n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid PSO-DE optimizer incorporating adaptive parameters and a dynamic population size to balance exploration and exploitation effectively across varied fitness landscapes.", "configspace": "", "generation": 56, "fitness": 0.39482054048780446, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.26.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7543133626055597, 0.7543133626055597, 0.7543133626055597, 0.7593026990899946, 0.7593026990899946, 0.7593026990899946, 0.7403636557104716, 0.7403636557104716, 0.7403636557104716, 0.5594637871209884, 0.5594637871209884, 0.5594637871209884, 0.552987132287138, 0.552987132287138, 0.552987132287138, 0.5736325509981511, 0.5736325509981511, 0.5736325509981511, 0.11329207563208188, 0.11329207563208188, 0.11329207563208188, 0.12071054477302201, 0.12071054477302201, 0.12071054477302201, 0.10431774480775224, 0.10431774480775224, 0.10431774480775224, 0.11988044225190242, 0.11988044225190242, 0.11988044225190242, 0.09899144905558332, 0.09899144905558332, 0.09899144905558332, 0.1318618809288773, 0.1318618809288773, 0.1318618809288773, 0.9868101343291392, 0.9868101343291392, 0.9868101343291392, 0.9858853552682719, 0.9858853552682719, 0.9858853552682719, 0.9828798711015232, 0.9828798711015232, 0.9828798711015232, 0.590421968976057, 0.590421968976057, 0.590421968976057, 0.5208309068695571, 0.5208309068695571, 0.5208309068695571, 0.6004267557386591, 0.6004267557386591, 0.6004267557386591, 0.704181272484844, 0.704181272484844, 0.704181272484844, 0.8254513700850665, 0.8254513700850665, 0.8254513700850665, 0.7772749030285006, 0.7772749030285006, 0.7772749030285006, 0.5346206123420585, 0.5346206123420585, 0.5346206123420585, 0.12311643969456343, 0.12311643969456343, 0.12311643969456343, 0.5513874863824889, 0.5513874863824889, 0.5513874863824889, 0.45068336025031996, 0.45068336025031996, 0.45068336025031996, 0.5270768906816082, 0.5270768906816082, 0.5270768906816082, 0.12781828375792414, 0.12781828375792414, 0.12781828375792414, 0.5029158192437095, 0.5029158192437095, 0.5029158192437095, 0.4664653902793572, 0.4664653902793572, 0.4664653902793572, 0.5066166489746824, 0.5066166489746824, 0.5066166489746824, 0.5800022633797227, 0.5800022633797227, 0.5800022633797227, 0.5469507449834109, 0.5469507449834109, 0.5469507449834109, 0.5873314204875597, 0.5873314204875597, 0.5873314204875597, 0.08485014879750907, 0.08485014879750907, 0.08485014879750907, 0.43039881414137193, 0.43039881414137193, 0.43039881414137193, 0.2209877413917123, 0.2209877413917123, 0.2209877413917123, 0.010592560500631176, 0.010592560500631176, 0.010592560500631176, 0.3216274733355059, 0.3216274733355059, 0.3216274733355059, 0.43064457937812994, 0.43064457937812994, 0.43064457937812994, 0.7186622627251937, 0.7186622627251937, 0.7186622627251937, 0.2085303139815492, 0.2085303139815492, 0.2085303139815492, 0.7021275779981755, 0.7021275779981755, 0.7021275779981755, 0.10846288914765378, 0.10846288914765378, 0.10846288914765378, 0.14771764510618302, 0.14771764510618302, 0.14771764510618302, 0.09295672032320945, 0.09295672032320945, 0.09295672032320945, 0.22789634131306713, 0.22789634131306713, 0.22789634131306713, 0.2258825445005701, 0.2258825445005701, 0.2258825445005701, 0.18249337559705914, 0.18249337559705914, 0.18249337559705914, 0.4424737457840009, 0.4424737457840009, 0.4424737457840009, 0.21368122818249802, 0.21368122818249802, 0.21368122818249802, 0.5271206861298219, 0.5271206861298219, 0.5271206861298219, 0.3951212851533391, 0.3951212851533391, 0.3951212851533391, 0.45207732525625544, 0.45207732525625544, 0.45207732525625544, 0.20189468441173386, 0.20189468441173386, 0.20189468441173386, 0.21713179709654395, 0.21713179709654395, 0.21713179709654395, 0.24768008321168156, 0.24768008321168156, 0.24768008321168156, 0.2049356210466804, 0.2049356210466804, 0.2049356210466804, 0.20750769215493148, 0.20750769215493148, 0.20750769215493148, 0.22895199842928082, 0.22895199842928082, 0.22895199842928082, 0.19980077317249478, 0.19980077317249478, 0.19980077317249478, 0.8319438064121885, 0.8319438064121885, 0.8319438064121885, 0.17802422670811757, 0.17802422670811757, 0.17802422670811757, 0.7630155490335747, 0.7630155490335747, 0.7630155490335747, 0.16787969045278317, 0.16787969045278317, 0.16787969045278317, 0.19811235438952957, 0.19811235438952957, 0.19811235438952957, 0.6132502001180662, 0.6132502001180662, 0.6132502001180662, 0.1998560154357365, 0.1998560154357365, 0.1998560154357365, 0.2264852044115797, 0.2264852044115797, 0.2264852044115797, 0.19854561647591795, 0.19854561647591795, 0.19854561647591795, 0.0967133481320821, 0.0967133481320821, 0.0967133481320821, 0.09967892571334236, 0.09967892571334236, 0.09967892571334236, 0.09310084597167534, 0.09310084597167534, 0.09310084597167534]}, "mutation_prompt": null}
{"id": "d2497016-d26e-46bc-899f-620c1b2f3ec2", "solution": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n        self.adaptive_rate = 0.1  # Adaptive rate for parameter adjustment\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n        prev_global_best_score = global_best_score\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            improvement = prev_global_best_score - global_best_score\n            self.w = max(0.4, self.w * (1 + self.adaptive_rate * improvement))\n            self.f = max(0.4, self.f * (1 + self.adaptive_rate * improvement))\n            prev_global_best_score = global_best_score\n            \n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "AdaptiveHybridPSODE", "description": "A refined adaptive hybrid PSO-DE optimizer that dynamically adjusts exploration and exploitation based on convergence trends for optimized performance across diverse fitness landscapes.", "configspace": "", "generation": 57, "fitness": 0.12068867382518561, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.21.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.361026030118655, 0.361026030118655, 0.361026030118655, 0.1539448778701118, 0.1539448778701118, 0.1539448778701118, 0.17766227034133242, 0.17766227034133242, 0.17766227034133242, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05237834215147452, 0.05237834215147452, 0.05237834215147452, 0.017437714213633604, 0.017437714213633604, 0.017437714213633604, 0.030610520887227044, 0.030610520887227044, 0.030610520887227044, 0.00030337761656751283, 0.00030337761656751283, 0.00030337761656751283, 0.0018456107748670014, 0.0018456107748670014, 0.0018456107748670014, 0.008491298122517588, 0.008491298122517588, 0.008491298122517588, 0.9867045447840113, 0.9867045447840113, 0.9867045447840113, 0.985283715322839, 0.985283715322839, 0.985283715322839, 0.9875185762782303, 0.9875185762782303, 0.9875185762782303, 0.054076884804846514, 0.054076884804846514, 0.054076884804846514, 0.015961869355356262, 0.015961869355356262, 0.015961869355356262, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11788237951697178, 0.11788237951697178, 0.11788237951697178, 0.16032068487717754, 0.16032068487717754, 0.16032068487717754, 0.037863292123044845, 0.037863292123044845, 0.037863292123044845, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5601756814828853, 0.5601756814828853, 0.5601756814828853, 0.19330155012236316, 0.19330155012236316, 0.19330155012236316, 0.2577926920779039, 0.2577926920779039, 0.2577926920779039, 0.03595822540890259, 0.03595822540890259, 0.03595822540890259, 0.028533923621293034, 0.028533923621293034, 0.028533923621293034, 0.01970831953144969, 0.01970831953144969, 0.01970831953144969, 0.11755098129365538, 0.11755098129365538, 0.11755098129365538, 0.12526427133620088, 0.12526427133620088, 0.12526427133620088, 0.13348774283036346, 0.13348774283036346, 0.13348774283036346, 0.1937143085063674, 0.1937143085063674, 0.1937143085063674, 0.17517618699932447, 0.17517618699932447, 0.17517618699932447, 0.17424006088506827, 0.17424006088506827, 0.17424006088506827, 0.0798236024526332, 0.0798236024526332, 0.0798236024526332, 0.09795186743952633, 0.09795186743952633, 0.09795186743952633, 0.11679245775215386, 0.11679245775215386, 0.11679245775215386, 0.15230780074123118, 0.15230780074123118, 0.15230780074123118, 0.14156586650177283, 0.14156586650177283, 0.14156586650177283, 0.1947179869867428, 0.1947179869867428, 0.1947179869867428, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010289928137811821, 0.010289928137811821, 0.010289928137811821, 0.4606522987078078, 0.4606522987078078, 0.4606522987078078, 0.14653072247195364, 0.14653072247195364, 0.14653072247195364, 0.10537889313172999, 0.10537889313172999, 0.10537889313172999, 0.10930813441126541, 0.10930813441126541, 0.10930813441126541, 0.16719338547580642, 0.16719338547580642, 0.16719338547580642, 0.11191329556087581, 0.11191329556087581, 0.11191329556087581, 0.1811760960023815, 0.1811760960023815, 0.1811760960023815, 0.1799276655607409, 0.1799276655607409, 0.1799276655607409, 0.17663976647441415, 0.17663976647441415, 0.17663976647441415, 0.042302682526136004, 0.042302682526136004, 0.042302682526136004, 0.027590159629176325, 0.027590159629176325, 0.027590159629176325, 0.020905972194563804, 0.020905972194563804, 0.020905972194563804]}, "mutation_prompt": null}
{"id": "0b3cf272-b681-4026-9151-47bcb85c23c6", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "28204d62-5057-42a6-b440-34ffd28d6e93", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "f40f7908-081d-45f8-8a7f-5cd87df101ea", "solution": "import numpy as np\nimport math\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.f = 0.8\n        self.cr = 0.9\n        self.epsilon = 1e-8\n\n    def chaotic_init(self, size, dim):\n        return self.lower_bound + (self.upper_bound - self.lower_bound) * np.random.rand(size, dim)**3\n\n    def adaptive_params(self, iter_max, current_iter):\n        self.w = 0.9 - ((0.9 - 0.4) * (current_iter / iter_max))\n        self.f = 0.5 + ((0.8 - 0.5) * (current_iter / iter_max))\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = self.chaotic_init(self.pop_size, self.dim)\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        iter_max = self.budget // self.pop_size\n        current_iter = 0\n\n        while eval_count < self.budget:\n            self.adaptive_params(iter_max, current_iter)\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n\n            current_iter += 1\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameters and chaotic initialization to improve exploration and convergence efficiency in diverse landscapes.", "configspace": "", "generation": 60, "fitness": 0.31358303833376544, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.24.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.6645861827102328, 0.6645861827102328, 0.6645861827102328, 0.8545708041754766, 0.8545708041754766, 0.8545708041754766, 0.7832868999961564, 0.7832868999961564, 0.7832868999961564, 0.4960896407395372, 0.4960896407395372, 0.4960896407395372, 0.4204251927267959, 0.4204251927267959, 0.4204251927267959, 0.5474037270113385, 0.5474037270113385, 0.5474037270113385, 0.29526836181400473, 0.29526836181400473, 0.29526836181400473, 0.12260385356212677, 0.12260385356212677, 0.12260385356212677, 0.11074371919263415, 0.11074371919263415, 0.11074371919263415, 0.0918656092362331, 0.0918656092362331, 0.0918656092362331, 0.11124641428104731, 0.11124641428104731, 0.11124641428104731, 0.10651779892118196, 0.10651779892118196, 0.10651779892118196, 0.9834754151077827, 0.9834754151077827, 0.9834754151077827, 0.9835342659840756, 0.9835342659840756, 0.9835342659840756, 0.9870652472387117, 0.9870652472387117, 0.9870652472387117, 0.05942987024239432, 0.05942987024239432, 0.05942987024239432, 0.45189044644452225, 0.45189044644452225, 0.45189044644452225, 0.0859891382871707, 0.0859891382871707, 0.0859891382871707, 0.8042678515421728, 0.8042678515421728, 0.8042678515421728, 0.6776573995283336, 0.6776573995283336, 0.6776573995283336, 0.16035448962081877, 0.16035448962081877, 0.16035448962081877, 0.3143766112777421, 0.3143766112777421, 0.3143766112777421, 0.3177220296661206, 0.3177220296661206, 0.3177220296661206, 0.3261478394540894, 0.3261478394540894, 0.3261478394540894, 0.32599181817152334, 0.32599181817152334, 0.32599181817152334, 0.35051546159787295, 0.35051546159787295, 0.35051546159787295, 0.2654121150903995, 0.2654121150903995, 0.2654121150903995, 0.07010622678893674, 0.07010622678893674, 0.07010622678893674, 0.33731390530442573, 0.33731390530442573, 0.33731390530442573, 0.21202679409265912, 0.21202679409265912, 0.21202679409265912, 0.19532466092254097, 0.19532466092254097, 0.19532466092254097, 0.032427385251435625, 0.032427385251435625, 0.032427385251435625, 0.2886694485497958, 0.2886694485497958, 0.2886694485497958, 0.06631250544553291, 0.06631250544553291, 0.06631250544553291, 0.19496074350103587, 0.19496074350103587, 0.19496074350103587, 0.2578105200293902, 0.2578105200293902, 0.2578105200293902, 0.17614901666835936, 0.17614901666835936, 0.17614901666835936, 0.21185642488857415, 0.21185642488857415, 0.21185642488857415, 0.28409614530511296, 0.28409614530511296, 0.28409614530511296, 0.5744382510546726, 0.5744382510546726, 0.5744382510546726, 0.20642973369315398, 0.20642973369315398, 0.20642973369315398, 0.549569148603563, 0.549569148603563, 0.549569148603563, 0.08717671112684022, 0.08717671112684022, 0.08717671112684022, 0.10725545095749078, 0.10725545095749078, 0.10725545095749078, 0.11379591503837605, 0.11379591503837605, 0.11379591503837605, 0.5920419384761542, 0.5920419384761542, 0.5920419384761542, 0.30222868545656434, 0.30222868545656434, 0.30222868545656434, 0.20778239956424527, 0.20778239956424527, 0.20778239956424527, 0.2718943488293881, 0.2718943488293881, 0.2718943488293881, 0.21860920616673019, 0.21860920616673019, 0.21860920616673019, 0.4186562307242391, 0.4186562307242391, 0.4186562307242391, 0.3047656000683392, 0.3047656000683392, 0.3047656000683392, 0.20100342853309394, 0.20100342853309394, 0.20100342853309394, 0.20053203004753684, 0.20053203004753684, 0.20053203004753684, 0.2053712827183506, 0.2053712827183506, 0.2053712827183506, 0.20873088355891856, 0.20873088355891856, 0.20873088355891856, 0.21524330246133982, 0.21524330246133982, 0.21524330246133982, 0.20198661309897803, 0.20198661309897803, 0.20198661309897803, 0.21395685737555825, 0.21395685737555825, 0.21395685737555825, 0.2009879629370913, 0.2009879629370913, 0.2009879629370913, 0.7831314443058046, 0.7831314443058046, 0.7831314443058046, 0.16747084475534701, 0.16747084475534701, 0.16747084475534701, 0.15154409404489466, 0.15154409404489466, 0.15154409404489466, 0.2082532427185242, 0.2082532427185242, 0.2082532427185242, 0.20751971412785775, 0.20751971412785775, 0.20751971412785775, 0.5650448559469592, 0.5650448559469592, 0.5650448559469592, 0.18620924672391215, 0.18620924672391215, 0.18620924672391215, 0.2127035002640174, 0.2127035002640174, 0.2127035002640174, 0.20345599180598184, 0.20345599180598184, 0.20345599180598184, 0.08907413315091672, 0.08907413315091672, 0.08907413315091672, 0.08423501849010939, 0.08423501849010939, 0.08423501849010939, 0.09138871283786598, 0.09138871283786598, 0.09138871283786598]}, "mutation_prompt": null}
{"id": "af21b716-3a64-45c5-bf46-1512cd7619f5", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "b127f0ed-c9c7-4a7a-be35-5cbe09cffb02", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "262bd4eb-c47f-4c9a-883e-d66326012ee9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "ec8caff5-a0b5-4c43-9070-7677caa9461b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "dade0137-ca03-418e-b8be-e89a73bfbce5", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "b94e88bc-2913-417c-967f-1677c703517f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "bbe56c7a-fe14-4cb6-b9e4-b118b1fcc053", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "27b5ec47-a586-4cbb-8d47-a63d03f26b0e", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr_init = 0.9  # Initial DE crossover probability\n        self.elite_frac = 0.2  # Fraction of elite individuals\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            w = self.w_final + (self.w_init - self.w_final) * ((self.budget - eval_count) / self.budget)\n            cr = self.cr_init - 0.5 * ((self.budget - eval_count) / self.budget)\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            elite_count = max(1, int(self.elite_frac * self.pop_size))\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            \n            for i in range(self.pop_size):\n                if i in elite_indices:\n                    continue\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "Enhanced Hybrid PSO-DE with adaptive control parameters and elitism to balance exploration and exploitation for improved convergence.", "configspace": "", "generation": 68, "fitness": 0.3078082534817182, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.25.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7252540458379886, 0.7252540458379886, 0.7252540458379886, 0.7307306552306323, 0.7307306552306323, 0.7307306552306323, 0.7227573115206173, 0.7227573115206173, 0.7227573115206173, 0.4478337914782131, 0.4478337914782131, 0.4478337914782131, 0.4563300004766637, 0.4563300004766637, 0.4563300004766637, 0.04519390353561881, 0.04519390353561881, 0.04519390353561881, 0.13201102501786044, 0.13201102501786044, 0.13201102501786044, 0.1397960352150761, 0.1397960352150761, 0.1397960352150761, 0.12965157799958527, 0.12965157799958527, 0.12965157799958527, 0.12292629646986719, 0.12292629646986719, 0.12292629646986719, 0.12910969671316708, 0.12910969671316708, 0.12910969671316708, 0.12455007001211504, 0.12455007001211504, 0.12455007001211504, 0.9720564171737769, 0.9720564171737769, 0.9720564171737769, 0.9608541281578299, 0.9608541281578299, 0.9608541281578299, 0.9881611188254936, 0.9881611188254936, 0.9881611188254936, 0.5948524546724736, 0.5948524546724736, 0.5948524546724736, 0.5692121813107165, 0.5692121813107165, 0.5692121813107165, 0.5470596849384656, 0.5470596849384656, 0.5470596849384656, 0.2109480054194529, 0.2109480054194529, 0.2109480054194529, 0.16004973988409144, 0.16004973988409144, 0.16004973988409144, 0.22641176028550347, 0.22641176028550347, 0.22641176028550347, 0.23795110836645994, 0.23795110836645994, 0.23795110836645994, 0.4191397467382628, 0.4191397467382628, 0.4191397467382628, 0.26628814490103714, 0.26628814490103714, 0.26628814490103714, 0.32638093277636737, 0.32638093277636737, 0.32638093277636737, 0.39148210666758865, 0.39148210666758865, 0.39148210666758865, 0.3941927172370241, 0.3941927172370241, 0.3941927172370241, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04203108416566792, 0.04203108416566792, 0.04203108416566792, 0.004563452799193679, 0.004563452799193679, 0.004563452799193679, 0.16676750018056552, 0.16676750018056552, 0.16676750018056552, 0.05531495868983727, 0.05531495868983727, 0.05531495868983727, 0.3661747660925939, 0.3661747660925939, 0.3661747660925939, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07433093211131014, 0.07433093211131014, 0.07433093211131014, 0.05813348154578668, 0.05813348154578668, 0.05813348154578668, 0.07755906082834718, 0.07755906082834718, 0.07755906082834718, 0.28091662329430256, 0.28091662329430256, 0.28091662329430256, 0.07620857604774478, 0.07620857604774478, 0.07620857604774478, 0.6029609961728605, 0.6029609961728605, 0.6029609961728605, 0.6142972814009763, 0.6142972814009763, 0.6142972814009763, 0.6366557178463805, 0.6366557178463805, 0.6366557178463805, 0.0948008553552836, 0.0948008553552836, 0.0948008553552836, 0.13054615936729663, 0.13054615936729663, 0.13054615936729663, 0.12644461407213314, 0.12644461407213314, 0.12644461407213314, 0.23377673814291078, 0.23377673814291078, 0.23377673814291078, 0.2345651628072929, 0.2345651628072929, 0.2345651628072929, 0.13329892253119413, 0.13329892253119413, 0.13329892253119413, 0.4151991939169225, 0.4151991939169225, 0.4151991939169225, 0.4631544277180215, 0.4631544277180215, 0.4631544277180215, 0.4161558230589697, 0.4161558230589697, 0.4161558230589697, 0.16400574357831865, 0.16400574357831865, 0.16400574357831865, 0.1958072491217333, 0.1958072491217333, 0.1958072491217333, 0.13391633371225087, 0.13391633371225087, 0.13391633371225087, 0.2568744094313288, 0.2568744094313288, 0.2568744094313288, 0.23868921131006526, 0.23868921131006526, 0.23868921131006526, 0.22802493966764126, 0.22802493966764126, 0.22802493966764126, 0.19853847690037252, 0.19853847690037252, 0.19853847690037252, 0.2258699879321704, 0.2258699879321704, 0.2258699879321704, 0.20009490110598593, 0.20009490110598593, 0.20009490110598593, 0.874544893881033, 0.874544893881033, 0.874544893881033, 0.19694724334549096, 0.19694724334549096, 0.19694724334549096, 0.8050867636219472, 0.8050867636219472, 0.8050867636219472, 0.7073115957489484, 0.7073115957489484, 0.7073115957489484, 0.2081923355084606, 0.2081923355084606, 0.2081923355084606, 0.1955017547157285, 0.1955017547157285, 0.1955017547157285, 0.19683511757098382, 0.19683511757098382, 0.19683511757098382, 0.19693063630763707, 0.19693063630763707, 0.19693063630763707, 0.17828281814560465, 0.17828281814560465, 0.17828281814560465, 0.09117120381821442, 0.09117120381821442, 0.09117120381821442, 0.10884509898348937, 0.10884509898348937, 0.10884509898348937, 0.08548255126876869, 0.08548255126876869, 0.08548255126876869]}, "mutation_prompt": null}
{"id": "4d8362a3-0d2d-4bb4-9912-0b43c68847d3", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "2d302a1d-05ba-4fff-badf-3832a4b5fa18", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "6992242c-2842-4c34-88e8-2e3aeb3ae104", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "ac9e3061-2d41-4e2e-a44e-5fdf3c9641a2", "solution": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1_initial = 1.5  # Initial PSO cognitive coefficient\n        self.c2_initial = 1.5  # Initial PSO social coefficient\n        self.w_initial = 0.7  # Initial inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr_initial = 0.9  # Initial DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Dynamic adjustment\n            progress = eval_count / self.budget\n            w = self.w_initial * (1 - progress)\n            c1 = self.c1_initial * (1 + progress)\n            c2 = self.c2_initial * (1 + progress)\n            cr = self.cr_initial * (1 - progress)\n\n            # Neighborhood learning\n            for i in range(self.pop_size):\n                neighbors = np.random.choice(self.pop_size, 3, replace=False)\n                r1, r2 = np.random.rand(2)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[neighbors[0]] - pop[i]) +\n                                 c2 * r2 * (global_best_position - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], self.lower_bound, self.upper_bound)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n\n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best_position, global_best_score", "name": "AdaptiveHybridPSODE", "description": "An enhanced adaptive hybrid PSO-DE optimizer leveraging dynamic coefficients and neighborhood learning for improved exploration and exploitation balance.", "configspace": "", "generation": 72, "fitness": 0.27606627612819107, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.25.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7520175096917593, 0.7520175096917593, 0.7520175096917593, 0.18233841752340996, 0.18233841752340996, 0.18233841752340996, 0.7305753692167167, 0.7305753692167167, 0.7305753692167167, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0620208274263474, 0.0620208274263474, 0.0620208274263474, 0.4483928997946687, 0.4483928997946687, 0.4483928997946687, 0.10059993780100973, 0.10059993780100973, 0.10059993780100973, 0.08905138720348327, 0.08905138720348327, 0.08905138720348327, 0.08563621752320505, 0.08563621752320505, 0.08563621752320505, 0.09183818608028638, 0.09183818608028638, 0.09183818608028638, 0.0819323446801078, 0.0819323446801078, 0.0819323446801078, 0.09678167795561954, 0.09678167795561954, 0.09678167795561954, 0.9938310799863362, 0.9938310799863362, 0.9938310799863362, 0.9908578898158458, 0.9908578898158458, 0.9908578898158458, 0.9850998128349463, 0.9850998128349463, 0.9850998128349463, 0.42054835694478554, 0.42054835694478554, 0.42054835694478554, 0.38428776307566825, 0.38428776307566825, 0.38428776307566825, 0.08852151976362255, 0.08852151976362255, 0.08852151976362255, 0.7559424219330634, 0.7559424219330634, 0.7559424219330634, 0.7878132490013666, 0.7878132490013666, 0.7878132490013666, 0.7845268780807785, 0.7845268780807785, 0.7845268780807785, 0.26515922857494545, 0.26515922857494545, 0.26515922857494545, 0.12621999274780393, 0.12621999274780393, 0.12621999274780393, 0.25638220907647424, 0.25638220907647424, 0.25638220907647424, 0.31592511228497, 0.31592511228497, 0.31592511228497, 0.1901733784003542, 0.1901733784003542, 0.1901733784003542, 0.18394592721713365, 0.18394592721713365, 0.18394592721713365, 0.059934066431731825, 0.059934066431731825, 0.059934066431731825, 0.04591965413983401, 0.04591965413983401, 0.04591965413983401, 0.25631849664441675, 0.25631849664441675, 0.25631849664441675, 0.15925962932816096, 0.15925962932816096, 0.15925962932816096, 0.11699159976819651, 0.11699159976819651, 0.11699159976819651, 0.1550220244244872, 0.1550220244244872, 0.1550220244244872, 0.030980833118442908, 0.030980833118442908, 0.030980833118442908, 0.10260645638581811, 0.10260645638581811, 0.10260645638581811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.23980756401048042, 0.23980756401048042, 0.23980756401048042, 0.25104121136321145, 0.25104121136321145, 0.25104121136321145, 0.04821304313491781, 0.04821304313491781, 0.04821304313491781, 0.6256818173324512, 0.6256818173324512, 0.6256818173324512, 0.5652338892655577, 0.5652338892655577, 0.5652338892655577, 0.5658727302919414, 0.5658727302919414, 0.5658727302919414, 0.11213249857535013, 0.11213249857535013, 0.11213249857535013, 0.09076948841608212, 0.09076948841608212, 0.09076948841608212, 0.09543842744961006, 0.09543842744961006, 0.09543842744961006, 0.16437877955461877, 0.16437877955461877, 0.16437877955461877, 0.2692684841525713, 0.2692684841525713, 0.2692684841525713, 0.2449075007978957, 0.2449075007978957, 0.2449075007978957, 0.24336285042614325, 0.24336285042614325, 0.24336285042614325, 0.2142982966435829, 0.2142982966435829, 0.2142982966435829, 0.35923325912901005, 0.35923325912901005, 0.35923325912901005, 0.27447183730960467, 0.27447183730960467, 0.27447183730960467, 0.19998962403741427, 0.19998962403741427, 0.19998962403741427, 0.13221669250486612, 0.13221669250486612, 0.13221669250486612, 0.1760173678507284, 0.1760173678507284, 0.1760173678507284, 0.19564414869463387, 0.19564414869463387, 0.19564414869463387, 0.20390601872584113, 0.20390601872584113, 0.20390601872584113, 0.20544212268447248, 0.20544212268447248, 0.20544212268447248, 0.19177545974167864, 0.19177545974167864, 0.19177545974167864, 0.22603285686492947, 0.22603285686492947, 0.22603285686492947, 0.8682363450090832, 0.8682363450090832, 0.8682363450090832, 0.1748966268755504, 0.1748966268755504, 0.1748966268755504, 0.16553000203777668, 0.16553000203777668, 0.16553000203777668, 0.16855032898606082, 0.16855032898606082, 0.16855032898606082, 0.4876088810047918, 0.4876088810047918, 0.4876088810047918, 0.15492567985385663, 0.15492567985385663, 0.15492567985385663, 0.17779059722338586, 0.17779059722338586, 0.17779059722338586, 0.17218237942037218, 0.17218237942037218, 0.17218237942037218, 0.19836793770766004, 0.19836793770766004, 0.19836793770766004, 0.07282431983464721, 0.07282431983464721, 0.07282431983464721, 0.08891435310767681, 0.08891435310767681, 0.08891435310767681, 0.07415610633550318, 0.07415610633550318, 0.07415610633550318]}, "mutation_prompt": null}
{"id": "03a77a58-129e-4bcf-8eb0-4ee37c5eb357", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.f_initial = 0.8\n        self.cr_initial = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            self.w = 0.4 + 0.3 * (1 - eval_count / self.budget)\n\n            r1, r2 = np.random.rand(2)\n            # PSO Update\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update with Dynamic Parameters\n            f = self.f_initial * (1 - eval_count / self.budget)\n            cr = self.cr_initial * (eval_count / self.budget)\n            \n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameters and local search to balance exploration and exploitation dynamically for improved convergence.", "configspace": "", "generation": 73, "fitness": 0.2647303445478239, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.25.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.8647075023948918, 0.8647075023948918, 0.8647075023948918, 0.17085476379241316, 0.17085476379241316, 0.17085476379241316, 0.8689655783438233, 0.8689655783438233, 0.8689655783438233, 0.6050028250644931, 0.6050028250644931, 0.6050028250644931, 0.41764718119099575, 0.41764718119099575, 0.41764718119099575, 0.11006446130114078, 0.11006446130114078, 0.11006446130114078, 0.1840397241010966, 0.1840397241010966, 0.1840397241010966, 0.10070970666654355, 0.10070970666654355, 0.10070970666654355, 0.17750511986367068, 0.17750511986367068, 0.17750511986367068, 0.06850953477513722, 0.06850953477513722, 0.06850953477513722, 0.08256743629976449, 0.08256743629976449, 0.08256743629976449, 0.13156016434248963, 0.13156016434248963, 0.13156016434248963, 0.9587305832037003, 0.9587305832037003, 0.9587305832037003, 0.9628838280255183, 0.9628838280255183, 0.9628838280255183, 0.954306941767115, 0.954306941767115, 0.954306941767115, 0.7784708044813327, 0.7784708044813327, 0.7784708044813327, 0.7690375837335485, 0.7690375837335485, 0.7690375837335485, 0.16406851580399784, 0.16406851580399784, 0.16406851580399784, 0.16010137929200197, 0.16010137929200197, 0.16010137929200197, 0.2730581868664307, 0.2730581868664307, 0.2730581868664307, 0.1389083177133703, 0.1389083177133703, 0.1389083177133703, 0.12957757872433873, 0.12957757872433873, 0.12957757872433873, 0.43793448007801694, 0.43793448007801694, 0.43793448007801694, 0.21098728479734263, 0.21098728479734263, 0.21098728479734263, 0.1915802129449582, 0.1915802129449582, 0.1915802129449582, 0.13098966695722303, 0.13098966695722303, 0.13098966695722303, 0.19059884543527383, 0.19059884543527383, 0.19059884543527383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12351656734389127, 0.12351656734389127, 0.12351656734389127, 0.07695733972190322, 0.07695733972190322, 0.07695733972190322, 0.12329912692702694, 0.12329912692702694, 0.12329912692702694, 0.0763643772394329, 0.0763643772394329, 0.0763643772394329, 0.08591465731872938, 0.08591465731872938, 0.08591465731872938, 0.23336161230339325, 0.23336161230339325, 0.23336161230339325, 0.09805538680143766, 0.09805538680143766, 0.09805538680143766, 0.09429747524548493, 0.09429747524548493, 0.09429747524548493, 0.1691737016064524, 0.1691737016064524, 0.1691737016064524, 0.16197054215217044, 0.16197054215217044, 0.16197054215217044, 0.5170967619631188, 0.5170967619631188, 0.5170967619631188, 0.5676661487241699, 0.5676661487241699, 0.5676661487241699, 0.5721365540903209, 0.5721365540903209, 0.5721365540903209, 0.14007163603239292, 0.14007163603239292, 0.14007163603239292, 0.07698110210715481, 0.07698110210715481, 0.07698110210715481, 0.14280698794399127, 0.14280698794399127, 0.14280698794399127, 0.26081187657357763, 0.26081187657357763, 0.26081187657357763, 0.2481926543175138, 0.2481926543175138, 0.2481926543175138, 0.20108373997989848, 0.20108373997989848, 0.20108373997989848, 0.16418417069382962, 0.16418417069382962, 0.16418417069382962, 0.1994418928587942, 0.1994418928587942, 0.1994418928587942, 0.18664042540116121, 0.18664042540116121, 0.18664042540116121, 0.15965751501763337, 0.15965751501763337, 0.15965751501763337, 0.18380105880189856, 0.18380105880189856, 0.18380105880189856, 0.1235238582193886, 0.1235238582193886, 0.1235238582193886, 0.23846204307080032, 0.23846204307080032, 0.23846204307080032, 0.2295253858135683, 0.2295253858135683, 0.2295253858135683, 0.24734121036256096, 0.24734121036256096, 0.24734121036256096, 0.17126847868621864, 0.17126847868621864, 0.17126847868621864, 0.20067952181800852, 0.20067952181800852, 0.20067952181800852, 0.2231820033186519, 0.2231820033186519, 0.2231820033186519, 0.8933432069687337, 0.8933432069687337, 0.8933432069687337, 0.19816822908745346, 0.19816822908745346, 0.19816822908745346, 0.13618015448046406, 0.13618015448046406, 0.13618015448046406, 0.1603535714282983, 0.1603535714282983, 0.1603535714282983, 0.2068471249036865, 0.2068471249036865, 0.2068471249036865, 0.09487907240798066, 0.09487907240798066, 0.09487907240798066, 0.19696587134184873, 0.19696587134184873, 0.19696587134184873, 0.2006695722962305, 0.2006695722962305, 0.2006695722962305, 0.1935539645928993, 0.1935539645928993, 0.1935539645928993, 0.08111648398354188, 0.08111648398354188, 0.08111648398354188, 0.06525010789956509, 0.06525010789956509, 0.06525010789956509, 0.10222342763741488, 0.10222342763741488, 0.10222342763741488]}, "mutation_prompt": null}
{"id": "8cbb92a6-9262-4f71-9f58-4b0ae7ed48c2", "solution": "import numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\n\nclass EnhancedPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.f = 0.8\n        self.cr = 0.9\n        self.forest = RandomForestRegressor(n_estimators=10, random_state=42)\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n        samples = np.copy(pop)\n        scores = np.copy(personal_best_scores)\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n            \n            samples = np.concatenate((samples, pop), axis=0)\n            scores = np.concatenate((scores, personal_best_scores), axis=0)\n            self.forest.fit(samples, scores)\n            predicted_scores = self.forest.predict(pop)\n            better_mask = predicted_scores < personal_best_scores\n            \n            personal_best_scores = np.where(better_mask, predicted_scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n\n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedPSODE", "description": "Enhanced Hybrid PSO-DE optimizer integrating Adaptive Random Forest-based guidance to balance exploration and exploitation.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "An exception occurred: ModuleNotFoundError(\"No module named 'sklearn'\").", "error": "ModuleNotFoundError(\"No module named 'sklearn'\")", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {}, "mutation_prompt": null}
{"id": "1ee588f0-acfa-4d85-a483-715df095c6fa", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "23258d51-5df7-4710-8850-fdd8ab7c4100", "solution": "import numpy as np\n\nclass AdaptiveHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1_initial = 2.0  # Initial PSO cognitive coefficient\n        self.c2_initial = 2.0  # Initial PSO social coefficient\n        self.w_initial = 0.9  # Initial inertia weight\n        self.f_min = 0.5  # Minimum DE scaling factor\n        self.f_max = 0.9  # Maximum DE scaling factor\n        self.cr_min = 0.5  # Minimum DE crossover probability\n        self.cr_max = 0.9  # Maximum DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive parameters\n            progress = eval_count / self.budget\n            self.w = self.w_initial * (1 - progress)\n            self.c1 = self.c1_initial * (1 - progress) + 1.5 * progress\n            self.c2 = self.c2_initial * (1 - progress) + 1.5 * progress\n\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update with adaptive parameters\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                f = self.f_min + (self.f_max - self.f_min) * progress\n                mutant = personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                cr = self.cr_min + (self.cr_max - self.cr_min) * progress\n                trial = np.where(np.random.rand(self.dim) < cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "AdaptiveHybridPSODE", "description": "An enhanced hybrid PSO-DE algorithm incorporating adaptive parameters for balancing exploration and exploitation dynamically during the optimization process.", "configspace": "", "generation": 76, "fitness": 0.3212709492089339, "feedback": "The algorithm AdaptiveHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.26.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7810988343483294, 0.7810988343483294, 0.7810988343483294, 0.7816917730171158, 0.7816917730171158, 0.7816917730171158, 0.7712110557968967, 0.7712110557968967, 0.7712110557968967, 0.6023096027205007, 0.6023096027205007, 0.6023096027205007, 0.582129135234047, 0.582129135234047, 0.582129135234047, 0.6054813748822563, 0.6054813748822563, 0.6054813748822563, 0.14136082197024824, 0.14136082197024824, 0.14136082197024824, 0.13326519597554376, 0.13326519597554376, 0.13326519597554376, 0.12943648700224875, 0.12943648700224875, 0.12943648700224875, 0.12446851371728995, 0.12446851371728995, 0.12446851371728995, 0.10521272679037175, 0.10521272679037175, 0.10521272679037175, 0.1380479345045864, 0.1380479345045864, 0.1380479345045864, 0.9827574428726318, 0.9827574428726318, 0.9827574428726318, 0.9868477472588928, 0.9868477472588928, 0.9868477472588928, 0.9863600180342886, 0.9863600180342886, 0.9863600180342886, 0.6476525333004224, 0.6476525333004224, 0.6476525333004224, 0.14420264590989829, 0.14420264590989829, 0.14420264590989829, 0.6474219327947714, 0.6474219327947714, 0.6474219327947714, 0.21600936673547044, 0.21600936673547044, 0.21600936673547044, 0.20892076052704367, 0.20892076052704367, 0.20892076052704367, 0.22602603856075254, 0.22602603856075254, 0.22602603856075254, 0.24970585352057473, 0.24970585352057473, 0.24970585352057473, 0.12466311624058013, 0.12466311624058013, 0.12466311624058013, 0.12660521909509537, 0.12660521909509537, 0.12660521909509537, 0.2277707063007931, 0.2277707063007931, 0.2277707063007931, 0.32469097623693244, 0.32469097623693244, 0.32469097623693244, 0.30347891388837245, 0.30347891388837245, 0.30347891388837245, 0.18545671993871649, 0.18545671993871649, 0.18545671993871649, 0.04818700390634734, 0.04818700390634734, 0.04818700390634734, 0.1545015924176827, 0.1545015924176827, 0.1545015924176827, 0.12395555410304637, 0.12395555410304637, 0.12395555410304637, 0.13502967673680555, 0.13502967673680555, 0.13502967673680555, 0.39793534335881964, 0.39793534335881964, 0.39793534335881964, 0.04032816225122948, 0.04032816225122948, 0.04032816225122948, 0.1573732560089982, 0.1573732560089982, 0.1573732560089982, 0.08314511827610127, 0.08314511827610127, 0.08314511827610127, 0.06746687966130471, 0.06746687966130471, 0.06746687966130471, 0.20663237797432077, 0.20663237797432077, 0.20663237797432077, 0.05272248789234979, 0.05272248789234979, 0.05272248789234979, 0.65135647922716, 0.65135647922716, 0.65135647922716, 0.5370284509998117, 0.5370284509998117, 0.5370284509998117, 0.6252355245337654, 0.6252355245337654, 0.6252355245337654, 0.12543158485637562, 0.12543158485637562, 0.12543158485637562, 0.17545719040213914, 0.17545719040213914, 0.17545719040213914, 0.12948336018056705, 0.12948336018056705, 0.12948336018056705, 0.2604649755056533, 0.2604649755056533, 0.2604649755056533, 0.1785675947819243, 0.1785675947819243, 0.1785675947819243, 0.1933097583372173, 0.1933097583372173, 0.1933097583372173, 0.3181874655233602, 0.3181874655233602, 0.3181874655233602, 0.4938041978770422, 0.4938041978770422, 0.4938041978770422, 0.4591958351689889, 0.4591958351689889, 0.4591958351689889, 0.3109747675588185, 0.3109747675588185, 0.3109747675588185, 0.2509931395287748, 0.2509931395287748, 0.2509931395287748, 0.15843372053905225, 0.15843372053905225, 0.15843372053905225, 0.25593133865265394, 0.25593133865265394, 0.25593133865265394, 0.21435059970795622, 0.21435059970795622, 0.21435059970795622, 0.23207675358486968, 0.23207675358486968, 0.23207675358486968, 0.19320211097463358, 0.19320211097463358, 0.19320211097463358, 0.23656004380785156, 0.23656004380785156, 0.23656004380785156, 0.21310147330705154, 0.21310147330705154, 0.21310147330705154, 0.8633473128108476, 0.8633473128108476, 0.8633473128108476, 0.19297346186333675, 0.19297346186333675, 0.19297346186333675, 0.8598151786811279, 0.8598151786811279, 0.8598151786811279, 0.7634643668218875, 0.7634643668218875, 0.7634643668218875, 0.20812819222067924, 0.20812819222067924, 0.20812819222067924, 0.1858157996592854, 0.1858157996592854, 0.1858157996592854, 0.19999715617924807, 0.19999715617924807, 0.19999715617924807, 0.19381603172675688, 0.19381603172675688, 0.19381603172675688, 0.18922151743646187, 0.18922151743646187, 0.18922151743646187, 0.09527860290853474, 0.09527860290853474, 0.09527860290853474, 0.12270124050994857, 0.12270124050994857, 0.12270124050994857, 0.09224221740778338, 0.09224221740778338, 0.09224221740778338]}, "mutation_prompt": null}
{"id": "187bf89b-1d83-4942-a8d5-a1da4a489387", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_max = 0.9  # Max inertia weight\n        self.w_min = 0.4  # Min inertia weight\n        self.f = 0.5  # Adjusted DE scaling factor\n        self.cr = 0.9\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)  # Adaptive inertia weight\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "An enhanced hybrid PSO-DE optimizer introducing adaptive inertia weight and dynamic DE parameters to improve convergence across various fitness landscapes.", "configspace": "", "generation": 77, "fitness": 0.3595232666997855, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.26.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7490830504026973, 0.7490830504026973, 0.7490830504026973, 0.7739975536949236, 0.7739975536949236, 0.7739975536949236, 0.7348825073793557, 0.7348825073793557, 0.7348825073793557, 0.6108379965911188, 0.6108379965911188, 0.6108379965911188, 0.5832431152670163, 0.5832431152670163, 0.5832431152670163, 0.5619060862527199, 0.5619060862527199, 0.5619060862527199, 0.12905758571175519, 0.12905758571175519, 0.12905758571175519, 0.12915011349770866, 0.12915011349770866, 0.12915011349770866, 0.44959918499152274, 0.44959918499152274, 0.44959918499152274, 0.10371673936797454, 0.10371673936797454, 0.10371673936797454, 0.11761996470429859, 0.11761996470429859, 0.11761996470429859, 0.13019670879944611, 0.13019670879944611, 0.13019670879944611, 0.9673785048465932, 0.9673785048465932, 0.9673785048465932, 0.9831929105620528, 0.9831929105620528, 0.9831929105620528, 0.9800680243869054, 0.9800680243869054, 0.9800680243869054, 0.5834591589601773, 0.5834591589601773, 0.5834591589601773, 0.5642734723166625, 0.5642734723166625, 0.5642734723166625, 0.5803383124942528, 0.5803383124942528, 0.5803383124942528, 0.7921403600622965, 0.7921403600622965, 0.7921403600622965, 0.21767461814475209, 0.21767461814475209, 0.21767461814475209, 0.8324538766524121, 0.8324538766524121, 0.8324538766524121, 0.48392263386574763, 0.48392263386574763, 0.48392263386574763, 0.522486200151431, 0.522486200151431, 0.522486200151431, 0.5106909086140272, 0.5106909086140272, 0.5106909086140272, 0.18465075061894554, 0.18465075061894554, 0.18465075061894554, 0.24333338664613402, 0.24333338664613402, 0.24333338664613402, 0.49921485265666243, 0.49921485265666243, 0.49921485265666243, 0.16234888565424166, 0.16234888565424166, 0.16234888565424166, 0.1373376742075838, 0.1373376742075838, 0.1373376742075838, 0.21830923209935083, 0.21830923209935083, 0.21830923209935083, 0.15292835247848102, 0.15292835247848102, 0.15292835247848102, 0.07821226966762185, 0.07821226966762185, 0.07821226966762185, 0.17628480424628812, 0.17628480424628812, 0.17628480424628812, 0.03574448797057883, 0.03574448797057883, 0.03574448797057883, 0.1285597939446037, 0.1285597939446037, 0.1285597939446037, 0.28429715324162985, 0.28429715324162985, 0.28429715324162985, 0.15672883704036522, 0.15672883704036522, 0.15672883704036522, 0.19587125089103619, 0.19587125089103619, 0.19587125089103619, 0.09614302833443411, 0.09614302833443411, 0.09614302833443411, 0.6325143805425029, 0.6325143805425029, 0.6325143805425029, 0.5756532432253789, 0.5756532432253789, 0.5756532432253789, 0.6029024873652196, 0.6029024873652196, 0.6029024873652196, 0.12766478239893098, 0.12766478239893098, 0.12766478239893098, 0.12503791560305, 0.12503791560305, 0.12503791560305, 0.1231439484934812, 0.1231439484934812, 0.1231439484934812, 0.3532280381712134, 0.3532280381712134, 0.3532280381712134, 0.21237997194655467, 0.21237997194655467, 0.21237997194655467, 0.17476621189323982, 0.17476621189323982, 0.17476621189323982, 0.583194175253767, 0.583194175253767, 0.583194175253767, 0.5260800275463964, 0.5260800275463964, 0.5260800275463964, 0.514981641589471, 0.514981641589471, 0.514981641589471, 0.3645555682209244, 0.3645555682209244, 0.3645555682209244, 0.19913660686975176, 0.19913660686975176, 0.19913660686975176, 0.2034354801236583, 0.2034354801236583, 0.2034354801236583, 0.2435082331700692, 0.2435082331700692, 0.2435082331700692, 0.2048360409977742, 0.2048360409977742, 0.2048360409977742, 0.22702433390058796, 0.22702433390058796, 0.22702433390058796, 0.5969149553980971, 0.5969149553980971, 0.5969149553980971, 0.21004174351347504, 0.21004174351347504, 0.21004174351347504, 0.23479322411150794, 0.23479322411150794, 0.23479322411150794, 0.8767616455226958, 0.8767616455226958, 0.8767616455226958, 0.157668074598469, 0.157668074598469, 0.157668074598469, 0.1361974524086902, 0.1361974524086902, 0.1361974524086902, 0.5928416746770662, 0.5928416746770662, 0.5928416746770662, 0.2118077466565561, 0.2118077466565561, 0.2118077466565561, 0.15155154535327797, 0.15155154535327797, 0.15155154535327797, 0.19425503517044507, 0.19425503517044507, 0.19425503517044507, 0.21148172228516515, 0.21148172228516515, 0.21148172228516515, 0.1907845554180967, 0.1907845554180967, 0.1907845554180967, 0.09555259870042299, 0.09555259870042299, 0.09555259870042299, 0.09133018427536976, 0.09133018427536976, 0.09133018427536976, 0.09831560956744634, 0.09831560956744634, 0.09831560956744634]}, "mutation_prompt": null}
{"id": "cbc9692b-51aa-4df1-88e9-711ee789ea48", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "17bc6ead-853b-4126-8138-e559349cd195", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "d9b419fa-a0c5-4571-ae73-f39b32d427b5", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "f67a2145-1f4e-4d49-a2d7-a14193068463", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "e9b2a4f2-e09b-4227-a7e5-ac05e27703cc", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "359973d9-617e-4f0d-a907-8181827d27ab", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "bb286077-b976-4e71-90dd-54dc81f4167b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "6a94f1b8-2adc-4967-9b2c-e8ae56ae4f17", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "f9aca59e-1be3-4194-90e3-a3649b391ec3", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "ff94d4b0-150e-4e80-8684-a488a747cdfd", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "9ca258f2-9b67-493a-acb5-3a09bff25046", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "66bc9815-16ed-4410-81e6-14b5414739b8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "aa6e2285-a861-4dd6-b0e6-f52b26b2a5b3", "solution": "import numpy as np\n\nclass AdaptivePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.init_c1 = 1.5  # Initial PSO cognitive coefficient\n        self.init_c2 = 1.5  # Initial PSO social coefficient\n        self.init_w = 0.7   # Initial inertia weight\n        self.init_f = 0.8   # Initial DE scaling factor\n        self.init_cr = 0.9  # Initial DE crossover probability\n        self.final_c1 = 1.0  # Final PSO cognitive coefficient\n        self.final_c2 = 2.0  # Final PSO social coefficient\n        self.final_w = 0.4   # Final inertia weight\n        self.final_f = 0.5   # Final DE scaling factor\n        self.final_cr = 0.6  # Final DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptation of parameters\n            progress = eval_count / self.budget\n            c1 = self.init_c1 + progress * (self.final_c1 - self.init_c1)\n            c2 = self.init_c2 + progress * (self.final_c2 - self.init_c2)\n            w = self.init_w + progress * (self.final_w - self.init_w)\n            f = self.init_f + progress * (self.final_f - self.init_f)\n            cr = self.init_cr + progress * (self.final_cr - self.init_cr)\n\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          c1 * r1 * (personal_best_positions - pop) +\n                          c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "AdaptivePSODE", "description": "Introducing Adaptive PSO-DE with dynamic adaptation of PSO and DE parameters to enhance performance in diverse fitness landscapes.", "configspace": "", "generation": 90, "fitness": 0.44025571841724376, "feedback": "The algorithm AdaptivePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.44 with standard deviation 0.30.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.8727379507005046, 0.8727379507005046, 0.8727379507005046, 0.8576552635411072, 0.8576552635411072, 0.8576552635411072, 0.8561395316126879, 0.8561395316126879, 0.8561395316126879, 0.7055410225263055, 0.7055410225263055, 0.7055410225263055, 0.7244420750677253, 0.7244420750677253, 0.7244420750677253, 0.7496435210187622, 0.7496435210187622, 0.7496435210187622, 0.14593905354696202, 0.14593905354696202, 0.14593905354696202, 0.15231621419886632, 0.15231621419886632, 0.15231621419886632, 0.11485698032240632, 0.11485698032240632, 0.11485698032240632, 0.08395509830942138, 0.08395509830942138, 0.08395509830942138, 0.1115816434724135, 0.1115816434724135, 0.1115816434724135, 0.10751095072348149, 0.10751095072348149, 0.10751095072348149, 0.9868361479018398, 0.9868361479018398, 0.9868361479018398, 0.9768129004801134, 0.9768129004801134, 0.9768129004801134, 0.9835962897275918, 0.9835962897275918, 0.9835962897275918, 0.7633554528046199, 0.7633554528046199, 0.7633554528046199, 0.7630859784811971, 0.7630859784811971, 0.7630859784811971, 0.7261464461201702, 0.7261464461201702, 0.7261464461201702, 0.8717322494771578, 0.8717322494771578, 0.8717322494771578, 0.8659159626205474, 0.8659159626205474, 0.8659159626205474, 0.864753205489383, 0.864753205489383, 0.864753205489383, 0.5940747783438436, 0.5940747783438436, 0.5940747783438436, 0.7372282417110119, 0.7372282417110119, 0.7372282417110119, 0.22381420393652274, 0.22381420393652274, 0.22381420393652274, 0.6346085913297796, 0.6346085913297796, 0.6346085913297796, 0.7238392185216449, 0.7238392185216449, 0.7238392185216449, 0.4230789572860365, 0.4230789572860365, 0.4230789572860365, 0.6445117964071595, 0.6445117964071595, 0.6445117964071595, 0.5979493669035849, 0.5979493669035849, 0.5979493669035849, 0.2099408561897792, 0.2099408561897792, 0.2099408561897792, 0.390979794912377, 0.390979794912377, 0.390979794912377, 0.28051606364457427, 0.28051606364457427, 0.28051606364457427, 0.7252077844435614, 0.7252077844435614, 0.7252077844435614, 0.03286418349514608, 0.03286418349514608, 0.03286418349514608, 0.17967912669324537, 0.17967912669324537, 0.17967912669324537, 0.13710154899305382, 0.13710154899305382, 0.13710154899305382, 0.34997670224490973, 0.34997670224490973, 0.34997670224490973, 0.5225093057405759, 0.5225093057405759, 0.5225093057405759, 0.057107589679396775, 0.057107589679396775, 0.057107589679396775, 0.7009696562469778, 0.7009696562469778, 0.7009696562469778, 0.6010145879244122, 0.6010145879244122, 0.6010145879244122, 0.802530638269545, 0.802530638269545, 0.802530638269545, 0.1561695952276665, 0.1561695952276665, 0.1561695952276665, 0.12979486562962517, 0.12979486562962517, 0.12979486562962517, 0.123336063218635, 0.123336063218635, 0.123336063218635, 0.15399126774146477, 0.15399126774146477, 0.15399126774146477, 0.19153382542150554, 0.19153382542150554, 0.19153382542150554, 0.3326137011632385, 0.3326137011632385, 0.3326137011632385, 0.5331656994323338, 0.5331656994323338, 0.5331656994323338, 0.3311474707417428, 0.3311474707417428, 0.3311474707417428, 0.5581057921074983, 0.5581057921074983, 0.5581057921074983, 0.2767044526911344, 0.2767044526911344, 0.2767044526911344, 0.3549632967627515, 0.3549632967627515, 0.3549632967627515, 0.14016797731280894, 0.14016797731280894, 0.14016797731280894, 0.28015198683734854, 0.28015198683734854, 0.28015198683734854, 0.24362843736210993, 0.24362843736210993, 0.24362843736210993, 0.23658766038123902, 0.23658766038123902, 0.23658766038123902, 0.2448826941218072, 0.2448826941218072, 0.2448826941218072, 0.22197122113863765, 0.22197122113863765, 0.22197122113863765, 0.1980932966477178, 0.1980932966477178, 0.1980932966477178, 0.9058982844066062, 0.9058982844066062, 0.9058982844066062, 0.19745986246756242, 0.19745986246756242, 0.19745986246756242, 0.1364972223923343, 0.1364972223923343, 0.1364972223923343, 0.8542378143389927, 0.8542378143389927, 0.8542378143389927, 0.2083944032859425, 0.2083944032859425, 0.2083944032859425, 0.8568877922669929, 0.8568877922669929, 0.8568877922669929, 0.22221761728853817, 0.22221761728853817, 0.22221761728853817, 0.2376977132408984, 0.2376977132408984, 0.2376977132408984, 0.23021210557051874, 0.23021210557051874, 0.23021210557051874, 0.10217746363559177, 0.10217746363559177, 0.10217746363559177, 0.08705913823811895, 0.08705913823811895, 0.08705913823811895, 0.09860607390978915, 0.09860607390978915, 0.09860607390978915]}, "mutation_prompt": null}
{"id": "b594a1e9-a0e7-4284-9552-5c55e0cac699", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "db4deb91-252e-4445-9ad7-b04526839a19", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "9f3abad9-7d02-4435-aa23-0ad080387bf6", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "3a8fd164-eaa2-463a-a2cf-981cb2e12814", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "f9073624-c697-489a-99d5-44e89c57f0dd", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.f = 0.8\n        self.cr = 0.9\n        self.elite_size = 5  # Number of elite solutions\n\n    def __call__(self, func):\n        np.random.seed(42)\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive Inertia Weight\n            self.w = 0.9 - (0.5 * eval_count / self.budget)\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            elite_indices = np.argsort(personal_best_scores)[:self.elite_size]\n            elite_positions = personal_best_positions[elite_indices]\n            \n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n\n            # Elite Opposition-Based Learning\n            opposition_positions = self.lower_bound + self.upper_bound - elite_positions\n            opposition_positions = np.clip(opposition_positions, self.lower_bound, self.upper_bound)\n            opposition_scores = np.array([func(op) for op in opposition_positions])\n            eval_count += self.elite_size\n            \n            for idx, op_score in zip(elite_indices, opposition_scores):\n                if op_score < personal_best_scores[idx]:\n                    personal_best_scores[idx] = op_score\n                    personal_best_positions[idx] = opposition_positions[elite_indices == idx]\n                    if op_score < global_best_score:\n                        global_best_score = op_score\n                        global_best_position = opposition_positions[elite_indices == idx]\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "Enhanced PSODE with adaptive parameters and elite opposition strategy for improved convergence and exploration-exploitation balance.", "configspace": "", "generation": 95, "fitness": 0.37866070676792235, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.25.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7370163130442449, 0.7370163130442449, 0.7370163130442449, 0.7172693304835389, 0.7172693304835389, 0.7172693304835389, 0.7074281178348356, 0.7074281178348356, 0.7074281178348356, 0.48847876171554483, 0.48847876171554483, 0.48847876171554483, 0.4744740078426577, 0.4744740078426577, 0.4744740078426577, 0.4821595398655867, 0.4821595398655867, 0.4821595398655867, 0.10223901025544091, 0.10223901025544091, 0.10223901025544091, 0.1457377270726422, 0.1457377270726422, 0.1457377270726422, 0.13455893861006885, 0.13455893861006885, 0.13455893861006885, 0.09777664263383246, 0.09777664263383246, 0.09777664263383246, 0.10140221516461279, 0.10140221516461279, 0.10140221516461279, 0.1002172659963102, 0.1002172659963102, 0.1002172659963102, 0.985433317185711, 0.985433317185711, 0.985433317185711, 0.9844821874878997, 0.9844821874878997, 0.9844821874878997, 0.9810923529452549, 0.9810923529452549, 0.9810923529452549, 0.5359908390420776, 0.5359908390420776, 0.5359908390420776, 0.521913156780333, 0.521913156780333, 0.521913156780333, 0.5397380106563878, 0.5397380106563878, 0.5397380106563878, 0.7985719473987111, 0.7985719473987111, 0.7985719473987111, 0.7411053719412196, 0.7411053719412196, 0.7411053719412196, 0.6805173838176923, 0.6805173838176923, 0.6805173838176923, 0.4553895614390886, 0.4553895614390886, 0.4553895614390886, 0.47574291112873324, 0.47574291112873324, 0.47574291112873324, 0.4746594437593311, 0.4746594437593311, 0.4746594437593311, 0.4280147214656358, 0.4280147214656358, 0.4280147214656358, 0.5616324291897543, 0.5616324291897543, 0.5616324291897543, 0.4460991911943807, 0.4460991911943807, 0.4460991911943807, 0.41246925425968173, 0.41246925425968173, 0.41246925425968173, 0.41177083621436017, 0.41177083621436017, 0.41177083621436017, 0.42633575192556483, 0.42633575192556483, 0.42633575192556483, 0.5334125684166331, 0.5334125684166331, 0.5334125684166331, 0.5086458413622168, 0.5086458413622168, 0.5086458413622168, 0.5393083819684831, 0.5393083819684831, 0.5393083819684831, 0.0861197790514927, 0.0861197790514927, 0.0861197790514927, 0.33314473867188243, 0.33314473867188243, 0.33314473867188243, 0.16047770261917016, 0.16047770261917016, 0.16047770261917016, 0.01017097511059839, 0.01017097511059839, 0.01017097511059839, 0.29840480924565005, 0.29840480924565005, 0.29840480924565005, 0.29965405390041366, 0.29965405390041366, 0.29965405390041366, 0.6468005809256322, 0.6468005809256322, 0.6468005809256322, 0.20824516183809272, 0.20824516183809272, 0.20824516183809272, 0.6566631403104147, 0.6566631403104147, 0.6566631403104147, 0.11915126303278434, 0.11915126303278434, 0.11915126303278434, 0.1226558411344204, 0.1226558411344204, 0.1226558411344204, 0.11405300639389493, 0.11405300639389493, 0.11405300639389493, 0.2661369770660247, 0.2661369770660247, 0.2661369770660247, 0.18495605423826988, 0.18495605423826988, 0.18495605423826988, 0.19287601117643705, 0.19287601117643705, 0.19287601117643705, 0.4130839076081946, 0.4130839076081946, 0.4130839076081946, 0.38865667309285845, 0.38865667309285845, 0.38865667309285845, 0.4622124721238332, 0.4622124721238332, 0.4622124721238332, 0.2813132439601951, 0.2813132439601951, 0.2813132439601951, 0.29482596789842164, 0.29482596789842164, 0.29482596789842164, 0.4076878983009604, 0.4076878983009604, 0.4076878983009604, 0.24699361297996247, 0.24699361297996247, 0.24699361297996247, 0.17609375603295285, 0.17609375603295285, 0.17609375603295285, 0.25879529217640107, 0.25879529217640107, 0.25879529217640107, 0.5385269072734724, 0.5385269072734724, 0.5385269072734724, 0.19608888304207772, 0.19608888304207772, 0.19608888304207772, 0.18238187772223124, 0.18238187772223124, 0.18238187772223124, 0.8221593392538781, 0.8221593392538781, 0.8221593392538781, 0.18748064511780427, 0.18748064511780427, 0.18748064511780427, 0.7254125214264946, 0.7254125214264946, 0.7254125214264946, 0.16759600840698896, 0.16759600840698896, 0.16759600840698896, 0.11214911147362405, 0.11214911147362405, 0.11214911147362405, 0.13554489860135377, 0.13554489860135377, 0.13554489860135377, 0.20598226024489974, 0.20598226024489974, 0.20598226024489974, 0.18762200630009862, 0.18762200630009862, 0.18762200630009862, 0.1785701048083307, 0.1785701048083307, 0.1785701048083307, 0.08578313083415656, 0.08578313083415656, 0.08578313083415656, 0.09752114485530583, 0.09752114485530583, 0.09752114485530583, 0.08049579894226777, 0.08049579894226777, 0.08049579894226777]}, "mutation_prompt": null}
{"id": "a5ebb1f0-1381-415a-8a78-34a7ac5695b4", "solution": "import numpy as np\n\nclass EnhancedHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.f_max = 0.9  # Maximum DE scaling factor\n        self.f_min = 0.5  # Minimum DE scaling factor\n        self.cr = 0.9    # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Adaptive scaling factor\n            f = self.f_max - (self.f_max - self.f_min) * (eval_count / self.budget)\n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "EnhancedHybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia weight and mutation factor strategy to maintain balance between exploration and exploitation dynamically.", "configspace": "", "generation": 96, "fitness": 0.40015955943246617, "feedback": "The algorithm EnhancedHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.40 with standard deviation 0.24.", "error": "", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.7091477787615528, 0.7091477787615528, 0.7091477787615528, 0.7304607708259028, 0.7304607708259028, 0.7304607708259028, 0.7106162669240434, 0.7106162669240434, 0.7106162669240434, 0.51424231619872, 0.51424231619872, 0.51424231619872, 0.4851869210657286, 0.4851869210657286, 0.4851869210657286, 0.521412957046325, 0.521412957046325, 0.521412957046325, 0.11808048501755097, 0.11808048501755097, 0.11808048501755097, 0.09483745865709459, 0.09483745865709459, 0.09483745865709459, 0.1371962534190908, 0.1371962534190908, 0.1371962534190908, 0.12449509640144374, 0.12449509640144374, 0.12449509640144374, 0.0992409196031192, 0.0992409196031192, 0.0992409196031192, 0.12169476577336413, 0.12169476577336413, 0.12169476577336413, 0.9869388233072066, 0.9869388233072066, 0.9869388233072066, 0.9832551914039888, 0.9832551914039888, 0.9832551914039888, 0.9832195161886695, 0.9832195161886695, 0.9832195161886695, 0.5744681466814772, 0.5744681466814772, 0.5744681466814772, 0.15126695948994662, 0.15126695948994662, 0.15126695948994662, 0.5666991003437423, 0.5666991003437423, 0.5666991003437423, 0.6776739402193932, 0.6776739402193932, 0.6776739402193932, 0.4391772759157274, 0.4391772759157274, 0.4391772759157274, 0.6937862873847306, 0.6937862873847306, 0.6937862873847306, 0.48537039422305184, 0.48537039422305184, 0.48537039422305184, 0.4870413853752158, 0.4870413853752158, 0.4870413853752158, 0.5374023620397168, 0.5374023620397168, 0.5374023620397168, 0.4867518325264145, 0.4867518325264145, 0.4867518325264145, 0.4949223967248154, 0.4949223967248154, 0.4949223967248154, 0.5584019985176303, 0.5584019985176303, 0.5584019985176303, 0.49568970313975247, 0.49568970313975247, 0.49568970313975247, 0.47353894914738426, 0.47353894914738426, 0.47353894914738426, 0.4614146535761987, 0.4614146535761987, 0.4614146535761987, 0.5570937999907484, 0.5570937999907484, 0.5570937999907484, 0.5867346045586821, 0.5867346045586821, 0.5867346045586821, 0.5356994858042033, 0.5356994858042033, 0.5356994858042033, 0.237694855306117, 0.237694855306117, 0.237694855306117, 0.40473410826790435, 0.40473410826790435, 0.40473410826790435, 0.09011112703976465, 0.09011112703976465, 0.09011112703976465, 0.3441036053141615, 0.3441036053141615, 0.3441036053141615, 0.29509831372856266, 0.29509831372856266, 0.29509831372856266, 0.3439086887064723, 0.3439086887064723, 0.3439086887064723, 0.6810542397503019, 0.6810542397503019, 0.6810542397503019, 0.6706118861825159, 0.6706118861825159, 0.6706118861825159, 0.6541285153329311, 0.6541285153329311, 0.6541285153329311, 0.10679490876843978, 0.10679490876843978, 0.10679490876843978, 0.09042434285692524, 0.09042434285692524, 0.09042434285692524, 0.08092001072253752, 0.08092001072253752, 0.08092001072253752, 0.47676744639540525, 0.47676744639540525, 0.47676744639540525, 0.2210180054275802, 0.2210180054275802, 0.2210180054275802, 0.19852384593774686, 0.19852384593774686, 0.19852384593774686, 0.3888955775323335, 0.3888955775323335, 0.3888955775323335, 0.3843628098446459, 0.3843628098446459, 0.3843628098446459, 0.44646241839360223, 0.44646241839360223, 0.44646241839360223, 0.2714224761211793, 0.2714224761211793, 0.2714224761211793, 0.35093759086310616, 0.35093759086310616, 0.35093759086310616, 0.3615301130019507, 0.3615301130019507, 0.3615301130019507, 0.21078550494066883, 0.21078550494066883, 0.21078550494066883, 0.20284537191690333, 0.20284537191690333, 0.20284537191690333, 0.21721738921602818, 0.21721738921602818, 0.21721738921602818, 0.2066102449236732, 0.2066102449236732, 0.2066102449236732, 0.2403116378786746, 0.2403116378786746, 0.2403116378786746, 0.2077091609455577, 0.2077091609455577, 0.2077091609455577, 0.8179052064045812, 0.8179052064045812, 0.8179052064045812, 0.1947684253986287, 0.1947684253986287, 0.1947684253986287, 0.7978345937728945, 0.7978345937728945, 0.7978345937728945, 0.7789954271690951, 0.7789954271690951, 0.7789954271690951, 0.20822484367705762, 0.20822484367705762, 0.20822484367705762, 0.15326676544588969, 0.15326676544588969, 0.15326676544588969, 0.185066611672136, 0.185066611672136, 0.185066611672136, 0.1953925592582143, 0.1953925592582143, 0.1953925592582143, 0.23931894265252507, 0.23931894265252507, 0.23931894265252507, 0.09310544096065876, 0.09310544096065876, 0.09310544096065876, 0.08551810577715346, 0.08551810577715346, 0.08551810577715346, 0.09394836538040685, 0.09394836538040685, 0.09394836538040685]}, "mutation_prompt": null}
{"id": "1d10b215-4c10-4c00-b3da-6b0d3b51e333", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "7fd0d41b-5928-4eec-9589-afaf8ae210f6", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}
{"id": "85be046c-9ee8-4d8c-a2d3-c5554dcec2f0", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.pop_size = 20  # Population size\n        self.c1 = 1.5  # PSO cognitive coefficient\n        self.c2 = 1.5  # PSO social coefficient\n        self.w = 0.7  # Inertia weight\n        self.f = 0.8  # DE scaling factor\n        self.cr = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        # Initialize population\n        pop = np.random.uniform(self.lower_bound, self.upper_bound, (self.pop_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.pop_size, self.dim))\n        personal_best_positions = np.copy(pop)\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - pop) +\n                          self.c2 * r2 * (global_best_position - pop))\n            pop += velocities\n            pop = np.clip(pop, self.lower_bound, self.upper_bound)\n            \n            # Evaluate the population\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.pop_size\n\n            # Update personal bests\n            better_mask = scores < personal_best_scores\n            personal_best_scores = np.where(better_mask, scores, personal_best_scores)\n            personal_best_positions = np.where(better_mask[:, np.newaxis], pop, personal_best_positions)\n            \n            # Update global best\n            current_global_best_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[current_global_best_idx] < global_best_score:\n                global_best_score = personal_best_scores[current_global_best_idx]\n                global_best_position = personal_best_positions[current_global_best_idx]\n            \n            # Differential Evolution Update\n            for i in range(self.pop_size):\n                indices = list(range(self.pop_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n                \n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                \n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                \n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = trial\n                    \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A novel hybrid evolutionary PSO-DE optimizer that combines Particle Swarm Optimization's exploration and Differential Evolution's exploitation to efficiently navigate diverse fitness landscapes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4f56d17f-3f3a-4223-9fcc-180d95455d26", "metadata": {"aucs": [0.85824301702014, 0.85824301702014, 0.85824301702014, 0.8276925542327722, 0.8276925542327722, 0.8276925542327722, 0.8303808297665882, 0.8303808297665882, 0.8303808297665882, 0.6481651016951431, 0.6481651016951431, 0.6481651016951431, 0.6612104241816255, 0.6612104241816255, 0.6612104241816255, 0.6670891811639477, 0.6670891811639477, 0.6670891811639477, 0.10952293319989626, 0.10952293319989626, 0.10952293319989626, 0.15741123333424534, 0.15741123333424534, 0.15741123333424534, 0.11824261631469113, 0.11824261631469113, 0.11824261631469113, 0.14101864757902127, 0.14101864757902127, 0.14101864757902127, 0.14096272940253451, 0.14096272940253451, 0.14096272940253451, 0.10204565528999954, 0.10204565528999954, 0.10204565528999954, 0.9868364332313071, 0.9868364332313071, 0.9868364332313071, 0.9751440388910008, 0.9751440388910008, 0.9751440388910008, 0.9835949818894533, 0.9835949818894533, 0.9835949818894533, 0.6801223050599465, 0.6801223050599465, 0.6801223050599465, 0.6860738558938366, 0.6860738558938366, 0.6860738558938366, 0.12690989436993128, 0.12690989436993128, 0.12690989436993128, 0.8769761901537635, 0.8769761901537635, 0.8769761901537635, 0.8640366519322692, 0.8640366519322692, 0.8640366519322692, 0.8310571531017913, 0.8310571531017913, 0.8310571531017913, 0.6255279205097339, 0.6255279205097339, 0.6255279205097339, 0.6854611051922517, 0.6854611051922517, 0.6854611051922517, 0.6287079395852588, 0.6287079395852588, 0.6287079395852588, 0.6761611137011676, 0.6761611137011676, 0.6761611137011676, 0.6673697629796741, 0.6673697629796741, 0.6673697629796741, 0.13332381071940325, 0.13332381071940325, 0.13332381071940325, 0.07005929666048161, 0.07005929666048161, 0.07005929666048161, 0.6056312507415179, 0.6056312507415179, 0.6056312507415179, 0.5700354722474826, 0.5700354722474826, 0.5700354722474826, 0.6140619841405882, 0.6140619841405882, 0.6140619841405882, 0.5952821222650029, 0.5952821222650029, 0.5952821222650029, 0.6271620931904373, 0.6271620931904373, 0.6271620931904373, 0.03153868346076194, 0.03153868346076194, 0.03153868346076194, 0.4635933298482581, 0.4635933298482581, 0.4635933298482581, 0.25192355026822466, 0.25192355026822466, 0.25192355026822466, 0.5144444879617479, 0.5144444879617479, 0.5144444879617479, 0.5423361370919619, 0.5423361370919619, 0.5423361370919619, 0.43442175147517936, 0.43442175147517936, 0.43442175147517936, 0.7807301777025871, 0.7807301777025871, 0.7807301777025871, 0.7794222634403665, 0.7794222634403665, 0.7794222634403665, 0.7732332085908307, 0.7732332085908307, 0.7732332085908307, 0.10843502051787168, 0.10843502051787168, 0.10843502051787168, 0.0858537888161589, 0.0858537888161589, 0.0858537888161589, 0.15823978128080185, 0.15823978128080185, 0.15823978128080185, 0.15361211688173604, 0.15361211688173604, 0.15361211688173604, 0.6593289880398916, 0.6593289880398916, 0.6593289880398916, 0.6817662974411254, 0.6817662974411254, 0.6817662974411254, 0.44733073406979196, 0.44733073406979196, 0.44733073406979196, 0.5842249817643885, 0.5842249817643885, 0.5842249817643885, 0.5177752750664957, 0.5177752750664957, 0.5177752750664957, 0.46319136151776286, 0.46319136151776286, 0.46319136151776286, 0.26381498353536803, 0.26381498353536803, 0.26381498353536803, 0.4756522644043689, 0.4756522644043689, 0.4756522644043689, 0.25857421487690535, 0.25857421487690535, 0.25857421487690535, 0.24467506787686533, 0.24467506787686533, 0.24467506787686533, 0.20887384732584335, 0.20887384732584335, 0.20887384732584335, 0.2079996969567376, 0.2079996969567376, 0.2079996969567376, 0.2093540614376157, 0.2093540614376157, 0.2093540614376157, 0.19720270557311348, 0.19720270557311348, 0.19720270557311348, 0.9071526504263286, 0.9071526504263286, 0.9071526504263286, 0.1970931935973409, 0.1970931935973409, 0.1970931935973409, 0.13648695979175096, 0.13648695979175096, 0.13648695979175096, 0.8255419051854599, 0.8255419051854599, 0.8255419051854599, 0.20932591758700803, 0.20932591758700803, 0.20932591758700803, 0.8345840675126401, 0.8345840675126401, 0.8345840675126401, 0.21947467869178738, 0.21947467869178738, 0.21947467869178738, 0.17692334038979662, 0.17692334038979662, 0.17692334038979662, 0.18054763469457213, 0.18054763469457213, 0.18054763469457213, 0.11121901374967169, 0.11121901374967169, 0.11121901374967169, 0.11054382172914123, 0.11054382172914123, 0.11054382172914123, 0.09546292973859472, 0.09546292973859472, 0.09546292973859472]}, "mutation_prompt": null}

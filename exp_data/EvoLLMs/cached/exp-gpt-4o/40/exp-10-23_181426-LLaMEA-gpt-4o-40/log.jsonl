{"id": "b465ea5b-1afe-413f-9ad1-2b3482c49816", "solution": "import numpy as np\n\nclass HybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.de_f = 0.8  # Differential weight\n        self.de_cr = 0.9  # Crossover probability\n        self.pso_w = 0.5  # Inertia weight\n        self.pso_c1 = 0.8  # Cognitive coefficient\n        self.pso_c2 = 1.2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (self.pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "HybridDEPSO", "description": "A hybrid metaheuristic combining Differential Evolution and Particle Swarm Optimization to enhance exploration and exploitation for robust black-box optimization.", "configspace": "", "generation": 0, "fitness": 0.3345266546854693, "feedback": "The algorithm HybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.30.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9259870234799317, 0.9259870234799317, 0.9259870234799317, 0.9322568761891042, 0.9322568761891042, 0.9322568761891042, 0.9156788825432689, 0.9156788825432689, 0.9156788825432689, 0.8173130326258328, 0.8173130326258328, 0.8173130326258328, 0.8182123312077272, 0.8182123312077272, 0.8182123312077272, 0.05571716091943002, 0.05571716091943002, 0.05571716091943002, 0.11062073894878288, 0.11062073894878288, 0.11062073894878288, 0.1268382351931856, 0.1268382351931856, 0.1268382351931856, 0.12431938939021714, 0.12431938939021714, 0.12431938939021714, 0.09703426106009061, 0.09703426106009061, 0.09703426106009061, 0.15154269197623238, 0.15154269197623238, 0.15154269197623238, 0.06918025754079804, 0.06918025754079804, 0.06918025754079804, 0.9854679253413878, 0.9854679253413878, 0.9854679253413878, 0.9850879974063018, 0.9850879974063018, 0.9850879974063018, 0.988785624328025, 0.988785624328025, 0.988785624328025, 0.8177260598710661, 0.8177260598710661, 0.8177260598710661, 0.5846705096740177, 0.5846705096740177, 0.5846705096740177, 0.8121406508913904, 0.8121406508913904, 0.8121406508913904, 0.3710695282709924, 0.3710695282709924, 0.3710695282709924, 0.1569558861424203, 0.1569558861424203, 0.1569558861424203, 0.13890339192575407, 0.13890339192575407, 0.13890339192575407, 0.3702299810704638, 0.3702299810704638, 0.3702299810704638, 0.10984743549451237, 0.10984743549451237, 0.10984743549451237, 0.4453458629578778, 0.4453458629578778, 0.4453458629578778, 0.31938648633494293, 0.31938648633494293, 0.31938648633494293, 0.4575823534546516, 0.4575823534546516, 0.4575823534546516, 0.35650999027668295, 0.35650999027668295, 0.35650999027668295, 0.09191478861479174, 0.09191478861479174, 0.09191478861479174, 0.00849836207168575, 0.00849836207168575, 0.00849836207168575, 0.06469887265509933, 0.06469887265509933, 0.06469887265509933, 0.1959081518821466, 0.1959081518821466, 0.1959081518821466, 0.12300608564380433, 0.12300608564380433, 0.12300608564380433, 0.08494614769445674, 0.08494614769445674, 0.08494614769445674, 0.06662018402723147, 0.06662018402723147, 0.06662018402723147, 0.082664841350367, 0.082664841350367, 0.082664841350367, 0.25829343837373697, 0.25829343837373697, 0.25829343837373697, 0.1323028240237638, 0.1323028240237638, 0.1323028240237638, 0.039528255670151835, 0.039528255670151835, 0.039528255670151835, 0.08504390905211767, 0.08504390905211767, 0.08504390905211767, 0.5989515587681531, 0.5989515587681531, 0.5989515587681531, 0.6008476910921885, 0.6008476910921885, 0.6008476910921885, 0.6142177926129211, 0.6142177926129211, 0.6142177926129211, 0.10752846163852114, 0.10752846163852114, 0.10752846163852114, 0.058487003290274675, 0.058487003290274675, 0.058487003290274675, 0.13242520968950644, 0.13242520968950644, 0.13242520968950644, 0.2365701791859054, 0.2365701791859054, 0.2365701791859054, 0.1471568017444359, 0.1471568017444359, 0.1471568017444359, 0.19427641873886636, 0.19427641873886636, 0.19427641873886636, 0.28949701917693205, 0.28949701917693205, 0.28949701917693205, 0.2760510043781944, 0.2760510043781944, 0.2760510043781944, 0.48257313972119753, 0.48257313972119753, 0.48257313972119753, 0.22721337406708286, 0.22721337406708286, 0.22721337406708286, 0.24527669211564984, 0.24527669211564984, 0.24527669211564984, 0.1312159943029002, 0.1312159943029002, 0.1312159943029002, 0.1972808165408454, 0.1972808165408454, 0.1972808165408454, 0.20926676227192054, 0.20926676227192054, 0.20926676227192054, 0.1854639813365827, 0.1854639813365827, 0.1854639813365827, 0.21581901849523633, 0.21581901849523633, 0.21581901849523633, 0.2037241767438217, 0.2037241767438217, 0.2037241767438217, 0.22486398036007638, 0.22486398036007638, 0.22486398036007638, 0.9492152691854389, 0.9492152691854389, 0.9492152691854389, 0.9577885790739145, 0.9577885790739145, 0.9577885790739145, 0.16760633459676932, 0.16760633459676932, 0.16760633459676932, 0.9452250858816291, 0.9452250858816291, 0.9452250858816291, 0.2132443277301994, 0.2132443277301994, 0.2132443277301994, 0.13037512229071924, 0.13037512229071924, 0.13037512229071924, 0.17844209773029085, 0.17844209773029085, 0.17844209773029085, 0.19152351505401244, 0.19152351505401244, 0.19152351505401244, 0.2005044564762195, 0.2005044564762195, 0.2005044564762195, 0.10545706886782913, 0.10545706886782913, 0.10545706886782913, 0.1021486850785841, 0.1021486850785841, 0.1021486850785841, 0.087845093542533, 0.087845093542533, 0.087845093542533]}, "mutation_prompt": null}
{"id": "f90a9360-d03e-4aed-8736-6c5d603f37ed", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.de_f = 0.8  # Differential weight\n        self.de_cr = 0.9  # Crossover probability\n        self.pso_w_max = 0.9  # Maximum inertia weight\n        self.pso_w_min = 0.4  # Minimum inertia weight\n        self.pso_c1 = 0.8  # Cognitive coefficient\n        self.pso_c2 = 1.2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adaptive inertia weight calculation\n            w = self.pso_w_max - ((self.pso_w_max - self.pso_w_min) * self.eval_count / self.max_evaluations)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Local search for precision improvement\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                local_solution = population[i] + np.random.normal(0, 0.1, self.dim)\n                local_solution = np.clip(local_solution, self.lb, self.ub)\n                local_fitness = func(local_solution)\n                self.eval_count += 1\n                if local_fitness < fitness[i]:\n                    population[i] = local_solution\n                    fitness[i] = local_fitness\n                    if local_fitness < personal_best_fitness[i]:\n                        personal_best[i] = local_solution\n                        personal_best_fitness[i] = local_fitness\n                        if local_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = local_solution\n                            global_best_idx = i\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedHybridDEPSO", "description": "Enhanced Hybrid DEPSO integrating adaptive inertia weight and local search to improve convergence speed and solution precision for diverse black-box optimization problems.", "configspace": "", "generation": 1, "fitness": 0.2534683951281278, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.23.", "error": "", "parent_id": "b465ea5b-1afe-413f-9ad1-2b3482c49816", "metadata": {"aucs": [0.6126628818429604, 0.6126628818429604, 0.6126628818429604, 0.643134665914832, 0.643134665914832, 0.643134665914832, 0.6231133318893101, 0.6231133318893101, 0.6231133318893101, 0.3777598222874885, 0.3777598222874885, 0.3777598222874885, 0.4036647294843043, 0.4036647294843043, 0.4036647294843043, 0.2978733443749063, 0.2978733443749063, 0.2978733443749063, 0.11077972724913465, 0.11077972724913465, 0.11077972724913465, 0.10272484954713867, 0.10272484954713867, 0.10272484954713867, 0.08840006485423979, 0.08840006485423979, 0.08840006485423979, 0.11173841179469224, 0.11173841179469224, 0.11173841179469224, 0.11154383765813469, 0.11154383765813469, 0.11154383765813469, 0.0929215919581462, 0.0929215919581462, 0.0929215919581462, 0.979375647402505, 0.979375647402505, 0.979375647402505, 0.97982145567012, 0.97982145567012, 0.97982145567012, 0.9853949595133248, 0.9853949595133248, 0.9853949595133248, 0.2462948727875276, 0.2462948727875276, 0.2462948727875276, 0.30719391594266154, 0.30719391594266154, 0.30719391594266154, 0.26623606484460016, 0.26623606484460016, 0.26623606484460016, 0.2038292181683703, 0.2038292181683703, 0.2038292181683703, 0.158348874768522, 0.158348874768522, 0.158348874768522, 0.4762031240641963, 0.4762031240641963, 0.4762031240641963, 0.17695483759831332, 0.17695483759831332, 0.17695483759831332, 0.07904563997371539, 0.07904563997371539, 0.07904563997371539, 0.14761336229682898, 0.14761336229682898, 0.14761336229682898, 0.19415066620289567, 0.19415066620289567, 0.19415066620289567, 0.16920468526625843, 0.16920468526625843, 0.16920468526625843, 0.2170459790347763, 0.2170459790347763, 0.2170459790347763, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00037560376954171026, 0.00037560376954171026, 0.00037560376954171026, 0.00036405800636352126, 0.00036405800636352126, 0.00036405800636352126, 0.0991175229353688, 0.0991175229353688, 0.0991175229353688, 0.009041674399413169, 0.009041674399413169, 0.009041674399413169, 0.03825594409118149, 0.03825594409118149, 0.03825594409118149, 0.14405540802099492, 0.14405540802099492, 0.14405540802099492, 0.03844838052894051, 0.03844838052894051, 0.03844838052894051, 0.08292305303125236, 0.08292305303125236, 0.08292305303125236, 0.06108806874426176, 0.06108806874426176, 0.06108806874426176, 0.09229851807018152, 0.09229851807018152, 0.09229851807018152, 0.12523629717703277, 0.12523629717703277, 0.12523629717703277, 0.4953217477087102, 0.4953217477087102, 0.4953217477087102, 0.4368451768436836, 0.4368451768436836, 0.4368451768436836, 0.46969129172745316, 0.46969129172745316, 0.46969129172745316, 0.07928571914422633, 0.07928571914422633, 0.07928571914422633, 0.09416818385522752, 0.09416818385522752, 0.09416818385522752, 0.12151001556192953, 0.12151001556192953, 0.12151001556192953, 0.1674834490781676, 0.1674834490781676, 0.1674834490781676, 0.15363634855303931, 0.15363634855303931, 0.15363634855303931, 0.15331358943422002, 0.15331358943422002, 0.15331358943422002, 0.330347596284279, 0.330347596284279, 0.330347596284279, 0.2948090655676401, 0.2948090655676401, 0.2948090655676401, 0.35373395081555714, 0.35373395081555714, 0.35373395081555714, 0.21802364368526805, 0.21802364368526805, 0.21802364368526805, 0.1402021804890501, 0.1402021804890501, 0.1402021804890501, 0.16664883779447415, 0.16664883779447415, 0.16664883779447415, 0.22729798004331392, 0.22729798004331392, 0.22729798004331392, 0.17389777994416744, 0.17389777994416744, 0.17389777994416744, 0.1990302567354214, 0.1990302567354214, 0.1990302567354214, 0.21155529579526133, 0.21155529579526133, 0.21155529579526133, 0.21651966560797087, 0.21651966560797087, 0.21651966560797087, 0.18684932213521754, 0.18684932213521754, 0.18684932213521754, 0.7091445073959839, 0.7091445073959839, 0.7091445073959839, 0.5882111103289018, 0.5882111103289018, 0.5882111103289018, 0.5517021689690698, 0.5517021689690698, 0.5517021689690698, 0.4990924389840965, 0.4990924389840965, 0.4990924389840965, 0.19981667058163743, 0.19981667058163743, 0.19981667058163743, 0.1512512031963501, 0.1512512031963501, 0.1512512031963501, 0.18199528665313758, 0.18199528665313758, 0.18199528665313758, 0.17737642359646166, 0.17737642359646166, 0.17737642359646166, 0.1984525678997906, 0.1984525678997906, 0.1984525678997906, 0.07745623623312181, 0.07745623623312181, 0.07745623623312181, 0.09361904016195932, 0.09361904016195932, 0.09361904016195932, 0.07710060725597545, 0.07710060725597545, 0.07710060725597545]}, "mutation_prompt": null}
{"id": "720199ad-b727-429e-8a05-b06c2c728599", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Initial Differential weight\n        self.initial_de_cr = 0.9  # Initial Crossover probability\n        self.initial_pso_w = 0.5  # Initial Inertia weight\n        self.pso_c1 = 0.8  # Cognitive coefficient\n        self.pso_c2 = 1.2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid metaheuristic combining Differential Evolution and Particle Swarm Optimization with dynamic parameter tuning for improved convergence in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.3348089313029071, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.31.", "error": "", "parent_id": "b465ea5b-1afe-413f-9ad1-2b3482c49816", "metadata": {"aucs": [0.9339725563951505, 0.9339725563951505, 0.9339725563951505, 0.9330231889239842, 0.9330231889239842, 0.9330231889239842, 0.9256036256393436, 0.9256036256393436, 0.9256036256393436, 0.8256146482236011, 0.8256146482236011, 0.8256146482236011, 0.8388097804739391, 0.8388097804739391, 0.8388097804739391, 0.05512810245303823, 0.05512810245303823, 0.05512810245303823, 0.13994739937588763, 0.13994739937588763, 0.13994739937588763, 0.12557516087798593, 0.12557516087798593, 0.12557516087798593, 0.15781560606594902, 0.15781560606594902, 0.15781560606594902, 0.09305798726684811, 0.09305798726684811, 0.09305798726684811, 0.11690710967418616, 0.11690710967418616, 0.11690710967418616, 0.15579508290917543, 0.15579508290917543, 0.15579508290917543, 0.9854640553796544, 0.9854640553796544, 0.9854640553796544, 0.9850952946413012, 0.9850952946413012, 0.9850952946413012, 0.9887847257319362, 0.9887847257319362, 0.9887847257319362, 0.8271107093010446, 0.8271107093010446, 0.8271107093010446, 0.80626729754881, 0.80626729754881, 0.80626729754881, 0.820616524611336, 0.820616524611336, 0.820616524611336, 0.11220299296783798, 0.11220299296783798, 0.11220299296783798, 0.15717062937694704, 0.15717062937694704, 0.15717062937694704, 0.1674645941316638, 0.1674645941316638, 0.1674645941316638, 0.30675241338932524, 0.30675241338932524, 0.30675241338932524, 0.1088711034397184, 0.1088711034397184, 0.1088711034397184, 0.3253007709306044, 0.3253007709306044, 0.3253007709306044, 0.3070392810818682, 0.3070392810818682, 0.3070392810818682, 0.4123952531383921, 0.4123952531383921, 0.4123952531383921, 0.28302453778476067, 0.28302453778476067, 0.28302453778476067, 0.017983383878773962, 0.017983383878773962, 0.017983383878773962, 0.08904366940139807, 0.08904366940139807, 0.08904366940139807, 0.07232083468011408, 0.07232083468011408, 0.07232083468011408, 0.2151318057848598, 0.2151318057848598, 0.2151318057848598, 0.027070855530059834, 0.027070855530059834, 0.027070855530059834, 0.0673365146537559, 0.0673365146537559, 0.0673365146537559, 0.06417376016032561, 0.06417376016032561, 0.06417376016032561, 0.08433784565478997, 0.08433784565478997, 0.08433784565478997, 0.17983994789053837, 0.17983994789053837, 0.17983994789053837, 0.11688050751210344, 0.11688050751210344, 0.11688050751210344, 0.03962667239839157, 0.03962667239839157, 0.03962667239839157, 0.08530988828009645, 0.08530988828009645, 0.08530988828009645, 0.5580025790752474, 0.5580025790752474, 0.5580025790752474, 0.6024245631455081, 0.6024245631455081, 0.6024245631455081, 0.6202405077733554, 0.6202405077733554, 0.6202405077733554, 0.1131351843518783, 0.1131351843518783, 0.1131351843518783, 0.04558345444470757, 0.04558345444470757, 0.04558345444470757, 0.1103901254975872, 0.1103901254975872, 0.1103901254975872, 0.19533774989491826, 0.19533774989491826, 0.19533774989491826, 0.13916585261960268, 0.13916585261960268, 0.13916585261960268, 0.20100846360364277, 0.20100846360364277, 0.20100846360364277, 0.44209136450341224, 0.44209136450341224, 0.44209136450341224, 0.26091067565248827, 0.26091067565248827, 0.26091067565248827, 0.7721040446086165, 0.7721040446086165, 0.7721040446086165, 0.2102517123495924, 0.2102517123495924, 0.2102517123495924, 0.19302146706305767, 0.19302146706305767, 0.19302146706305767, 0.22096271383349653, 0.22096271383349653, 0.22096271383349653, 0.2084750212809774, 0.2084750212809774, 0.2084750212809774, 0.21741596023268173, 0.21741596023268173, 0.21741596023268173, 0.1889726386456556, 0.1889726386456556, 0.1889726386456556, 0.21262632706368612, 0.21262632706368612, 0.21262632706368612, 0.2040763578114495, 0.2040763578114495, 0.2040763578114495, 0.25287101713371984, 0.25287101713371984, 0.25287101713371984, 0.9463904615236902, 0.9463904615236902, 0.9463904615236902, 0.9576596506883958, 0.9576596506883958, 0.9576596506883958, 0.16796337524311133, 0.16796337524311133, 0.16796337524311133, 0.9139672802159426, 0.9139672802159426, 0.9139672802159426, 0.21331730480780475, 0.21331730480780475, 0.21331730480780475, 0.13035052690846627, 0.13035052690846627, 0.13035052690846627, 0.17971081791160437, 0.17971081791160437, 0.17971081791160437, 0.18229336876633329, 0.18229336876633329, 0.18229336876633329, 0.19645373411435718, 0.19645373411435718, 0.19645373411435718, 0.09175106975049274, 0.09175106975049274, 0.09175106975049274, 0.10903095908759874, 0.10903095908759874, 0.10903095908759874, 0.09442060664673735, 0.09442060664673735, 0.09442060664673735]}, "mutation_prompt": null}
{"id": "1a710ca5-9a6b-4702-bd0d-60a73c840a55", "solution": "import numpy as np\n\nclass DynamicBalancedDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size\n        self.initial_de_f = 0.9  # Modified Differential weight for exploration\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Modified Inertia weight\n        self.pso_c1 = 1.0  # Increased Cognitive coefficient\n        self.pso_c2 = 1.5  # Increased Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicBalancedDEPSO", "description": "A dynamically balanced DE-PSO hybrid that adapts mutation, crossover, and velocity to enhance exploration and exploitation in variable black-box landscapes.", "configspace": "", "generation": 3, "fitness": 0.28117462979698643, "feedback": "The algorithm DynamicBalancedDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.26.", "error": "", "parent_id": "720199ad-b727-429e-8a05-b06c2c728599", "metadata": {"aucs": [0.8395205268872161, 0.8395205268872161, 0.8395205268872161, 0.842614613246983, 0.842614613246983, 0.842614613246983, 0.832657468891856, 0.832657468891856, 0.832657468891856, 0.7024909936319196, 0.7024909936319196, 0.7024909936319196, 0.6651937668932637, 0.6651937668932637, 0.6651937668932637, 0.004803904585029328, 0.004803904585029328, 0.004803904585029328, 0.10819239359129096, 0.10819239359129096, 0.10819239359129096, 0.1071996413124231, 0.1071996413124231, 0.1071996413124231, 0.1660334919412324, 0.1660334919412324, 0.1660334919412324, 0.1092038376392318, 0.1092038376392318, 0.1092038376392318, 0.14515511237506784, 0.14515511237506784, 0.14515511237506784, 0.16483041339668203, 0.16483041339668203, 0.16483041339668203, 0.9804843892106927, 0.9804843892106927, 0.9804843892106927, 0.9812136545834106, 0.9812136545834106, 0.9812136545834106, 0.9897784229533296, 0.9897784229533296, 0.9897784229533296, 0.453371174962937, 0.453371174962937, 0.453371174962937, 0.46234583582953903, 0.46234583582953903, 0.46234583582953903, 0.0893259783001158, 0.0893259783001158, 0.0893259783001158, 0.21249285895503944, 0.21249285895503944, 0.21249285895503944, 0.16116201241305717, 0.16116201241305717, 0.16116201241305717, 0.23346187780820693, 0.23346187780820693, 0.23346187780820693, 0.2661476038662747, 0.2661476038662747, 0.2661476038662747, 0.21007399981746366, 0.21007399981746366, 0.21007399981746366, 0.2648214233700281, 0.2648214233700281, 0.2648214233700281, 0.21797834889079226, 0.21797834889079226, 0.21797834889079226, 0.26348344982122607, 0.26348344982122607, 0.26348344982122607, 0.12688695168827102, 0.12688695168827102, 0.12688695168827102, 0.05120493810658777, 0.05120493810658777, 0.05120493810658777, 0.023459074351242504, 0.023459074351242504, 0.023459074351242504, 0.002748746879932873, 0.002748746879932873, 0.002748746879932873, 0.040635256819508525, 0.040635256819508525, 0.040635256819508525, 0.04170702571688545, 0.04170702571688545, 0.04170702571688545, 0.08090507516324574, 0.08090507516324574, 0.08090507516324574, 0.03258912474065001, 0.03258912474065001, 0.03258912474065001, 0.07557868865643635, 0.07557868865643635, 0.07557868865643635, 0.06669687000956293, 0.06669687000956293, 0.06669687000956293, 0.1456751735002274, 0.1456751735002274, 0.1456751735002274, 0.20385585120148197, 0.20385585120148197, 0.20385585120148197, 0.12109448633592124, 0.12109448633592124, 0.12109448633592124, 0.5392562563218777, 0.5392562563218777, 0.5392562563218777, 0.5430312717720893, 0.5430312717720893, 0.5430312717720893, 0.6229134286714089, 0.6229134286714089, 0.6229134286714089, 0.10876237592864213, 0.10876237592864213, 0.10876237592864213, 0.11831032004424646, 0.11831032004424646, 0.11831032004424646, 0.13316658456404584, 0.13316658456404584, 0.13316658456404584, 0.158702221563373, 0.158702221563373, 0.158702221563373, 0.18079244634994007, 0.18079244634994007, 0.18079244634994007, 0.15734752359107862, 0.15734752359107862, 0.15734752359107862, 0.4829485144071083, 0.4829485144071083, 0.4829485144071083, 0.4208195677997364, 0.4208195677997364, 0.4208195677997364, 0.5371832925010901, 0.5371832925010901, 0.5371832925010901, 0.2720188621705152, 0.2720188621705152, 0.2720188621705152, 0.34252867431686795, 0.34252867431686795, 0.34252867431686795, 0.15476630342494446, 0.15476630342494446, 0.15476630342494446, 0.194016608793797, 0.194016608793797, 0.194016608793797, 0.20015482370060944, 0.20015482370060944, 0.20015482370060944, 0.17538690154211012, 0.17538690154211012, 0.17538690154211012, 0.1921535007942029, 0.1921535007942029, 0.1921535007942029, 0.19368457937009176, 0.19368457937009176, 0.19368457937009176, 0.6017809829013586, 0.6017809829013586, 0.6017809829013586, 0.8479641055300624, 0.8479641055300624, 0.8479641055300624, 0.1567419973591737, 0.1567419973591737, 0.1567419973591737, 0.16042399437944155, 0.16042399437944155, 0.16042399437944155, 0.11001327315837439, 0.11001327315837439, 0.11001327315837439, 0.20986629928240919, 0.20986629928240919, 0.20986629928240919, 0.15595631459182713, 0.15595631459182713, 0.15595631459182713, 0.18085370447751647, 0.18085370447751647, 0.18085370447751647, 0.1861322228800284, 0.1861322228800284, 0.1861322228800284, 0.18405112549213298, 0.18405112549213298, 0.18405112549213298, 0.07705096010901502, 0.07705096010901502, 0.07705096010901502, 0.08190827800827849, 0.08190827800827849, 0.08190827800827849, 0.0768115712413695, 0.0768115712413695, 0.0768115712413695]}, "mutation_prompt": null}
{"id": "31c4bdc8-ccae-4d4d-a379-7bf4a9fb2291", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Initial Differential weight\n        self.initial_de_cr = 0.9  # Initial Crossover probability\n        self.initial_pso_w = 0.5  # Initial Inertia weight\n        self.pso_c1 = 0.8  # Cognitive coefficient\n        self.pso_c2 = 1.2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid metaheuristic combining Differential Evolution and Particle Swarm Optimization with dynamic parameter tuning for improved convergence in black-box optimization.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "720199ad-b727-429e-8a05-b06c2c728599", "metadata": {"aucs": [0.9339725563951505, 0.9339725563951505, 0.9339725563951505, 0.9330231889239842, 0.9330231889239842, 0.9330231889239842, 0.9256036256393436, 0.9256036256393436, 0.9256036256393436, 0.8256146482236011, 0.8256146482236011, 0.8256146482236011, 0.8388097804739391, 0.8388097804739391, 0.8388097804739391, 0.05512810245303823, 0.05512810245303823, 0.05512810245303823, 0.13994739937588763, 0.13994739937588763, 0.13994739937588763, 0.12557516087798593, 0.12557516087798593, 0.12557516087798593, 0.15781560606594902, 0.15781560606594902, 0.15781560606594902, 0.09305798726684811, 0.09305798726684811, 0.09305798726684811, 0.11690710967418616, 0.11690710967418616, 0.11690710967418616, 0.15579508290917543, 0.15579508290917543, 0.15579508290917543, 0.9854640553796544, 0.9854640553796544, 0.9854640553796544, 0.9850952946413012, 0.9850952946413012, 0.9850952946413012, 0.9887847257319362, 0.9887847257319362, 0.9887847257319362, 0.8271107093010446, 0.8271107093010446, 0.8271107093010446, 0.80626729754881, 0.80626729754881, 0.80626729754881, 0.820616524611336, 0.820616524611336, 0.820616524611336, 0.11220299296783798, 0.11220299296783798, 0.11220299296783798, 0.15717062937694704, 0.15717062937694704, 0.15717062937694704, 0.1674645941316638, 0.1674645941316638, 0.1674645941316638, 0.30675241338932524, 0.30675241338932524, 0.30675241338932524, 0.1088711034397184, 0.1088711034397184, 0.1088711034397184, 0.3253007709306044, 0.3253007709306044, 0.3253007709306044, 0.3070392810818682, 0.3070392810818682, 0.3070392810818682, 0.4123952531383921, 0.4123952531383921, 0.4123952531383921, 0.28302453778476067, 0.28302453778476067, 0.28302453778476067, 0.017983383878773962, 0.017983383878773962, 0.017983383878773962, 0.08904366940139807, 0.08904366940139807, 0.08904366940139807, 0.07232083468011408, 0.07232083468011408, 0.07232083468011408, 0.2151318057848598, 0.2151318057848598, 0.2151318057848598, 0.027070855530059834, 0.027070855530059834, 0.027070855530059834, 0.0673365146537559, 0.0673365146537559, 0.0673365146537559, 0.06417376016032561, 0.06417376016032561, 0.06417376016032561, 0.08433784565478997, 0.08433784565478997, 0.08433784565478997, 0.17983994789053837, 0.17983994789053837, 0.17983994789053837, 0.11688050751210344, 0.11688050751210344, 0.11688050751210344, 0.03962667239839157, 0.03962667239839157, 0.03962667239839157, 0.08530988828009645, 0.08530988828009645, 0.08530988828009645, 0.5580025790752474, 0.5580025790752474, 0.5580025790752474, 0.6024245631455081, 0.6024245631455081, 0.6024245631455081, 0.6202405077733554, 0.6202405077733554, 0.6202405077733554, 0.1131351843518783, 0.1131351843518783, 0.1131351843518783, 0.04558345444470757, 0.04558345444470757, 0.04558345444470757, 0.1103901254975872, 0.1103901254975872, 0.1103901254975872, 0.19533774989491826, 0.19533774989491826, 0.19533774989491826, 0.13916585261960268, 0.13916585261960268, 0.13916585261960268, 0.20100846360364277, 0.20100846360364277, 0.20100846360364277, 0.44209136450341224, 0.44209136450341224, 0.44209136450341224, 0.26091067565248827, 0.26091067565248827, 0.26091067565248827, 0.7721040446086165, 0.7721040446086165, 0.7721040446086165, 0.2102517123495924, 0.2102517123495924, 0.2102517123495924, 0.19302146706305767, 0.19302146706305767, 0.19302146706305767, 0.22096271383349653, 0.22096271383349653, 0.22096271383349653, 0.2084750212809774, 0.2084750212809774, 0.2084750212809774, 0.21741596023268173, 0.21741596023268173, 0.21741596023268173, 0.1889726386456556, 0.1889726386456556, 0.1889726386456556, 0.21262632706368612, 0.21262632706368612, 0.21262632706368612, 0.2040763578114495, 0.2040763578114495, 0.2040763578114495, 0.25287101713371984, 0.25287101713371984, 0.25287101713371984, 0.9463904615236902, 0.9463904615236902, 0.9463904615236902, 0.9576596506883958, 0.9576596506883958, 0.9576596506883958, 0.16796337524311133, 0.16796337524311133, 0.16796337524311133, 0.9139672802159426, 0.9139672802159426, 0.9139672802159426, 0.21331730480780475, 0.21331730480780475, 0.21331730480780475, 0.13035052690846627, 0.13035052690846627, 0.13035052690846627, 0.17971081791160437, 0.17971081791160437, 0.17971081791160437, 0.18229336876633329, 0.18229336876633329, 0.18229336876633329, 0.19645373411435718, 0.19645373411435718, 0.19645373411435718, 0.09175106975049274, 0.09175106975049274, 0.09175106975049274, 0.10903095908759874, 0.10903095908759874, 0.10903095908759874, 0.09442060664673735, 0.09442060664673735, 0.09442060664673735]}, "mutation_prompt": null}
{"id": "3e84517e-4ff6-43e4-84e1-0cbf0525f042", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Initial Differential weight\n        self.initial_de_cr = 0.9  # Initial Crossover probability\n        self.initial_pso_w = 0.5  # Initial Inertia weight\n        self.pso_c1 = 0.8  # Cognitive coefficient\n        self.pso_c2 = 1.2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by repositioning some solutions\n            if self.eval_count >= self.max_evaluations * 0.8:\n                diversity_count = max(1, int(self.population_size * 0.1))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A self-adaptive evolutionary algorithm blending Differential Evolution and Particle Swarm Optimization with progressive parameter tuning and diversity preservation for enhanced global search efficiency.", "configspace": "", "generation": 5, "fitness": 0.3362411742986524, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.31.", "error": "", "parent_id": "720199ad-b727-429e-8a05-b06c2c728599", "metadata": {"aucs": [0.9339725563951505, 0.9339725563951505, 0.9339725563951505, 0.9330231889239842, 0.9330231889239842, 0.9330231889239842, 0.9256036256393436, 0.9256036256393436, 0.9256036256393436, 0.8256146482236011, 0.8256146482236011, 0.8256146482236011, 0.8388097804739391, 0.8388097804739391, 0.8388097804739391, 0.11820172441560639, 0.11820172441560639, 0.11820172441560639, 0.13994739937588763, 0.13994739937588763, 0.13994739937588763, 0.12975802823500904, 0.12975802823500904, 0.12975802823500904, 0.15867674281757793, 0.15867674281757793, 0.15867674281757793, 0.09318302201600859, 0.09318302201600859, 0.09318302201600859, 0.11830715412440918, 0.11830715412440918, 0.11830715412440918, 0.15579508290917543, 0.15579508290917543, 0.15579508290917543, 0.9854640553796544, 0.9854640553796544, 0.9854640553796544, 0.9850952946413012, 0.9850952946413012, 0.9850952946413012, 0.9887847257319362, 0.9887847257319362, 0.9887847257319362, 0.8271107093010446, 0.8271107093010446, 0.8271107093010446, 0.80626729754881, 0.80626729754881, 0.80626729754881, 0.820616524611336, 0.820616524611336, 0.820616524611336, 0.11768762883217987, 0.11768762883217987, 0.11768762883217987, 0.16355859011826546, 0.16355859011826546, 0.16355859011826546, 0.1720145839965369, 0.1720145839965369, 0.1720145839965369, 0.30692499356969005, 0.30692499356969005, 0.30692499356969005, 0.11397174123145182, 0.11397174123145182, 0.11397174123145182, 0.323992965993784, 0.323992965993784, 0.323992965993784, 0.30555616300052746, 0.30555616300052746, 0.30555616300052746, 0.40906146207238814, 0.40906146207238814, 0.40906146207238814, 0.28240236952066233, 0.28240236952066233, 0.28240236952066233, 0.01788095746837859, 0.01788095746837859, 0.01788095746837859, 0.08901611329903047, 0.08901611329903047, 0.08901611329903047, 0.0717114942397653, 0.0717114942397653, 0.0717114942397653, 0.21474922454467216, 0.21474922454467216, 0.21474922454467216, 0.02701792857305141, 0.02701792857305141, 0.02701792857305141, 0.06903542074227131, 0.06903542074227131, 0.06903542074227131, 0.064169353986546, 0.064169353986546, 0.064169353986546, 0.08433498558456087, 0.08433498558456087, 0.08433498558456087, 0.17983713043141947, 0.17983713043141947, 0.17983713043141947, 0.11688050751210344, 0.11688050751210344, 0.11688050751210344, 0.03962667239839157, 0.03962667239839157, 0.03962667239839157, 0.08530988828009645, 0.08530988828009645, 0.08530988828009645, 0.5568409834636784, 0.5568409834636784, 0.5568409834636784, 0.6021336387685623, 0.6021336387685623, 0.6021336387685623, 0.6202735366921859, 0.6202735366921859, 0.6202735366921859, 0.1131351843518783, 0.1131351843518783, 0.1131351843518783, 0.047171435325926714, 0.047171435325926714, 0.047171435325926714, 0.1103901254975872, 0.1103901254975872, 0.1103901254975872, 0.19533774989491826, 0.19533774989491826, 0.19533774989491826, 0.13916585261960268, 0.13916585261960268, 0.13916585261960268, 0.20100846360364277, 0.20100846360364277, 0.20100846360364277, 0.44209136450341224, 0.44209136450341224, 0.44209136450341224, 0.2609106756456526, 0.2609106756456526, 0.2609106756456526, 0.7721040446086165, 0.7721040446086165, 0.7721040446086165, 0.21025170294937456, 0.21025170294937456, 0.21025170294937456, 0.19302146684021204, 0.19302146684021204, 0.19302146684021204, 0.22096271383349653, 0.22096271383349653, 0.22096271383349653, 0.21225989169416393, 0.21225989169416393, 0.21225989169416393, 0.21741596023268173, 0.21741596023268173, 0.21741596023268173, 0.18936488060375656, 0.18936488060375656, 0.18936488060375656, 0.21262632706368612, 0.21262632706368612, 0.21262632706368612, 0.2040763578114495, 0.2040763578114495, 0.2040763578114495, 0.25287101713371984, 0.25287101713371984, 0.25287101713371984, 0.9463904615236902, 0.9463904615236902, 0.9463904615236902, 0.9576596506883958, 0.9576596506883958, 0.9576596506883958, 0.1766314777945439, 0.1766314777945439, 0.1766314777945439, 0.9139672802159426, 0.9139672802159426, 0.9139672802159426, 0.21331730480780475, 0.21331730480780475, 0.21331730480780475, 0.13565278344356124, 0.13565278344356124, 0.13565278344356124, 0.17904416987479477, 0.17904416987479477, 0.17904416987479477, 0.1825268851212838, 0.1825268851212838, 0.1825268851212838, 0.19643967528431672, 0.19643967528431672, 0.19643967528431672, 0.09176619259860508, 0.09176619259860508, 0.09176619259860508, 0.1091588354143549, 0.1091588354143549, 0.1091588354143549, 0.09442472343792652, 0.09442472343792652, 0.09442472343792652]}, "mutation_prompt": null}
{"id": "45a7820c-10c0-40cf-aa38-de7a8b3c738e", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population for diversity\n        self.initial_de_f = 0.7  # Adjusted Differential weight for balance\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.4  # Adjusted Inertia weight for exploration\n        self.pso_c1 = 1.0  # Increased cognitive coefficient for exploration\n        self.pso_c2 = 1.5  # Increased social coefficient for exploitation\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by repositioning some solutions\n            if self.eval_count >= self.max_evaluations * 0.7:\n                diversity_count = max(1, int(self.population_size * 0.15))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with dynamic parameter adaptation and spatial diversity strategies for robust global optimization.", "configspace": "", "generation": 6, "fitness": 0.31271322408724445, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.30.", "error": "", "parent_id": "3e84517e-4ff6-43e4-84e1-0cbf0525f042", "metadata": {"aucs": [0.926365353094424, 0.926365353094424, 0.926365353094424, 0.9112108341514201, 0.9112108341514201, 0.9112108341514201, 0.9330378628231683, 0.9330378628231683, 0.9330378628231683, 0.8335368236254249, 0.8335368236254249, 0.8335368236254249, 0.8400599322409387, 0.8400599322409387, 0.8400599322409387, 0.8480852860370265, 0.8480852860370265, 0.8480852860370265, 0.11093256403988183, 0.11093256403988183, 0.11093256403988183, 0.10348787966151962, 0.10348787966151962, 0.10348787966151962, 0.07008912572645754, 0.07008912572645754, 0.07008912572645754, 0.11695293409260343, 0.11695293409260343, 0.11695293409260343, 0.10578522150693859, 0.10578522150693859, 0.10578522150693859, 0.10051037280845943, 0.10051037280845943, 0.10051037280845943, 0.9801445658959937, 0.9801445658959937, 0.9801445658959937, 0.9892544552821826, 0.9892544552821826, 0.9892544552821826, 0.9863094044798876, 0.9863094044798876, 0.9863094044798876, 0.7865682661838908, 0.7865682661838908, 0.7865682661838908, 0.8025790602791469, 0.8025790602791469, 0.8025790602791469, 0.8351186137617598, 0.8351186137617598, 0.8351186137617598, 0.22666353412153828, 0.22666353412153828, 0.22666353412153828, 0.16220868293849977, 0.16220868293849977, 0.16220868293849977, 0.1522621215614105, 0.1522621215614105, 0.1522621215614105, 0.21740795162884552, 0.21740795162884552, 0.21740795162884552, 0.23737720227925407, 0.23737720227925407, 0.23737720227925407, 0.30880413603933987, 0.30880413603933987, 0.30880413603933987, 0.13610622221858015, 0.13610622221858015, 0.13610622221858015, 0.13532482543164337, 0.13532482543164337, 0.13532482543164337, 0.3413317422780454, 0.3413317422780454, 0.3413317422780454, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02318365167203207, 0.02318365167203207, 0.02318365167203207, 0.07392587022471764, 0.07392587022471764, 0.07392587022471764, 0.003077838501073571, 0.003077838501073571, 0.003077838501073571, 0.03278904572496599, 0.03278904572496599, 0.03278904572496599, 0.060572785492876036, 0.060572785492876036, 0.060572785492876036, 0.1834558469639883, 0.1834558469639883, 0.1834558469639883, 0.07797870013912911, 0.07797870013912911, 0.07797870013912911, 0.2700697013862484, 0.2700697013862484, 0.2700697013862484, 0.050719508951105996, 0.050719508951105996, 0.050719508951105996, 0.19099770586042197, 0.19099770586042197, 0.19099770586042197, 0.606372274106926, 0.606372274106926, 0.606372274106926, 0.5792425432432364, 0.5792425432432364, 0.5792425432432364, 0.5872938610933054, 0.5872938610933054, 0.5872938610933054, 0.1262488177092077, 0.1262488177092077, 0.1262488177092077, 0.14189260433226059, 0.14189260433226059, 0.14189260433226059, 0.15366691734417381, 0.15366691734417381, 0.15366691734417381, 0.1599846661364145, 0.1599846661364145, 0.1599846661364145, 0.25847290165582604, 0.25847290165582604, 0.25847290165582604, 0.20240623296084415, 0.20240623296084415, 0.20240623296084415, 0.23571152686395513, 0.23571152686395513, 0.23571152686395513, 0.20246213018373915, 0.20246213018373915, 0.20246213018373915, 0.4666543215579889, 0.4666543215579889, 0.4666543215579889, 0.19386300618075647, 0.19386300618075647, 0.19386300618075647, 0.2103362618183795, 0.2103362618183795, 0.2103362618183795, 0.30948960743026965, 0.30948960743026965, 0.30948960743026965, 0.28824566759880177, 0.28824566759880177, 0.28824566759880177, 0.19054102331390443, 0.19054102331390443, 0.19054102331390443, 0.22510571124803924, 0.22510571124803924, 0.22510571124803924, 0.18167432361833968, 0.18167432361833968, 0.18167432361833968, 0.2115501579656498, 0.2115501579656498, 0.2115501579656498, 0.2094163177892987, 0.2094163177892987, 0.2094163177892987, 0.9376548708393853, 0.9376548708393853, 0.9376548708393853, 0.1594179139218268, 0.1594179139218268, 0.1594179139218268, 0.12566622916673498, 0.12566622916673498, 0.12566622916673498, 0.16915254171672844, 0.16915254171672844, 0.16915254171672844, 0.21070340642930807, 0.21070340642930807, 0.21070340642930807, 0.1570066592664614, 0.1570066592664614, 0.1570066592664614, 0.20036864593466586, 0.20036864593466586, 0.20036864593466586, 0.19672967685364606, 0.19672967685364606, 0.19672967685364606, 0.18338543111544958, 0.18338543111544958, 0.18338543111544958, 0.09424368713817255, 0.09424368713817255, 0.09424368713817255, 0.09035183019634407, 0.09035183019634407, 0.09035183019634407, 0.08555473844671868, 0.08555473844671868, 0.08555473844671868]}, "mutation_prompt": null}
{"id": "6eaa4dcb-72e4-4f27-ab0d-aee1ab0990ef", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO_StochasticTunneling:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8\n        self.initial_de_cr = 0.9\n        self.initial_pso_w = 0.5\n        self.pso_c1 = 0.8\n        self.pso_c2 = 1.2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                for i in range(self.population_size):\n                    if self.eval_count >= self.max_evaluations:\n                        break\n                    tunneling_prob = np.random.rand()\n                    if tunneling_prob < 0.1:\n                        candidate = np.random.uniform(self.lb, self.ub, self.dim)\n                        candidate_fitness = func(candidate)\n                        self.eval_count += 1\n                        if candidate_fitness < fitness[i]:\n                            population[i] = candidate\n                            fitness[i] = candidate_fitness\n                            if candidate_fitness < personal_best_fitness[i]:\n                                personal_best[i] = candidate\n                                personal_best_fitness[i] = candidate_fitness\n                                if candidate_fitness < personal_best_fitness[global_best_idx]:\n                                    global_best = candidate\n                                    global_best_idx = i\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO_StochasticTunneling", "description": "A self-adaptive hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with dynamic parameter adjustment and stochastic tunneling for enhanced exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.3279747984859102, "feedback": "The algorithm AdaptiveHybridDEPSO_StochasticTunneling got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.31.", "error": "", "parent_id": "3e84517e-4ff6-43e4-84e1-0cbf0525f042", "metadata": {"aucs": [0.9229869302064724, 0.9229869302064724, 0.9229869302064724, 0.928746958233055, 0.928746958233055, 0.928746958233055, 0.9288808309999367, 0.9288808309999367, 0.9288808309999367, 0.821116710183588, 0.821116710183588, 0.821116710183588, 0.8400530540122357, 0.8400530540122357, 0.8400530540122357, 0.0552740594760216, 0.0552740594760216, 0.0552740594760216, 0.14313000827989586, 0.14313000827989586, 0.14313000827989586, 0.08985257902245525, 0.08985257902245525, 0.08985257902245525, 0.14365972254491877, 0.14365972254491877, 0.14365972254491877, 0.11757307194828959, 0.11757307194828959, 0.11757307194828959, 0.11743155020126106, 0.11743155020126106, 0.11743155020126106, 0.08888261031418476, 0.08888261031418476, 0.08888261031418476, 0.9854624730160755, 0.9854624730160755, 0.9854624730160755, 0.9850947329540954, 0.9850947329540954, 0.9850947329540954, 0.9887844447900065, 0.9887844447900065, 0.9887844447900065, 0.8593137718129817, 0.8593137718129817, 0.8593137718129817, 0.8050598168195702, 0.8050598168195702, 0.8050598168195702, 0.8088382592884856, 0.8088382592884856, 0.8088382592884856, 0.13941262854757375, 0.13941262854757375, 0.13941262854757375, 0.1571348703703701, 0.1571348703703701, 0.1571348703703701, 0.23614877512801835, 0.23614877512801835, 0.23614877512801835, 0.30020901855503446, 0.30020901855503446, 0.30020901855503446, 0.10905421429080686, 0.10905421429080686, 0.10905421429080686, 0.32590046241707504, 0.32590046241707504, 0.32590046241707504, 0.29395326071090344, 0.29395326071090344, 0.29395326071090344, 0.3057090540613413, 0.3057090540613413, 0.3057090540613413, 0.30710545795597877, 0.30710545795597877, 0.30710545795597877, 0.057157359602695745, 0.057157359602695745, 0.057157359602695745, 0.007317878065412287, 0.007317878065412287, 0.007317878065412287, 0.06325462548482541, 0.06325462548482541, 0.06325462548482541, 0.17306044151070832, 0.17306044151070832, 0.17306044151070832, 0.031145112278053277, 0.031145112278053277, 0.031145112278053277, 0.04436956483141363, 0.04436956483141363, 0.04436956483141363, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08656656581229982, 0.08656656581229982, 0.08656656581229982, 0.13643109438512924, 0.13643109438512924, 0.13643109438512924, 0.1403618797063877, 0.1403618797063877, 0.1403618797063877, 0.03955707820686072, 0.03955707820686072, 0.03955707820686072, 0.08481230853622024, 0.08481230853622024, 0.08481230853622024, 0.585550026358747, 0.585550026358747, 0.585550026358747, 0.6066600632750925, 0.6066600632750925, 0.6066600632750925, 0.6281536394603278, 0.6281536394603278, 0.6281536394603278, 0.15825638642346984, 0.15825638642346984, 0.15825638642346984, 0.06901949227220505, 0.06901949227220505, 0.06901949227220505, 0.09608000165933916, 0.09608000165933916, 0.09608000165933916, 0.18511250187678707, 0.18511250187678707, 0.18511250187678707, 0.19422588994860557, 0.19422588994860557, 0.19422588994860557, 0.21180252663284105, 0.21180252663284105, 0.21180252663284105, 0.4111750335470551, 0.4111750335470551, 0.4111750335470551, 0.2055859086229591, 0.2055859086229591, 0.2055859086229591, 0.4411090268478213, 0.4411090268478213, 0.4411090268478213, 0.27879047371848453, 0.27879047371848453, 0.27879047371848453, 0.25187709985330176, 0.25187709985330176, 0.25187709985330176, 0.1651093517274328, 0.1651093517274328, 0.1651093517274328, 0.23075013795070354, 0.23075013795070354, 0.23075013795070354, 0.21592077442218893, 0.21592077442218893, 0.21592077442218893, 0.2079115533960436, 0.2079115533960436, 0.2079115533960436, 0.20336408788556193, 0.20336408788556193, 0.20336408788556193, 0.2260628334255792, 0.2260628334255792, 0.2260628334255792, 0.2133064210738247, 0.2133064210738247, 0.2133064210738247, 0.9463482029723296, 0.9463482029723296, 0.9463482029723296, 0.9606648431508055, 0.9606648431508055, 0.9606648431508055, 0.16791755961673893, 0.16791755961673893, 0.16791755961673893, 0.8851269580717578, 0.8851269580717578, 0.8851269580717578, 0.21326051721643036, 0.21326051721643036, 0.21326051721643036, 0.1303566672631652, 0.1303566672631652, 0.1303566672631652, 0.1859731558995541, 0.1859731558995541, 0.1859731558995541, 0.18514862895655382, 0.18514862895655382, 0.18514862895655382, 0.1918633011705545, 0.1918633011705545, 0.1918633011705545, 0.09393352537380628, 0.09393352537380628, 0.09393352537380628, 0.10864495910376804, 0.10864495910376804, 0.10864495910376804, 0.0902207072510619, 0.0902207072510619, 0.0902207072510619]}, "mutation_prompt": null}
{"id": "06a7e5da-bf1c-4d8a-9e0a-4de22cb5d8bc", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for more diversity\n        self.initial_de_f = 0.7  # Adjusted initial Differential weight\n        self.initial_de_cr = 0.9  # Initial Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted initial Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(None)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1.0, 1.0, (self.population_size, self.dim))  # Random initial velocity\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * np.cos(progress_ratio * np.pi / 2)  # Dynamic DE scaling\n            de_cr = self.initial_de_cr * (1 - 0.4 * progress_ratio)\n            pso_w = self.initial_pso_w * (1 - 0.5 * progress_ratio)\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.15))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A stochastic optimization algorithm integrating Differential Evolution, Particle Swarm Optimization, and dynamic parameter scaling for robust performance on diverse problem landscapes.", "configspace": "", "generation": 8, "fitness": 0.31011779459722755, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "3e84517e-4ff6-43e4-84e1-0cbf0525f042", "metadata": {"aucs": [0.8442970258271894, 0.8475989368581073, 0.8694170892523185, 0.8696630577895373, 0.8504623890712476, 0.8375204009608691, 0.85328514605128, 0.8715926352976017, 0.8669081266353817, 0.07266434531435284, 0.7200996107308972, 0.0412819971266144, 0.7243160287632392, 0.7068120632581062, 0.6778406023110524, 0.7456505025572928, 0.06190031381887129, 0.7262237047053084, 0.1188514447655592, 0.1316659678961718, 0.14058477648245626, 0.1286629593058527, 0.17779407661328206, 0.14563776191537403, 0.11426441185202019, 0.15168393005531833, 0.11944915379091436, 0.11350017798646417, 0.12923292456622404, 0.1049497591957248, 0.12805094239270043, 0.11704324083058293, 0.13918085865893115, 0.1282758968181733, 0.13560400557848984, 0.13245532438694285, 0.9906035945485873, 0.9858715111682109, 0.9892226389143284, 0.9901867531374683, 0.9902715439988405, 0.986245722496011, 0.986241119365596, 0.9889097195849721, 0.9806378423747055, 0.6383317645779093, 0.6617362847069739, 0.6285103568813253, 0.6223109240961245, 0.664018591016069, 0.623950367156455, 0.6432111521173515, 0.1214429694586554, 0.125920427591232, 0.7461689476140827, 0.7578056189498008, 0.17067766524734873, 0.35992034006654106, 0.2104156124367088, 0.2701089995469137, 0.2263670024500617, 0.17839225281896087, 0.39414590143010064, 0.29377834850221685, 0.31371749996914267, 0.27264776159144244, 0.2648288526672128, 0.13272958216079622, 0.12643482683050677, 0.29872630628657515, 0.2993460978846251, 0.31942524470457867, 0.06889177905907817, 0.2753868927021076, 0.25344787977977323, 0.40575748024827096, 0.2873754953266118, 0.28477044221260783, 0.10452005846478463, 0.3319436697113044, 0.3087471572035231, 0.004374087507670432, 0.03698595898554757, 9.999999999998899e-05, 0.04312216655762435, 0.00015175099514885826, 9.999999999998899e-05, 0.057659694259013516, 0.0798806228050768, 0.06825382588277429, 0.03019285011884043, 0.044575860895775254, 0.06034913217152693, 0.01529284492643368, 0.10104615407382078, 0.01833340614629908, 0.10388626977360182, 0.013100689509759289, 0.14094450093414834, 9.999999999998899e-05, 0.09479914564744119, 0.0006388729184853004, 0.07506937817098658, 0.08937109662001863, 0.15754253615859615, 0.08692602191981003, 0.09832790114128165, 0.11239838785050105, 0.08612550745211234, 0.07860379563429865, 0.30154438542194373, 0.10227522643875475, 0.2004192665202187, 0.11465437124283506, 0.057369524623759216, 0.057234071789864505, 0.07942378701145847, 0.5830150408419884, 0.6098382821229416, 0.5816088666558181, 0.6116972465550248, 0.5457586312180793, 0.5572509886765589, 0.5657947733582759, 0.6036648411207586, 0.5902687913542048, 0.12467265557165352, 0.08449173594923709, 0.0882194985282091, 0.09780777408474173, 0.1325893330919411, 0.11589667521230529, 0.12337920351176401, 0.14462128138845487, 0.1490078049369875, 0.1678984644334106, 0.16756209322129323, 0.1692175866321204, 0.17749822749895028, 0.14437772042415253, 0.13551299507920123, 0.1973149152136865, 0.42019102403356123, 0.16214481261893143, 0.2555351412403367, 0.4864706018989059, 0.29195748162369783, 0.3790427998954733, 0.4555919466461926, 0.38984778732745085, 0.660486785035578, 0.6684268210593236, 0.558541750880661, 0.23851612626947094, 0.22341200438137265, 0.16975567068140152, 0.36435229552715687, 0.18807311313602115, 0.21488161986551202, 0.1559388705991529, 0.30511547408939454, 0.3908351161055911, 0.197919173679851, 0.21538250203544718, 0.2022824010677633, 0.20093070956852133, 0.21902267742454784, 0.1963096448351188, 0.20114613664895764, 0.19334179979208943, 0.1989881037354696, 0.208649176255863, 0.1891022407824855, 0.21843221511731048, 0.20578104777206552, 0.20258743801753298, 0.21026285641812137, 0.22565212146901215, 0.2179383186470245, 0.2065485425969945, 0.9217352335408345, 0.8853822918632933, 0.18480575482214978, 0.16946850093163557, 0.14149877325182336, 0.1522272471693994, 0.8329982751865368, 0.8586899333274138, 0.17001525491116465, 0.21050366500447315, 0.12765602973966328, 0.1633003879280963, 0.16890251298903236, 0.8071559850107504, 0.762262954209231, 0.16710043572651356, 0.8041545112200283, 0.16814782047556798, 0.1683033983490133, 0.20600713655991199, 0.18174719591863742, 0.18228906066068717, 0.1913046339511083, 0.18915438969635145, 0.18085156946581193, 0.1867415374178092, 0.18392319988719097, 0.07889327583022987, 0.0783786057588115, 0.08507123515366533, 0.07864849766428905, 0.08429755211568501, 0.08068479987246224, 0.07664942886745196, 0.08504255117328063, 0.08339454130766755]}, "mutation_prompt": null}
{"id": "44eb9728-75bc-4ac1-ba8e-fedaae4dc73c", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Initial Differential weight\n        self.initial_de_cr = 0.9  # Initial Crossover probability\n        self.initial_pso_w = 0.5  # Initial Inertia weight\n        self.pso_c1 = 0.8  # Cognitive coefficient\n        self.pso_c2 = 1.2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by repositioning some solutions\n            if self.eval_count >= self.max_evaluations * 0.8:\n                diversity_count = max(1, int(self.population_size * 0.1))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A self-adaptive evolutionary algorithm blending Differential Evolution and Particle Swarm Optimization with progressive parameter tuning and diversity preservation for enhanced global search efficiency.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "3e84517e-4ff6-43e4-84e1-0cbf0525f042", "metadata": {"aucs": [0.9339725563951505, 0.9339725563951505, 0.9339725563951505, 0.9330231889239842, 0.9330231889239842, 0.9330231889239842, 0.9256036256393436, 0.9256036256393436, 0.9256036256393436, 0.8256146482236011, 0.8256146482236011, 0.8256146482236011, 0.8388097804739391, 0.8388097804739391, 0.8388097804739391, 0.11820172441560639, 0.11820172441560639, 0.11820172441560639, 0.13994739937588763, 0.13994739937588763, 0.13994739937588763, 0.12975802823500904, 0.12975802823500904, 0.12975802823500904, 0.15867674281757793, 0.15867674281757793, 0.15867674281757793, 0.09318302201600859, 0.09318302201600859, 0.09318302201600859, 0.11830715412440918, 0.11830715412440918, 0.11830715412440918, 0.15579508290917543, 0.15579508290917543, 0.15579508290917543, 0.9854640553796544, 0.9854640553796544, 0.9854640553796544, 0.9850952946413012, 0.9850952946413012, 0.9850952946413012, 0.9887847257319362, 0.9887847257319362, 0.9887847257319362, 0.8271107093010446, 0.8271107093010446, 0.8271107093010446, 0.80626729754881, 0.80626729754881, 0.80626729754881, 0.820616524611336, 0.820616524611336, 0.820616524611336, 0.11768762883217987, 0.11768762883217987, 0.11768762883217987, 0.16355859011826546, 0.16355859011826546, 0.16355859011826546, 0.1720145839965369, 0.1720145839965369, 0.1720145839965369, 0.30692499356969005, 0.30692499356969005, 0.30692499356969005, 0.11397174123145182, 0.11397174123145182, 0.11397174123145182, 0.323992965993784, 0.323992965993784, 0.323992965993784, 0.30555616300052746, 0.30555616300052746, 0.30555616300052746, 0.40906146207238814, 0.40906146207238814, 0.40906146207238814, 0.28240236952066233, 0.28240236952066233, 0.28240236952066233, 0.01788095746837859, 0.01788095746837859, 0.01788095746837859, 0.08901611329903047, 0.08901611329903047, 0.08901611329903047, 0.0717114942397653, 0.0717114942397653, 0.0717114942397653, 0.21474922454467216, 0.21474922454467216, 0.21474922454467216, 0.02701792857305141, 0.02701792857305141, 0.02701792857305141, 0.06903542074227131, 0.06903542074227131, 0.06903542074227131, 0.064169353986546, 0.064169353986546, 0.064169353986546, 0.08433498558456087, 0.08433498558456087, 0.08433498558456087, 0.17983713043141947, 0.17983713043141947, 0.17983713043141947, 0.11688050751210344, 0.11688050751210344, 0.11688050751210344, 0.03962667239839157, 0.03962667239839157, 0.03962667239839157, 0.08530988828009645, 0.08530988828009645, 0.08530988828009645, 0.5568409834636784, 0.5568409834636784, 0.5568409834636784, 0.6021336387685623, 0.6021336387685623, 0.6021336387685623, 0.6202735366921859, 0.6202735366921859, 0.6202735366921859, 0.1131351843518783, 0.1131351843518783, 0.1131351843518783, 0.047171435325926714, 0.047171435325926714, 0.047171435325926714, 0.1103901254975872, 0.1103901254975872, 0.1103901254975872, 0.19533774989491826, 0.19533774989491826, 0.19533774989491826, 0.13916585261960268, 0.13916585261960268, 0.13916585261960268, 0.20100846360364277, 0.20100846360364277, 0.20100846360364277, 0.44209136450341224, 0.44209136450341224, 0.44209136450341224, 0.2609106756456526, 0.2609106756456526, 0.2609106756456526, 0.7721040446086165, 0.7721040446086165, 0.7721040446086165, 0.21025170294937456, 0.21025170294937456, 0.21025170294937456, 0.19302146684021204, 0.19302146684021204, 0.19302146684021204, 0.22096271383349653, 0.22096271383349653, 0.22096271383349653, 0.21225989169416393, 0.21225989169416393, 0.21225989169416393, 0.21741596023268173, 0.21741596023268173, 0.21741596023268173, 0.18936488060375656, 0.18936488060375656, 0.18936488060375656, 0.21262632706368612, 0.21262632706368612, 0.21262632706368612, 0.2040763578114495, 0.2040763578114495, 0.2040763578114495, 0.25287101713371984, 0.25287101713371984, 0.25287101713371984, 0.9463904615236902, 0.9463904615236902, 0.9463904615236902, 0.9576596506883958, 0.9576596506883958, 0.9576596506883958, 0.1766314777945439, 0.1766314777945439, 0.1766314777945439, 0.9139672802159426, 0.9139672802159426, 0.9139672802159426, 0.21331730480780475, 0.21331730480780475, 0.21331730480780475, 0.13565278344356124, 0.13565278344356124, 0.13565278344356124, 0.17904416987479477, 0.17904416987479477, 0.17904416987479477, 0.1825268851212838, 0.1825268851212838, 0.1825268851212838, 0.19643967528431672, 0.19643967528431672, 0.19643967528431672, 0.09176619259860508, 0.09176619259860508, 0.09176619259860508, 0.1091588354143549, 0.1091588354143549, 0.1091588354143549, 0.09442472343792652, 0.09442472343792652, 0.09442472343792652]}, "mutation_prompt": null}
{"id": "28c8ca26-b005-41af-af53-046195d67863", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Initial Differential weight\n        self.initial_de_cr = 0.9  # Initial Crossover probability\n        self.initial_pso_w = 0.5  # Initial Inertia weight\n        self.pso_c1 = 0.8  # Cognitive coefficient\n        self.pso_c2 = 1.2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by repositioning some solutions\n            if self.eval_count >= self.max_evaluations * 0.8:\n                diversity_count = max(1, int(self.population_size * 0.1))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A self-adaptive evolutionary algorithm blending Differential Evolution and Particle Swarm Optimization with progressive parameter tuning and diversity preservation for enhanced global search efficiency.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "3e84517e-4ff6-43e4-84e1-0cbf0525f042", "metadata": {"aucs": [0.9339725563951505, 0.9339725563951505, 0.9339725563951505, 0.9330231889239842, 0.9330231889239842, 0.9330231889239842, 0.9256036256393436, 0.9256036256393436, 0.9256036256393436, 0.8256146482236011, 0.8256146482236011, 0.8256146482236011, 0.8388097804739391, 0.8388097804739391, 0.8388097804739391, 0.11820172441560639, 0.11820172441560639, 0.11820172441560639, 0.13994739937588763, 0.13994739937588763, 0.13994739937588763, 0.12975802823500904, 0.12975802823500904, 0.12975802823500904, 0.15867674281757793, 0.15867674281757793, 0.15867674281757793, 0.09318302201600859, 0.09318302201600859, 0.09318302201600859, 0.11830715412440918, 0.11830715412440918, 0.11830715412440918, 0.15579508290917543, 0.15579508290917543, 0.15579508290917543, 0.9854640553796544, 0.9854640553796544, 0.9854640553796544, 0.9850952946413012, 0.9850952946413012, 0.9850952946413012, 0.9887847257319362, 0.9887847257319362, 0.9887847257319362, 0.8271107093010446, 0.8271107093010446, 0.8271107093010446, 0.80626729754881, 0.80626729754881, 0.80626729754881, 0.820616524611336, 0.820616524611336, 0.820616524611336, 0.11768762883217987, 0.11768762883217987, 0.11768762883217987, 0.16355859011826546, 0.16355859011826546, 0.16355859011826546, 0.1720145839965369, 0.1720145839965369, 0.1720145839965369, 0.30692499356969005, 0.30692499356969005, 0.30692499356969005, 0.11397174123145182, 0.11397174123145182, 0.11397174123145182, 0.323992965993784, 0.323992965993784, 0.323992965993784, 0.30555616300052746, 0.30555616300052746, 0.30555616300052746, 0.40906146207238814, 0.40906146207238814, 0.40906146207238814, 0.28240236952066233, 0.28240236952066233, 0.28240236952066233, 0.01788095746837859, 0.01788095746837859, 0.01788095746837859, 0.08901611329903047, 0.08901611329903047, 0.08901611329903047, 0.0717114942397653, 0.0717114942397653, 0.0717114942397653, 0.21474922454467216, 0.21474922454467216, 0.21474922454467216, 0.02701792857305141, 0.02701792857305141, 0.02701792857305141, 0.06903542074227131, 0.06903542074227131, 0.06903542074227131, 0.064169353986546, 0.064169353986546, 0.064169353986546, 0.08433498558456087, 0.08433498558456087, 0.08433498558456087, 0.17983713043141947, 0.17983713043141947, 0.17983713043141947, 0.11688050751210344, 0.11688050751210344, 0.11688050751210344, 0.03962667239839157, 0.03962667239839157, 0.03962667239839157, 0.08530988828009645, 0.08530988828009645, 0.08530988828009645, 0.5568409834636784, 0.5568409834636784, 0.5568409834636784, 0.6021336387685623, 0.6021336387685623, 0.6021336387685623, 0.6202735366921859, 0.6202735366921859, 0.6202735366921859, 0.1131351843518783, 0.1131351843518783, 0.1131351843518783, 0.047171435325926714, 0.047171435325926714, 0.047171435325926714, 0.1103901254975872, 0.1103901254975872, 0.1103901254975872, 0.19533774989491826, 0.19533774989491826, 0.19533774989491826, 0.13916585261960268, 0.13916585261960268, 0.13916585261960268, 0.20100846360364277, 0.20100846360364277, 0.20100846360364277, 0.44209136450341224, 0.44209136450341224, 0.44209136450341224, 0.2609106756456526, 0.2609106756456526, 0.2609106756456526, 0.7721040446086165, 0.7721040446086165, 0.7721040446086165, 0.21025170294937456, 0.21025170294937456, 0.21025170294937456, 0.19302146684021204, 0.19302146684021204, 0.19302146684021204, 0.22096271383349653, 0.22096271383349653, 0.22096271383349653, 0.21225989169416393, 0.21225989169416393, 0.21225989169416393, 0.21741596023268173, 0.21741596023268173, 0.21741596023268173, 0.18936488060375656, 0.18936488060375656, 0.18936488060375656, 0.21262632706368612, 0.21262632706368612, 0.21262632706368612, 0.2040763578114495, 0.2040763578114495, 0.2040763578114495, 0.25287101713371984, 0.25287101713371984, 0.25287101713371984, 0.9463904615236902, 0.9463904615236902, 0.9463904615236902, 0.9576596506883958, 0.9576596506883958, 0.9576596506883958, 0.1766314777945439, 0.1766314777945439, 0.1766314777945439, 0.9139672802159426, 0.9139672802159426, 0.9139672802159426, 0.21331730480780475, 0.21331730480780475, 0.21331730480780475, 0.13565278344356124, 0.13565278344356124, 0.13565278344356124, 0.17904416987479477, 0.17904416987479477, 0.17904416987479477, 0.1825268851212838, 0.1825268851212838, 0.1825268851212838, 0.19643967528431672, 0.19643967528431672, 0.19643967528431672, 0.09176619259860508, 0.09176619259860508, 0.09176619259860508, 0.1091588354143549, 0.1091588354143549, 0.1091588354143549, 0.09442472343792652, 0.09442472343792652, 0.09442472343792652]}, "mutation_prompt": null}
{"id": "6dcd508d-9319-4836-abff-6daa1fd2d504", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.7  # Initial Differential weight\n        self.initial_de_cr = 0.9  # Initial Crossover probability\n        self.initial_pso_w = 0.6  # Initial Inertia weight\n        self.pso_c1 = 0.9  # Cognitive coefficient\n        self.pso_c2 = 1.1  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by repositioning some solutions\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.15))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive evolutionary algorithm merging Differential Evolution and Particle Swarm Optimization with dynamically scaled parameters to efficiently navigate diverse search landscapes.", "configspace": "", "generation": 11, "fitness": 0.35693403441658406, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.31.", "error": "", "parent_id": "3e84517e-4ff6-43e4-84e1-0cbf0525f042", "metadata": {"aucs": [0.906364400078229, 0.906364400078229, 0.906364400078229, 0.9125687853140318, 0.9125687853140318, 0.9125687853140318, 0.9167019928618971, 0.9167019928618971, 0.9167019928618971, 0.7860216062481643, 0.7860216062481643, 0.7860216062481643, 0.16505983103815747, 0.16505983103815747, 0.16505983103815747, 0.11065759841127187, 0.11065759841127187, 0.11065759841127187, 0.1457218482172542, 0.1457218482172542, 0.1457218482172542, 0.09340417081930841, 0.09340417081930841, 0.09340417081930841, 0.13640090645727798, 0.13640090645727798, 0.13640090645727798, 0.11717334494898746, 0.11717334494898746, 0.11717334494898746, 0.10215217990536496, 0.10215217990536496, 0.10215217990536496, 0.15406313321288745, 0.15406313321288745, 0.15406313321288745, 0.9866572981629553, 0.9866572981629553, 0.9866572981629553, 0.9820228876528952, 0.9820228876528952, 0.9820228876528952, 0.9852383735534468, 0.9852383735534468, 0.9852383735534468, 0.7040905794732376, 0.7040905794732376, 0.7040905794732376, 0.7701772677078574, 0.7701772677078574, 0.7701772677078574, 0.7767653402672848, 0.7767653402672848, 0.7767653402672848, 0.8597237633043748, 0.8597237633043748, 0.8597237633043748, 0.16520382849556103, 0.16520382849556103, 0.16520382849556103, 0.3773449338760628, 0.3773449338760628, 0.3773449338760628, 0.30721922168643345, 0.30721922168643345, 0.30721922168643345, 0.2600541501457472, 0.2600541501457472, 0.2600541501457472, 0.30034524455623546, 0.30034524455623546, 0.30034524455623546, 0.27885002614945187, 0.27885002614945187, 0.27885002614945187, 0.31631562239588573, 0.31631562239588573, 0.31631562239588573, 0.42002100355452987, 0.42002100355452987, 0.42002100355452987, 0.06698291543592261, 0.06698291543592261, 0.06698291543592261, 0.030124929793161614, 0.030124929793161614, 0.030124929793161614, 0.005278785915141637, 0.005278785915141637, 0.005278785915141637, 0.1600781245824252, 0.1600781245824252, 0.1600781245824252, 0.11311749709886754, 0.11311749709886754, 0.11311749709886754, 0.21110375059556585, 0.21110375059556585, 0.21110375059556585, 0.036708630961386546, 0.036708630961386546, 0.036708630961386546, 0.08039788480311616, 0.08039788480311616, 0.08039788480311616, 0.1153016830055873, 0.1153016830055873, 0.1153016830055873, 0.04362534055290834, 0.04362534055290834, 0.04362534055290834, 0.07034828518590475, 0.07034828518590475, 0.07034828518590475, 0.2979299413345756, 0.2979299413345756, 0.2979299413345756, 0.5703575643808648, 0.5703575643808648, 0.5703575643808648, 0.5750400707804513, 0.5750400707804513, 0.5750400707804513, 0.6553554017040883, 0.6553554017040883, 0.6553554017040883, 0.08491081364695552, 0.08491081364695552, 0.08491081364695552, 0.1222865052592711, 0.1222865052592711, 0.1222865052592711, 0.13369867098282318, 0.13369867098282318, 0.13369867098282318, 0.2994391409502225, 0.2994391409502225, 0.2994391409502225, 0.1970801136721948, 0.1970801136721948, 0.1970801136721948, 0.26969418284592195, 0.26969418284592195, 0.26969418284592195, 0.5187004680504477, 0.5187004680504477, 0.5187004680504477, 0.24385231627607062, 0.24385231627607062, 0.24385231627607062, 0.4216886179055698, 0.4216886179055698, 0.4216886179055698, 0.3527125788313994, 0.3527125788313994, 0.3527125788313994, 0.19866415854261954, 0.19866415854261954, 0.19866415854261954, 0.14236396115274674, 0.14236396115274674, 0.14236396115274674, 0.20276769018907248, 0.20276769018907248, 0.20276769018907248, 0.2025236472933306, 0.2025236472933306, 0.2025236472933306, 0.23006651716686177, 0.23006651716686177, 0.23006651716686177, 0.8574014318258433, 0.8574014318258433, 0.8574014318258433, 0.19249200831098356, 0.19249200831098356, 0.19249200831098356, 0.7687888945603192, 0.7687888945603192, 0.7687888945603192, 0.9431349905331528, 0.9431349905331528, 0.9431349905331528, 0.2026563632695153, 0.2026563632695153, 0.2026563632695153, 0.9263805802424856, 0.9263805802424856, 0.9263805802424856, 0.9072479445135053, 0.9072479445135053, 0.9072479445135053, 0.21328208414898842, 0.21328208414898842, 0.21328208414898842, 0.1564227170378626, 0.1564227170378626, 0.1564227170378626, 0.18166175991754163, 0.18166175991754163, 0.18166175991754163, 0.18584719815854223, 0.18584719815854223, 0.18584719815854223, 0.183430928591914, 0.183430928591914, 0.183430928591914, 0.09002572081930937, 0.09002572081930937, 0.09002572081930937, 0.11037921117019611, 0.11037921117019611, 0.11037921117019611, 0.09157911750362546, 0.09157911750362546, 0.09157911750362546]}, "mutation_prompt": null}
{"id": "99054548-3838-4233-8ce4-6f74f076ae98", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.6  # Initial Differential weight (changed)\n        self.initial_de_cr = 0.85  # Initial Crossover probability (changed)\n        self.initial_pso_w = 0.7  # Initial Inertia weight (changed)\n        self.pso_c1 = 1.0  # Cognitive coefficient (changed)\n        self.pso_c2 = 1.2  # Social coefficient (changed)\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio  # Adjusted blending\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio  # Adjusted blending\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio  # Adjusted blending\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by repositioning some solutions\n            if self.eval_count >= self.max_evaluations * 0.7:  # Adjusted trigger point\n                diversity_count = max(1, int(self.population_size * 0.2))  # Adjusted diversity count\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A stochastic optimization algorithm blending dynamically adaptive Differential Evolution and Particle Swarm Optimization, with strategic reinforcement of exploration and exploitation through diverse solution repositioning.", "configspace": "", "generation": 12, "fitness": 0.3125938608711532, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "6dcd508d-9319-4836-abff-6daa1fd2d504", "metadata": {"aucs": [0.861082512577831, 0.861082512577831, 0.861082512577831, 0.8590446806659239, 0.8590446806659239, 0.8590446806659239, 0.8565715073579157, 0.8565715073579157, 0.8565715073579157, 0.03880329486908962, 0.03880329486908962, 0.03880329486908962, 0.08426438416636739, 0.08426438416636739, 0.08426438416636739, 0.5777444627553754, 0.5777444627553754, 0.5777444627553754, 0.14124126423650818, 0.14124126423650818, 0.14124126423650818, 0.11412867067938792, 0.11412867067938792, 0.11412867067938792, 0.11700971398801252, 0.11700971398801252, 0.11700971398801252, 0.09760024745917162, 0.09760024745917162, 0.09760024745917162, 0.10914803702618647, 0.10914803702618647, 0.10914803702618647, 0.16678569178753655, 0.16678569178753655, 0.16678569178753655, 0.9890111386205716, 0.9890111386205716, 0.9890111386205716, 0.9872995737502437, 0.9872995737502437, 0.9872995737502437, 0.9889630668507509, 0.9889630668507509, 0.9889630668507509, 0.5775124176690232, 0.5775124176690232, 0.5775124176690232, 0.6255049736490612, 0.6255049736490612, 0.6255049736490612, 0.5784664881514969, 0.5784664881514969, 0.5784664881514969, 0.8078647713713452, 0.8078647713713452, 0.8078647713713452, 0.16125907849074916, 0.16125907849074916, 0.16125907849074916, 0.1305380533216881, 0.1305380533216881, 0.1305380533216881, 0.30593003900039595, 0.30593003900039595, 0.30593003900039595, 0.30470279941655654, 0.30470279941655654, 0.30470279941655654, 0.30827773005645753, 0.30827773005645753, 0.30827773005645753, 0.2641910927544159, 0.2641910927544159, 0.2641910927544159, 0.32346071858001735, 0.32346071858001735, 0.32346071858001735, 0.29902258764413936, 0.29902258764413936, 0.29902258764413936, 0.0047084427021516495, 0.0047084427021516495, 0.0047084427021516495, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16101759438593233, 0.16101759438593233, 0.16101759438593233, 0.035309671219827754, 0.035309671219827754, 0.035309671219827754, 0.0883613254073512, 0.0883613254073512, 0.0883613254073512, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07554985839398431, 0.07554985839398431, 0.07554985839398431, 0.2837187908886617, 0.2837187908886617, 0.2837187908886617, 0.04315600724332869, 0.04315600724332869, 0.04315600724332869, 0.03929437983072226, 0.03929437983072226, 0.03929437983072226, 0.11512133897063648, 0.11512133897063648, 0.11512133897063648, 0.5558153469173921, 0.5558153469173921, 0.5558153469173921, 0.2354371638457463, 0.2354371638457463, 0.2354371638457463, 0.6287286380606, 0.6287286380606, 0.6287286380606, 0.07919185505490423, 0.07919185505490423, 0.07919185505490423, 0.16634199501475744, 0.16634199501475744, 0.16634199501475744, 0.1329522458546355, 0.1329522458546355, 0.1329522458546355, 0.15929060435418507, 0.15929060435418507, 0.15929060435418507, 0.19606643928572665, 0.19606643928572665, 0.19606643928572665, 0.22044434303630722, 0.22044434303630722, 0.22044434303630722, 0.5361290534697869, 0.5361290534697869, 0.5361290534697869, 0.4445455963636661, 0.4445455963636661, 0.4445455963636661, 0.6730936113876929, 0.6730936113876929, 0.6730936113876929, 0.17867658997184988, 0.17867658997184988, 0.17867658997184988, 0.2961980104229076, 0.2961980104229076, 0.2961980104229076, 0.20338194403542187, 0.20338194403542187, 0.20338194403542187, 0.18523170224612628, 0.18523170224612628, 0.18523170224612628, 0.20913787793404048, 0.20913787793404048, 0.20913787793404048, 0.20882133678717485, 0.20882133678717485, 0.20882133678717485, 0.21954588324783586, 0.21954588324783586, 0.21954588324783586, 0.1975434103497553, 0.1975434103497553, 0.1975434103497553, 0.2208417117209307, 0.2208417117209307, 0.2208417117209307, 0.8906884411024931, 0.8906884411024931, 0.8906884411024931, 0.20204936099550364, 0.20204936099550364, 0.20204936099550364, 0.8431196407331752, 0.8431196407331752, 0.8431196407331752, 0.7460374127434045, 0.7460374127434045, 0.7460374127434045, 0.20902791962063194, 0.20902791962063194, 0.20902791962063194, 0.3187353301904844, 0.3187353301904844, 0.3187353301904844, 0.1967603920314036, 0.1967603920314036, 0.1967603920314036, 0.1946658816771475, 0.1946658816771475, 0.1946658816771475, 0.17730375895162598, 0.17730375895162598, 0.17730375895162598, 0.08990620211802491, 0.08990620211802491, 0.08990620211802491, 0.0912959493023896, 0.0912959493023896, 0.0912959493023896, 0.07778592795648798, 0.07778592795648798, 0.07778592795648798]}, "mutation_prompt": null}
{"id": "387fcbb6-e7c9-4d70-9928-4e137a1b1746", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.7  # Initial Differential weight\n        self.initial_de_cr = 0.9  # Initial Crossover probability\n        self.initial_pso_w = 0.6  # Initial Inertia weight\n        self.pso_c1 = 0.9  # Cognitive coefficient\n        self.pso_c2 = 1.1  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by repositioning some solutions\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.15))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive evolutionary algorithm merging Differential Evolution and Particle Swarm Optimization with dynamically scaled parameters to efficiently navigate diverse search landscapes.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6dcd508d-9319-4836-abff-6daa1fd2d504", "metadata": {"aucs": [0.906364400078229, 0.906364400078229, 0.906364400078229, 0.9125687853140318, 0.9125687853140318, 0.9125687853140318, 0.9167019928618971, 0.9167019928618971, 0.9167019928618971, 0.7860216062481643, 0.7860216062481643, 0.7860216062481643, 0.16505983103815747, 0.16505983103815747, 0.16505983103815747, 0.11065759841127187, 0.11065759841127187, 0.11065759841127187, 0.1457218482172542, 0.1457218482172542, 0.1457218482172542, 0.09340417081930841, 0.09340417081930841, 0.09340417081930841, 0.13640090645727798, 0.13640090645727798, 0.13640090645727798, 0.11717334494898746, 0.11717334494898746, 0.11717334494898746, 0.10215217990536496, 0.10215217990536496, 0.10215217990536496, 0.15406313321288745, 0.15406313321288745, 0.15406313321288745, 0.9866572981629553, 0.9866572981629553, 0.9866572981629553, 0.9820228876528952, 0.9820228876528952, 0.9820228876528952, 0.9852383735534468, 0.9852383735534468, 0.9852383735534468, 0.7040905794732376, 0.7040905794732376, 0.7040905794732376, 0.7701772677078574, 0.7701772677078574, 0.7701772677078574, 0.7767653402672848, 0.7767653402672848, 0.7767653402672848, 0.8597237633043748, 0.8597237633043748, 0.8597237633043748, 0.16520382849556103, 0.16520382849556103, 0.16520382849556103, 0.3773449338760628, 0.3773449338760628, 0.3773449338760628, 0.30721922168643345, 0.30721922168643345, 0.30721922168643345, 0.2600541501457472, 0.2600541501457472, 0.2600541501457472, 0.30034524455623546, 0.30034524455623546, 0.30034524455623546, 0.27885002614945187, 0.27885002614945187, 0.27885002614945187, 0.31631562239588573, 0.31631562239588573, 0.31631562239588573, 0.42002100355452987, 0.42002100355452987, 0.42002100355452987, 0.06698291543592261, 0.06698291543592261, 0.06698291543592261, 0.030124929793161614, 0.030124929793161614, 0.030124929793161614, 0.005278785915141637, 0.005278785915141637, 0.005278785915141637, 0.1600781245824252, 0.1600781245824252, 0.1600781245824252, 0.11311749709886754, 0.11311749709886754, 0.11311749709886754, 0.21110375059556585, 0.21110375059556585, 0.21110375059556585, 0.036708630961386546, 0.036708630961386546, 0.036708630961386546, 0.08039788480311616, 0.08039788480311616, 0.08039788480311616, 0.1153016830055873, 0.1153016830055873, 0.1153016830055873, 0.04362534055290834, 0.04362534055290834, 0.04362534055290834, 0.07034828518590475, 0.07034828518590475, 0.07034828518590475, 0.2979299413345756, 0.2979299413345756, 0.2979299413345756, 0.5703575643808648, 0.5703575643808648, 0.5703575643808648, 0.5750400707804513, 0.5750400707804513, 0.5750400707804513, 0.6553554017040883, 0.6553554017040883, 0.6553554017040883, 0.08491081364695552, 0.08491081364695552, 0.08491081364695552, 0.1222865052592711, 0.1222865052592711, 0.1222865052592711, 0.13369867098282318, 0.13369867098282318, 0.13369867098282318, 0.2994391409502225, 0.2994391409502225, 0.2994391409502225, 0.1970801136721948, 0.1970801136721948, 0.1970801136721948, 0.26969418284592195, 0.26969418284592195, 0.26969418284592195, 0.5187004680504477, 0.5187004680504477, 0.5187004680504477, 0.24385231627607062, 0.24385231627607062, 0.24385231627607062, 0.4216886179055698, 0.4216886179055698, 0.4216886179055698, 0.3527125788313994, 0.3527125788313994, 0.3527125788313994, 0.19866415854261954, 0.19866415854261954, 0.19866415854261954, 0.14236396115274674, 0.14236396115274674, 0.14236396115274674, 0.20276769018907248, 0.20276769018907248, 0.20276769018907248, 0.2025236472933306, 0.2025236472933306, 0.2025236472933306, 0.23006651716686177, 0.23006651716686177, 0.23006651716686177, 0.8574014318258433, 0.8574014318258433, 0.8574014318258433, 0.19249200831098356, 0.19249200831098356, 0.19249200831098356, 0.7687888945603192, 0.7687888945603192, 0.7687888945603192, 0.9431349905331528, 0.9431349905331528, 0.9431349905331528, 0.2026563632695153, 0.2026563632695153, 0.2026563632695153, 0.9263805802424856, 0.9263805802424856, 0.9263805802424856, 0.9072479445135053, 0.9072479445135053, 0.9072479445135053, 0.21328208414898842, 0.21328208414898842, 0.21328208414898842, 0.1564227170378626, 0.1564227170378626, 0.1564227170378626, 0.18166175991754163, 0.18166175991754163, 0.18166175991754163, 0.18584719815854223, 0.18584719815854223, 0.18584719815854223, 0.183430928591914, 0.183430928591914, 0.183430928591914, 0.09002572081930937, 0.09002572081930937, 0.09002572081930937, 0.11037921117019611, 0.11037921117019611, 0.11037921117019611, 0.09157911750362546, 0.09157911750362546, 0.09157911750362546]}, "mutation_prompt": null}
{"id": "e2250d08-0c7c-4566-88f9-f4f6dda1e5e7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for more exploration\n        self.initial_de_f = 0.8  # Increased Differential weight for faster convergence\n        self.initial_de_cr = 0.9\n        self.initial_pso_w = 0.7  # Adjusted Inertia weight for better balance\n        self.pso_c1 = 1.2  # Adjusted Cognitive coefficient for more individual exploration\n        self.pso_c2 = 1.4  # Adjusted Social coefficient for better collaboration\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio  # Further dynamic adjustment\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.4 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.2 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.2))  # Increased diversity adaptation\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedAdaptiveHybridDEPSO", "description": "An enhanced adaptive hybrid algorithm combining DE and PSO using stochastic parameter tuning and diversity increase to optimize in complex landscapes.", "configspace": "", "generation": 14, "fitness": 0.2870543725946742, "feedback": "The algorithm EnhancedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.26.", "error": "", "parent_id": "6dcd508d-9319-4836-abff-6daa1fd2d504", "metadata": {"aucs": [0.8432515605505051, 0.8432515605505051, 0.8432515605505051, 0.8143729539860531, 0.8143729539860531, 0.8143729539860531, 0.8085392069566931, 0.8085392069566931, 0.8085392069566931, 0.6564655837219506, 0.6564655837219506, 0.6564655837219506, 0.6471780419146466, 0.6471780419146466, 0.6471780419146466, 0.06122141388728053, 0.06122141388728053, 0.06122141388728053, 0.1355676096092311, 0.1355676096092311, 0.1355676096092311, 0.0899786863006331, 0.0899786863006331, 0.0899786863006331, 0.1542914205910655, 0.1542914205910655, 0.1542914205910655, 0.11786186761838713, 0.11786186761838713, 0.11786186761838713, 0.11421441425116008, 0.11421441425116008, 0.11421441425116008, 0.12693246236235156, 0.12693246236235156, 0.12693246236235156, 0.9784963155558367, 0.9784963155558367, 0.9784963155558367, 0.9859911237269803, 0.9859911237269803, 0.9859911237269803, 0.9897374736638405, 0.9897374736638405, 0.9897374736638405, 0.48031620065590963, 0.48031620065590963, 0.48031620065590963, 0.4730674886424915, 0.4730674886424915, 0.4730674886424915, 0.5039617799751848, 0.5039617799751848, 0.5039617799751848, 0.7179588107408377, 0.7179588107408377, 0.7179588107408377, 0.1924289110362537, 0.1924289110362537, 0.1924289110362537, 0.12576975486144093, 0.12576975486144093, 0.12576975486144093, 0.25895360955138347, 0.25895360955138347, 0.25895360955138347, 0.22903483359576315, 0.22903483359576315, 0.22903483359576315, 0.25663664732808544, 0.25663664732808544, 0.25663664732808544, 0.22644999331273397, 0.22644999331273397, 0.22644999331273397, 0.34419918662811144, 0.34419918662811144, 0.34419918662811144, 0.23093537121036456, 0.23093537121036456, 0.23093537121036456, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09155808548702593, 0.09155808548702593, 0.09155808548702593, 0.050725726776869706, 0.050725726776869706, 0.050725726776869706, 0.026971100762586686, 0.026971100762586686, 0.026971100762586686, 0.06904474631357771, 0.06904474631357771, 0.06904474631357771, 0.06562176577712597, 0.06562176577712597, 0.06562176577712597, 0.08729334816195955, 0.08729334816195955, 0.08729334816195955, 0.11246043393139149, 0.11246043393139149, 0.11246043393139149, 0.08234663148865329, 0.08234663148865329, 0.08234663148865329, 0.10659157200451685, 0.10659157200451685, 0.10659157200451685, 0.5085941394073068, 0.5085941394073068, 0.5085941394073068, 0.5498995634420047, 0.5498995634420047, 0.5498995634420047, 0.5259356773059896, 0.5259356773059896, 0.5259356773059896, 0.11472837778463252, 0.11472837778463252, 0.11472837778463252, 0.10783855207153137, 0.10783855207153137, 0.10783855207153137, 0.09692883922367546, 0.09692883922367546, 0.09692883922367546, 0.16997102184493618, 0.16997102184493618, 0.16997102184493618, 0.1545721621615801, 0.1545721621615801, 0.1545721621615801, 0.14637235682666527, 0.14637235682666527, 0.14637235682666527, 0.5430864753137519, 0.5430864753137519, 0.5430864753137519, 0.2007470071438996, 0.2007470071438996, 0.2007470071438996, 0.4686732753074736, 0.4686732753074736, 0.4686732753074736, 0.2724370230737363, 0.2724370230737363, 0.2724370230737363, 0.18847774266110384, 0.18847774266110384, 0.18847774266110384, 0.11504970464801845, 0.11504970464801845, 0.11504970464801845, 0.1689080802106988, 0.1689080802106988, 0.1689080802106988, 0.2146434601538456, 0.2146434601538456, 0.2146434601538456, 0.20546176015781592, 0.20546176015781592, 0.20546176015781592, 0.20701217267346794, 0.20701217267346794, 0.20701217267346794, 0.2098347332013818, 0.2098347332013818, 0.2098347332013818, 0.6501300425136893, 0.6501300425136893, 0.6501300425136893, 0.8537960442990674, 0.8537960442990674, 0.8537960442990674, 0.1580894948691568, 0.1580894948691568, 0.1580894948691568, 0.18088620836585245, 0.18088620836585245, 0.18088620836585245, 0.20973604032633186, 0.20973604032633186, 0.20973604032633186, 0.2048150779905028, 0.2048150779905028, 0.2048150779905028, 0.18147644885784053, 0.18147644885784053, 0.18147644885784053, 0.17848684661362146, 0.17848684661362146, 0.17848684661362146, 0.1925155209402699, 0.1925155209402699, 0.1925155209402699, 0.18282003837546346, 0.18282003837546346, 0.18282003837546346, 0.08968735913872716, 0.08968735913872716, 0.08968735913872716, 0.07719267687543141, 0.07719267687543141, 0.07719267687543141, 0.08238477009819145, 0.08238477009819145, 0.08238477009819145]}, "mutation_prompt": null}
{"id": "bac41858-28ba-46bf-a0ea-f50dcfd05180", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.7  # Initial Differential weight\n        self.initial_de_cr = 0.9  # Initial Crossover probability\n        self.initial_pso_w = 0.6  # Initial Inertia weight\n        self.pso_c1 = 0.9  # Cognitive coefficient\n        self.pso_c2 = 1.1  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by repositioning some solutions\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.15))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive evolutionary algorithm merging Differential Evolution and Particle Swarm Optimization with dynamically scaled parameters to efficiently navigate diverse search landscapes.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6dcd508d-9319-4836-abff-6daa1fd2d504", "metadata": {"aucs": [0.906364400078229, 0.906364400078229, 0.906364400078229, 0.9125687853140318, 0.9125687853140318, 0.9125687853140318, 0.9167019928618971, 0.9167019928618971, 0.9167019928618971, 0.7860216062481643, 0.7860216062481643, 0.7860216062481643, 0.16505983103815747, 0.16505983103815747, 0.16505983103815747, 0.11065759841127187, 0.11065759841127187, 0.11065759841127187, 0.1457218482172542, 0.1457218482172542, 0.1457218482172542, 0.09340417081930841, 0.09340417081930841, 0.09340417081930841, 0.13640090645727798, 0.13640090645727798, 0.13640090645727798, 0.11717334494898746, 0.11717334494898746, 0.11717334494898746, 0.10215217990536496, 0.10215217990536496, 0.10215217990536496, 0.15406313321288745, 0.15406313321288745, 0.15406313321288745, 0.9866572981629553, 0.9866572981629553, 0.9866572981629553, 0.9820228876528952, 0.9820228876528952, 0.9820228876528952, 0.9852383735534468, 0.9852383735534468, 0.9852383735534468, 0.7040905794732376, 0.7040905794732376, 0.7040905794732376, 0.7701772677078574, 0.7701772677078574, 0.7701772677078574, 0.7767653402672848, 0.7767653402672848, 0.7767653402672848, 0.8597237633043748, 0.8597237633043748, 0.8597237633043748, 0.16520382849556103, 0.16520382849556103, 0.16520382849556103, 0.3773449338760628, 0.3773449338760628, 0.3773449338760628, 0.30721922168643345, 0.30721922168643345, 0.30721922168643345, 0.2600541501457472, 0.2600541501457472, 0.2600541501457472, 0.30034524455623546, 0.30034524455623546, 0.30034524455623546, 0.27885002614945187, 0.27885002614945187, 0.27885002614945187, 0.31631562239588573, 0.31631562239588573, 0.31631562239588573, 0.42002100355452987, 0.42002100355452987, 0.42002100355452987, 0.06698291543592261, 0.06698291543592261, 0.06698291543592261, 0.030124929793161614, 0.030124929793161614, 0.030124929793161614, 0.005278785915141637, 0.005278785915141637, 0.005278785915141637, 0.1600781245824252, 0.1600781245824252, 0.1600781245824252, 0.11311749709886754, 0.11311749709886754, 0.11311749709886754, 0.21110375059556585, 0.21110375059556585, 0.21110375059556585, 0.036708630961386546, 0.036708630961386546, 0.036708630961386546, 0.08039788480311616, 0.08039788480311616, 0.08039788480311616, 0.1153016830055873, 0.1153016830055873, 0.1153016830055873, 0.04362534055290834, 0.04362534055290834, 0.04362534055290834, 0.07034828518590475, 0.07034828518590475, 0.07034828518590475, 0.2979299413345756, 0.2979299413345756, 0.2979299413345756, 0.5703575643808648, 0.5703575643808648, 0.5703575643808648, 0.5750400707804513, 0.5750400707804513, 0.5750400707804513, 0.6553554017040883, 0.6553554017040883, 0.6553554017040883, 0.08491081364695552, 0.08491081364695552, 0.08491081364695552, 0.1222865052592711, 0.1222865052592711, 0.1222865052592711, 0.13369867098282318, 0.13369867098282318, 0.13369867098282318, 0.2994391409502225, 0.2994391409502225, 0.2994391409502225, 0.1970801136721948, 0.1970801136721948, 0.1970801136721948, 0.26969418284592195, 0.26969418284592195, 0.26969418284592195, 0.5187004680504477, 0.5187004680504477, 0.5187004680504477, 0.24385231627607062, 0.24385231627607062, 0.24385231627607062, 0.4216886179055698, 0.4216886179055698, 0.4216886179055698, 0.3527125788313994, 0.3527125788313994, 0.3527125788313994, 0.19866415854261954, 0.19866415854261954, 0.19866415854261954, 0.14236396115274674, 0.14236396115274674, 0.14236396115274674, 0.20276769018907248, 0.20276769018907248, 0.20276769018907248, 0.2025236472933306, 0.2025236472933306, 0.2025236472933306, 0.23006651716686177, 0.23006651716686177, 0.23006651716686177, 0.8574014318258433, 0.8574014318258433, 0.8574014318258433, 0.19249200831098356, 0.19249200831098356, 0.19249200831098356, 0.7687888945603192, 0.7687888945603192, 0.7687888945603192, 0.9431349905331528, 0.9431349905331528, 0.9431349905331528, 0.2026563632695153, 0.2026563632695153, 0.2026563632695153, 0.9263805802424856, 0.9263805802424856, 0.9263805802424856, 0.9072479445135053, 0.9072479445135053, 0.9072479445135053, 0.21328208414898842, 0.21328208414898842, 0.21328208414898842, 0.1564227170378626, 0.1564227170378626, 0.1564227170378626, 0.18166175991754163, 0.18166175991754163, 0.18166175991754163, 0.18584719815854223, 0.18584719815854223, 0.18584719815854223, 0.183430928591914, 0.183430928591914, 0.183430928591914, 0.09002572081930937, 0.09002572081930937, 0.09002572081930937, 0.11037921117019611, 0.11037921117019611, 0.11037921117019611, 0.09157911750362546, 0.09157911750362546, 0.09157911750362546]}, "mutation_prompt": null}
{"id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 16, "fitness": 0.36363449387435054, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.32.", "error": "", "parent_id": "6dcd508d-9319-4836-abff-6daa1fd2d504", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "2f3062f8-fc5d-4678-b05b-b670c1b36ff4", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "595fc656-0486-433b-b152-8c8ddf1a4cce", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_de_f = 0.9  # Adapted Differential weight\n        self.initial_de_cr = 0.8  # Adapted Crossover probability\n        self.initial_pso_w = 0.6  # Increased Inertia weight\n        self.pso_c1 = 1.4  # Increased Cognitive coefficient\n        self.pso_c2 = 1.6  # Increased Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adapting DE and PSO parameters dynamically\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.9 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.2 * progress_ratio\n\n            # Differential Evolution operations\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization updates\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Diversity enhancement by mutation\n            if self.eval_count >= self.max_evaluations * 0.80:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedAdaptiveHybridDEPSO", "description": "A hybrid metaheuristic algorithm that integrates adaptive Differential Evolution with enhanced Particle Swarm Optimization and a mutation-based diversity strategy for robust exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.2943275010156877, "feedback": "The algorithm EnhancedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8249214101371566, 0.8249214101371566, 0.8249214101371566, 0.8377770371071351, 0.8377770371071351, 0.8377770371071351, 0.837488406840518, 0.837488406840518, 0.837488406840518, 0.6600398291341067, 0.6600398291341067, 0.6600398291341067, 0.6630098757942979, 0.6630098757942979, 0.6630098757942979, 0.04737015405384459, 0.04737015405384459, 0.04737015405384459, 0.12428076510540287, 0.12428076510540287, 0.12428076510540287, 0.47781110579048214, 0.47781110579048214, 0.47781110579048214, 0.1097199663177334, 0.1097199663177334, 0.1097199663177334, 0.12794780454600618, 0.12794780454600618, 0.12794780454600618, 0.14921142960597522, 0.14921142960597522, 0.14921142960597522, 0.08951651227396329, 0.08951651227396329, 0.08951651227396329, 0.9832869851554962, 0.9832869851554962, 0.9832869851554962, 0.9881951298241703, 0.9881951298241703, 0.9881951298241703, 0.9876714878337604, 0.9876714878337604, 0.9876714878337604, 0.5261878778234104, 0.5261878778234104, 0.5261878778234104, 0.4956722480040535, 0.4956722480040535, 0.4956722480040535, 0.516811045735234, 0.516811045735234, 0.516811045735234, 0.6629012537947208, 0.6629012537947208, 0.6629012537947208, 0.2554492327802632, 0.2554492327802632, 0.2554492327802632, 0.3478666030220805, 0.3478666030220805, 0.3478666030220805, 0.2329343085764155, 0.2329343085764155, 0.2329343085764155, 0.2321646421394723, 0.2321646421394723, 0.2321646421394723, 0.21917516611331944, 0.21917516611331944, 0.21917516611331944, 0.23617360981466307, 0.23617360981466307, 0.23617360981466307, 0.26700302195577574, 0.26700302195577574, 0.26700302195577574, 0.2423775938530447, 0.2423775938530447, 0.2423775938530447, 0.07957964805071405, 0.07957964805071405, 0.07957964805071405, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028740257189383556, 0.028740257189383556, 0.028740257189383556, 0.05922701450965939, 0.05922701450965939, 0.05922701450965939, 0.04670594652095883, 0.04670594652095883, 0.04670594652095883, 0.04463758194751166, 0.04463758194751166, 0.04463758194751166, 0.08918643846893559, 0.08918643846893559, 0.08918643846893559, 0.08628261694653283, 0.08628261694653283, 0.08628261694653283, 0.06284555852376283, 0.06284555852376283, 0.06284555852376283, 0.1613718803219475, 0.1613718803219475, 0.1613718803219475, 0.04808947689229137, 0.04808947689229137, 0.04808947689229137, 0.5641118742468245, 0.5641118742468245, 0.5641118742468245, 0.5046235704283712, 0.5046235704283712, 0.5046235704283712, 0.5297522588372514, 0.5297522588372514, 0.5297522588372514, 0.11108487347719742, 0.11108487347719742, 0.11108487347719742, 0.12428362081033117, 0.12428362081033117, 0.12428362081033117, 0.11031343628795331, 0.11031343628795331, 0.11031343628795331, 0.18909951326196928, 0.18909951326196928, 0.18909951326196928, 0.25829544463039134, 0.25829544463039134, 0.25829544463039134, 0.16793074102227634, 0.16793074102227634, 0.16793074102227634, 0.47570856402360473, 0.47570856402360473, 0.47570856402360473, 0.41913747385132794, 0.41913747385132794, 0.41913747385132794, 0.5552751372398361, 0.5552751372398361, 0.5552751372398361, 0.25255947330101525, 0.25255947330101525, 0.25255947330101525, 0.2808957490386601, 0.2808957490386601, 0.2808957490386601, 0.13863938120399288, 0.13863938120399288, 0.13863938120399288, 0.18556603925743076, 0.18556603925743076, 0.18556603925743076, 0.17575179637889904, 0.17575179637889904, 0.17575179637889904, 0.20905361485369156, 0.20905361485369156, 0.20905361485369156, 0.18905987997974927, 0.18905987997974927, 0.18905987997974927, 0.2001580203613289, 0.2001580203613289, 0.2001580203613289, 0.1987934323299928, 0.1987934323299928, 0.1987934323299928, 0.8821834508287566, 0.8821834508287566, 0.8821834508287566, 0.15783834552446585, 0.15783834552446585, 0.15783834552446585, 0.1697151282453757, 0.1697151282453757, 0.1697151282453757, 0.11866066198921432, 0.11866066198921432, 0.11866066198921432, 0.2089396431778685, 0.2089396431778685, 0.2089396431778685, 0.1651822186415749, 0.1651822186415749, 0.1651822186415749, 0.19778605408899075, 0.19778605408899075, 0.19778605408899075, 0.18604668931466228, 0.18604668931466228, 0.18604668931466228, 0.1781593686395888, 0.1781593686395888, 0.1781593686395888, 0.08622015528127669, 0.08622015528127669, 0.08622015528127669, 0.07941744624131097, 0.07941744624131097, 0.07941744624131097, 0.07150609383013484, 0.07150609383013484, 0.07150609383013484]}, "mutation_prompt": null}
{"id": "118e1057-df9e-45af-b99b-b2a8185b714c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Slightly increased Differential weight\n        self.initial_de_cr = 0.9  # Slightly increased Crossover probability\n        self.initial_pso_w = 0.6  # Slightly increased Inertia weight\n        self.pso_c1 = 1.5  # Increased Cognitive coefficient\n        self.pso_c2 = 1.5  # Increased Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * np.cos(progress_ratio * np.pi / 2)  # Dynamic inertia weight\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.3))  # Increased diversity count\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedAdaptiveHybridDEPSO", "description": "An enhanced adaptive hybrid evolutionary algorithm integrating dynamic parameter tuning, crossover strategies, and stochastic updates to improve exploration and exploitation across diverse optimization landscapes.", "configspace": "", "generation": 19, "fitness": 0.27072030769446515, "feedback": "The algorithm EnhancedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8869913641700086, 0.8869913641700086, 0.8869913641700086, 0.8266085129240891, 0.8266085129240891, 0.8266085129240891, 0.8271141566318787, 0.8271141566318787, 0.8271141566318787, 0.7001909448434125, 0.7001909448434125, 0.7001909448434125, 0.07907413385063922, 0.07907413385063922, 0.07907413385063922, 0.7500766370422826, 0.7500766370422826, 0.7500766370422826, 0.1478669972137866, 0.1478669972137866, 0.1478669972137866, 0.11653959261542934, 0.11653959261542934, 0.11653959261542934, 0.1488478478576415, 0.1488478478576415, 0.1488478478576415, 0.12867617067634307, 0.12867617067634307, 0.12867617067634307, 0.10208474562990522, 0.10208474562990522, 0.10208474562990522, 0.13217216796878184, 0.13217216796878184, 0.13217216796878184, 0.9831661481699059, 0.9831661481699059, 0.9831661481699059, 0.9887926172810358, 0.9887926172810358, 0.9887926172810358, 0.9916991725593679, 0.9916991725593679, 0.9916991725593679, 0.4437052178542492, 0.4437052178542492, 0.4437052178542492, 0.15055278764412217, 0.15055278764412217, 0.15055278764412217, 0.07678227927492154, 0.07678227927492154, 0.07678227927492154, 0.2052287636694552, 0.2052287636694552, 0.2052287636694552, 0.16118712367855115, 0.16118712367855115, 0.16118712367855115, 0.32954605327256703, 0.32954605327256703, 0.32954605327256703, 0.23430894670562907, 0.23430894670562907, 0.23430894670562907, 0.241353230663222, 0.241353230663222, 0.241353230663222, 0.2546608390377091, 0.2546608390377091, 0.2546608390377091, 0.2235112545838337, 0.2235112545838337, 0.2235112545838337, 0.2324394712612855, 0.2324394712612855, 0.2324394712612855, 0.2672654125186156, 0.2672654125186156, 0.2672654125186156, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01583270390452529, 0.01583270390452529, 0.01583270390452529, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03328666430121607, 0.03328666430121607, 0.03328666430121607, 0.046694826287895896, 0.046694826287895896, 0.046694826287895896, 0.06487455685095034, 0.06487455685095034, 0.06487455685095034, 0.09093377329881436, 0.09093377329881436, 0.09093377329881436, 0.07630299439289046, 0.07630299439289046, 0.07630299439289046, 0.1560727105857117, 0.1560727105857117, 0.1560727105857117, 0.14993137874739382, 0.14993137874739382, 0.14993137874739382, 0.1834416392150685, 0.1834416392150685, 0.1834416392150685, 0.08131601248126386, 0.08131601248126386, 0.08131601248126386, 0.5501207955176308, 0.5501207955176308, 0.5501207955176308, 0.5765949492442101, 0.5765949492442101, 0.5765949492442101, 0.5826186351091185, 0.5826186351091185, 0.5826186351091185, 0.11726171281524189, 0.11726171281524189, 0.11726171281524189, 0.10895176510928772, 0.10895176510928772, 0.10895176510928772, 0.11667285762409829, 0.11667285762409829, 0.11667285762409829, 0.1838488904776554, 0.1838488904776554, 0.1838488904776554, 0.15513647664754282, 0.15513647664754282, 0.15513647664754282, 0.15858601902960867, 0.15858601902960867, 0.15858601902960867, 0.2742439539184476, 0.2742439539184476, 0.2742439539184476, 0.23478814947478588, 0.23478814947478588, 0.23478814947478588, 0.4374930481926004, 0.4374930481926004, 0.4374930481926004, 0.2029698084014756, 0.2029698084014756, 0.2029698084014756, 0.20040441526245067, 0.20040441526245067, 0.20040441526245067, 0.3084511374882599, 0.3084511374882599, 0.3084511374882599, 0.19406581763571995, 0.19406581763571995, 0.19406581763571995, 0.19574997651582804, 0.19574997651582804, 0.19574997651582804, 0.17478955142374875, 0.17478955142374875, 0.17478955142374875, 0.18642731927869383, 0.18642731927869383, 0.18642731927869383, 0.19559993807459863, 0.19559993807459863, 0.19559993807459863, 0.2317271533826919, 0.2317271533826919, 0.2317271533826919, 0.9061446710634605, 0.9061446710634605, 0.9061446710634605, 0.20517342426491847, 0.20517342426491847, 0.20517342426491847, 0.16084633640884316, 0.16084633640884316, 0.16084633640884316, 0.1691080277736724, 0.1691080277736724, 0.1691080277736724, 0.18075617232737007, 0.18075617232737007, 0.18075617232737007, 0.15584635319342743, 0.15584635319342743, 0.15584635319342743, 0.18527588080154067, 0.18527588080154067, 0.18527588080154067, 0.17940928433575387, 0.17940928433575387, 0.17940928433575387, 0.1915138067401303, 0.1915138067401303, 0.1915138067401303, 0.0843121363462771, 0.0843121363462771, 0.0843121363462771, 0.06718786780581065, 0.06718786780581065, 0.06718786780581065, 0.09045597265219107, 0.09045597265219107, 0.09045597265219107]}, "mutation_prompt": null}
{"id": "3f5882c6-3530-4f52-911b-1888852068ff", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "e410e642-cffd-4bbc-927a-312be70ec4e3", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Changed population size\n        self.initial_de_f = 0.9  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.2  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.3  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio  # Made DE mutation adaptive\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.4 * progress_ratio  # Made DE crossover adaptive\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio  # Made PSO inertia adaptive\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.25))  # Enhanced diversity strategy\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "RefinedAdaptiveHybridDEPSO", "description": "A refined adaptive hybrid algorithm integrates Differential Evolution and Particle Swarm Optimization, enhancing parameter adaptation and diversity to optimize performance across diverse search landscapes.", "configspace": "", "generation": 21, "fitness": 0.28658661688258774, "feedback": "The algorithm RefinedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.27.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8665578240695192, 0.8665578240695192, 0.8665578240695192, 0.8698393309425547, 0.8698393309425547, 0.8698393309425547, 0.8650090488138309, 0.8650090488138309, 0.8650090488138309, 0.739195726659817, 0.739195726659817, 0.739195726659817, 0.7435112699671819, 0.7435112699671819, 0.7435112699671819, 0.09581147583398708, 0.09581147583398708, 0.09581147583398708, 0.12867684558245507, 0.12867684558245507, 0.12867684558245507, 0.11208864117371597, 0.11208864117371597, 0.11208864117371597, 0.13953870902094223, 0.13953870902094223, 0.13953870902094223, 0.1378189604462594, 0.1378189604462594, 0.1378189604462594, 0.13550815702571795, 0.13550815702571795, 0.13550815702571795, 0.10959377044644714, 0.10959377044644714, 0.10959377044644714, 0.35028580711514146, 0.35028580711514146, 0.35028580711514146, 0.9800576878218754, 0.9800576878218754, 0.9800576878218754, 0.9897423894641271, 0.9897423894641271, 0.9897423894641271, 0.5882296864491332, 0.5882296864491332, 0.5882296864491332, 0.28212232209421606, 0.28212232209421606, 0.28212232209421606, 0.6746819633197525, 0.6746819633197525, 0.6746819633197525, 0.36135513872317704, 0.36135513872317704, 0.36135513872317704, 0.36968834936967765, 0.36968834936967765, 0.36968834936967765, 0.12210878975407291, 0.12210878975407291, 0.12210878975407291, 0.27522545771527596, 0.27522545771527596, 0.27522545771527596, 0.10639053323431658, 0.10639053323431658, 0.10639053323431658, 0.2746709040602797, 0.2746709040602797, 0.2746709040602797, 0.054177991492366684, 0.054177991492366684, 0.054177991492366684, 0.13591647099034854, 0.13591647099034854, 0.13591647099034854, 0.32657367441862095, 0.32657367441862095, 0.32657367441862095, 0.023317104605259376, 0.023317104605259376, 0.023317104605259376, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04609514679626647, 0.04609514679626647, 0.04609514679626647, 0.044058449566262925, 0.044058449566262925, 0.044058449566262925, 0.040563279657519935, 0.040563279657519935, 0.040563279657519935, 0.07595535780707852, 0.07595535780707852, 0.07595535780707852, 0.13065799697048608, 0.13065799697048608, 0.13065799697048608, 0.06953964923519984, 0.06953964923519984, 0.06953964923519984, 0.06784537757444431, 0.06784537757444431, 0.06784537757444431, 0.24731126416497606, 0.24731126416497606, 0.24731126416497606, 0.013864103833063357, 0.013864103833063357, 0.013864103833063357, 0.5529764918363497, 0.5529764918363497, 0.5529764918363497, 0.5602523499974175, 0.5602523499974175, 0.5602523499974175, 0.5873279483841307, 0.5873279483841307, 0.5873279483841307, 0.1041189304072162, 0.1041189304072162, 0.1041189304072162, 0.13758620988560355, 0.13758620988560355, 0.13758620988560355, 0.11563235962673402, 0.11563235962673402, 0.11563235962673402, 0.17378258885732556, 0.17378258885732556, 0.17378258885732556, 0.22283172440006205, 0.22283172440006205, 0.22283172440006205, 0.14206514562876926, 0.14206514562876926, 0.14206514562876926, 0.28437852712931344, 0.28437852712931344, 0.28437852712931344, 0.2075899405721373, 0.2075899405721373, 0.2075899405721373, 0.47986226447488567, 0.47986226447488567, 0.47986226447488567, 0.3721313105269852, 0.3721313105269852, 0.3721313105269852, 0.18710786107312716, 0.18710786107312716, 0.18710786107312716, 0.13969785409756263, 0.13969785409756263, 0.13969785409756263, 0.2333220601618886, 0.2333220601618886, 0.2333220601618886, 0.17914311752028556, 0.17914311752028556, 0.17914311752028556, 0.21201259800473649, 0.21201259800473649, 0.21201259800473649, 0.20298286877103722, 0.20298286877103722, 0.20298286877103722, 0.202463986634406, 0.202463986634406, 0.202463986634406, 0.7248751454610125, 0.7248751454610125, 0.7248751454610125, 0.8442331789274505, 0.8442331789274505, 0.8442331789274505, 0.16224787054576972, 0.16224787054576972, 0.16224787054576972, 0.1566195487888814, 0.1566195487888814, 0.1566195487888814, 0.12094276211055932, 0.12094276211055932, 0.12094276211055932, 0.7943522029862399, 0.7943522029862399, 0.7943522029862399, 0.15589544656429366, 0.15589544656429366, 0.15589544656429366, 0.17628768753888469, 0.17628768753888469, 0.17628768753888469, 0.17918237396241, 0.17918237396241, 0.17918237396241, 0.1807687437187656, 0.1807687437187656, 0.1807687437187656, 0.0882569528550946, 0.0882569528550946, 0.0882569528550946, 0.07691032808626985, 0.07691032808626985, 0.07691032808626985, 0.082613379795342, 0.082613379795342, 0.082613379795342]}, "mutation_prompt": null}
{"id": "f0ddeeee-e36f-46ee-a858-c046379023fe", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8\n        self.initial_de_cr = 0.85\n        self.initial_pso_w = 0.5\n        self.pso_c1 = 1.0\n        self.pso_c2 = 1.2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio \n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.4 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A dynamically adapting hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with a focus on progressive diversity management and parameter tuning.", "configspace": "", "generation": 22, "fitness": 0.34661955630518715, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.31.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9341340009970892, 0.9341340009970892, 0.9341340009970892, 0.9315623427468719, 0.9315623427468719, 0.9315623427468719, 0.9277380455828967, 0.9277380455828967, 0.9277380455828967, 0.8465164528225584, 0.8465164528225584, 0.8465164528225584, 0.8569395933229774, 0.8569395933229774, 0.8569395933229774, 0.1506967517362302, 0.1506967517362302, 0.1506967517362302, 0.14772615526618427, 0.14772615526618427, 0.14772615526618427, 0.1606490623761685, 0.1606490623761685, 0.1606490623761685, 0.15460811843067335, 0.15460811843067335, 0.15460811843067335, 0.11457856340206585, 0.11457856340206585, 0.11457856340206585, 0.1281432457516588, 0.1281432457516588, 0.1281432457516588, 0.08962403035395838, 0.08962403035395838, 0.08962403035395838, 0.9889014232132185, 0.9889014232132185, 0.9889014232132185, 0.9871532933026772, 0.9871532933026772, 0.9871532933026772, 0.9880386738526277, 0.9880386738526277, 0.9880386738526277, 0.8121498268591564, 0.8121498268591564, 0.8121498268591564, 0.15439000724476826, 0.15439000724476826, 0.15439000724476826, 0.8260334384234501, 0.8260334384234501, 0.8260334384234501, 0.1765369333207496, 0.1765369333207496, 0.1765369333207496, 0.1959276716783993, 0.1959276716783993, 0.1959276716783993, 0.8607911637948097, 0.8607911637948097, 0.8607911637948097, 0.29519782593269184, 0.29519782593269184, 0.29519782593269184, 0.12645583449102815, 0.12645583449102815, 0.12645583449102815, 0.284152289810928, 0.284152289810928, 0.284152289810928, 0.28877136515049917, 0.28877136515049917, 0.28877136515049917, 0.32842152061178587, 0.32842152061178587, 0.32842152061178587, 0.3185132395000504, 0.3185132395000504, 0.3185132395000504, 0.2557995874317587, 0.2557995874317587, 0.2557995874317587, 0.005682349972619849, 0.005682349972619849, 0.005682349972619849, 0.009143868112385878, 0.009143868112385878, 0.009143868112385878, 0.15691172711646506, 0.15691172711646506, 0.15691172711646506, 0.01162940814110247, 0.01162940814110247, 0.01162940814110247, 0.07647728435845635, 0.07647728435845635, 0.07647728435845635, 0.13299175460541424, 0.13299175460541424, 0.13299175460541424, 0.08309620985770894, 0.08309620985770894, 0.08309620985770894, 0.07597553485163844, 0.07597553485163844, 0.07597553485163844, 0.18012708280231549, 0.18012708280231549, 0.18012708280231549, 0.03985086048736608, 0.03985086048736608, 0.03985086048736608, 0.16307792783742314, 0.16307792783742314, 0.16307792783742314, 0.5657436999210317, 0.5657436999210317, 0.5657436999210317, 0.6003567022254912, 0.6003567022254912, 0.6003567022254912, 0.6413975067692428, 0.6413975067692428, 0.6413975067692428, 0.09848712175588248, 0.09848712175588248, 0.09848712175588248, 0.08238417427402256, 0.08238417427402256, 0.08238417427402256, 0.12265187111239628, 0.12265187111239628, 0.12265187111239628, 0.18188273997426818, 0.18188273997426818, 0.18188273997426818, 0.24048510158164382, 0.24048510158164382, 0.24048510158164382, 0.26052248633185104, 0.26052248633185104, 0.26052248633185104, 0.30520161876801744, 0.30520161876801744, 0.30520161876801744, 0.25157830522338986, 0.25157830522338986, 0.25157830522338986, 0.46170214941561516, 0.46170214941561516, 0.46170214941561516, 0.2436276467065598, 0.2436276467065598, 0.2436276467065598, 0.35258096934992356, 0.35258096934992356, 0.35258096934992356, 0.1882665081653776, 0.1882665081653776, 0.1882665081653776, 0.20858885079684897, 0.20858885079684897, 0.20858885079684897, 0.19363387374272523, 0.19363387374272523, 0.19363387374272523, 0.20001392291115938, 0.20001392291115938, 0.20001392291115938, 0.21125528948939432, 0.21125528948939432, 0.21125528948939432, 0.22663908709179748, 0.22663908709179748, 0.22663908709179748, 0.18642165568206692, 0.18642165568206692, 0.18642165568206692, 0.9515415975620096, 0.9515415975620096, 0.9515415975620096, 0.9405620122392895, 0.9405620122392895, 0.9405620122392895, 0.9324744064193785, 0.9324744064193785, 0.9324744064193785, 0.8062797647401126, 0.8062797647401126, 0.8062797647401126, 0.2119480012797994, 0.2119480012797994, 0.2119480012797994, 0.16922156266694022, 0.16922156266694022, 0.16922156266694022, 0.1904732667228033, 0.1904732667228033, 0.1904732667228033, 0.1913105678718302, 0.1913105678718302, 0.1913105678718302, 0.18629713424915084, 0.18629713424915084, 0.18629713424915084, 0.07950821881939574, 0.07950821881939574, 0.07950821881939574, 0.11444626586768814, 0.11444626586768814, 0.11444626586768814, 0.0940095086955387, 0.0940095086955387, 0.0940095086955387]}, "mutation_prompt": null}
{"id": "f2df0f1f-b2b1-4172-a0e2-feb6a22ee7a9", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSOWithStochasticSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Differential weight\n        self.initial_de_cr = 0.85  # Crossover probability\n        self.initial_pso_w = 0.5  # Inertia weight\n        self.pso_c1 = 1.0  # Cognitive coefficient\n        self.pso_c2 = 1.2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Stochastic local search to enhance exploitation\n            if self.eval_count >= self.max_evaluations * 0.80:\n                for i in range(self.population_size):\n                    if self.eval_count >= self.max_evaluations:\n                        break\n                    if np.random.rand() < 0.3:  # Randomly select individuals for local search\n                        perturbation = np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(population[i] + perturbation, self.lb, self.ub)\n                        candidate_fitness = func(candidate)\n                        self.eval_count += 1\n                        if candidate_fitness < fitness[i]:\n                            population[i] = candidate\n                            fitness[i] = candidate_fitness\n                            if candidate_fitness < personal_best_fitness[i]:\n                                personal_best[i] = candidate\n                                personal_best_fitness[i] = candidate_fitness\n                                if candidate_fitness < personal_best_fitness[global_best_idx]:\n                                    global_best = candidate\n                                    global_best_idx = i\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSOWithStochasticSearch", "description": "A dynamical adaptive hybrid evolutionary algorithm that integrates Differential Evolution, Particle Swarm Optimization, and stochastic local search to balance exploration and exploitation effectively across diverse problem landscapes.", "configspace": "", "generation": 23, "fitness": 0.3562219097195366, "feedback": "The algorithm AdaptiveHybridDEPSOWithStochasticSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.31.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9335489921147115, 0.9335489921147115, 0.9335489921147115, 0.9301635121310402, 0.9301635121310402, 0.9301635121310402, 0.9278069212614813, 0.9278069212614813, 0.9278069212614813, 0.8542470156612583, 0.8542470156612583, 0.8542470156612583, 0.8316468963842805, 0.8316468963842805, 0.8316468963842805, 0.018152529557445618, 0.018152529557445618, 0.018152529557445618, 0.16294283129300324, 0.16294283129300324, 0.16294283129300324, 0.18616647611702497, 0.18616647611702497, 0.18616647611702497, 0.13351664586100964, 0.13351664586100964, 0.13351664586100964, 0.1321458115856542, 0.1321458115856542, 0.1321458115856542, 0.12475851268583005, 0.12475851268583005, 0.12475851268583005, 0.08961764265060412, 0.08961764265060412, 0.08961764265060412, 0.9889014232132185, 0.9889014232132185, 0.9889014232132185, 0.9871532933026772, 0.9871532933026772, 0.9871532933026772, 0.9880386738526277, 0.9880386738526277, 0.9880386738526277, 0.7958734907540459, 0.7958734907540459, 0.7958734907540459, 0.6915656681830987, 0.6915656681830987, 0.6915656681830987, 0.8298590668073527, 0.8298590668073527, 0.8298590668073527, 0.22598512770620272, 0.22598512770620272, 0.22598512770620272, 0.1933886722428032, 0.1933886722428032, 0.1933886722428032, 0.22137332450687686, 0.22137332450687686, 0.22137332450687686, 0.2710217584124295, 0.2710217584124295, 0.2710217584124295, 0.1253930824930658, 0.1253930824930658, 0.1253930824930658, 0.30107302780617884, 0.30107302780617884, 0.30107302780617884, 0.28465908099820614, 0.28465908099820614, 0.28465908099820614, 0.3391081442980244, 0.3391081442980244, 0.3391081442980244, 0.29854508903867616, 0.29854508903867616, 0.29854508903867616, 0.18762795321509806, 0.18762795321509806, 0.18762795321509806, 0.00010277182678075647, 0.00010277182678075647, 0.00010277182678075647, 0.017913926197457797, 0.017913926197457797, 0.017913926197457797, 0.07740298773445631, 0.07740298773445631, 0.07740298773445631, 0.0014226600365394582, 0.0014226600365394582, 0.0014226600365394582, 0.11845725751851865, 0.11845725751851865, 0.11845725751851865, 0.11382577099255631, 0.11382577099255631, 0.11382577099255631, 0.08210037123028646, 0.08210037123028646, 0.08210037123028646, 0.07679508611483798, 0.07679508611483798, 0.07679508611483798, 0.4252996890668065, 0.4252996890668065, 0.4252996890668065, 0.03976671499555218, 0.03976671499555218, 0.03976671499555218, 0.1531326410367979, 0.1531326410367979, 0.1531326410367979, 0.5417779110564855, 0.5417779110564855, 0.5417779110564855, 0.5894130506815879, 0.5894130506815879, 0.5894130506815879, 0.6336371097925495, 0.6336371097925495, 0.6336371097925495, 0.10494998777017739, 0.10494998777017739, 0.10494998777017739, 0.07514568392526466, 0.07514568392526466, 0.07514568392526466, 0.15224693053359484, 0.15224693053359484, 0.15224693053359484, 0.1819968764345692, 0.1819968764345692, 0.1819968764345692, 0.1889041686435743, 0.1889041686435743, 0.1889041686435743, 0.2577412816360094, 0.2577412816360094, 0.2577412816360094, 0.471774846650279, 0.471774846650279, 0.471774846650279, 0.2392896128922275, 0.2392896128922275, 0.2392896128922275, 0.3407596574654642, 0.3407596574654642, 0.3407596574654642, 0.398113205903299, 0.398113205903299, 0.398113205903299, 0.30712090836504036, 0.30712090836504036, 0.30712090836504036, 0.20237720850927876, 0.20237720850927876, 0.20237720850927876, 0.21756542777189947, 0.21756542777189947, 0.21756542777189947, 0.20243332578635942, 0.20243332578635942, 0.20243332578635942, 0.17939354598359802, 0.17939354598359802, 0.17939354598359802, 0.19493741071288373, 0.19493741071288373, 0.19493741071288373, 0.22619340880805716, 0.22619340880805716, 0.22619340880805716, 0.8773590579528734, 0.8773590579528734, 0.8773590579528734, 0.9502715380250574, 0.9502715380250574, 0.9502715380250574, 0.9400000487429454, 0.9400000487429454, 0.9400000487429454, 0.9315718158231208, 0.9315718158231208, 0.9315718158231208, 0.8721914335883106, 0.8721914335883106, 0.8721914335883106, 0.21158382466454484, 0.21158382466454484, 0.21158382466454484, 0.15698452101602978, 0.15698452101602978, 0.15698452101602978, 0.179116750978904, 0.179116750978904, 0.179116750978904, 0.18618823798678108, 0.18618823798678108, 0.18618823798678108, 0.19419501612188206, 0.19419501612188206, 0.19419501612188206, 0.08544711128833149, 0.08544711128833149, 0.08544711128833149, 0.10791541448919817, 0.10791541448919817, 0.10791541448919817, 0.08888062892194304, 0.08888062892194304, 0.08888062892194304]}, "mutation_prompt": null}
{"id": "109e6662-93ab-408f-abb8-6df765192d0a", "solution": "import numpy as np\n\nclass StochasticAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Differential weight\n        self.initial_de_cr = 0.85  # Crossover probability\n        self.initial_pso_w = 0.5  # Inertia weight\n        self.pso_c1 = 1.0  # Cognitive coefficient\n        self.pso_c2 = 1.2  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Dynamic DE and PSO parameter adjustment\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Introduce random restarts for diversity enhancement\n            if self.eval_count >= self.max_evaluations * 0.75:\n                restart_count = max(1, int(self.population_size * 0.3))\n                for _ in range(restart_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "StochasticAdaptiveDEPSO", "description": "A stochastic adaptive algorithm blending Differential Evolution and Particle Swarm Optimization with dynamic parameter tuning and random restart strategies for enhanced exploration and exploitation.", "configspace": "", "generation": 24, "fitness": 0.33185822892104, "feedback": "The algorithm StochasticAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.31.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9302884565709402, 0.9302884565709402, 0.9302884565709402, 0.917692846890013, 0.917692846890013, 0.917692846890013, 0.9244031300474208, 0.9244031300474208, 0.9244031300474208, 0.8541752820032714, 0.8541752820032714, 0.8541752820032714, 0.8465092663397251, 0.8465092663397251, 0.8465092663397251, 0.017167626817643722, 0.017167626817643722, 0.017167626817643722, 0.16005728758036653, 0.16005728758036653, 0.16005728758036653, 0.11085641476493968, 0.11085641476493968, 0.11085641476493968, 0.10740949689347612, 0.10740949689347612, 0.10740949689347612, 0.12960174774246347, 0.12960174774246347, 0.12960174774246347, 0.1423990177148049, 0.1423990177148049, 0.1423990177148049, 0.07895312346954086, 0.07895312346954086, 0.07895312346954086, 0.9889029659257126, 0.9889029659257126, 0.9889029659257126, 0.9871540026575152, 0.9871540026575152, 0.9871540026575152, 0.9880393573152759, 0.9880393573152759, 0.9880393573152759, 0.7487482420536562, 0.7487482420536562, 0.7487482420536562, 0.15446483680219703, 0.15446483680219703, 0.15446483680219703, 0.772470899962867, 0.772470899962867, 0.772470899962867, 0.17154012759701387, 0.17154012759701387, 0.17154012759701387, 0.19377642875735468, 0.19377642875735468, 0.19377642875735468, 0.2366685015155947, 0.2366685015155947, 0.2366685015155947, 0.3385072089827227, 0.3385072089827227, 0.3385072089827227, 0.1276803681778076, 0.1276803681778076, 0.1276803681778076, 0.34705157033769474, 0.34705157033769474, 0.34705157033769474, 0.30849613127818765, 0.30849613127818765, 0.30849613127818765, 0.3726181906912944, 0.3726181906912944, 0.3726181906912944, 0.321581870515777, 0.321581870515777, 0.321581870515777, 0.15205994239258402, 0.15205994239258402, 0.15205994239258402, 0.010088431933753639, 0.010088431933753639, 0.010088431933753639, 0.011928343094709248, 0.011928343094709248, 0.011928343094709248, 0.0901392240923311, 0.0901392240923311, 0.0901392240923311, 0.004066501377688603, 0.004066501377688603, 0.004066501377688603, 0.05715686822204058, 0.05715686822204058, 0.05715686822204058, 0.0905228714411318, 0.0905228714411318, 0.0905228714411318, 0.08039811336029412, 0.08039811336029412, 0.08039811336029412, 0.08066736949311559, 0.08066736949311559, 0.08066736949311559, 0.26379006385267934, 0.26379006385267934, 0.26379006385267934, 0.03980492450063433, 0.03980492450063433, 0.03980492450063433, 0.15395314942688443, 0.15395314942688443, 0.15395314942688443, 0.6065699740328823, 0.6065699740328823, 0.6065699740328823, 0.6440239113356245, 0.6440239113356245, 0.6440239113356245, 0.6501140230121623, 0.6501140230121623, 0.6501140230121623, 0.0985258682100395, 0.0985258682100395, 0.0985258682100395, 0.06616208998610495, 0.06616208998610495, 0.06616208998610495, 0.09365995566919649, 0.09365995566919649, 0.09365995566919649, 0.15068493150991003, 0.15068493150991003, 0.15068493150991003, 0.19478170464466538, 0.19478170464466538, 0.19478170464466538, 0.17353863909311762, 0.17353863909311762, 0.17353863909311762, 0.5377488315687464, 0.5377488315687464, 0.5377488315687464, 0.25034190924484867, 0.25034190924484867, 0.25034190924484867, 0.27750251096725287, 0.27750251096725287, 0.27750251096725287, 0.22781113506600115, 0.22781113506600115, 0.22781113506600115, 0.24582123866161798, 0.24582123866161798, 0.24582123866161798, 0.20700374039188718, 0.20700374039188718, 0.20700374039188718, 0.17527582775325323, 0.17527582775325323, 0.17527582775325323, 0.2219074851151237, 0.2219074851151237, 0.2219074851151237, 0.18034453576779053, 0.18034453576779053, 0.18034453576779053, 0.1974692167751393, 0.1974692167751393, 0.1974692167751393, 0.20466101092200906, 0.20466101092200906, 0.20466101092200906, 0.2545238217310257, 0.2545238217310257, 0.2545238217310257, 0.9438590676211864, 0.9438590676211864, 0.9438590676211864, 0.9294285323328298, 0.9294285323328298, 0.9294285323328298, 0.9338739924178726, 0.9338739924178726, 0.9338739924178726, 0.9008460690974815, 0.9008460690974815, 0.9008460690974815, 0.21187145735178659, 0.21187145735178659, 0.21187145735178659, 0.16313304650959237, 0.16313304650959237, 0.16313304650959237, 0.1860463766003242, 0.1860463766003242, 0.1860463766003242, 0.18572186455689954, 0.18572186455689954, 0.18572186455689954, 0.19222544129595132, 0.19222544129595132, 0.19222544129595132, 0.08058880288636427, 0.08058880288636427, 0.08058880288636427, 0.10495388353828494, 0.10495388353828494, 0.10495388353828494, 0.09098138405478062, 0.09098138405478062, 0.09098138405478062]}, "mutation_prompt": null}
{"id": "30fbdc8c-1fba-406d-a706-8c797da0dbf0", "solution": "import numpy as np\n\nclass DynamicHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_de_f = 0.7  # Tunable Differential weight\n        self.initial_de_cr = 0.9  # Tunable Crossover probability\n        self.initial_pso_w = 0.6  # Tunable Inertia weight\n        self.pso_c1 = 1.5  # Tunable Cognitive coefficient\n        self.pso_c2 = 1.5  # Tunable Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = 0.5 + 0.5 * np.sin(progress_ratio * np.pi)  # Dynamic DE mutation factor\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.3 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.15))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicHybridDEPSO", "description": "A dynamic hybrid algorithm blending Differential Evolution, Particle Swarm Optimization, and adaptive evolution strategies to balance exploration and exploitation efficiently in diverse search landscapes.", "configspace": "", "generation": 25, "fitness": 0.2960733932564111, "feedback": "The algorithm DynamicHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8007259800172064, 0.8007259800172064, 0.8007259800172064, 0.8322420179450621, 0.8322420179450621, 0.8322420179450621, 0.8271297612479829, 0.8271297612479829, 0.8271297612479829, 0.6316993440214907, 0.6316993440214907, 0.6316993440214907, 0.675763293393043, 0.675763293393043, 0.675763293393043, 0.6658177911337597, 0.6658177911337597, 0.6658177911337597, 0.14674947512841263, 0.14674947512841263, 0.14674947512841263, 0.11663832455968626, 0.11663832455968626, 0.11663832455968626, 0.13751189137576525, 0.13751189137576525, 0.13751189137576525, 0.14131959891539658, 0.14131959891539658, 0.14131959891539658, 0.11199044731095598, 0.11199044731095598, 0.11199044731095598, 0.10614331367313512, 0.10614331367313512, 0.10614331367313512, 0.981568083661526, 0.981568083661526, 0.981568083661526, 0.9868984436411313, 0.9868984436411313, 0.9868984436411313, 0.9863189395137854, 0.9863189395137854, 0.9863189395137854, 0.49216610343790435, 0.49216610343790435, 0.49216610343790435, 0.3516761511922558, 0.3516761511922558, 0.3516761511922558, 0.46867091610488265, 0.46867091610488265, 0.46867091610488265, 0.6745816768187205, 0.6745816768187205, 0.6745816768187205, 0.24711778838705167, 0.24711778838705167, 0.24711778838705167, 0.7562463510728099, 0.7562463510728099, 0.7562463510728099, 0.2087126022918484, 0.2087126022918484, 0.2087126022918484, 0.12039315462627942, 0.12039315462627942, 0.12039315462627942, 0.20854716713425203, 0.20854716713425203, 0.20854716713425203, 0.21473691972128695, 0.21473691972128695, 0.21473691972128695, 0.1577381158978658, 0.1577381158978658, 0.1577381158978658, 0.2666975512381772, 0.2666975512381772, 0.2666975512381772, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.027796108630278815, 0.027796108630278815, 0.027796108630278815, 0.09747036125977482, 0.09747036125977482, 0.09747036125977482, 0.05245858070349585, 0.05245858070349585, 0.05245858070349585, 0.08219001042088059, 0.08219001042088059, 0.08219001042088059, 0.11753121103623398, 0.11753121103623398, 0.11753121103623398, 0.09148006415907561, 0.09148006415907561, 0.09148006415907561, 0.09020922901459705, 0.09020922901459705, 0.09020922901459705, 0.10987680205287398, 0.10987680205287398, 0.10987680205287398, 0.03781194216504624, 0.03781194216504624, 0.03781194216504624, 0.04913370349252, 0.04913370349252, 0.04913370349252, 0.5062239626825633, 0.5062239626825633, 0.5062239626825633, 0.5636847362223647, 0.5636847362223647, 0.5636847362223647, 0.5931793395355017, 0.5931793395355017, 0.5931793395355017, 0.1372444667520334, 0.1372444667520334, 0.1372444667520334, 0.09618603599231423, 0.09618603599231423, 0.09618603599231423, 0.10526923223578866, 0.10526923223578866, 0.10526923223578866, 0.1665420478797841, 0.1665420478797841, 0.1665420478797841, 0.2283760734798913, 0.2283760734798913, 0.2283760734798913, 0.16313606985610563, 0.16313606985610563, 0.16313606985610563, 0.3551031140123593, 0.3551031140123593, 0.3551031140123593, 0.34385648126127655, 0.34385648126127655, 0.34385648126127655, 0.48508452456012496, 0.48508452456012496, 0.48508452456012496, 0.29268289737870223, 0.29268289737870223, 0.29268289737870223, 0.20298761703669743, 0.20298761703669743, 0.20298761703669743, 0.3069466086638135, 0.3069466086638135, 0.3069466086638135, 0.1835632549659264, 0.1835632549659264, 0.1835632549659264, 0.2237708437274425, 0.2237708437274425, 0.2237708437274425, 0.21693229499280786, 0.21693229499280786, 0.21693229499280786, 0.21568962716579376, 0.21568962716579376, 0.21568962716579376, 0.20975312487825015, 0.20975312487825015, 0.20975312487825015, 0.2153175435128344, 0.2153175435128344, 0.2153175435128344, 0.19839017346228072, 0.19839017346228072, 0.19839017346228072, 0.18886031612915355, 0.18886031612915355, 0.18886031612915355, 0.20834409506528728, 0.20834409506528728, 0.20834409506528728, 0.16954614667296697, 0.16954614667296697, 0.16954614667296697, 0.20540935292550866, 0.20540935292550866, 0.20540935292550866, 0.6519874867434687, 0.6519874867434687, 0.6519874867434687, 0.2011750059992925, 0.2011750059992925, 0.2011750059992925, 0.1952586427919626, 0.1952586427919626, 0.1952586427919626, 0.16894178916616442, 0.16894178916616442, 0.16894178916616442, 0.07811138343650015, 0.07811138343650015, 0.07811138343650015, 0.08284439974694957, 0.08284439974694957, 0.08284439974694957, 0.08492640913323524, 0.08492640913323524, 0.08492640913323524]}, "mutation_prompt": null}
{"id": "3f8e087f-f239-4484-bad1-b7766c1f0e26", "solution": "import numpy as np\n\nclass SynergisticEvoAlgo:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Adjusted population size\n        self.initial_de_f = 0.9  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.7  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "SynergisticEvoAlgo", "description": "A synergistic evolutionary algorithm integrating Differential Evolution, Particle Swarm Optimization, and dynamic population adjustments to robustly navigate diverse optimization landscapes.", "configspace": "", "generation": 26, "fitness": 0.21838649598691923, "feedback": "The algorithm SynergisticEvoAlgo got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.22.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.762267561673057, 0.762267561673057, 0.762267561673057, 0.204559250342096, 0.204559250342096, 0.204559250342096, 0.7462240026704896, 0.7462240026704896, 0.7462240026704896, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.35074148479001155, 0.35074148479001155, 0.35074148479001155, 0.04399416320279126, 0.04399416320279126, 0.04399416320279126, 0.13765898918486164, 0.13765898918486164, 0.13765898918486164, 0.07855924090906519, 0.07855924090906519, 0.07855924090906519, 0.11285107618492785, 0.11285107618492785, 0.11285107618492785, 0.11416521372135957, 0.11416521372135957, 0.11416521372135957, 0.1167623323046062, 0.1167623323046062, 0.1167623323046062, 0.08905658194064403, 0.08905658194064403, 0.08905658194064403, 0.9813847649032592, 0.9813847649032592, 0.9813847649032592, 0.9799180499427296, 0.9799180499427296, 0.9799180499427296, 0.9898034853457955, 0.9898034853457955, 0.9898034853457955, 0.17882236365130266, 0.17882236365130266, 0.17882236365130266, 0.21286941708313145, 0.21286941708313145, 0.21286941708313145, 0.21438513519308122, 0.21438513519308122, 0.21438513519308122, 0.2764108268988039, 0.2764108268988039, 0.2764108268988039, 0.16175680648142077, 0.16175680648142077, 0.16175680648142077, 0.14970205732040398, 0.14970205732040398, 0.14970205732040398, 0.17742152609986117, 0.17742152609986117, 0.17742152609986117, 0.11482960369826001, 0.11482960369826001, 0.11482960369826001, 0.18109478224769548, 0.18109478224769548, 0.18109478224769548, 0.1197072671740671, 0.1197072671740671, 0.1197072671740671, 0.1816312254692547, 0.1816312254692547, 0.1816312254692547, 0.1762368309143021, 0.1762368309143021, 0.1762368309143021, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08100906542403119, 0.08100906542403119, 0.08100906542403119, 0.038632190288177104, 0.038632190288177104, 0.038632190288177104, 0.048985043772455494, 0.048985043772455494, 0.048985043772455494, 0.026325486567798206, 0.026325486567798206, 0.026325486567798206, 0.056307711003632854, 0.056307711003632854, 0.056307711003632854, 0.04495456555398536, 0.04495456555398536, 0.04495456555398536, 0.08471461231481103, 0.08471461231481103, 0.08471461231481103, 0.07564161145915127, 0.07564161145915127, 0.07564161145915127, 0.05430371717565774, 0.05430371717565774, 0.05430371717565774, 0.47892298676830636, 0.47892298676830636, 0.47892298676830636, 0.5445620392289283, 0.5445620392289283, 0.5445620392289283, 0.4657965639219772, 0.4657965639219772, 0.4657965639219772, 0.0813168626162507, 0.0813168626162507, 0.0813168626162507, 0.10211579860383246, 0.10211579860383246, 0.10211579860383246, 0.10177502433572294, 0.10177502433572294, 0.10177502433572294, 0.19189328668845929, 0.19189328668845929, 0.19189328668845929, 0.20082696994036664, 0.20082696994036664, 0.20082696994036664, 0.19192549087980848, 0.19192549087980848, 0.19192549087980848, 0.27923272632695517, 0.27923272632695517, 0.27923272632695517, 0.3180113248201788, 0.3180113248201788, 0.3180113248201788, 0.4084524940295823, 0.4084524940295823, 0.4084524940295823, 0.3088515427687809, 0.3088515427687809, 0.3088515427687809, 0.18748298491033533, 0.18748298491033533, 0.18748298491033533, 0.13075378970636686, 0.13075378970636686, 0.13075378970636686, 0.17469563675162958, 0.17469563675162958, 0.17469563675162958, 0.17071932054842742, 0.17071932054842742, 0.17071932054842742, 0.19896884932371606, 0.19896884932371606, 0.19896884932371606, 0.1830379339750663, 0.1830379339750663, 0.1830379339750663, 0.21371200693180348, 0.21371200693180348, 0.21371200693180348, 0.18420482716612874, 0.18420482716612874, 0.18420482716612874, 0.6673031910168363, 0.6673031910168363, 0.6673031910168363, 0.15706937932525322, 0.15706937932525322, 0.15706937932525322, 0.17753827854429438, 0.17753827854429438, 0.17753827854429438, 0.13137270844272841, 0.13137270844272841, 0.13137270844272841, 0.2012880899869942, 0.2012880899869942, 0.2012880899869942, 0.15592905395137335, 0.15592905395137335, 0.15592905395137335, 0.17336182732060879, 0.17336182732060879, 0.17336182732060879, 0.19337762278796666, 0.19337762278796666, 0.19337762278796666, 0.1782811720666666, 0.1782811720666666, 0.1782811720666666, 0.07605754845283319, 0.07605754845283319, 0.07605754845283319, 0.06532534855360195, 0.06532534855360195, 0.06532534855360195, 0.06557698745942486, 0.06557698745942486, 0.06557698745942486]}, "mutation_prompt": null}
{"id": "d4ef7561-dec5-4d67-b478-2fdf258db3e4", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Adjusted population size\n        self.initial_de_f = 0.9  # Higher initial Differential weight\n        self.initial_de_cr = 0.9  # Higher initial Crossover probability\n        self.initial_pso_w = 0.7  # Higher initial Inertia weight\n        self.pso_c1 = 1.5  # Higher Cognitive coefficient\n        self.pso_c2 = 1.5  # Higher Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adaptive parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Enhanced Differential Evolution\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c + np.random.rand(self.dim)), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Dynamic Particle Swarm Optimization\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Maintain diversity by introducing random solutions\n            if self.eval_count >= self.max_evaluations * 0.60:\n                diversity_count = max(1, int(self.population_size * 0.3))  # Increased diversity\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedHybridDEPSO", "description": "A novel stochastic hybrid approach combining Adaptive Differential Evolution and Dynamic Particle Swarm Optimization with enhanced mutation strategies and adaptive parameters to efficiently handle diverse optimization landscapes.", "configspace": "", "generation": 27, "fitness": 0.24825071579957034, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.24.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.7393796108830157, 0.7393796108830157, 0.7393796108830157, 0.7738277758280067, 0.7738277758280067, 0.7738277758280067, 0.7783436524588047, 0.7783436524588047, 0.7783436524588047, 0.08136033608365456, 0.08136033608365456, 0.08136033608365456, 0.5534026738237336, 0.5534026738237336, 0.5534026738237336, 0.10781508816365226, 0.10781508816365226, 0.10781508816365226, 0.11414470333597071, 0.11414470333597071, 0.11414470333597071, 0.12080260700271483, 0.12080260700271483, 0.12080260700271483, 0.27801774434359927, 0.27801774434359927, 0.27801774434359927, 0.15108632821841872, 0.15108632821841872, 0.15108632821841872, 0.1065450991591439, 0.1065450991591439, 0.1065450991591439, 0.12041871544454519, 0.12041871544454519, 0.12041871544454519, 0.9904089417800767, 0.9904089417800767, 0.9904089417800767, 0.9903559595128516, 0.9903559595128516, 0.9903559595128516, 0.9883687799515741, 0.9883687799515741, 0.9883687799515741, 0.41305988779054403, 0.41305988779054403, 0.41305988779054403, 0.2869567845535588, 0.2869567845535588, 0.2869567845535588, 0.22880379302300757, 0.22880379302300757, 0.22880379302300757, 0.28517327521063807, 0.28517327521063807, 0.28517327521063807, 0.1902397002593973, 0.1902397002593973, 0.1902397002593973, 0.28952621774620646, 0.28952621774620646, 0.28952621774620646, 0.11990599114794787, 0.11990599114794787, 0.11990599114794787, 0.17923014898033085, 0.17923014898033085, 0.17923014898033085, 0.1702191032016257, 0.1702191032016257, 0.1702191032016257, 0.10204594402114564, 0.10204594402114564, 0.10204594402114564, 0.16600147720290281, 0.16600147720290281, 0.16600147720290281, 0.00757887363378229, 0.00757887363378229, 0.00757887363378229, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06631239457008031, 0.06631239457008031, 0.06631239457008031, 0.051974490493308045, 0.051974490493308045, 0.051974490493308045, 0.040972261266082, 0.040972261266082, 0.040972261266082, 0.02503541782113139, 0.02503541782113139, 0.02503541782113139, 0.1284372515455834, 0.1284372515455834, 0.1284372515455834, 0.15267883676030014, 0.15267883676030014, 0.15267883676030014, 0.14255897012736607, 0.14255897012736607, 0.14255897012736607, 0.11355843602617388, 0.11355843602617388, 0.11355843602617388, 0.09601995944489339, 0.09601995944489339, 0.09601995944489339, 0.447212418310834, 0.447212418310834, 0.447212418310834, 0.5148437183837562, 0.5148437183837562, 0.5148437183837562, 0.5230011549789203, 0.5230011549789203, 0.5230011549789203, 0.10568392669153925, 0.10568392669153925, 0.10568392669153925, 0.0856052421858039, 0.0856052421858039, 0.0856052421858039, 0.08625600056122262, 0.08625600056122262, 0.08625600056122262, 0.19036166217578898, 0.19036166217578898, 0.19036166217578898, 0.12807318509471477, 0.12807318509471477, 0.12807318509471477, 0.14530496955480376, 0.14530496955480376, 0.14530496955480376, 0.3618131161985838, 0.3618131161985838, 0.3618131161985838, 0.3464190119520518, 0.3464190119520518, 0.3464190119520518, 0.3561913816223903, 0.3561913816223903, 0.3561913816223903, 0.2557863284582119, 0.2557863284582119, 0.2557863284582119, 0.17562860184427043, 0.17562860184427043, 0.17562860184427043, 0.1233049688562653, 0.1233049688562653, 0.1233049688562653, 0.16922141144826786, 0.16922141144826786, 0.16922141144826786, 0.20162185164673652, 0.20162185164673652, 0.20162185164673652, 0.18085905385661805, 0.18085905385661805, 0.18085905385661805, 0.2082961715898236, 0.2082961715898236, 0.2082961715898236, 0.20479245239486754, 0.20479245239486754, 0.20479245239486754, 0.19474695046041535, 0.19474695046041535, 0.19474695046041535, 0.7966179075713695, 0.7966179075713695, 0.7966179075713695, 0.18601138947338136, 0.18601138947338136, 0.18601138947338136, 0.2243982085017172, 0.2243982085017172, 0.2243982085017172, 0.17316314114115083, 0.17316314114115083, 0.17316314114115083, 0.3550557615253932, 0.3550557615253932, 0.3550557615253932, 0.15548635727554228, 0.15548635727554228, 0.15548635727554228, 0.19199345480979546, 0.19199345480979546, 0.19199345480979546, 0.1898296600337912, 0.1898296600337912, 0.1898296600337912, 0.21894937184781582, 0.21894937184781582, 0.21894937184781582, 0.08162708820031983, 0.08162708820031983, 0.08162708820031983, 0.06685873964994626, 0.06685873964994626, 0.06685873964994626, 0.07816964845718577, 0.07816964845718577, 0.07816964845718577]}, "mutation_prompt": null}
{"id": "0452842a-d5aa-42d6-830d-7c7d9d445161", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "cd084e69-f817-4a99-86dd-4e563ed43e62", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Adjusted Differential weight\n        self.initial_de_cr = 0.8  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def chaotic_mutation(self, x):\n        \"\"\"Apply chaotic mutation using logistic map.\"\"\"\n        r = 4.0\n        return np.clip(x + r * x * (1 - x), self.lb, self.ub)\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Simulated annealing-inspired parameter adjustment\n            t = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * np.exp(-4 * t)\n            de_cr = self.initial_de_cr * (1 - t) + 0.5 * t\n            pso_w = self.initial_pso_w * (1 - 0.5 * t)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = self.chaotic_mutation(a + de_f * (b - c))\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with chaotic mutation and annealing-inspired parameter tuning for balanced exploration and exploitation.", "configspace": "", "generation": 29, "fitness": 0.23229534419772305, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.25.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8690927330461046, 0.8690927330461046, 0.8690927330461046, 0.1966779508552965, 0.1966779508552965, 0.1966779508552965, 0.859458613896607, 0.859458613896607, 0.859458613896607, 0.039139997108405766, 0.039139997108405766, 0.039139997108405766, 0.6727893211624618, 0.6727893211624618, 0.6727893211624618, 0.017797404699771313, 0.017797404699771313, 0.017797404699771313, 0.1398236166585235, 0.1398236166585235, 0.1398236166585235, 0.09303013239663593, 0.09303013239663593, 0.09303013239663593, 0.1781521905846315, 0.1781521905846315, 0.1781521905846315, 0.08856438144784151, 0.08856438144784151, 0.08856438144784151, 0.11061068231990234, 0.11061068231990234, 0.11061068231990234, 0.07111493636339694, 0.07111493636339694, 0.07111493636339694, 0.9883120329048491, 0.9883120329048491, 0.9883120329048491, 0.9914750672861313, 0.9914750672861313, 0.9914750672861313, 0.9924169562401309, 0.9924169562401309, 0.9924169562401309, 0.11229497455702386, 0.11229497455702386, 0.11229497455702386, 0.07804070602889801, 0.07804070602889801, 0.07804070602889801, 0.09901964670163566, 0.09901964670163566, 0.09901964670163566, 0.06693453507180891, 0.06693453507180891, 0.06693453507180891, 0.16167994852619072, 0.16167994852619072, 0.16167994852619072, 0.22132829984495972, 0.22132829984495972, 0.22132829984495972, 0.12337745715053383, 0.12337745715053383, 0.12337745715053383, 0.09899664495361049, 0.09899664495361049, 0.09899664495361049, 0.32698717145521017, 0.32698717145521017, 0.32698717145521017, 0.20498676427459994, 0.20498676427459994, 0.20498676427459994, 0.12621443233599405, 0.12621443233599405, 0.12621443233599405, 0.2381370743193445, 0.2381370743193445, 0.2381370743193445, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04829414489008066, 0.04829414489008066, 0.04829414489008066, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05920916365724971, 0.05920916365724971, 0.05920916365724971, 0.06412785962626744, 0.06412785962626744, 0.06412785962626744, 0.03659363359138079, 0.03659363359138079, 0.03659363359138079, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08683287308037291, 0.08683287308037291, 0.08683287308037291, 0.09250187038021673, 0.09250187038021673, 0.09250187038021673, 0.05246421209521834, 0.05246421209521834, 0.05246421209521834, 0.039128346032753725, 0.039128346032753725, 0.039128346032753725, 0.0563008131180639, 0.0563008131180639, 0.0563008131180639, 0.5537905502842442, 0.5537905502842442, 0.5537905502842442, 0.5259469113555421, 0.5259469113555421, 0.5259469113555421, 0.5900236772941959, 0.5900236772941959, 0.5900236772941959, 0.0854700011149242, 0.0854700011149242, 0.0854700011149242, 0.14937838845387563, 0.14937838845387563, 0.14937838845387563, 0.09693829243006935, 0.09693829243006935, 0.09693829243006935, 0.14626867414011613, 0.14626867414011613, 0.14626867414011613, 0.1608221185852473, 0.1608221185852473, 0.1608221185852473, 0.14813043679399307, 0.14813043679399307, 0.14813043679399307, 0.3698293490272031, 0.3698293490272031, 0.3698293490272031, 0.212420583598953, 0.212420583598953, 0.212420583598953, 0.4347289099419135, 0.4347289099419135, 0.4347289099419135, 0.28324556419926283, 0.28324556419926283, 0.28324556419926283, 0.19935579135023884, 0.19935579135023884, 0.19935579135023884, 0.1624582448793993, 0.1624582448793993, 0.1624582448793993, 0.24427120562154714, 0.24427120562154714, 0.24427120562154714, 0.24458980730803848, 0.24458980730803848, 0.24458980730803848, 0.20979014787540018, 0.20979014787540018, 0.20979014787540018, 0.19767084906475674, 0.19767084906475674, 0.19767084906475674, 0.22596084496712643, 0.22596084496712643, 0.22596084496712643, 0.19477142894958277, 0.19477142894958277, 0.19477142894958277, 0.8987280622645154, 0.8987280622645154, 0.8987280622645154, 0.16216064273164144, 0.16216064273164144, 0.16216064273164144, 0.16646519822926908, 0.16646519822926908, 0.16646519822926908, 0.15666945938485444, 0.15666945938485444, 0.15666945938485444, 0.20644274383901262, 0.20644274383901262, 0.20644274383901262, 0.2122555462770902, 0.2122555462770902, 0.2122555462770902, 0.19054837605159547, 0.19054837605159547, 0.19054837605159547, 0.17286709153239788, 0.17286709153239788, 0.17286709153239788, 0.1791786953417217, 0.1791786953417217, 0.1791786953417217, 0.09360665015239322, 0.09360665015239322, 0.09360665015239322, 0.07419836849186501, 0.07419836849186501, 0.07419836849186501, 0.07407558204196851, 0.07407558204196851, 0.07407558204196851]}, "mutation_prompt": null}
{"id": "d9e21c8c-24e2-4ded-ac21-7b159c8a0c07", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Changed Differential weight for enhanced exploration\n        self.initial_de_cr = 0.7  # Changed Crossover probability for more diversity\n        self.initial_pso_w = 0.6  # Changed Inertia weight for balance\n        self.pso_c1 = 1.5  # Increased Cognitive coefficient for better local search\n        self.pso_c2 = 1.0  # Decreased Social coefficient to reduce premature convergence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio  # Adjusted DE F\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.9 * progress_ratio  # Adjusted DE CR\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.7 * progress_ratio  # Adjusted PSO W\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.80:  # Increased diversity phase\n                diversity_count = max(1, int(self.population_size * 0.3))  # More individuals for diversity\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A novel synergy of Differential Evolution and Particle Swarm Optimization with adaptive parameters and diversity preservation to efficiently navigate complex search spaces.", "configspace": "", "generation": 30, "fitness": 0.3021089409124667, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.27.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8890870252468449, 0.8890870252468449, 0.8890870252468449, 0.8845686980931674, 0.8845686980931674, 0.8845686980931674, 0.8837240372184101, 0.8837240372184101, 0.8837240372184101, 0.6451084597268346, 0.6451084597268346, 0.6451084597268346, 0.7673238159832394, 0.7673238159832394, 0.7673238159832394, 0.796895976985989, 0.796895976985989, 0.796895976985989, 0.10459599122653762, 0.10459599122653762, 0.10459599122653762, 0.1489046541500273, 0.1489046541500273, 0.1489046541500273, 0.11198158445799422, 0.11198158445799422, 0.11198158445799422, 0.14976513392504132, 0.14976513392504132, 0.14976513392504132, 0.15094860988813985, 0.15094860988813985, 0.15094860988813985, 0.16780921069196397, 0.16780921069196397, 0.16780921069196397, 0.9872949056526762, 0.9872949056526762, 0.9872949056526762, 0.9871023255092726, 0.9871023255092726, 0.9871023255092726, 0.9880460151763398, 0.9880460151763398, 0.9880460151763398, 0.2963260228627522, 0.2963260228627522, 0.2963260228627522, 0.30055742166407295, 0.30055742166407295, 0.30055742166407295, 0.4764214247638684, 0.4764214247638684, 0.4764214247638684, 0.5576099655994724, 0.5576099655994724, 0.5576099655994724, 0.213403617598385, 0.213403617598385, 0.213403617598385, 0.8256474193781013, 0.8256474193781013, 0.8256474193781013, 0.2544102204707205, 0.2544102204707205, 0.2544102204707205, 0.16072811628609163, 0.16072811628609163, 0.16072811628609163, 0.2700806706169032, 0.2700806706169032, 0.2700806706169032, 0.25256219343091235, 0.25256219343091235, 0.25256219343091235, 0.132631045380328, 0.132631045380328, 0.132631045380328, 0.257224573095993, 0.257224573095993, 0.257224573095993, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.031636699893735076, 0.031636699893735076, 0.031636699893735076, 0.0007373879311993736, 0.0007373879311993736, 0.0007373879311993736, 0.07667844590792228, 0.07667844590792228, 0.07667844590792228, 0.028788892596933846, 0.028788892596933846, 0.028788892596933846, 0.07381014861997082, 0.07381014861997082, 0.07381014861997082, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08140653042080737, 0.08140653042080737, 0.08140653042080737, 0.100387825010533, 0.100387825010533, 0.100387825010533, 0.04471729560450932, 0.04471729560450932, 0.04471729560450932, 0.18510574507007604, 0.18510574507007604, 0.18510574507007604, 0.08208466333922548, 0.08208466333922548, 0.08208466333922548, 0.5643154679328544, 0.5643154679328544, 0.5643154679328544, 0.5544882447902792, 0.5544882447902792, 0.5544882447902792, 0.5876599895668447, 0.5876599895668447, 0.5876599895668447, 0.12139439474823555, 0.12139439474823555, 0.12139439474823555, 0.09355884245495727, 0.09355884245495727, 0.09355884245495727, 0.08699319523874671, 0.08699319523874671, 0.08699319523874671, 0.16713266014956007, 0.16713266014956007, 0.16713266014956007, 0.1724102981787784, 0.1724102981787784, 0.1724102981787784, 0.1921138987205674, 0.1921138987205674, 0.1921138987205674, 0.4174931270164519, 0.4174931270164519, 0.4174931270164519, 0.2928418519359417, 0.2928418519359417, 0.2928418519359417, 0.22107443309375363, 0.22107443309375363, 0.22107443309375363, 0.3469766018233241, 0.3469766018233241, 0.3469766018233241, 0.20040688469513035, 0.20040688469513035, 0.20040688469513035, 0.23657970191582767, 0.23657970191582767, 0.23657970191582767, 0.2097786784053116, 0.2097786784053116, 0.2097786784053116, 0.19510648930487196, 0.19510648930487196, 0.19510648930487196, 0.17014365816850974, 0.17014365816850974, 0.17014365816850974, 0.20696125405704047, 0.20696125405704047, 0.20696125405704047, 0.20473053414749642, 0.20473053414749642, 0.20473053414749642, 0.22293744884158606, 0.22293744884158606, 0.22293744884158606, 0.869926995565808, 0.869926995565808, 0.869926995565808, 0.165069673772126, 0.165069673772126, 0.165069673772126, 0.16727192105928856, 0.16727192105928856, 0.16727192105928856, 0.4987633693447765, 0.4987633693447765, 0.4987633693447765, 0.21176822559974273, 0.21176822559974273, 0.21176822559974273, 0.2134824967556006, 0.2134824967556006, 0.2134824967556006, 0.19225802965979233, 0.19225802965979233, 0.19225802965979233, 0.2037970732767318, 0.2037970732767318, 0.2037970732767318, 0.19551819021415973, 0.19551819021415973, 0.19551819021415973, 0.07080644805768677, 0.07080644805768677, 0.07080644805768677, 0.0686522116606677, 0.0686522116606677, 0.0686522116606677, 0.06311868607015947, 0.06311868607015947, 0.06311868607015947]}, "mutation_prompt": null}
{"id": "0c74af72-2513-477e-9121-39fbaa47fe99", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.initial_de_f = 0.9  # Enhanced Differential weight for exploration\n        self.initial_de_cr = 0.9  # Enhanced Crossover probability\n        self.initial_pso_w = 0.6  # Enhanced Inertia weight for better convergence\n        self.pso_c1 = 1.5  # Enhanced Cognitive coefficient\n        self.pso_c2 = 1.5  # Enhanced Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO_v2", "description": "A revised hybrid DE-PSO algorithm with adaptive parameter adjustment and enhanced diversity maintenance to effectively navigate complex optimization landscapes.", "configspace": "", "generation": 31, "fitness": 0.28615292034885337, "feedback": "The algorithm AdaptiveHybridDEPSO_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8312340957703979, 0.8312340957703979, 0.8312340957703979, 0.833283245645253, 0.833283245645253, 0.833283245645253, 0.836882320633899, 0.836882320633899, 0.836882320633899, 0.1729103503670698, 0.1729103503670698, 0.1729103503670698, 0.176534331830424, 0.176534331830424, 0.176534331830424, 0.6517576512330077, 0.6517576512330077, 0.6517576512330077, 0.1487350014054677, 0.1487350014054677, 0.1487350014054677, 0.10956459237623617, 0.10956459237623617, 0.10956459237623617, 0.13548751605641296, 0.13548751605641296, 0.13548751605641296, 0.17563725699587995, 0.17563725699587995, 0.17563725699587995, 0.10414675869813983, 0.10414675869813983, 0.10414675869813983, 0.1165785956185551, 0.1165785956185551, 0.1165785956185551, 0.9903135134964416, 0.9903135134964416, 0.9903135134964416, 0.9864418749710406, 0.9864418749710406, 0.9864418749710406, 0.9891968899677482, 0.9891968899677482, 0.9891968899677482, 0.3099871011200295, 0.3099871011200295, 0.3099871011200295, 0.43929368574832806, 0.43929368574832806, 0.43929368574832806, 0.47425437146333105, 0.47425437146333105, 0.47425437146333105, 0.21380506746507544, 0.21380506746507544, 0.21380506746507544, 0.6502394335364012, 0.6502394335364012, 0.6502394335364012, 0.17242122563128215, 0.17242122563128215, 0.17242122563128215, 0.268763260100885, 0.268763260100885, 0.268763260100885, 0.2232290675904337, 0.2232290675904337, 0.2232290675904337, 0.210448853019932, 0.210448853019932, 0.210448853019932, 0.21320000505112757, 0.21320000505112757, 0.21320000505112757, 0.2987945347945391, 0.2987945347945391, 0.2987945347945391, 0.2421271922498338, 0.2421271922498338, 0.2421271922498338, 0.02095660255711196, 0.02095660255711196, 0.02095660255711196, 0.00024208207558107375, 0.00024208207558107375, 0.00024208207558107375, 0.013763980170592549, 0.013763980170592549, 0.013763980170592549, 0.07079749540797586, 0.07079749540797586, 0.07079749540797586, 0.03524451462286837, 0.03524451462286837, 0.03524451462286837, 0.040311039832603424, 0.040311039832603424, 0.040311039832603424, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08431632109636689, 0.08431632109636689, 0.08431632109636689, 0.06794933043987073, 0.06794933043987073, 0.06794933043987073, 0.217049185571763, 0.217049185571763, 0.217049185571763, 0.14616913840776635, 0.14616913840776635, 0.14616913840776635, 0.08080168979467994, 0.08080168979467994, 0.08080168979467994, 0.5331331607365526, 0.5331331607365526, 0.5331331607365526, 0.5483670086391133, 0.5483670086391133, 0.5483670086391133, 0.5330349617570262, 0.5330349617570262, 0.5330349617570262, 0.10094632930111291, 0.10094632930111291, 0.10094632930111291, 0.10437597149485667, 0.10437597149485667, 0.10437597149485667, 0.4989237150013762, 0.4989237150013762, 0.4989237150013762, 0.18639748337891004, 0.18639748337891004, 0.18639748337891004, 0.1328430983077209, 0.1328430983077209, 0.1328430983077209, 0.20183178264685386, 0.20183178264685386, 0.20183178264685386, 0.3921705840312564, 0.3921705840312564, 0.3921705840312564, 0.225417083993259, 0.225417083993259, 0.225417083993259, 0.3718150008277147, 0.3718150008277147, 0.3718150008277147, 0.19674813444926642, 0.19674813444926642, 0.19674813444926642, 0.40922572850411665, 0.40922572850411665, 0.40922572850411665, 0.21392471217075337, 0.21392471217075337, 0.21392471217075337, 0.20025123036443815, 0.20025123036443815, 0.20025123036443815, 0.19418360795645362, 0.19418360795645362, 0.19418360795645362, 0.17927140854308787, 0.17927140854308787, 0.17927140854308787, 0.2122523113403163, 0.2122523113403163, 0.2122523113403163, 0.23437091733962745, 0.23437091733962745, 0.23437091733962745, 0.1843988082827277, 0.1843988082827277, 0.1843988082827277, 0.8135325163425373, 0.8135325163425373, 0.8135325163425373, 0.16644026397948075, 0.16644026397948075, 0.16644026397948075, 0.18423632125711542, 0.18423632125711542, 0.18423632125711542, 0.16734030083278417, 0.16734030083278417, 0.16734030083278417, 0.746921755559465, 0.746921755559465, 0.746921755559465, 0.15595653264829268, 0.15595653264829268, 0.15595653264829268, 0.16836743901513818, 0.16836743901513818, 0.16836743901513818, 0.17583153712584532, 0.17583153712584532, 0.17583153712584532, 0.1870812682321331, 0.1870812682321331, 0.1870812682321331, 0.08135896602211923, 0.08135896602211923, 0.08135896602211923, 0.0887066561733394, 0.0887066561733394, 0.0887066561733394, 0.06038449604829732, 0.06038449604829732, 0.06038449604829732]}, "mutation_prompt": null}
{"id": "b4bb899d-e437-4f13-a132-a365229b9c3e", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size for better exploration\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.4  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.60:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm leveraging Differential Evolution, Particle Swarm Optimization, and dynamic parameter adjustment with diversity strategies, enabling efficient exploration and exploitation of diverse search spaces.", "configspace": "", "generation": 32, "fitness": 0.33903499167247236, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.30.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9058353013076273, 0.9058353013076273, 0.9058353013076273, 0.9098904813760542, 0.9098904813760542, 0.9098904813760542, 0.9094579015425893, 0.9094579015425893, 0.9094579015425893, 0.8176251970197239, 0.8176251970197239, 0.8176251970197239, 0.8155185008809904, 0.8155185008809904, 0.8155185008809904, 0.8006071788590171, 0.8006071788590171, 0.8006071788590171, 0.12220313711683117, 0.12220313711683117, 0.12220313711683117, 0.17457740111781972, 0.17457740111781972, 0.17457740111781972, 0.14142199228302377, 0.14142199228302377, 0.14142199228302377, 0.10349441644981938, 0.10349441644981938, 0.10349441644981938, 0.15001946309788838, 0.15001946309788838, 0.15001946309788838, 0.1029539663539728, 0.1029539663539728, 0.1029539663539728, 0.9834795139962247, 0.9834795139962247, 0.9834795139962247, 0.9872141631399256, 0.9872141631399256, 0.9872141631399256, 0.9880686639520635, 0.9880686639520635, 0.9880686639520635, 0.7130795946440238, 0.7130795946440238, 0.7130795946440238, 0.6594089686439457, 0.6594089686439457, 0.6594089686439457, 0.655496152574828, 0.655496152574828, 0.655496152574828, 0.3669173057898907, 0.3669173057898907, 0.3669173057898907, 0.8700100537458398, 0.8700100537458398, 0.8700100537458398, 0.17823007537649904, 0.17823007537649904, 0.17823007537649904, 0.2779578781475569, 0.2779578781475569, 0.2779578781475569, 0.13437336885671014, 0.13437336885671014, 0.13437336885671014, 0.2491402069704335, 0.2491402069704335, 0.2491402069704335, 0.2598142818707039, 0.2598142818707039, 0.2598142818707039, 0.2879388236726388, 0.2879388236726388, 0.2879388236726388, 0.1280171053558461, 0.1280171053558461, 0.1280171053558461, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002536223577768393, 0.002536223577768393, 0.002536223577768393, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1780591294982301, 0.1780591294982301, 0.1780591294982301, 0.06565310080861819, 0.06565310080861819, 0.06565310080861819, 0.06161967649767919, 0.06161967649767919, 0.06161967649767919, 0.1234372482662216, 0.1234372482662216, 0.1234372482662216, 0.21483192897416603, 0.21483192897416603, 0.21483192897416603, 0.07785530132868557, 0.07785530132868557, 0.07785530132868557, 0.3002118202948394, 0.3002118202948394, 0.3002118202948394, 0.039551090999971006, 0.039551090999971006, 0.039551090999971006, 0.0830233928599835, 0.0830233928599835, 0.0830233928599835, 0.5677989688221821, 0.5677989688221821, 0.5677989688221821, 0.5859987396950331, 0.5859987396950331, 0.5859987396950331, 0.6106843255824737, 0.6106843255824737, 0.6106843255824737, 0.13556188251662749, 0.13556188251662749, 0.13556188251662749, 0.16377238067704292, 0.16377238067704292, 0.16377238067704292, 0.1607144803090268, 0.1607144803090268, 0.1607144803090268, 0.17561144380727256, 0.17561144380727256, 0.17561144380727256, 0.15237677081657386, 0.15237677081657386, 0.15237677081657386, 0.1572916752333271, 0.1572916752333271, 0.1572916752333271, 0.3241199150180575, 0.3241199150180575, 0.3241199150180575, 0.24032710120336342, 0.24032710120336342, 0.24032710120336342, 0.6664167517795432, 0.6664167517795432, 0.6664167517795432, 0.2110702352148217, 0.2110702352148217, 0.2110702352148217, 0.201064993721772, 0.201064993721772, 0.201064993721772, 0.24888614754736837, 0.24888614754736837, 0.24888614754736837, 0.20197055877217984, 0.20197055877217984, 0.20197055877217984, 0.20845376290244555, 0.20845376290244555, 0.20845376290244555, 0.22117463771728674, 0.22117463771728674, 0.22117463771728674, 0.2114710711102784, 0.2114710711102784, 0.2114710711102784, 0.19893918065673089, 0.19893918065673089, 0.19893918065673089, 0.19195211053821148, 0.19195211053821148, 0.19195211053821148, 0.9259248737843481, 0.9259248737843481, 0.9259248737843481, 0.16788401146254217, 0.16788401146254217, 0.16788401146254217, 0.17773108534860016, 0.17773108534860016, 0.17773108534860016, 0.6175110333678322, 0.6175110333678322, 0.6175110333678322, 0.2116347551556783, 0.2116347551556783, 0.2116347551556783, 0.8207902076964151, 0.8207902076964151, 0.8207902076964151, 0.19950927565018284, 0.19950927565018284, 0.19950927565018284, 0.18637358764371303, 0.18637358764371303, 0.18637358764371303, 0.17820334450097786, 0.17820334450097786, 0.17820334450097786, 0.08018557387597125, 0.08018557387597125, 0.08018557387597125, 0.08352972625521382, 0.08352972625521382, 0.08352972625521382, 0.08585478478626252, 0.08585478478626252, 0.08585478478626252]}, "mutation_prompt": null}
{"id": "826f464a-c668-45b4-b690-849a4996ffe4", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "2267614c-6222-4439-b2a9-ea173f6256f2", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.8  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.0  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters dynamically\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.2 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.65:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "RefinedAdaptiveHybridDEPSO", "description": "A refined hybrid evolutionary algorithm integrating adaptive Differential Evolution and Particle Swarm Optimization with strategic diversity enhancements to efficiently optimize across diverse search spaces.", "configspace": "", "generation": 34, "fitness": 0.3414598276119508, "feedback": "The algorithm RefinedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.30.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9159308411104665, 0.9159308411104665, 0.9159308411104665, 0.9088430277889695, 0.9088430277889695, 0.9088430277889695, 0.8911717479662447, 0.8911717479662447, 0.8911717479662447, 0.8151074216834915, 0.8151074216834915, 0.8151074216834915, 0.8110109951948676, 0.8110109951948676, 0.8110109951948676, 0.8513226625818759, 0.8513226625818759, 0.8513226625818759, 0.11682989031636803, 0.11682989031636803, 0.11682989031636803, 0.17041851595756907, 0.17041851595756907, 0.17041851595756907, 0.17104695944134585, 0.17104695944134585, 0.17104695944134585, 0.11267843893261065, 0.11267843893261065, 0.11267843893261065, 0.15438752245099385, 0.15438752245099385, 0.15438752245099385, 0.1315055695385703, 0.1315055695385703, 0.1315055695385703, 0.9780204570892186, 0.9780204570892186, 0.9780204570892186, 0.9843159853697834, 0.9843159853697834, 0.9843159853697834, 0.9872183924872409, 0.9872183924872409, 0.9872183924872409, 0.7741645122923926, 0.7741645122923926, 0.7741645122923926, 0.6921044955705788, 0.6921044955705788, 0.6921044955705788, 0.7352379779750503, 0.7352379779750503, 0.7352379779750503, 0.17356181736950693, 0.17356181736950693, 0.17356181736950693, 0.16173983261547398, 0.16173983261547398, 0.16173983261547398, 0.23467997380784977, 0.23467997380784977, 0.23467997380784977, 0.13502339321237, 0.13502339321237, 0.13502339321237, 0.2808174057506311, 0.2808174057506311, 0.2808174057506311, 0.24968048099895146, 0.24968048099895146, 0.24968048099895146, 0.21281614949302907, 0.21281614949302907, 0.21281614949302907, 0.2885411347790314, 0.2885411347790314, 0.2885411347790314, 0.12983443065542655, 0.12983443065542655, 0.12983443065542655, 0.00718231210193121, 0.00718231210193121, 0.00718231210193121, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07000421243914567, 0.07000421243914567, 0.07000421243914567, 0.04701821435615039, 0.04701821435615039, 0.04701821435615039, 0.11684141070483278, 0.11684141070483278, 0.11684141070483278, 0.07031148549826571, 0.07031148549826571, 0.07031148549826571, 0.11691660817698735, 0.11691660817698735, 0.11691660817698735, 0.10310188978013235, 0.10310188978013235, 0.10310188978013235, 0.23459479211366085, 0.23459479211366085, 0.23459479211366085, 0.08016204352451373, 0.08016204352451373, 0.08016204352451373, 0.21790370356813016, 0.21790370356813016, 0.21790370356813016, 0.5388605238132271, 0.5388605238132271, 0.5388605238132271, 0.5889477572076658, 0.5889477572076658, 0.5889477572076658, 0.5969113202784926, 0.5969113202784926, 0.5969113202784926, 0.6072722814974634, 0.6072722814974634, 0.6072722814974634, 0.1840881025438199, 0.1840881025438199, 0.1840881025438199, 0.13340515238694983, 0.13340515238694983, 0.13340515238694983, 0.18915382850797924, 0.18915382850797924, 0.18915382850797924, 0.19814969038638652, 0.19814969038638652, 0.19814969038638652, 0.4983353398834862, 0.4983353398834862, 0.4983353398834862, 0.4998065755881639, 0.4998065755881639, 0.4998065755881639, 0.325118810538513, 0.325118810538513, 0.325118810538513, 0.6076002593634312, 0.6076002593634312, 0.6076002593634312, 0.32456461599817155, 0.32456461599817155, 0.32456461599817155, 0.19653617499510578, 0.19653617499510578, 0.19653617499510578, 0.32742966929497075, 0.32742966929497075, 0.32742966929497075, 0.2027484320965841, 0.2027484320965841, 0.2027484320965841, 0.1899083451017045, 0.1899083451017045, 0.1899083451017045, 0.1963995412424322, 0.1963995412424322, 0.1963995412424322, 0.22342569800890655, 0.22342569800890655, 0.22342569800890655, 0.21954067810084832, 0.21954067810084832, 0.21954067810084832, 0.18750379059982736, 0.18750379059982736, 0.18750379059982736, 0.9189773889162294, 0.9189773889162294, 0.9189773889162294, 0.1583619510750206, 0.1583619510750206, 0.1583619510750206, 0.9368331207730904, 0.9368331207730904, 0.9368331207730904, 0.16960227705893827, 0.16960227705893827, 0.16960227705893827, 0.21273120577268045, 0.21273120577268045, 0.21273120577268045, 0.15822062221074196, 0.15822062221074196, 0.15822062221074196, 0.2031272014370048, 0.2031272014370048, 0.2031272014370048, 0.2059150402248009, 0.2059150402248009, 0.2059150402248009, 0.2052914645172801, 0.2052914645172801, 0.2052914645172801, 0.08042332127817131, 0.08042332127817131, 0.08042332127817131, 0.08927433847245703, 0.08927433847245703, 0.08927433847245703, 0.07839636419625584, 0.07839636419625584, 0.07839636419625584]}, "mutation_prompt": null}
{"id": "14c79d6a-1ad4-436c-a458-d1f101d83f3d", "solution": "import numpy as np\n\nclass DynamicHybridDEPSOARS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Modified Differential weight\n        self.initial_de_cr = 0.9  # Modified Crossover probability\n        self.initial_pso_w = 0.6  # Modified Inertia weight\n        self.pso_c1 = 1.5  # Modified Cognitive coefficient\n        self.pso_c2 = 1.5  # Modified Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicHybridDEPSOARS", "description": "A dynamic hybrid algorithm blending Differential Evolution, Particle Swarm Optimization, and Adaptive Random Search to enhance exploration, exploitation, and diversity management in complex search landscapes.", "configspace": "", "generation": 35, "fitness": 0.3295636301623521, "feedback": "The algorithm DynamicHybridDEPSOARS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.28.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8584382160724158, 0.8584382160724158, 0.8584382160724158, 0.8849801367950918, 0.8849801367950918, 0.8849801367950918, 0.850240482428009, 0.850240482428009, 0.850240482428009, 0.7135704467005881, 0.7135704467005881, 0.7135704467005881, 0.7440265116911458, 0.7440265116911458, 0.7440265116911458, 0.7278599341658765, 0.7278599341658765, 0.7278599341658765, 0.25345083980298155, 0.25345083980298155, 0.25345083980298155, 0.11753942722239918, 0.11753942722239918, 0.11753942722239918, 0.16163956843356098, 0.16163956843356098, 0.16163956843356098, 0.6352099158252524, 0.6352099158252524, 0.6352099158252524, 0.1283578999706746, 0.1283578999706746, 0.1283578999706746, 0.15446014570038602, 0.15446014570038602, 0.15446014570038602, 0.989136931170124, 0.989136931170124, 0.989136931170124, 0.9907025625844, 0.9907025625844, 0.9907025625844, 0.9915334776616692, 0.9915334776616692, 0.9915334776616692, 0.40390363930789686, 0.40390363930789686, 0.40390363930789686, 0.587667257892017, 0.587667257892017, 0.587667257892017, 0.546351820540198, 0.546351820540198, 0.546351820540198, 0.21105088929472482, 0.21105088929472482, 0.21105088929472482, 0.16092786328952713, 0.16092786328952713, 0.16092786328952713, 0.7759375600501479, 0.7759375600501479, 0.7759375600501479, 0.27425928639576236, 0.27425928639576236, 0.27425928639576236, 0.2287705144409663, 0.2287705144409663, 0.2287705144409663, 0.12109842444317798, 0.12109842444317798, 0.12109842444317798, 0.25395747903415045, 0.25395747903415045, 0.25395747903415045, 0.26061859737224746, 0.26061859737224746, 0.26061859737224746, 0.034554543762120415, 0.034554543762120415, 0.034554543762120415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014560599529386153, 0.014560599529386153, 0.014560599529386153, 0.08337797424284965, 0.08337797424284965, 0.08337797424284965, 0.061391339907784226, 0.061391339907784226, 0.061391339907784226, 0.10209506896616871, 0.10209506896616871, 0.10209506896616871, 0.1303626068012691, 0.1303626068012691, 0.1303626068012691, 0.07098305909032865, 0.07098305909032865, 0.07098305909032865, 0.09566255227520304, 0.09566255227520304, 0.09566255227520304, 0.09724814562193862, 0.09724814562193862, 0.09724814562193862, 0.1550852935399838, 0.1550852935399838, 0.1550852935399838, 0.13949132137316633, 0.13949132137316633, 0.13949132137316633, 0.5421820800070782, 0.5421820800070782, 0.5421820800070782, 0.5919886798204212, 0.5919886798204212, 0.5919886798204212, 0.5493305925076593, 0.5493305925076593, 0.5493305925076593, 0.1116844616039081, 0.1116844616039081, 0.1116844616039081, 0.11177820100342284, 0.11177820100342284, 0.11177820100342284, 0.1426972228376724, 0.1426972228376724, 0.1426972228376724, 0.21376474699353842, 0.21376474699353842, 0.21376474699353842, 0.1609541810380386, 0.1609541810380386, 0.1609541810380386, 0.20613652356112067, 0.20613652356112067, 0.20613652356112067, 0.4328384809026289, 0.4328384809026289, 0.4328384809026289, 0.6288239499729651, 0.6288239499729651, 0.6288239499729651, 0.684656195128103, 0.684656195128103, 0.684656195128103, 0.3071203256202597, 0.3071203256202597, 0.3071203256202597, 0.2208396991764523, 0.2208396991764523, 0.2208396991764523, 0.3025448988069538, 0.3025448988069538, 0.3025448988069538, 0.18124418190538305, 0.18124418190538305, 0.18124418190538305, 0.22536199960448644, 0.22536199960448644, 0.22536199960448644, 0.19113556039613755, 0.19113556039613755, 0.19113556039613755, 0.19861433523012484, 0.19861433523012484, 0.19861433523012484, 0.2516402133660125, 0.2516402133660125, 0.2516402133660125, 0.1964601371183815, 0.1964601371183815, 0.1964601371183815, 0.7979350774713341, 0.7979350774713341, 0.7979350774713341, 0.8532756971252704, 0.8532756971252704, 0.8532756971252704, 0.19781446592881924, 0.19781446592881924, 0.19781446592881924, 0.20099526435434123, 0.20099526435434123, 0.20099526435434123, 0.20750705905367306, 0.20750705905367306, 0.20750705905367306, 0.1864149294276497, 0.1864149294276497, 0.1864149294276497, 0.19842969640690522, 0.19842969640690522, 0.19842969640690522, 0.1789682164841433, 0.1789682164841433, 0.1789682164841433, 0.19835429191807574, 0.19835429191807574, 0.19835429191807574, 0.07212820092519379, 0.07212820092519379, 0.07212820092519379, 0.09158065052103215, 0.09158065052103215, 0.09158065052103215, 0.08267882207656985, 0.08267882207656985, 0.08267882207656985]}, "mutation_prompt": null}
{"id": "e5f41d27-091e-403b-8daa-cd768cc7a5b9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Enhanced Differential weight\n        self.initial_de_cr = 0.9  # Enhanced Crossover probability\n        self.initial_pso_w = 0.6  # Enhanced Inertia weight\n        self.pso_c1 = 1.5  # Enhanced Cognitive coefficient\n        self.pso_c2 = 1.5  # Enhanced Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.60:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedAdaptiveHybridDEPSO", "description": "An enhanced adaptive hybrid evolutionary algorithm integrating Differential Evolution, Particle Swarm Optimization, and dynamic diversity injection to robustly navigate and optimize complex search landscapes.", "configspace": "", "generation": 36, "fitness": 0.31404375648190086, "feedback": "The algorithm EnhancedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8502972936696727, 0.8502972936696727, 0.8502972936696727, 0.8553009378463861, 0.8553009378463861, 0.8553009378463861, 0.8756364637681253, 0.8756364637681253, 0.8756364637681253, 0.6688594921742914, 0.6688594921742914, 0.6688594921742914, 0.7321654008660932, 0.7321654008660932, 0.7321654008660932, 0.2424239502166362, 0.2424239502166362, 0.2424239502166362, 0.10901200398080568, 0.10901200398080568, 0.10901200398080568, 0.16628852080109413, 0.16628852080109413, 0.16628852080109413, 0.15083895728605434, 0.15083895728605434, 0.15083895728605434, 0.11098172325549294, 0.11098172325549294, 0.11098172325549294, 0.5902820985989672, 0.5902820985989672, 0.5902820985989672, 0.107313073582892, 0.107313073582892, 0.107313073582892, 0.989136931170124, 0.989136931170124, 0.989136931170124, 0.9907025625844, 0.9907025625844, 0.9907025625844, 0.9915334776616692, 0.9915334776616692, 0.9915334776616692, 0.39664877917198826, 0.39664877917198826, 0.39664877917198826, 0.39322206442392327, 0.39322206442392327, 0.39322206442392327, 0.4481055051940954, 0.4481055051940954, 0.4481055051940954, 0.7180133139706404, 0.7180133139706404, 0.7180133139706404, 0.27264504444781024, 0.27264504444781024, 0.27264504444781024, 0.2125071101559144, 0.2125071101559144, 0.2125071101559144, 0.24218207843099093, 0.24218207843099093, 0.24218207843099093, 0.2054777888963486, 0.2054777888963486, 0.2054777888963486, 0.12050815447785646, 0.12050815447785646, 0.12050815447785646, 0.12816166452393318, 0.12816166452393318, 0.12816166452393318, 0.24247561046369215, 0.24247561046369215, 0.24247561046369215, 0.09759444722667521, 0.09759444722667521, 0.09759444722667521, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03033519972129728, 0.03033519972129728, 0.03033519972129728, 0.007702147187324759, 0.007702147187324759, 0.007702147187324759, 0.09595261592983151, 0.09595261592983151, 0.09595261592983151, 0.09553368688448083, 0.09553368688448083, 0.09553368688448083, 0.0787334946626721, 0.0787334946626721, 0.0787334946626721, 0.13368360601333495, 0.13368360601333495, 0.13368360601333495, 0.07506226066694233, 0.07506226066694233, 0.07506226066694233, 0.09747665339774536, 0.09747665339774536, 0.09747665339774536, 0.0526309912692704, 0.0526309912692704, 0.0526309912692704, 0.19530637985987043, 0.19530637985987043, 0.19530637985987043, 0.14440932947751262, 0.14440932947751262, 0.14440932947751262, 0.5290704190781712, 0.5290704190781712, 0.5290704190781712, 0.5555565701945205, 0.5555565701945205, 0.5555565701945205, 0.574118650718149, 0.574118650718149, 0.574118650718149, 0.11258797805669896, 0.11258797805669896, 0.11258797805669896, 0.11115896860241137, 0.11115896860241137, 0.11115896860241137, 0.11296188819192599, 0.11296188819192599, 0.11296188819192599, 0.1816457103640866, 0.1816457103640866, 0.1816457103640866, 0.14523383628375486, 0.14523383628375486, 0.14523383628375486, 0.1851004315357776, 0.1851004315357776, 0.1851004315357776, 0.5065874849347738, 0.5065874849347738, 0.5065874849347738, 0.49160520292063237, 0.49160520292063237, 0.49160520292063237, 0.5207986195603982, 0.5207986195603982, 0.5207986195603982, 0.21317086447950184, 0.21317086447950184, 0.21317086447950184, 0.1821347136822955, 0.1821347136822955, 0.1821347136822955, 0.2900675761629814, 0.2900675761629814, 0.2900675761629814, 0.17574005576893437, 0.17574005576893437, 0.17574005576893437, 0.2343608955810429, 0.2343608955810429, 0.2343608955810429, 0.21743678608421235, 0.21743678608421235, 0.21743678608421235, 0.21397531678876025, 0.21397531678876025, 0.21397531678876025, 0.25108096536138513, 0.25108096536138513, 0.25108096536138513, 0.19471259400643404, 0.19471259400643404, 0.19471259400643404, 0.866264690760464, 0.866264690760464, 0.866264690760464, 0.8789968073021645, 0.8789968073021645, 0.8789968073021645, 0.16641613158740853, 0.16641613158740853, 0.16641613158740853, 0.16819439741063014, 0.16819439741063014, 0.16819439741063014, 0.20664046009755443, 0.20664046009755443, 0.20664046009755443, 0.645641258113994, 0.645641258113994, 0.645641258113994, 0.18060876108908774, 0.18060876108908774, 0.18060876108908774, 0.18412351128114346, 0.18412351128114346, 0.18412351128114346, 0.18187181695977528, 0.18187181695977528, 0.18187181695977528, 0.06427470865280138, 0.06427470865280138, 0.06427470865280138, 0.07661546438811473, 0.07661546438811473, 0.07661546438811473, 0.07715611678002299, 0.07715611678002299, 0.07715611678002299]}, "mutation_prompt": null}
{"id": "caa4a967-94d2-48cd-bdbc-f599a8950f0c", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Adjusted Differential weight for more exploration\n        self.initial_de_cr = 0.7  # Adjusted Crossover probability for diversity\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight for balance\n        self.pso_c1 = 1.5  # Higher Cognitive coefficient for local search emphasis\n        self.pso_c2 = 1.0  # Lower Social coefficient to reduce global convergence speed\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Dynamically adjust DE and PSO parameters\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.9 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Promote diversity by randomly reinitializing part of the population\n            if self.eval_count >= self.max_evaluations * 0.8:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid evolutionary algorithm integrating Differential Evolution and Particle Swarm Optimization with dynamic parameter tuning and diversity reinforcement for robust search space exploration.", "configspace": "", "generation": 37, "fitness": 0.33762334978985464, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8836801305145331, 0.8836801305145331, 0.8836801305145331, 0.9074645670863375, 0.9074645670863375, 0.9074645670863375, 0.9012378714514224, 0.9012378714514224, 0.9012378714514224, 0.786833450146623, 0.786833450146623, 0.786833450146623, 0.7783379182522517, 0.7783379182522517, 0.7783379182522517, 0.7887307967063012, 0.7887307967063012, 0.7887307967063012, 0.17087088880349488, 0.17087088880349488, 0.17087088880349488, 0.10756999694748115, 0.10756999694748115, 0.10756999694748115, 0.16805984348285619, 0.16805984348285619, 0.16805984348285619, 0.08510124880120151, 0.08510124880120151, 0.08510124880120151, 0.14065176111671185, 0.14065176111671185, 0.14065176111671185, 0.12713955353341921, 0.12713955353341921, 0.12713955353341921, 0.9851655448339217, 0.9851655448339217, 0.9851655448339217, 0.9822744091237435, 0.9822744091237435, 0.9822744091237435, 0.9886923111777324, 0.9886923111777324, 0.9886923111777324, 0.5987731328184092, 0.5987731328184092, 0.5987731328184092, 0.6234233335173616, 0.6234233335173616, 0.6234233335173616, 0.684954229559838, 0.684954229559838, 0.684954229559838, 0.7779484119083664, 0.7779484119083664, 0.7779484119083664, 0.16093525655714147, 0.16093525655714147, 0.16093525655714147, 0.8421394629838088, 0.8421394629838088, 0.8421394629838088, 0.2691739072245064, 0.2691739072245064, 0.2691739072245064, 0.2905907752781126, 0.2905907752781126, 0.2905907752781126, 0.2827135100116287, 0.2827135100116287, 0.2827135100116287, 0.2818862357708103, 0.2818862357708103, 0.2818862357708103, 0.2959696017829735, 0.2959696017829735, 0.2959696017829735, 0.2792816775514161, 0.2792816775514161, 0.2792816775514161, 0.08031821548147622, 0.08031821548147622, 0.08031821548147622, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06456459439084483, 0.06456459439084483, 0.06456459439084483, 0.04431828273382887, 0.04431828273382887, 0.04431828273382887, 0.020088996568911166, 0.020088996568911166, 0.020088996568911166, 0.050794932037562135, 0.050794932037562135, 0.050794932037562135, 0.08364041987057913, 0.08364041987057913, 0.08364041987057913, 0.2067671806775805, 0.2067671806775805, 0.2067671806775805, 0.29041981092919367, 0.29041981092919367, 0.29041981092919367, 0.21005342592599652, 0.21005342592599652, 0.21005342592599652, 0.11348933166639219, 0.11348933166639219, 0.11348933166639219, 0.6297799898988283, 0.6297799898988283, 0.6297799898988283, 0.5882310285669752, 0.5882310285669752, 0.5882310285669752, 0.6521006751915266, 0.6521006751915266, 0.6521006751915266, 0.13428108205336098, 0.13428108205336098, 0.13428108205336098, 0.14160986842797285, 0.14160986842797285, 0.14160986842797285, 0.1546064758027076, 0.1546064758027076, 0.1546064758027076, 0.32595605564335306, 0.32595605564335306, 0.32595605564335306, 0.16659967996017, 0.16659967996017, 0.16659967996017, 0.2917967617021815, 0.2917967617021815, 0.2917967617021815, 0.3706466881896835, 0.3706466881896835, 0.3706466881896835, 0.2622312287837917, 0.2622312287837917, 0.2622312287837917, 0.5371501042992961, 0.5371501042992961, 0.5371501042992961, 0.1403274096366819, 0.1403274096366819, 0.1403274096366819, 0.31329360665671724, 0.31329360665671724, 0.31329360665671724, 0.3920084950069932, 0.3920084950069932, 0.3920084950069932, 0.19649872278709024, 0.19649872278709024, 0.19649872278709024, 0.23446912537635656, 0.23446912537635656, 0.23446912537635656, 0.19353308036135153, 0.19353308036135153, 0.19353308036135153, 0.20187650170435523, 0.20187650170435523, 0.20187650170435523, 0.22261744131089156, 0.22261744131089156, 0.22261744131089156, 0.21553097152254064, 0.21553097152254064, 0.21553097152254064, 0.9084335566853389, 0.9084335566853389, 0.9084335566853389, 0.15887676972191822, 0.15887676972191822, 0.15887676972191822, 0.1606953911996981, 0.1606953911996981, 0.1606953911996981, 0.16664530226088714, 0.16664530226088714, 0.16664530226088714, 0.21297858668949843, 0.21297858668949843, 0.21297858668949843, 0.15640998407537443, 0.15640998407537443, 0.15640998407537443, 0.1841523308327685, 0.1841523308327685, 0.1841523308327685, 0.17964524873927623, 0.17964524873927623, 0.17964524873927623, 0.20669795935319513, 0.20669795935319513, 0.20669795935319513, 0.08043311975231937, 0.08043311975231937, 0.08043311975231937, 0.10005719291657211, 0.10005719291657211, 0.10005719291657211, 0.07445573253508952, 0.07445573253508952, 0.07445573253508952]}, "mutation_prompt": null}
{"id": "0f2fda0b-97fc-4e16-b6ea-ea581e188661", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "3ac13e21-3a8e-40b2-919b-b16ccd759e9f", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.15))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A refined hybrid algorithm integrating Differential Evolution and Particle Swarm Optimization with adaptive parameter tuning and enhanced diversity mechanisms for improved exploration and exploitation balance.", "configspace": "", "generation": 39, "fitness": 0.28930881955262466, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.83983837294119, 0.83983837294119, 0.83983837294119, 0.8464112511870087, 0.8464112511870087, 0.8464112511870087, 0.8502530616226754, 0.8502530616226754, 0.8502530616226754, 0.6560493760644937, 0.6560493760644937, 0.6560493760644937, 0.6828234912147093, 0.6828234912147093, 0.6828234912147093, 0.677734319865225, 0.677734319865225, 0.677734319865225, 0.119395976079402, 0.119395976079402, 0.119395976079402, 0.12112589961936082, 0.12112589961936082, 0.12112589961936082, 0.12679179705272126, 0.12679179705272126, 0.12679179705272126, 0.11589043517594999, 0.11589043517594999, 0.11589043517594999, 0.13131105520301567, 0.13131105520301567, 0.13131105520301567, 0.11634327398015976, 0.11634327398015976, 0.11634327398015976, 0.9811353396004086, 0.9811353396004086, 0.9811353396004086, 0.9876969426908354, 0.9876969426908354, 0.9876969426908354, 0.9897221006595637, 0.9897221006595637, 0.9897221006595637, 0.4783214208940505, 0.4783214208940505, 0.4783214208940505, 0.3174324338388328, 0.3174324338388328, 0.3174324338388328, 0.3112986078681308, 0.3112986078681308, 0.3112986078681308, 0.3606103153050496, 0.3606103153050496, 0.3606103153050496, 0.16042665413890322, 0.16042665413890322, 0.16042665413890322, 0.14959457801295573, 0.14959457801295573, 0.14959457801295573, 0.12498438699813874, 0.12498438699813874, 0.12498438699813874, 0.22024524924150835, 0.22024524924150835, 0.22024524924150835, 0.2433289158791192, 0.2433289158791192, 0.2433289158791192, 0.23266500262604617, 0.23266500262604617, 0.23266500262604617, 0.2523865148431549, 0.2523865148431549, 0.2523865148431549, 0.2623497912402699, 0.2623497912402699, 0.2623497912402699, 0.04339783304153566, 0.04339783304153566, 0.04339783304153566, 0.033397353290259724, 0.033397353290259724, 0.033397353290259724, 0.07836862674402889, 0.07836862674402889, 0.07836862674402889, 0.10076460796475617, 0.10076460796475617, 0.10076460796475617, 0.009129418892195984, 0.009129418892195984, 0.009129418892195984, 0.031751422384805994, 0.031751422384805994, 0.031751422384805994, 0.033374875596010156, 0.033374875596010156, 0.033374875596010156, 0.06861223174870579, 0.06861223174870579, 0.06861223174870579, 0.07080318548662834, 0.07080318548662834, 0.07080318548662834, 0.339776660559315, 0.339776660559315, 0.339776660559315, 0.1656130856147311, 0.1656130856147311, 0.1656130856147311, 0.08215621148778429, 0.08215621148778429, 0.08215621148778429, 0.5384071717948691, 0.5384071717948691, 0.5384071717948691, 0.5265261022497107, 0.5265261022497107, 0.5265261022497107, 0.639518062514286, 0.639518062514286, 0.639518062514286, 0.09578911458765638, 0.09578911458765638, 0.09578911458765638, 0.1311052538634958, 0.1311052538634958, 0.1311052538634958, 0.11208137872596635, 0.11208137872596635, 0.11208137872596635, 0.22112264416456995, 0.22112264416456995, 0.22112264416456995, 0.1934152455731275, 0.1934152455731275, 0.1934152455731275, 0.33836104682309975, 0.33836104682309975, 0.33836104682309975, 0.441496157282788, 0.441496157282788, 0.441496157282788, 0.4513201372468161, 0.4513201372468161, 0.4513201372468161, 0.4989665430853638, 0.4989665430853638, 0.4989665430853638, 0.1446101886967368, 0.1446101886967368, 0.1446101886967368, 0.18714945691412244, 0.18714945691412244, 0.18714945691412244, 0.1300858142639365, 0.1300858142639365, 0.1300858142639365, 0.21304256185698978, 0.21304256185698978, 0.21304256185698978, 0.18686605438127302, 0.18686605438127302, 0.18686605438127302, 0.17532977864974386, 0.17532977864974386, 0.17532977864974386, 0.23216791648574098, 0.23216791648574098, 0.23216791648574098, 0.20294844731382755, 0.20294844731382755, 0.20294844731382755, 0.22433440469686516, 0.22433440469686516, 0.22433440469686516, 0.8840158795341915, 0.8840158795341915, 0.8840158795341915, 0.1584053367538265, 0.1584053367538265, 0.1584053367538265, 0.12219824208538232, 0.12219824208538232, 0.12219824208538232, 0.16727045227481574, 0.16727045227481574, 0.16727045227481574, 0.20670484247307996, 0.20670484247307996, 0.20670484247307996, 0.15651447115495576, 0.15651447115495576, 0.15651447115495576, 0.19017457338812038, 0.19017457338812038, 0.19017457338812038, 0.19334331610835243, 0.19334331610835243, 0.19334331610835243, 0.18423712480570842, 0.18423712480570842, 0.18423712480570842, 0.10565164913613567, 0.10565164913613567, 0.10565164913613567, 0.08845589726383729, 0.08845589726383729, 0.08845589726383729, 0.07530766498594732, 0.07530766498594732, 0.07530766498594732]}, "mutation_prompt": null}
{"id": "35f897ee-6803-40be-87d0-9e90534eff5c", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Changed for increased diversity\n        self.initial_de_f = 0.7  # Adjusted Differential weight for better exploration\n        self.initial_de_cr = 0.9  # Higher Crossover probability for diverse offspring\n        self.initial_pso_w = 0.4  # Lower Inertia weight for faster convergence\n        self.pso_c1 = 1.2  # Higher Cognitive coefficient for personal best attraction\n        self.pso_c2 = 1.4  # Higher Social coefficient for global best attraction\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.25))  # Increased diversity injection\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization, with progressive parameter tuning and mutation-based diversity injection, to efficiently navigate and exploit complex search spaces.", "configspace": "", "generation": 40, "fitness": 0.3115675532114687, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.29.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9161782477857914, 0.9161782477857914, 0.9161782477857914, 0.9209381102662539, 0.9209381102662539, 0.9209381102662539, 0.9310077660586863, 0.9310077660586863, 0.9310077660586863, 0.8117802304414257, 0.8117802304414257, 0.8117802304414257, 0.8447347028242842, 0.8447347028242842, 0.8447347028242842, 0.8484292738353671, 0.8484292738353671, 0.8484292738353671, 0.1587597961635091, 0.1587597961635091, 0.1587597961635091, 0.1834349701366247, 0.1834349701366247, 0.1834349701366247, 0.11796393988772669, 0.11796393988772669, 0.11796393988772669, 0.14115541214640837, 0.14115541214640837, 0.14115541214640837, 0.13031435479223386, 0.13031435479223386, 0.13031435479223386, 0.13359353200983337, 0.13359353200983337, 0.13359353200983337, 0.9793969545895815, 0.9793969545895815, 0.9793969545895815, 0.9855343620505447, 0.9855343620505447, 0.9855343620505447, 0.9897124209218847, 0.9897124209218847, 0.9897124209218847, 0.7526790160102779, 0.7526790160102779, 0.7526790160102779, 0.7499657979487228, 0.7499657979487228, 0.7499657979487228, 0.7060251157029038, 0.7060251157029038, 0.7060251157029038, 0.33947196973250404, 0.33947196973250404, 0.33947196973250404, 0.19527570754103518, 0.19527570754103518, 0.19527570754103518, 0.12905895522771116, 0.12905895522771116, 0.12905895522771116, 0.3009998201024664, 0.3009998201024664, 0.3009998201024664, 0.13472601392082129, 0.13472601392082129, 0.13472601392082129, 0.13329399503150274, 0.13329399503150274, 0.13329399503150274, 0.2793844709544787, 0.2793844709544787, 0.2793844709544787, 0.3217554701632104, 0.3217554701632104, 0.3217554701632104, 0.31362200624207903, 0.31362200624207903, 0.31362200624207903, 0.024238821172527625, 0.024238821172527625, 0.024238821172527625, 0.049048717567117595, 0.049048717567117595, 0.049048717567117595, 0.012199577064007316, 0.012199577064007316, 0.012199577064007316, 0.07431451827442992, 0.07431451827442992, 0.07431451827442992, 0.015603657446312758, 0.015603657446312758, 0.015603657446312758, 0.07017519626928947, 0.07017519626928947, 0.07017519626928947, 0.03704071431697631, 0.03704071431697631, 0.03704071431697631, 0.08537931802278675, 0.08537931802278675, 0.08537931802278675, 0.07660119276497901, 0.07660119276497901, 0.07660119276497901, 0.20443266458606058, 0.20443266458606058, 0.20443266458606058, 0.03957423152057815, 0.03957423152057815, 0.03957423152057815, 0.1043702433181225, 0.1043702433181225, 0.1043702433181225, 0.553346879585527, 0.553346879585527, 0.553346879585527, 0.6109768472808503, 0.6109768472808503, 0.6109768472808503, 0.5538588757691894, 0.5538588757691894, 0.5538588757691894, 0.0836782635788762, 0.0836782635788762, 0.0836782635788762, 0.12486299666700162, 0.12486299666700162, 0.12486299666700162, 0.15311424846520527, 0.15311424846520527, 0.15311424846520527, 0.18768601291364206, 0.18768601291364206, 0.18768601291364206, 0.2694207333639518, 0.2694207333639518, 0.2694207333639518, 0.32125656020870774, 0.32125656020870774, 0.32125656020870774, 0.39972909712263005, 0.39972909712263005, 0.39972909712263005, 0.230363471289057, 0.230363471289057, 0.230363471289057, 0.28565386967246975, 0.28565386967246975, 0.28565386967246975, 0.17057808949246844, 0.17057808949246844, 0.17057808949246844, 0.2075438747046583, 0.2075438747046583, 0.2075438747046583, 0.16582127686451364, 0.16582127686451364, 0.16582127686451364, 0.2070938548551362, 0.2070938548551362, 0.2070938548551362, 0.19901800934326808, 0.19901800934326808, 0.19901800934326808, 0.20074963897437303, 0.20074963897437303, 0.20074963897437303, 0.19776731146158477, 0.19776731146158477, 0.19776731146158477, 0.18864720230028365, 0.18864720230028365, 0.18864720230028365, 0.19302062611529103, 0.19302062611529103, 0.19302062611529103, 0.9390090338943823, 0.9390090338943823, 0.9390090338943823, 0.15961978930194876, 0.15961978930194876, 0.15961978930194876, 0.15550136534731573, 0.15550136534731573, 0.15550136534731573, 0.2134600672001873, 0.2134600672001873, 0.2134600672001873, 0.2119693530412109, 0.2119693530412109, 0.2119693530412109, 0.15690497992826946, 0.15690497992826946, 0.15690497992826946, 0.18141067626704077, 0.18141067626704077, 0.18141067626704077, 0.20925187508724752, 0.20925187508724752, 0.20925187508724752, 0.174482752038977, 0.174482752038977, 0.174482752038977, 0.11044130357278159, 0.11044130357278159, 0.11044130357278159, 0.08442874558395774, 0.08442874558395774, 0.08442874558395774, 0.09002488512268592, 0.09002488512268592, 0.09002488512268592]}, "mutation_prompt": null}
{"id": "70158b60-e19c-4486-baad-03577ccecea9", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "ceeb78bf-bbc5-4f18-b3bf-962a5b2d4b0c", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.2  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.sa_temp = 1000  # Initial temperature for Simulated Annealing\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.randn(self.population_size, self.dim) * 0.1\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n            cooling_rate = 0.99\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Simulated Annealing inspired perturbation\n            if np.random.rand() < 0.1:\n                for i in range(self.population_size):\n                    if self.eval_count >= self.max_evaluations:\n                        break\n                    candidate = population[i] + np.random.normal(0, self.sa_temp, self.dim)\n                    candidate = np.clip(candidate, self.lb, self.ub)\n                    candidate_fitness = func(candidate)\n                    self.eval_count += 1\n                    if candidate_fitness < fitness[i] or np.exp((fitness[i] - candidate_fitness) / self.sa_temp) > np.random.rand():\n                        population[i] = candidate\n                        fitness[i] = candidate_fitness\n                        if candidate_fitness < personal_best_fitness[i]:\n                            personal_best[i] = candidate\n                            personal_best_fitness[i] = candidate_fitness\n                            if candidate_fitness < personal_best_fitness[global_best_idx]:\n                                global_best = candidate\n                                global_best_idx = i\n                self.sa_temp *= cooling_rate\n\n            # Diversity enhancement by resetting some individuals\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSA", "description": "A novel adaptive hybrid optimization algorithm that combines strategies from Differential Evolution, Particle Swarm Optimization, and Simulated Annealing with focus on dynamic parameter tuning and diversity enhancement for robust black-box optimization.", "configspace": "", "generation": 42, "fitness": 0.2646445352164387, "feedback": "The algorithm AdaptiveHybridDEPSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.23.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.6889721935775021, 0.6889721935775021, 0.6889721935775021, 0.6595996587990465, 0.6595996587990465, 0.6595996587990465, 0.5829103263638655, 0.5829103263638655, 0.5829103263638655, 0.7284577966137447, 0.7284577966137447, 0.7284577966137447, 0.0827257346701985, 0.0827257346701985, 0.0827257346701985, 0.05487185038619535, 0.05487185038619535, 0.05487185038619535, 0.1435796408184693, 0.1435796408184693, 0.1435796408184693, 0.13373521160392143, 0.13373521160392143, 0.13373521160392143, 0.09930928794502758, 0.09930928794502758, 0.09930928794502758, 0.1290927769180218, 0.1290927769180218, 0.1290927769180218, 0.10559206673155841, 0.10559206673155841, 0.10559206673155841, 0.13014977302820807, 0.13014977302820807, 0.13014977302820807, 0.9898197895954312, 0.9898197895954312, 0.9898197895954312, 0.9910858016922054, 0.9910858016922054, 0.9910858016922054, 0.9807503242335909, 0.9807503242335909, 0.9807503242335909, 0.4666537115115241, 0.4666537115115241, 0.4666537115115241, 0.516842774707538, 0.516842774707538, 0.516842774707538, 0.6195676163142643, 0.6195676163142643, 0.6195676163142643, 0.2154218335074901, 0.2154218335074901, 0.2154218335074901, 0.1619247116147886, 0.1619247116147886, 0.1619247116147886, 0.15157647510467964, 0.15157647510467964, 0.15157647510467964, 0.31748085239062007, 0.31748085239062007, 0.31748085239062007, 0.13401138002409352, 0.13401138002409352, 0.13401138002409352, 0.29944259012712604, 0.29944259012712604, 0.29944259012712604, 0.2825477584470877, 0.2825477584470877, 0.2825477584470877, 0.3046946923040186, 0.3046946923040186, 0.3046946923040186, 0.3195619743787639, 0.3195619743787639, 0.3195619743787639, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07792283166290037, 0.07792283166290037, 0.07792283166290037, 0.017999656972557898, 0.017999656972557898, 0.017999656972557898, 0.09786724842567507, 0.09786724842567507, 0.09786724842567507, 0.1302934768647046, 0.1302934768647046, 0.1302934768647046, 0.07960501630821704, 0.07960501630821704, 0.07960501630821704, 0.4088746640659646, 0.4088746640659646, 0.4088746640659646, 0.19327104705488107, 0.19327104705488107, 0.19327104705488107, 0.0384732418360858, 0.0384732418360858, 0.0384732418360858, 0.0562710006200936, 0.0562710006200936, 0.0562710006200936, 0.4603317238295205, 0.4603317238295205, 0.4603317238295205, 0.48821666038932165, 0.48821666038932165, 0.48821666038932165, 0.43658838934376765, 0.43658838934376765, 0.43658838934376765, 0.11381529931171042, 0.11381529931171042, 0.11381529931171042, 0.1491265289995385, 0.1491265289995385, 0.1491265289995385, 0.20826260941728347, 0.20826260941728347, 0.20826260941728347, 0.15112704188227688, 0.15112704188227688, 0.15112704188227688, 0.17037069659318693, 0.17037069659318693, 0.17037069659318693, 0.13563785712615994, 0.13563785712615994, 0.13563785712615994, 0.2719549062529766, 0.2719549062529766, 0.2719549062529766, 0.32710030089410647, 0.32710030089410647, 0.32710030089410647, 0.28240836592860874, 0.28240836592860874, 0.28240836592860874, 0.23625205827409967, 0.23625205827409967, 0.23625205827409967, 0.18805175906694305, 0.18805175906694305, 0.18805175906694305, 0.13851600838896427, 0.13851600838896427, 0.13851600838896427, 0.19179264573299293, 0.19179264573299293, 0.19179264573299293, 0.2140465410634762, 0.2140465410634762, 0.2140465410634762, 0.1931028941632651, 0.1931028941632651, 0.1931028941632651, 0.17773761940320942, 0.17773761940320942, 0.17773761940320942, 0.2029402951010434, 0.2029402951010434, 0.2029402951010434, 0.2500598826403835, 0.2500598826403835, 0.2500598826403835, 0.8324395072043497, 0.8324395072043497, 0.8324395072043497, 0.15762947677526173, 0.15762947677526173, 0.15762947677526173, 0.2775711315192543, 0.2775711315192543, 0.2775711315192543, 0.1688333093608929, 0.1688333093608929, 0.1688333093608929, 0.21237591186459637, 0.21237591186459637, 0.21237591186459637, 0.18471321252007733, 0.18471321252007733, 0.18471321252007733, 0.190613053779211, 0.190613053779211, 0.190613053779211, 0.20939674059993618, 0.20939674059993618, 0.20939674059993618, 0.1911249243583798, 0.1911249243583798, 0.1911249243583798, 0.08500915010116772, 0.08500915010116772, 0.08500915010116772, 0.07720382041174922, 0.07720382041174922, 0.07720382041174922, 0.08879942606581659, 0.08879942606581659, 0.08879942606581659]}, "mutation_prompt": null}
{"id": "2429e941-e300-43bc-87b2-2c2c227c0c96", "solution": "import numpy as np\n\nclass AdvancedAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.initial_de_f = 0.9  # Enhanced Differential weight\n        self.initial_de_cr = 0.9  # Enhanced Crossover probability\n        self.initial_pso_w = 0.6  # Enhanced Inertia weight\n        self.pso_c1 = 1.5  # Enhanced Cognitive coefficient\n        self.pso_c2 = 1.5  # Enhanced Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Incorporate increased diversity at end stages\n            if self.eval_count >= self.max_evaluations * 0.80:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdvancedAdaptiveDEPSO", "description": "AdvancedAdaptiveDEPSO: Enhances the synergy of Differential Evolution and Particle Swarm Optimization using adaptive parameter tuning, diversity enforcement, and convergence sensitivity to optimize diverse search landscapes.", "configspace": "", "generation": 43, "fitness": 0.26076154507625626, "feedback": "The algorithm AdvancedAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.24.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.7817953208023103, 0.7817953208023103, 0.7817953208023103, 0.8067431432850332, 0.8067431432850332, 0.8067431432850332, 0.834600660723751, 0.834600660723751, 0.834600660723751, 0.6850014777479794, 0.6850014777479794, 0.6850014777479794, 0.031467414763316826, 0.031467414763316826, 0.031467414763316826, 0.05692829418449019, 0.05692829418449019, 0.05692829418449019, 0.11037443098136268, 0.11037443098136268, 0.11037443098136268, 0.13234294062814222, 0.13234294062814222, 0.13234294062814222, 0.15529746001249878, 0.15529746001249878, 0.15529746001249878, 0.12588572523413188, 0.12588572523413188, 0.12588572523413188, 0.10929192427892709, 0.10929192427892709, 0.10929192427892709, 0.12900349482048734, 0.12900349482048734, 0.12900349482048734, 0.989900250725693, 0.989900250725693, 0.989900250725693, 0.9862380911317353, 0.9862380911317353, 0.9862380911317353, 0.9890659011108967, 0.9890659011108967, 0.9890659011108967, 0.38461146696379267, 0.38461146696379267, 0.38461146696379267, 0.2526817073236153, 0.2526817073236153, 0.2526817073236153, 0.2721237544685383, 0.2721237544685383, 0.2721237544685383, 0.21635131256892648, 0.21635131256892648, 0.21635131256892648, 0.2671966764691207, 0.2671966764691207, 0.2671966764691207, 0.19422806308217744, 0.19422806308217744, 0.19422806308217744, 0.28854573178620835, 0.28854573178620835, 0.28854573178620835, 0.21815022681506724, 0.21815022681506724, 0.21815022681506724, 0.22018458383128325, 0.22018458383128325, 0.22018458383128325, 0.24235449551437527, 0.24235449551437527, 0.24235449551437527, 0.2296814189442734, 0.2296814189442734, 0.2296814189442734, 0.2070422530228061, 0.2070422530228061, 0.2070422530228061, 0.03839125925401132, 0.03839125925401132, 0.03839125925401132, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003156056109919647, 0.003156056109919647, 0.003156056109919647, 0.04600260899482378, 0.04600260899482378, 0.04600260899482378, 0.04571875152082139, 0.04571875152082139, 0.04571875152082139, 0.06453347666675979, 0.06453347666675979, 0.06453347666675979, 0.11478306908446179, 0.11478306908446179, 0.11478306908446179, 0.10679001636907615, 0.10679001636907615, 0.10679001636907615, 0.08771881930830949, 0.08771881930830949, 0.08771881930830949, 0.16302669542064485, 0.16302669542064485, 0.16302669542064485, 0.08000508939880802, 0.08000508939880802, 0.08000508939880802, 0.09784161762874466, 0.09784161762874466, 0.09784161762874466, 0.4853021490323618, 0.4853021490323618, 0.4853021490323618, 0.5265761133265174, 0.5265761133265174, 0.5265761133265174, 0.5469394217191663, 0.5469394217191663, 0.5469394217191663, 0.09889497157855132, 0.09889497157855132, 0.09889497157855132, 0.10522951388282276, 0.10522951388282276, 0.10522951388282276, 0.12043727525627312, 0.12043727525627312, 0.12043727525627312, 0.15058040607836487, 0.15058040607836487, 0.15058040607836487, 0.14506043344537212, 0.14506043344537212, 0.14506043344537212, 0.15971842806632852, 0.15971842806632852, 0.15971842806632852, 0.3568419932301736, 0.3568419932301736, 0.3568419932301736, 0.4440274902697483, 0.4440274902697483, 0.4440274902697483, 0.36377251087790696, 0.36377251087790696, 0.36377251087790696, 0.23921611153403932, 0.23921611153403932, 0.23921611153403932, 0.18518582453579335, 0.18518582453579335, 0.18518582453579335, 0.35569770100943454, 0.35569770100943454, 0.35569770100943454, 0.20562166279564087, 0.20562166279564087, 0.20562166279564087, 0.18047475127254897, 0.18047475127254897, 0.18047475127254897, 0.1828470202668877, 0.1828470202668877, 0.1828470202668877, 0.19736530626396454, 0.19736530626396454, 0.19736530626396454, 0.23659326522113755, 0.23659326522113755, 0.23659326522113755, 0.19645249963846056, 0.19645249963846056, 0.19645249963846056, 0.8655281708906392, 0.8655281708906392, 0.8655281708906392, 0.16576449256841608, 0.16576449256841608, 0.16576449256841608, 0.16625096682347051, 0.16625096682347051, 0.16625096682347051, 0.16942507184835065, 0.16942507184835065, 0.16942507184835065, 0.20658991118580894, 0.20658991118580894, 0.20658991118580894, 0.15549285987416228, 0.15549285987416228, 0.15549285987416228, 0.18529579849070388, 0.18529579849070388, 0.18529579849070388, 0.18279077551990897, 0.18279077551990897, 0.18279077551990897, 0.18983915449073674, 0.18983915449073674, 0.18983915449073674, 0.07455464870985273, 0.07455464870985273, 0.07455464870985273, 0.07555464922249355, 0.07555464922249355, 0.07555464922249355, 0.08975421558709207, 0.08975421558709207, 0.08975421558709207]}, "mutation_prompt": null}
{"id": "a697be12-3010-40e7-9edb-a0c9d245aa8f", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.1  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.3  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm blending Differential Evolution and Particle Swarm Optimization with dynamic parameter adjustment and stochastic diversification to efficiently balance exploration and exploitation.", "configspace": "", "generation": 44, "fitness": 0.3368743675571859, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.30.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8863482209198768, 0.8863482209198768, 0.8863482209198768, 0.8992262638330237, 0.8992262638330237, 0.8992262638330237, 0.8864903883110682, 0.8864903883110682, 0.8864903883110682, 0.1593606255968787, 0.1593606255968787, 0.1593606255968787, 0.7989692114731219, 0.7989692114731219, 0.7989692114731219, 0.7669481042720367, 0.7669481042720367, 0.7669481042720367, 0.12925157493954553, 0.12925157493954553, 0.12925157493954553, 0.10530665661299676, 0.10530665661299676, 0.10530665661299676, 0.12428945993899831, 0.12428945993899831, 0.12428945993899831, 0.10485551878048571, 0.10485551878048571, 0.10485551878048571, 0.1363441340266205, 0.1363441340266205, 0.1363441340266205, 0.11546052021339981, 0.11546052021339981, 0.11546052021339981, 0.9879549278511147, 0.9879549278511147, 0.9879549278511147, 0.9881844516187768, 0.9881844516187768, 0.9881844516187768, 0.9851232339589875, 0.9851232339589875, 0.9851232339589875, 0.7125091509935135, 0.7125091509935135, 0.7125091509935135, 0.6549315649077521, 0.6549315649077521, 0.6549315649077521, 0.5933685538170373, 0.5933685538170373, 0.5933685538170373, 0.137546526165358, 0.137546526165358, 0.137546526165358, 0.8682241107991553, 0.8682241107991553, 0.8682241107991553, 0.7149271542303387, 0.7149271542303387, 0.7149271542303387, 0.3040362932329226, 0.3040362932329226, 0.3040362932329226, 0.3055995722477648, 0.3055995722477648, 0.3055995722477648, 0.134172558987802, 0.134172558987802, 0.134172558987802, 0.28143145222211174, 0.28143145222211174, 0.28143145222211174, 0.34574942284991417, 0.34574942284991417, 0.34574942284991417, 0.1316608846797479, 0.1316608846797479, 0.1316608846797479, 0.004590854118779131, 0.004590854118779131, 0.004590854118779131, 0.01529542274935125, 0.01529542274935125, 0.01529542274935125, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03806838185143002, 0.03806838185143002, 0.03806838185143002, 0.021950309266890455, 0.021950309266890455, 0.021950309266890455, 0.08804817894607897, 0.08804817894607897, 0.08804817894607897, 0.0367316594382181, 0.0367316594382181, 0.0367316594382181, 0.11343936909600938, 0.11343936909600938, 0.11343936909600938, 0.09682269206723981, 0.09682269206723981, 0.09682269206723981, 0.376476553248715, 0.376476553248715, 0.376476553248715, 0.1696453686077215, 0.1696453686077215, 0.1696453686077215, 0.09807228766411813, 0.09807228766411813, 0.09807228766411813, 0.5801056390115993, 0.5801056390115993, 0.5801056390115993, 0.598180214521499, 0.598180214521499, 0.598180214521499, 0.6149511433616489, 0.6149511433616489, 0.6149511433616489, 0.11143442298633632, 0.11143442298633632, 0.11143442298633632, 0.11522950868030835, 0.11522950868030835, 0.11522950868030835, 0.08959506541182694, 0.08959506541182694, 0.08959506541182694, 0.17709947157503414, 0.17709947157503414, 0.17709947157503414, 0.13151967882920412, 0.13151967882920412, 0.13151967882920412, 0.34412132000626705, 0.34412132000626705, 0.34412132000626705, 0.48422522888443076, 0.48422522888443076, 0.48422522888443076, 0.27599299975993075, 0.27599299975993075, 0.27599299975993075, 0.5061662706852947, 0.5061662706852947, 0.5061662706852947, 0.2581560842896552, 0.2581560842896552, 0.2581560842896552, 0.28538126800795927, 0.28538126800795927, 0.28538126800795927, 0.1405107249396258, 0.1405107249396258, 0.1405107249396258, 0.20278870623331735, 0.20278870623331735, 0.20278870623331735, 0.21968706061185406, 0.21968706061185406, 0.21968706061185406, 0.20001186399290505, 0.20001186399290505, 0.20001186399290505, 0.20347149510837026, 0.20347149510837026, 0.20347149510837026, 0.2410869825469878, 0.2410869825469878, 0.2410869825469878, 0.2445210114412737, 0.2445210114412737, 0.2445210114412737, 0.9307110059373239, 0.9307110059373239, 0.9307110059373239, 0.15952879140493426, 0.15952879140493426, 0.15952879140493426, 0.8539460549389186, 0.8539460549389186, 0.8539460549389186, 0.1691170059266075, 0.1691170059266075, 0.1691170059266075, 0.21071728574562298, 0.21071728574562298, 0.21071728574562298, 0.7747330163486879, 0.7747330163486879, 0.7747330163486879, 0.18849059718933003, 0.18849059718933003, 0.18849059718933003, 0.19048298707221567, 0.19048298707221567, 0.19048298707221567, 0.18324204254456544, 0.18324204254456544, 0.18324204254456544, 0.08234190806116914, 0.08234190806116914, 0.08234190806116914, 0.0751721914539808, 0.0751721914539808, 0.0751721914539808, 0.09472380207379794, 0.09472380207379794, 0.09472380207379794]}, "mutation_prompt": null}
{"id": "b5fe9583-a930-40df-a724-b7e44f309493", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.3  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "RefinedAdaptiveHybridDEPSO", "description": "A refined adaptive hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with dynamic parameter tuning and enhanced diversity strategies for efficient exploration and exploitation.", "configspace": "", "generation": 45, "fitness": 0.29705324956611967, "feedback": "The algorithm RefinedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8393879534243978, 0.8393879534243978, 0.8393879534243978, 0.8452275030442704, 0.8452275030442704, 0.8452275030442704, 0.8345984077029165, 0.8345984077029165, 0.8345984077029165, 0.6715574489935391, 0.6715574489935391, 0.6715574489935391, 0.644072627237483, 0.644072627237483, 0.644072627237483, 0.16614649362781098, 0.16614649362781098, 0.16614649362781098, 0.1614935561469838, 0.1614935561469838, 0.1614935561469838, 0.15644984097184556, 0.15644984097184556, 0.15644984097184556, 0.1249738982857056, 0.1249738982857056, 0.1249738982857056, 0.10130850961044258, 0.10130850961044258, 0.10130850961044258, 0.13631819997269723, 0.13631819997269723, 0.13631819997269723, 0.10013645971868901, 0.10013645971868901, 0.10013645971868901, 0.9834697511550284, 0.9834697511550284, 0.9834697511550284, 0.9871956536440357, 0.9871956536440357, 0.9871956536440357, 0.988061763900247, 0.988061763900247, 0.988061763900247, 0.4767323234975577, 0.4767323234975577, 0.4767323234975577, 0.31348736923089116, 0.31348736923089116, 0.31348736923089116, 0.44789663140808245, 0.44789663140808245, 0.44789663140808245, 0.6677799548207066, 0.6677799548207066, 0.6677799548207066, 0.20617601974823652, 0.20617601974823652, 0.20617601974823652, 0.7082794344859569, 0.7082794344859569, 0.7082794344859569, 0.24524584683109119, 0.24524584683109119, 0.24524584683109119, 0.25166060203136487, 0.25166060203136487, 0.25166060203136487, 0.22982904023323258, 0.22982904023323258, 0.22982904023323258, 0.21072041266312824, 0.21072041266312824, 0.21072041266312824, 0.25632431318899074, 0.25632431318899074, 0.25632431318899074, 0.12678812602660217, 0.12678812602660217, 0.12678812602660217, 0.05535079667145326, 0.05535079667145326, 0.05535079667145326, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03236256060696685, 0.03236256060696685, 0.03236256060696685, 0.13840498506453536, 0.13840498506453536, 0.13840498506453536, 0.060889584886906545, 0.060889584886906545, 0.060889584886906545, 0.14808263656219045, 0.14808263656219045, 0.14808263656219045, 0.19929477251038363, 0.19929477251038363, 0.19929477251038363, 0.09805947330773268, 0.09805947330773268, 0.09805947330773268, 0.14351410472486092, 0.14351410472486092, 0.14351410472486092, 0.037589462698120024, 0.037589462698120024, 0.037589462698120024, 0.15512969546979205, 0.15512969546979205, 0.15512969546979205, 0.5442283304118294, 0.5442283304118294, 0.5442283304118294, 0.586017012671834, 0.586017012671834, 0.586017012671834, 0.574345493949051, 0.574345493949051, 0.574345493949051, 0.06111171077012734, 0.06111171077012734, 0.06111171077012734, 0.12601051525690832, 0.12601051525690832, 0.12601051525690832, 0.10620930127935413, 0.10620930127935413, 0.10620930127935413, 0.16054563114129428, 0.16054563114129428, 0.16054563114129428, 0.2104149866178836, 0.2104149866178836, 0.2104149866178836, 0.19054647912405653, 0.19054647912405653, 0.19054647912405653, 0.39285473986095776, 0.39285473986095776, 0.39285473986095776, 0.21133313919891084, 0.21133313919891084, 0.21133313919891084, 0.5279748252223115, 0.5279748252223115, 0.5279748252223115, 0.2083338235854223, 0.2083338235854223, 0.2083338235854223, 0.15760236602509103, 0.15760236602509103, 0.15760236602509103, 0.1453782554395553, 0.1453782554395553, 0.1453782554395553, 0.20286657273508446, 0.20286657273508446, 0.20286657273508446, 0.17745681807551572, 0.17745681807551572, 0.17745681807551572, 0.19177279924684965, 0.19177279924684965, 0.19177279924684965, 0.18479748389202955, 0.18479748389202955, 0.18479748389202955, 0.21542533766012362, 0.21542533766012362, 0.21542533766012362, 0.19834509609017292, 0.19834509609017292, 0.19834509609017292, 0.8837781277086372, 0.8837781277086372, 0.8837781277086372, 0.1672373928016334, 0.1672373928016334, 0.1672373928016334, 0.17564243514771993, 0.17564243514771993, 0.17564243514771993, 0.6010643952031915, 0.6010643952031915, 0.6010643952031915, 0.2098424948288583, 0.2098424948288583, 0.2098424948288583, 0.19823021288476472, 0.19823021288476472, 0.19823021288476472, 0.1981354143939017, 0.1981354143939017, 0.1981354143939017, 0.19108649320658222, 0.19108649320658222, 0.19108649320658222, 0.18660562240726775, 0.18660562240726775, 0.18660562240726775, 0.08748090045866697, 0.08748090045866697, 0.08748090045866697, 0.07526084851228765, 0.07526084851228765, 0.07526084851228765, 0.08970269884786852, 0.08970269884786852, 0.08970269884786852]}, "mutation_prompt": null}
{"id": "8c070335-d904-4171-ad2e-364cbc145666", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Slight increase for better exploration\n        self.initial_de_f = 0.9  # Enhanced Differential weight\n        self.initial_de_cr = 0.9  # Increased Crossover probability\n        self.initial_pso_w = 0.6  # Increased Inertia weight\n        self.pso_c1 = 1.2  # Enhanced Cognitive coefficient\n        self.pso_c2 = 1.3  # Enhanced Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Initialize velocities randomly\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio  # More aggressive reduction\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.3 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.2 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity dynamically based on evaluation progress\n            if self.eval_count >= self.max_evaluations * 0.50:\n                diversity_count = max(1, int(self.population_size * 0.15 * (1 + progress_ratio)))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An improved adaptive hybrid combining Differential Evolution and Particle Swarm Optimization with dynamic parameter adjustment and enhanced population diversity to robustly navigate complex search spaces.", "configspace": "", "generation": 46, "fitness": 0.2806899602848762, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.27.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.835207137436067, 0.835207137436067, 0.835207137436067, 0.8684654450154672, 0.8684654450154672, 0.8684654450154672, 0.8653870164913257, 0.8653870164913257, 0.8653870164913257, 0.11572933983013467, 0.11572933983013467, 0.11572933983013467, 0.11094787769860881, 0.11094787769860881, 0.11094787769860881, 0.7328482867923891, 0.7328482867923891, 0.7328482867923891, 0.17595980143682732, 0.17595980143682732, 0.17595980143682732, 0.1712733821037784, 0.1712733821037784, 0.1712733821037784, 0.14516973335372185, 0.14516973335372185, 0.14516973335372185, 0.10573075867163806, 0.10573075867163806, 0.10573075867163806, 0.10427054043162076, 0.10427054043162076, 0.10427054043162076, 0.12493233515308311, 0.12493233515308311, 0.12493233515308311, 0.989758546549999, 0.989758546549999, 0.989758546549999, 0.9786665192997955, 0.9786665192997955, 0.9786665192997955, 0.9858657404441589, 0.9858657404441589, 0.9858657404441589, 0.5088455327401855, 0.5088455327401855, 0.5088455327401855, 0.19112807354091743, 0.19112807354091743, 0.19112807354091743, 0.5430318290395449, 0.5430318290395449, 0.5430318290395449, 0.6912091927208246, 0.6912091927208246, 0.6912091927208246, 0.161305906780303, 0.161305906780303, 0.161305906780303, 0.2333827152075082, 0.2333827152075082, 0.2333827152075082, 0.12944218355793435, 0.12944218355793435, 0.12944218355793435, 0.12646791495622456, 0.12646791495622456, 0.12646791495622456, 0.25837705781660114, 0.25837705781660114, 0.25837705781660114, 0.11410395608774782, 0.11410395608774782, 0.11410395608774782, 0.2895347979533722, 0.2895347979533722, 0.2895347979533722, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08328859362490926, 0.08328859362490926, 0.08328859362490926, 0.05298981219978649, 0.05298981219978649, 0.05298981219978649, 0.08904592217548801, 0.08904592217548801, 0.08904592217548801, 0.04121078931486721, 0.04121078931486721, 0.04121078931486721, 0.1426894040626958, 0.1426894040626958, 0.1426894040626958, 0.07147729087971622, 0.07147729087971622, 0.07147729087971622, 0.16922887395523611, 0.16922887395523611, 0.16922887395523611, 0.03870260784225643, 0.03870260784225643, 0.03870260784225643, 0.08405239848572199, 0.08405239848572199, 0.08405239848572199, 0.5685013777353041, 0.5685013777353041, 0.5685013777353041, 0.5482565076713739, 0.5482565076713739, 0.5482565076713739, 0.5513246261554287, 0.5513246261554287, 0.5513246261554287, 0.11772791044981545, 0.11772791044981545, 0.11772791044981545, 0.13090763397715222, 0.13090763397715222, 0.13090763397715222, 0.1028364627516366, 0.1028364627516366, 0.1028364627516366, 0.15701981795628872, 0.15701981795628872, 0.15701981795628872, 0.21544281815489208, 0.21544281815489208, 0.21544281815489208, 0.14345061775585977, 0.14345061775585977, 0.14345061775585977, 0.3776100951186401, 0.3776100951186401, 0.3776100951186401, 0.429781460392622, 0.429781460392622, 0.429781460392622, 0.5060513631819209, 0.5060513631819209, 0.5060513631819209, 0.3574264464200474, 0.3574264464200474, 0.3574264464200474, 0.19089422034475778, 0.19089422034475778, 0.19089422034475778, 0.12735994802223505, 0.12735994802223505, 0.12735994802223505, 0.20668825381756228, 0.20668825381756228, 0.20668825381756228, 0.1886070551511656, 0.1886070551511656, 0.1886070551511656, 0.20024451189677583, 0.20024451189677583, 0.20024451189677583, 0.2012739520218949, 0.2012739520218949, 0.2012739520218949, 0.21807374792104772, 0.21807374792104772, 0.21807374792104772, 0.19129556032685424, 0.19129556032685424, 0.19129556032685424, 0.9296720649224655, 0.9296720649224655, 0.9296720649224655, 0.16581993868316136, 0.16581993868316136, 0.16581993868316136, 0.1918963604663757, 0.1918963604663757, 0.1918963604663757, 0.1709301019012328, 0.1709301019012328, 0.1709301019012328, 0.7309111276988691, 0.7309111276988691, 0.7309111276988691, 0.15503061674215457, 0.15503061674215457, 0.15503061674215457, 0.19161142505241224, 0.19161142505241224, 0.19161142505241224, 0.18339026989549878, 0.18339026989549878, 0.18339026989549878, 0.19440953186965237, 0.19440953186965237, 0.19440953186965237, 0.08145234293111081, 0.08145234293111081, 0.08145234293111081, 0.07368293211847254, 0.07368293211847254, 0.07368293211847254, 0.07996872735594984, 0.07996872735594984, 0.07996872735594984]}, "mutation_prompt": null}
{"id": "7700b9c0-e550-4c30-8a81-6f36db3aaf9f", "solution": "import numpy as np\n\nclass SynergisticDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Adjusted Differential weight\n        self.initial_de_cr = 0.8  # Adjusted Crossover probability\n        self.initial_pso_w = 0.4  # Adjusted Inertia weight\n        self.pso_c1 = 1.3  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.randn(self.population_size, self.dim) * 0.5\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "SynergisticDEPSO", "description": "Synergistic Differential Evolution and Particle Swarm Optimization with adaptive parameter tuning and dynamic diversity enhancement for robust global search.", "configspace": "", "generation": 47, "fitness": 0.3027063703079537, "feedback": "The algorithm SynergisticDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.29.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9293189057423532, 0.9293189057423532, 0.9293189057423532, 0.932721454462653, 0.932721454462653, 0.932721454462653, 0.9180744118132234, 0.9180744118132234, 0.9180744118132234, 0.14172952734726318, 0.14172952734726318, 0.14172952734726318, 0.8489457685127342, 0.8489457685127342, 0.8489457685127342, 0.055425432477998804, 0.055425432477998804, 0.055425432477998804, 0.15129118450426327, 0.15129118450426327, 0.15129118450426327, 0.14330582372680745, 0.14330582372680745, 0.14330582372680745, 0.13907355043083225, 0.13907355043083225, 0.13907355043083225, 0.12875540622689585, 0.12875540622689585, 0.12875540622689585, 0.09513132018090642, 0.09513132018090642, 0.09513132018090642, 0.08348299495572242, 0.08348299495572242, 0.08348299495572242, 0.9891380467649256, 0.9891380467649256, 0.9891380467649256, 0.9887503741339709, 0.9887503741339709, 0.9887503741339709, 0.987688365049813, 0.987688365049813, 0.987688365049813, 0.7860176624356607, 0.7860176624356607, 0.7860176624356607, 0.774444154728797, 0.774444154728797, 0.774444154728797, 0.7734322044940236, 0.7734322044940236, 0.7734322044940236, 0.14000405419388373, 0.14000405419388373, 0.14000405419388373, 0.22154387937064735, 0.22154387937064735, 0.22154387937064735, 0.8762652115551254, 0.8762652115551254, 0.8762652115551254, 0.2903141204696602, 0.2903141204696602, 0.2903141204696602, 0.3005659570891508, 0.3005659570891508, 0.3005659570891508, 0.303898913216083, 0.303898913216083, 0.303898913216083, 0.13421805514797835, 0.13421805514797835, 0.13421805514797835, 0.13617225046888193, 0.13617225046888193, 0.13617225046888193, 0.15536265750071565, 0.15536265750071565, 0.15536265750071565, 0.007854173751039029, 0.007854173751039029, 0.007854173751039029, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03565648865111193, 0.03565648865111193, 0.03565648865111193, 0.1284128086249593, 0.1284128086249593, 0.1284128086249593, 0.08347103051416893, 0.08347103051416893, 0.08347103051416893, 0.17108352027339102, 0.17108352027339102, 0.17108352027339102, 0.09295621389747522, 0.09295621389747522, 0.09295621389747522, 0.10117139121401031, 0.10117139121401031, 0.10117139121401031, 0.10674685354836388, 0.10674685354836388, 0.10674685354836388, 0.11248451801281278, 0.11248451801281278, 0.11248451801281278, 0.10297408874618574, 0.10297408874618574, 0.10297408874618574, 0.3247260644976101, 0.3247260644976101, 0.3247260644976101, 0.5656021905559192, 0.5656021905559192, 0.5656021905559192, 0.6100550377692437, 0.6100550377692437, 0.6100550377692437, 0.6275113312364466, 0.6275113312364466, 0.6275113312364466, 0.1377268750513565, 0.1377268750513565, 0.1377268750513565, 0.07806521293051627, 0.07806521293051627, 0.07806521293051627, 0.11278894822843866, 0.11278894822843866, 0.11278894822843866, 0.14745579325824187, 0.14745579325824187, 0.14745579325824187, 0.18841908280327901, 0.18841908280327901, 0.18841908280327901, 0.2026670616943982, 0.2026670616943982, 0.2026670616943982, 0.27331615681477806, 0.27331615681477806, 0.27331615681477806, 0.2749338383700527, 0.2749338383700527, 0.2749338383700527, 0.17642765731724463, 0.17642765731724463, 0.17642765731724463, 0.1839876801400494, 0.1839876801400494, 0.1839876801400494, 0.3078671084129734, 0.3078671084129734, 0.3078671084129734, 0.404311128594402, 0.404311128594402, 0.404311128594402, 0.19543892595141954, 0.19543892595141954, 0.19543892595141954, 0.20434764082402213, 0.20434764082402213, 0.20434764082402213, 0.20880005086559106, 0.20880005086559106, 0.20880005086559106, 0.20685343559089975, 0.20685343559089975, 0.20685343559089975, 0.21331947838089704, 0.21331947838089704, 0.21331947838089704, 0.19941199273691357, 0.19941199273691357, 0.19941199273691357, 0.9504983762368516, 0.9504983762368516, 0.9504983762368516, 0.15845974791134176, 0.15845974791134176, 0.15845974791134176, 0.14038669517326485, 0.14038669517326485, 0.14038669517326485, 0.1571371337096389, 0.1571371337096389, 0.1571371337096389, 0.16951523131549473, 0.16951523131549473, 0.16951523131549473, 0.1689456079601921, 0.1689456079601921, 0.1689456079601921, 0.1862966443931081, 0.1862966443931081, 0.1862966443931081, 0.18541286143494085, 0.18541286143494085, 0.18541286143494085, 0.1918755651208226, 0.1918755651208226, 0.1918755651208226, 0.07992733730435808, 0.07992733730435808, 0.07992733730435808, 0.09961484381010577, 0.09961484381010577, 0.09961484381010577, 0.09477315154336519, 0.09477315154336519, 0.09477315154336519]}, "mutation_prompt": null}
{"id": "5cc30984-79fb-44a5-ac29-f83602c93085", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSOEnhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 24  # Enhanced population size\n        self.initial_de_f = 0.9  # Enhanced Differential weight\n        self.initial_de_cr = 0.9  # Enhanced Crossover probability\n        self.initial_pso_w = 0.6  # Enhanced Inertia weight\n        self.pso_c1 = 1.5  # Enhanced Cognitive coefficient\n        self.pso_c2 = 1.5  # Enhanced Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.65 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSOEnhanced", "description": "A hybrid evolutionary algorithm with dynamic parameter adaptation and stochastic individual enhancements to balance exploration and exploitation across diverse problem landscapes.", "configspace": "", "generation": 48, "fitness": 0.270551193056862, "feedback": "The algorithm AdaptiveHybridDEPSOEnhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8167234485598539, 0.8167234485598539, 0.8167234485598539, 0.8296149300581602, 0.8296149300581602, 0.8296149300581602, 0.8313775933706173, 0.8313775933706173, 0.8313775933706173, 0.675001332477285, 0.675001332477285, 0.675001332477285, 0.6675744145181433, 0.6675744145181433, 0.6675744145181433, 0.6894441029544494, 0.6894441029544494, 0.6894441029544494, 0.13602353852644078, 0.13602353852644078, 0.13602353852644078, 0.13072005409892717, 0.13072005409892717, 0.13072005409892717, 0.13005289868157632, 0.13005289868157632, 0.13005289868157632, 0.14573414443151744, 0.14573414443151744, 0.14573414443151744, 0.09390353792182982, 0.09390353792182982, 0.09390353792182982, 0.10923682249074551, 0.10923682249074551, 0.10923682249074551, 0.9874159034555772, 0.9874159034555772, 0.9874159034555772, 0.9852694684312703, 0.9852694684312703, 0.9852694684312703, 0.985295305981131, 0.985295305981131, 0.985295305981131, 0.2859002714697265, 0.2859002714697265, 0.2859002714697265, 0.27916996807979433, 0.27916996807979433, 0.27916996807979433, 0.2764785764429871, 0.2764785764429871, 0.2764785764429871, 0.4669304724095841, 0.4669304724095841, 0.4669304724095841, 0.16045728622852273, 0.16045728622852273, 0.16045728622852273, 0.4511095161871159, 0.4511095161871159, 0.4511095161871159, 0.12577504496136882, 0.12577504496136882, 0.12577504496136882, 0.10436707581539573, 0.10436707581539573, 0.10436707581539573, 0.20371520990747394, 0.20371520990747394, 0.20371520990747394, 0.05020483533963993, 0.05020483533963993, 0.05020483533963993, 0.22844101253563054, 0.22844101253563054, 0.22844101253563054, 0.12482420126301419, 0.12482420126301419, 0.12482420126301419, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04116067788141786, 0.04116067788141786, 0.04116067788141786, 0.05350260424355091, 0.05350260424355091, 0.05350260424355091, 0.03821669472643008, 0.03821669472643008, 0.03821669472643008, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0814859015667273, 0.0814859015667273, 0.0814859015667273, 0.0965364060980024, 0.0965364060980024, 0.0965364060980024, 0.04263475988751941, 0.04263475988751941, 0.04263475988751941, 0.2093549338603904, 0.2093549338603904, 0.2093549338603904, 0.054772235867755814, 0.054772235867755814, 0.054772235867755814, 0.49634071897338417, 0.49634071897338417, 0.49634071897338417, 0.5453610603021348, 0.5453610603021348, 0.5453610603021348, 0.562472094395884, 0.562472094395884, 0.562472094395884, 0.09064523857083351, 0.09064523857083351, 0.09064523857083351, 0.12779682451368757, 0.12779682451368757, 0.12779682451368757, 0.09489197867196875, 0.09489197867196875, 0.09489197867196875, 0.14047063989371833, 0.14047063989371833, 0.14047063989371833, 0.1949719537773743, 0.1949719537773743, 0.1949719537773743, 0.18311253717220144, 0.18311253717220144, 0.18311253717220144, 0.35543756426586504, 0.35543756426586504, 0.35543756426586504, 0.24650297520258913, 0.24650297520258913, 0.24650297520258913, 0.4267899304068581, 0.4267899304068581, 0.4267899304068581, 0.24666201951334765, 0.24666201951334765, 0.24666201951334765, 0.2662841382679957, 0.2662841382679957, 0.2662841382679957, 0.13881497779415664, 0.13881497779415664, 0.13881497779415664, 0.186027276525218, 0.186027276525218, 0.186027276525218, 0.2344450803773408, 0.2344450803773408, 0.2344450803773408, 0.17436607949186278, 0.17436607949186278, 0.17436607949186278, 0.1832735716578482, 0.1832735716578482, 0.1832735716578482, 0.22337226786747943, 0.22337226786747943, 0.22337226786747943, 0.20786181902573386, 0.20786181902573386, 0.20786181902573386, 0.829516576258755, 0.829516576258755, 0.829516576258755, 0.16593369560574478, 0.16593369560574478, 0.16593369560574478, 0.1542660317887048, 0.1542660317887048, 0.1542660317887048, 0.2754427482677222, 0.2754427482677222, 0.2754427482677222, 0.21022389038414324, 0.21022389038414324, 0.21022389038414324, 0.1296707754117712, 0.1296707754117712, 0.1296707754117712, 0.18518991435493193, 0.18518991435493193, 0.18518991435493193, 0.19561209772443855, 0.19561209772443855, 0.19561209772443855, 0.19654149790854858, 0.19654149790854858, 0.19654149790854858, 0.08130628482782143, 0.08130628482782143, 0.08130628482782143, 0.06982564814354753, 0.06982564814354753, 0.06982564814354753, 0.0714308120208792, 0.0714308120208792, 0.0714308120208792]}, "mutation_prompt": null}
{"id": "7e0490cd-69f7-4e34-a449-05208dd859c4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size\n        self.initial_de_f = 0.9  # Slightly increased Differential weight\n        self.initial_de_cr = 0.8  # Slightly adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Increased Inertia weight\n        self.pso_c1 = 1.5  # Increased Cognitive coefficient\n        self.pso_c2 = 1.3  # Increased Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adaptive DE and PSO parameters based on evaluations\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Promote diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedAdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm enhancing DE and PSO with adaptive parameter tuning and diversity promotion to achieve robust optimization performance across varying search spaces.", "configspace": "", "generation": 49, "fitness": 0.30574382810811424, "feedback": "The algorithm EnhancedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8072584034536499, 0.8072584034536499, 0.8072584034536499, 0.8035006692141525, 0.8035006692141525, 0.8035006692141525, 0.8263886244542604, 0.8263886244542604, 0.8263886244542604, 0.6925012282755536, 0.6925012282755536, 0.6925012282755536, 0.6138864607887438, 0.6138864607887438, 0.6138864607887438, 0.6150423958177205, 0.6150423958177205, 0.6150423958177205, 0.13273057199030214, 0.13273057199030214, 0.13273057199030214, 0.13590226133191552, 0.13590226133191552, 0.13590226133191552, 0.15740978449105292, 0.15740978449105292, 0.15740978449105292, 0.12574261707745027, 0.12574261707745027, 0.12574261707745027, 0.10799457864962736, 0.10799457864962736, 0.10799457864962736, 0.11823837317377095, 0.11823837317377095, 0.11823837317377095, 0.9828310107096554, 0.9828310107096554, 0.9828310107096554, 0.9836638758212874, 0.9836638758212874, 0.9836638758212874, 0.9864869024971529, 0.9864869024971529, 0.9864869024971529, 0.46760086014161284, 0.46760086014161284, 0.46760086014161284, 0.45280460093874486, 0.45280460093874486, 0.45280460093874486, 0.3231178875540569, 0.3231178875540569, 0.3231178875540569, 0.5982896571937395, 0.5982896571937395, 0.5982896571937395, 0.7683002462848223, 0.7683002462848223, 0.7683002462848223, 0.5946373178958129, 0.5946373178958129, 0.5946373178958129, 0.29162294510690345, 0.29162294510690345, 0.29162294510690345, 0.1278459780298501, 0.1278459780298501, 0.1278459780298501, 0.23061524449047788, 0.23061524449047788, 0.23061524449047788, 0.12694247305730044, 0.12694247305730044, 0.12694247305730044, 0.25005240968754094, 0.25005240968754094, 0.25005240968754094, 0.24285719390139515, 0.24285719390139515, 0.24285719390139515, 0.009845339298673594, 0.009845339298673594, 0.009845339298673594, 0.014875828131762359, 0.014875828131762359, 0.014875828131762359, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11702760803532763, 0.11702760803532763, 0.11702760803532763, 0.08408368730987492, 0.08408368730987492, 0.08408368730987492, 0.04241768193237172, 0.04241768193237172, 0.04241768193237172, 0.04162054050201436, 0.04162054050201436, 0.04162054050201436, 0.07638000008009072, 0.07638000008009072, 0.07638000008009072, 0.06815882810910756, 0.06815882810910756, 0.06815882810910756, 0.11066967081712409, 0.11066967081712409, 0.11066967081712409, 0.04133172642276928, 0.04133172642276928, 0.04133172642276928, 0.07827494309964911, 0.07827494309964911, 0.07827494309964911, 0.5217074331270748, 0.5217074331270748, 0.5217074331270748, 0.5697328625554525, 0.5697328625554525, 0.5697328625554525, 0.5422017401912422, 0.5422017401912422, 0.5422017401912422, 0.09404063966577836, 0.09404063966577836, 0.09404063966577836, 0.1419489631047025, 0.1419489631047025, 0.1419489631047025, 0.0981360408928611, 0.0981360408928611, 0.0981360408928611, 0.1269984255704003, 0.1269984255704003, 0.1269984255704003, 0.14551924400347782, 0.14551924400347782, 0.14551924400347782, 0.16879712751667209, 0.16879712751667209, 0.16879712751667209, 0.40789403016210535, 0.40789403016210535, 0.40789403016210535, 0.3642640386033261, 0.3642640386033261, 0.3642640386033261, 0.4525596688566358, 0.4525596688566358, 0.4525596688566358, 0.2841435129589225, 0.2841435129589225, 0.2841435129589225, 0.20064126139264116, 0.20064126139264116, 0.20064126139264116, 0.2675500466915338, 0.2675500466915338, 0.2675500466915338, 0.19116696261373323, 0.19116696261373323, 0.19116696261373323, 0.19598163103461208, 0.19598163103461208, 0.19598163103461208, 0.2055813272404735, 0.2055813272404735, 0.2055813272404735, 0.23194875062150244, 0.23194875062150244, 0.23194875062150244, 0.20720737383014043, 0.20720737383014043, 0.20720737383014043, 0.188954336613967, 0.188954336613967, 0.188954336613967, 0.849943097127574, 0.849943097127574, 0.849943097127574, 0.9037515222634079, 0.9037515222634079, 0.9037515222634079, 0.12244616832529376, 0.12244616832529376, 0.12244616832529376, 0.11950727439293063, 0.11950727439293063, 0.11950727439293063, 0.20968575850810434, 0.20968575850810434, 0.20968575850810434, 0.17573510955115712, 0.17573510955115712, 0.17573510955115712, 0.17742408236915763, 0.17742408236915763, 0.17742408236915763, 0.18818670680687355, 0.18818670680687355, 0.18818670680687355, 0.18683751672696003, 0.18683751672696003, 0.18683751672696003, 0.0701730586428988, 0.0701730586428988, 0.0701730586428988, 0.0797454299372965, 0.0797454299372965, 0.0797454299372965, 0.0740940561179988, 0.0740940561179988, 0.0740940561179988]}, "mutation_prompt": null}
{"id": "d441b679-b2fe-410d-8e2c-9c737027857a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.initial_de_f = 0.75  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.2  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedAdaptiveHybridDEPSO", "description": "A robust evolution strategy with enhanced adaptivity combining Differential Evolution and Particle Swarm Optimization, optimized for exploration-exploitation balance with dynamic parameter adjustment and diversity maintenance.", "configspace": "", "generation": 50, "fitness": 0.28325259437596895, "feedback": "The algorithm EnhancedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8607794180781287, 0.8607794180781287, 0.8607794180781287, 0.8536872409175158, 0.8536872409175158, 0.8536872409175158, 0.8366286411182158, 0.8366286411182158, 0.8366286411182158, 0.6152760890040747, 0.6152760890040747, 0.6152760890040747, 0.7024941757914245, 0.7024941757914245, 0.7024941757914245, 0.15628565518896176, 0.15628565518896176, 0.15628565518896176, 0.13385464243091827, 0.13385464243091827, 0.13385464243091827, 0.13658357861864256, 0.13658357861864256, 0.13658357861864256, 0.153292015289186, 0.153292015289186, 0.153292015289186, 0.11981997739089312, 0.11981997739089312, 0.11981997739089312, 0.09910192217244296, 0.09910192217244296, 0.09910192217244296, 0.12814985512298394, 0.12814985512298394, 0.12814985512298394, 0.9807882510112167, 0.9807882510112167, 0.9807882510112167, 0.9854651810705835, 0.9854651810705835, 0.9854651810705835, 0.9897429057183794, 0.9897429057183794, 0.9897429057183794, 0.5852518987008676, 0.5852518987008676, 0.5852518987008676, 0.49097303879061527, 0.49097303879061527, 0.49097303879061527, 0.5769163800024061, 0.5769163800024061, 0.5769163800024061, 0.2256714558265397, 0.2256714558265397, 0.2256714558265397, 0.1622843935998688, 0.1622843935998688, 0.1622843935998688, 0.11691110834339435, 0.11691110834339435, 0.11691110834339435, 0.2518391512601579, 0.2518391512601579, 0.2518391512601579, 0.12477867536973786, 0.12477867536973786, 0.12477867536973786, 0.258733930030528, 0.258733930030528, 0.258733930030528, 0.24772971535497024, 0.24772971535497024, 0.24772971535497024, 0.22951351115645968, 0.22951351115645968, 0.22951351115645968, 0.27572744426963625, 0.27572744426963625, 0.27572744426963625, 0.05832581971812145, 0.05832581971812145, 0.05832581971812145, 0.038161496301024944, 0.038161496301024944, 0.038161496301024944, 0.03677011173444156, 0.03677011173444156, 0.03677011173444156, 0.07568554021078544, 0.07568554021078544, 0.07568554021078544, 0.05173793865057319, 0.05173793865057319, 0.05173793865057319, 0.024106871565559462, 0.024106871565559462, 0.024106871565559462, 0.03781464859792216, 0.03781464859792216, 0.03781464859792216, 0.07396848907709208, 0.07396848907709208, 0.07396848907709208, 0.11244152560168674, 0.11244152560168674, 0.11244152560168674, 0.20619728709477936, 0.20619728709477936, 0.20619728709477936, 0.038710324678702834, 0.038710324678702834, 0.038710324678702834, 0.10621306725059843, 0.10621306725059843, 0.10621306725059843, 0.5254145336858045, 0.5254145336858045, 0.5254145336858045, 0.5583701668518316, 0.5583701668518316, 0.5583701668518316, 0.5748914802064533, 0.5748914802064533, 0.5748914802064533, 0.08495076430267035, 0.08495076430267035, 0.08495076430267035, 0.11104077366174347, 0.11104077366174347, 0.11104077366174347, 0.09217790625903799, 0.09217790625903799, 0.09217790625903799, 0.20948948491034824, 0.20948948491034824, 0.20948948491034824, 0.15403488354943728, 0.15403488354943728, 0.15403488354943728, 0.1717085972400233, 0.1717085972400233, 0.1717085972400233, 0.46436219240476595, 0.46436219240476595, 0.46436219240476595, 0.3060560579013216, 0.3060560579013216, 0.3060560579013216, 0.36324522869325837, 0.36324522869325837, 0.36324522869325837, 0.28205204640777926, 0.28205204640777926, 0.28205204640777926, 0.1895091417242346, 0.1895091417242346, 0.1895091417242346, 0.35066239987207715, 0.35066239987207715, 0.35066239987207715, 0.19566124326614331, 0.19566124326614331, 0.19566124326614331, 0.19639672894788218, 0.19639672894788218, 0.19639672894788218, 0.21065840081250675, 0.21065840081250675, 0.21065840081250675, 0.2465818339779693, 0.2465818339779693, 0.2465818339779693, 0.18773962567055802, 0.18773962567055802, 0.18773962567055802, 0.19919742386178785, 0.19919742386178785, 0.19919742386178785, 0.8588405207901224, 0.8588405207901224, 0.8588405207901224, 0.15781100820507687, 0.15781100820507687, 0.15781100820507687, 0.2055285538436452, 0.2055285538436452, 0.2055285538436452, 0.1642631510322453, 0.1642631510322453, 0.1642631510322453, 0.20751233314724526, 0.20751233314724526, 0.20751233314724526, 0.15584848334052692, 0.15584848334052692, 0.15584848334052692, 0.18711768839437826, 0.18711768839437826, 0.18711768839437826, 0.1997384504555324, 0.1997384504555324, 0.1997384504555324, 0.20170201825023082, 0.20170201825023082, 0.20170201825023082, 0.0728340357070536, 0.0728340357070536, 0.0728340357070536, 0.07815186775591543, 0.07815186775591543, 0.07815186775591543, 0.07222439783012036, 0.07222439783012036, 0.07222439783012036]}, "mutation_prompt": null}
{"id": "0e777bfc-2b2a-46f8-af90-57dd1b6a4879", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Fine-tuned Differential weight\n        self.initial_de_cr = 0.9  # Fine-tuned Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Enhanced Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adaptive adjustment of DE and PSO parameters\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Enhanced diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A metaheuristic combining Differential Evolution, Particle Swarm Optimization, and adaptive parameter tuning to efficiently handle complex optimization landscapes.", "configspace": "", "generation": 51, "fitness": 0.32226718144677485, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.30.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.910755122677766, 0.910755122677766, 0.910755122677766, 0.9126204366283667, 0.9126204366283667, 0.9126204366283667, 0.8958626855881291, 0.8958626855881291, 0.8958626855881291, 0.7502263293070104, 0.7502263293070104, 0.7502263293070104, 0.7871843465465286, 0.7871843465465286, 0.7871843465465286, 0.08569782028891315, 0.08569782028891315, 0.08569782028891315, 0.11439224774643664, 0.11439224774643664, 0.11439224774643664, 0.11637039867322296, 0.11637039867322296, 0.11637039867322296, 0.13972231395938994, 0.13972231395938994, 0.13972231395938994, 0.11162517901443858, 0.11162517901443858, 0.11162517901443858, 0.15421793635603698, 0.15421793635603698, 0.15421793635603698, 0.12022756416960712, 0.12022756416960712, 0.12022756416960712, 0.9881328611032889, 0.9881328611032889, 0.9881328611032889, 0.9906917739589836, 0.9906917739589836, 0.9906917739589836, 0.9895283966864329, 0.9895283966864329, 0.9895283966864329, 0.7076026485381011, 0.7076026485381011, 0.7076026485381011, 0.7580130754060255, 0.7580130754060255, 0.7580130754060255, 0.7554717438400168, 0.7554717438400168, 0.7554717438400168, 0.2338759922660275, 0.2338759922660275, 0.2338759922660275, 0.16229632946628203, 0.16229632946628203, 0.16229632946628203, 0.23453581236881793, 0.23453581236881793, 0.23453581236881793, 0.277822411368273, 0.277822411368273, 0.277822411368273, 0.3781624343181619, 0.3781624343181619, 0.3781624343181619, 0.12382535193748423, 0.12382535193748423, 0.12382535193748423, 0.2552260254476053, 0.2552260254476053, 0.2552260254476053, 0.28023541625429493, 0.28023541625429493, 0.28023541625429493, 0.13883849129937076, 0.13883849129937076, 0.13883849129937076, 0.0024257725934468954, 0.0024257725934468954, 0.0024257725934468954, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0038861968446674, 0.0038861968446674, 0.0038861968446674, 0.07000108794355075, 0.07000108794355075, 0.07000108794355075, 0.03594594165569165, 0.03594594165569165, 0.03594594165569165, 0.09596106932245863, 0.09596106932245863, 0.09596106932245863, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07891112569186065, 0.07891112569186065, 0.07891112569186065, 0.10694577606638866, 0.10694577606638866, 0.10694577606638866, 0.043712255231938224, 0.043712255231938224, 0.043712255231938224, 0.06250419829422194, 0.06250419829422194, 0.06250419829422194, 0.06376089716284661, 0.06376089716284661, 0.06376089716284661, 0.5654522114595331, 0.5654522114595331, 0.5654522114595331, 0.732143949502094, 0.732143949502094, 0.732143949502094, 0.6268907017169734, 0.6268907017169734, 0.6268907017169734, 0.13699756322666268, 0.13699756322666268, 0.13699756322666268, 0.14108655852758534, 0.14108655852758534, 0.14108655852758534, 0.13548315461343552, 0.13548315461343552, 0.13548315461343552, 0.1563087446677941, 0.1563087446677941, 0.1563087446677941, 0.3225508981147085, 0.3225508981147085, 0.3225508981147085, 0.20714909713976037, 0.20714909713976037, 0.20714909713976037, 0.40682910306481435, 0.40682910306481435, 0.40682910306481435, 0.29801816691232696, 0.29801816691232696, 0.29801816691232696, 0.3020801723133547, 0.3020801723133547, 0.3020801723133547, 0.35185268713297235, 0.35185268713297235, 0.35185268713297235, 0.18330077103390086, 0.18330077103390086, 0.18330077103390086, 0.3090467858988112, 0.3090467858988112, 0.3090467858988112, 0.2013510079951366, 0.2013510079951366, 0.2013510079951366, 0.2078587193464566, 0.2078587193464566, 0.2078587193464566, 0.2643440064713244, 0.2643440064713244, 0.2643440064713244, 0.2536705509894772, 0.2536705509894772, 0.2536705509894772, 0.19284662927000473, 0.19284662927000473, 0.19284662927000473, 0.1980976517352755, 0.1980976517352755, 0.1980976517352755, 0.9294442529852639, 0.9294442529852639, 0.9294442529852639, 0.9362775749587683, 0.9362775749587683, 0.9362775749587683, 0.18862199049081585, 0.18862199049081585, 0.18862199049081585, 0.12812021655071126, 0.12812021655071126, 0.12812021655071126, 0.21096773805393498, 0.21096773805393498, 0.21096773805393498, 0.8593712102162538, 0.8593712102162538, 0.8593712102162538, 0.1849947800247006, 0.1849947800247006, 0.1849947800247006, 0.17679332633896738, 0.17679332633896738, 0.17679332633896738, 0.17992047902070718, 0.17992047902070718, 0.17992047902070718, 0.08083208786948148, 0.08083208786948148, 0.08083208786948148, 0.10446249197106316, 0.10446249197106316, 0.10446249197106316, 0.09265631853263567, 0.09265631853263567, 0.09265631853263567]}, "mutation_prompt": null}
{"id": "64e36a92-78c7-4152-91cd-82efa155019e", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for better exploration\n        self.initial_de_f = 0.9  # Slightly higher Differential weight for strong mutation\n        self.initial_de_cr = 0.8  # Reduced Crossover probability for diverse trials\n        self.initial_pso_w = 0.6  # Higher inertia to maintain particle momentum\n        self.pso_c1 = 1.5  # Increased Cognitive coefficient for personal exploration\n        self.pso_c2 = 1.5  # Increased Social coefficient for stronger collective influence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Dynamic adjustment of DE and PSO parameters\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Enhanced diversity management\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "RefinedHybridDEPSO", "description": "An improved adaptive hybrid evolutionary algorithm integrating Differential Evolution and Particle Swarm Optimization with dynamic parameter tuning and population diversity management for efficient search.", "configspace": "", "generation": 52, "fitness": 0.27348814176560704, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.25.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8502491391681388, 0.8502491391681388, 0.8502491391681388, 0.8413110809498356, 0.8413110809498356, 0.8413110809498356, 0.8531541954638245, 0.8531541954638245, 0.8531541954638245, 0.7199157949281272, 0.7199157949281272, 0.7199157949281272, 0.7143778491343407, 0.7143778491343407, 0.7143778491343407, 0.049817106801406386, 0.049817106801406386, 0.049817106801406386, 0.1318561874014469, 0.1318561874014469, 0.1318561874014469, 0.13072900047269653, 0.13072900047269653, 0.13072900047269653, 0.141214832265651, 0.141214832265651, 0.141214832265651, 0.13992506429559304, 0.13992506429559304, 0.13992506429559304, 0.11855589804959576, 0.11855589804959576, 0.11855589804959576, 0.11806517700044694, 0.11806517700044694, 0.11806517700044694, 0.3174845657090235, 0.3174845657090235, 0.3174845657090235, 0.980171711296777, 0.980171711296777, 0.980171711296777, 0.9897561472467938, 0.9897561472467938, 0.9897561472467938, 0.5406016842109903, 0.5406016842109903, 0.5406016842109903, 0.15594502793475928, 0.15594502793475928, 0.15594502793475928, 0.47433428328826577, 0.47433428328826577, 0.47433428328826577, 0.7509729338276893, 0.7509729338276893, 0.7509729338276893, 0.16116928546815512, 0.16116928546815512, 0.16116928546815512, 0.18213657630640867, 0.18213657630640867, 0.18213657630640867, 0.23090112770975113, 0.23090112770975113, 0.23090112770975113, 0.11993825016994997, 0.11993825016994997, 0.11993825016994997, 0.2410280810113724, 0.2410280810113724, 0.2410280810113724, 0.24055185393675083, 0.24055185393675083, 0.24055185393675083, 0.2588177034466598, 0.2588177034466598, 0.2588177034466598, 0.2729199760513239, 0.2729199760513239, 0.2729199760513239, 0.018542233519936557, 0.018542233519936557, 0.018542233519936557, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028144615621237823, 0.028144615621237823, 0.028144615621237823, 0.1367667099762614, 0.1367667099762614, 0.1367667099762614, 0.11192099194670113, 0.11192099194670113, 0.11192099194670113, 0.08847747917416904, 0.08847747917416904, 0.08847747917416904, 0.07129432003377423, 0.07129432003377423, 0.07129432003377423, 0.0679723401951704, 0.0679723401951704, 0.0679723401951704, 0.10909879484996254, 0.10909879484996254, 0.10909879484996254, 0.080704083237637, 0.080704083237637, 0.080704083237637, 0.0850106090435162, 0.0850106090435162, 0.0850106090435162, 0.5919354620694424, 0.5919354620694424, 0.5919354620694424, 0.5471398343726019, 0.5471398343726019, 0.5471398343726019, 0.526429762420533, 0.526429762420533, 0.526429762420533, 0.1037428313864821, 0.1037428313864821, 0.1037428313864821, 0.1102326975979473, 0.1102326975979473, 0.1102326975979473, 0.08232242704360071, 0.08232242704360071, 0.08232242704360071, 0.15859181811180845, 0.15859181811180845, 0.15859181811180845, 0.13914212449683183, 0.13914212449683183, 0.13914212449683183, 0.21037548766573044, 0.21037548766573044, 0.21037548766573044, 0.4875423880601335, 0.4875423880601335, 0.4875423880601335, 0.38714619631537783, 0.38714619631537783, 0.38714619631537783, 0.48538505790913833, 0.48538505790913833, 0.48538505790913833, 0.27549253077517166, 0.27549253077517166, 0.27549253077517166, 0.2069610406218425, 0.2069610406218425, 0.2069610406218425, 0.14705433610699525, 0.14705433610699525, 0.14705433610699525, 0.18573571144810275, 0.18573571144810275, 0.18573571144810275, 0.20974794251508055, 0.20974794251508055, 0.20974794251508055, 0.19346018763669348, 0.19346018763669348, 0.19346018763669348, 0.19725287064861963, 0.19725287064861963, 0.19725287064861963, 0.24204389765568957, 0.24204389765568957, 0.24204389765568957, 0.1748049438246626, 0.1748049438246626, 0.1748049438246626, 0.8801131283828766, 0.8801131283828766, 0.8801131283828766, 0.16000617785829163, 0.16000617785829163, 0.16000617785829163, 0.17291725452344275, 0.17291725452344275, 0.17291725452344275, 0.12878107969184438, 0.12878107969184438, 0.12878107969184438, 0.2082845415187108, 0.2082845415187108, 0.2082845415187108, 0.15632255731412315, 0.15632255731412315, 0.15632255731412315, 0.19830172157948345, 0.19830172157948345, 0.19830172157948345, 0.1841591269630367, 0.1841591269630367, 0.1841591269630367, 0.18443117073147053, 0.18443117073147053, 0.18443117073147053, 0.0710592248383124, 0.0710592248383124, 0.0710592248383124, 0.07919343451203309, 0.07919343451203309, 0.07919343451203309, 0.08100452938345626, 0.08100452938345626, 0.08100452938345626]}, "mutation_prompt": null}
{"id": "55ca0d23-1594-493c-8a66-bee80fa591e7", "solution": "import numpy as np\n\nclass DynamicHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.4 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.2 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.60:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicHybridDEPSO", "description": "A dynamically adaptive hybrid algorithm blending Differential Evolution and Particle Swarm Optimization with strategic parameter adjustments and enhanced diversity control for robust exploration in diverse optimization landscapes.", "configspace": "", "generation": 53, "fitness": 0.3148662852962593, "feedback": "The algorithm DynamicHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.29.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.851980101071268, 0.851980101071268, 0.851980101071268, 0.8578845825163414, 0.8578845825163414, 0.8578845825163414, 0.8839968605378044, 0.8839968605378044, 0.8839968605378044, 0.7524418011582974, 0.7524418011582974, 0.7524418011582974, 0.7640396555068409, 0.7640396555068409, 0.7640396555068409, 0.01788404269897359, 0.01788404269897359, 0.01788404269897359, 0.13485205370860642, 0.13485205370860642, 0.13485205370860642, 0.1373674996923382, 0.1373674996923382, 0.1373674996923382, 0.10989371901627365, 0.10989371901627365, 0.10989371901627365, 0.12192458061966449, 0.12192458061966449, 0.12192458061966449, 0.11458512341104432, 0.11458512341104432, 0.11458512341104432, 0.1288016342205296, 0.1288016342205296, 0.1288016342205296, 0.9887593072084494, 0.9887593072084494, 0.9887593072084494, 0.9907031928758618, 0.9907031928758618, 0.9907031928758618, 0.9893304938161197, 0.9893304938161197, 0.9893304938161197, 0.5423803921576558, 0.5423803921576558, 0.5423803921576558, 0.5880440190905472, 0.5880440190905472, 0.5880440190905472, 0.5794455539550749, 0.5794455539550749, 0.5794455539550749, 0.20981374134676223, 0.20981374134676223, 0.20981374134676223, 0.2754264779954627, 0.2754264779954627, 0.2754264779954627, 0.3488340000151051, 0.3488340000151051, 0.3488340000151051, 0.13176971831710926, 0.13176971831710926, 0.13176971831710926, 0.24718456405559797, 0.24718456405559797, 0.24718456405559797, 0.12140096348451646, 0.12140096348451646, 0.12140096348451646, 0.13096784690577445, 0.13096784690577445, 0.13096784690577445, 0.2600782516606275, 0.2600782516606275, 0.2600782516606275, 0.25708779996643294, 0.25708779996643294, 0.25708779996643294, 0.07353431513339326, 0.07353431513339326, 0.07353431513339326, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13651553027332908, 0.13651553027332908, 0.13651553027332908, 0.03546083383309784, 0.03546083383309784, 0.03546083383309784, 0.09713443474099481, 0.09713443474099481, 0.09713443474099481, 0.035973097658460795, 0.035973097658460795, 0.035973097658460795, 0.10535931626958261, 0.10535931626958261, 0.10535931626958261, 0.0961624283707635, 0.0961624283707635, 0.0961624283707635, 0.04327703202246991, 0.04327703202246991, 0.04327703202246991, 0.03844128320635809, 0.03844128320635809, 0.03844128320635809, 0.21720149427246938, 0.21720149427246938, 0.21720149427246938, 0.5799594369401495, 0.5799594369401495, 0.5799594369401495, 0.6211982031437684, 0.6211982031437684, 0.6211982031437684, 0.5735201556919431, 0.5735201556919431, 0.5735201556919431, 0.09241458780167544, 0.09241458780167544, 0.09241458780167544, 0.12098556601954602, 0.12098556601954602, 0.12098556601954602, 0.1588682585845832, 0.1588682585845832, 0.1588682585845832, 0.19263466356202186, 0.19263466356202186, 0.19263466356202186, 0.17871433270888315, 0.17871433270888315, 0.17871433270888315, 0.14230269097845683, 0.14230269097845683, 0.14230269097845683, 0.30428746490759473, 0.30428746490759473, 0.30428746490759473, 0.4562968548824524, 0.4562968548824524, 0.4562968548824524, 0.5747702219776147, 0.5747702219776147, 0.5747702219776147, 0.2513099433921667, 0.2513099433921667, 0.2513099433921667, 0.20935545067638728, 0.20935545067638728, 0.20935545067638728, 0.12746060170555684, 0.12746060170555684, 0.12746060170555684, 0.2008812238132982, 0.2008812238132982, 0.2008812238132982, 0.20637088860793695, 0.20637088860793695, 0.20637088860793695, 0.22617031123627018, 0.22617031123627018, 0.22617031123627018, 0.2057830510269879, 0.2057830510269879, 0.2057830510269879, 0.21871762833424246, 0.21871762833424246, 0.21871762833424246, 0.20370243629976925, 0.20370243629976925, 0.20370243629976925, 0.9007720682635652, 0.9007720682635652, 0.9007720682635652, 0.9164378627308907, 0.9164378627308907, 0.9164378627308907, 0.16714258411601735, 0.16714258411601735, 0.16714258411601735, 0.6797106077752113, 0.6797106077752113, 0.6797106077752113, 0.20842378939796047, 0.20842378939796047, 0.20842378939796047, 0.7423199444815958, 0.7423199444815958, 0.7423199444815958, 0.19165327890952832, 0.19165327890952832, 0.19165327890952832, 0.1808899857754407, 0.1808899857754407, 0.1808899857754407, 0.17756121781946443, 0.17756121781946443, 0.17756121781946443, 0.07522648745644123, 0.07522648745644123, 0.07522648745644123, 0.08097100414025349, 0.08097100414025349, 0.08097100414025349, 0.08742199538299666, 0.08742199538299666, 0.08742199538299666]}, "mutation_prompt": null}
{"id": "f2a57548-3ffb-477c-83ec-8f0b8086d267", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "RefinedHybridDEPSO", "description": "A refined hybrid evolutionary algorithm blending Differential Evolution and Particle Swarm Optimization with dynamic parameter tuning and enhanced diversity maintenance.", "configspace": "", "generation": 54, "fitness": 0.2895495445510569, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.27.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8699762134854454, 0.8699762134854454, 0.8699762134854454, 0.8445960492307892, 0.8445960492307892, 0.8445960492307892, 0.8459031056458074, 0.8459031056458074, 0.8459031056458074, 0.7706425797247235, 0.7706425797247235, 0.7706425797247235, 0.6827033740019707, 0.6827033740019707, 0.6827033740019707, 0.7660636095428167, 0.7660636095428167, 0.7660636095428167, 0.14503402814949728, 0.14503402814949728, 0.14503402814949728, 0.15829856108030382, 0.15829856108030382, 0.15829856108030382, 0.127659007155982, 0.127659007155982, 0.127659007155982, 0.1036138722497304, 0.1036138722497304, 0.1036138722497304, 0.11382011041003748, 0.11382011041003748, 0.11382011041003748, 0.1125024575980067, 0.1125024575980067, 0.1125024575980067, 0.9831682044905374, 0.9831682044905374, 0.9831682044905374, 0.9887919797310813, 0.9887919797310813, 0.9887919797310813, 0.9916988985929618, 0.9916988985929618, 0.9916988985929618, 0.4257314819260578, 0.4257314819260578, 0.4257314819260578, 0.42384638066131297, 0.42384638066131297, 0.42384638066131297, 0.06227974575561823, 0.06227974575561823, 0.06227974575561823, 0.3115003081974943, 0.3115003081974943, 0.3115003081974943, 0.16179523631027626, 0.16179523631027626, 0.16179523631027626, 0.6629033886315445, 0.6629033886315445, 0.6629033886315445, 0.3896158444410338, 0.3896158444410338, 0.3896158444410338, 0.26420734629416565, 0.26420734629416565, 0.26420734629416565, 0.24956792576634756, 0.24956792576634756, 0.24956792576634756, 0.25637935357739483, 0.25637935357739483, 0.25637935357739483, 0.25358249189560833, 0.25358249189560833, 0.25358249189560833, 0.13038776972850297, 0.13038776972850297, 0.13038776972850297, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04976535032278373, 0.04976535032278373, 0.04976535032278373, 0.04703633224530801, 0.04703633224530801, 0.04703633224530801, 0.06230079778009079, 0.06230079778009079, 0.06230079778009079, 0.034607259461018614, 0.034607259461018614, 0.034607259461018614, 0.07703395552695425, 0.07703395552695425, 0.07703395552695425, 0.11873120228970269, 0.11873120228970269, 0.11873120228970269, 0.09238722406392175, 0.09238722406392175, 0.09238722406392175, 0.09064833847860665, 0.09064833847860665, 0.09064833847860665, 0.10402140883969935, 0.10402140883969935, 0.10402140883969935, 0.5028619077014285, 0.5028619077014285, 0.5028619077014285, 0.5310105690810438, 0.5310105690810438, 0.5310105690810438, 0.5545153327230228, 0.5545153327230228, 0.5545153327230228, 0.09133980649798268, 0.09133980649798268, 0.09133980649798268, 0.1029418699774517, 0.1029418699774517, 0.1029418699774517, 0.11514886617645659, 0.11514886617645659, 0.11514886617645659, 0.15132630757901477, 0.15132630757901477, 0.15132630757901477, 0.17651749268935835, 0.17651749268935835, 0.17651749268935835, 0.2029457149227346, 0.2029457149227346, 0.2029457149227346, 0.2118037419438391, 0.2118037419438391, 0.2118037419438391, 0.20835728763910133, 0.20835728763910133, 0.20835728763910133, 0.4286352959368267, 0.4286352959368267, 0.4286352959368267, 0.2665282964358905, 0.2665282964358905, 0.2665282964358905, 0.28319868389146796, 0.28319868389146796, 0.28319868389146796, 0.12757050713497753, 0.12757050713497753, 0.12757050713497753, 0.197104382844017, 0.197104382844017, 0.197104382844017, 0.21291416012331754, 0.21291416012331754, 0.21291416012331754, 0.19454179178542474, 0.19454179178542474, 0.19454179178542474, 0.2390959312644575, 0.2390959312644575, 0.2390959312644575, 0.1982450580056253, 0.1982450580056253, 0.1982450580056253, 0.5508523660331444, 0.5508523660331444, 0.5508523660331444, 0.9076330797448328, 0.9076330797448328, 0.9076330797448328, 0.15849042450023842, 0.15849042450023842, 0.15849042450023842, 0.16141183508125445, 0.16141183508125445, 0.16141183508125445, 0.16911275460084363, 0.16911275460084363, 0.16911275460084363, 0.16932837662280142, 0.16932837662280142, 0.16932837662280142, 0.15582729865302625, 0.15582729865302625, 0.15582729865302625, 0.18723897923858812, 0.18723897923858812, 0.18723897923858812, 0.18542988603345667, 0.18542988603345667, 0.18542988603345667, 0.18523957208066433, 0.18523957208066433, 0.18523957208066433, 0.07387294921943843, 0.07387294921943843, 0.07387294921943843, 0.07680972896021632, 0.07680972896021632, 0.07680972896021632, 0.09661575927101695, 0.09661575927101695, 0.09661575927101695]}, "mutation_prompt": null}
{"id": "92de7571-c848-4651-8e64-54f341f7f8f5", "solution": "import numpy as np\n\nclass QuantumInspiredHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.2  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.3  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def quantum_rotation(self, pos, pivot, angle):\n        direction = pos - pivot\n        norm = np.linalg.norm(direction)\n        if norm > 0:\n            direction /= norm\n            rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n            rotated = np.dot(rotation_matrix, direction[:2])\n            direction[:2] = rotated\n            pos = pivot + norm * direction\n        return pos\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial = self.quantum_rotation(trial, population[i], np.pi * progress_ratio)\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by quantum-inspired perturbation\n            if self.eval_count >= self.max_evaluations * 0.60:\n                diversity_count = max(1, int(self.population_size * 0.15))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        pivot = np.random.uniform(self.lb, self.ub, self.dim)\n                        population[idx] = self.quantum_rotation(population[idx], pivot, np.pi / 4)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "QuantumInspiredHybridDEPSO", "description": "Quantum-Inspired Adaptive Hybrid DE-PSO optimizes using quantum-inspired rotation gates and parameter adaptation in Differential Evolution and Particle Swarm Optimization for enhanced exploration and exploitation.", "configspace": "", "generation": 55, "fitness": 0.306929413150707, "feedback": "The algorithm QuantumInspiredHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8984561462259983, 0.8984561462259983, 0.8984561462259983, 0.1836758645979134, 0.1836758645979134, 0.1836758645979134, 0.9032858145348639, 0.9032858145348639, 0.9032858145348639, 0.7913561553912543, 0.7913561553912543, 0.7913561553912543, 0.7931566485399797, 0.7931566485399797, 0.7931566485399797, 0.7834023127016939, 0.7834023127016939, 0.7834023127016939, 0.29246929002953115, 0.29246929002953115, 0.29246929002953115, 0.16279822641592834, 0.16279822641592834, 0.16279822641592834, 0.13541708425243126, 0.13541708425243126, 0.13541708425243126, 0.12688624201026433, 0.12688624201026433, 0.12688624201026433, 0.13262524313504143, 0.13262524313504143, 0.13262524313504143, 0.11971429213136675, 0.11971429213136675, 0.11971429213136675, 0.9852393728964459, 0.9852393728964459, 0.9852393728964459, 0.984394559154649, 0.984394559154649, 0.984394559154649, 0.9889131406646788, 0.9889131406646788, 0.9889131406646788, 0.44779276463238304, 0.44779276463238304, 0.44779276463238304, 0.705798851769319, 0.705798851769319, 0.705798851769319, 0.6919161337655895, 0.6919161337655895, 0.6919161337655895, 0.3764258270607893, 0.3764258270607893, 0.3764258270607893, 0.17318981468317218, 0.17318981468317218, 0.17318981468317218, 0.12683800544577373, 0.12683800544577373, 0.12683800544577373, 0.18229432890009933, 0.18229432890009933, 0.18229432890009933, 0.12780195871007238, 0.12780195871007238, 0.12780195871007238, 0.25307123065495085, 0.25307123065495085, 0.25307123065495085, 0.2616195841539567, 0.2616195841539567, 0.2616195841539567, 0.2842582561071044, 0.2842582561071044, 0.2842582561071044, 0.2958266963549844, 0.2958266963549844, 0.2958266963549844, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07621128180126091, 0.07621128180126091, 0.07621128180126091, 0.05149394303927368, 0.05149394303927368, 0.05149394303927368, 0.19749361744226213, 0.19749361744226213, 0.19749361744226213, 0.1379340121228121, 0.1379340121228121, 0.1379340121228121, 0.07832483814148183, 0.07832483814148183, 0.07832483814148183, 0.09662837000695312, 0.09662837000695312, 0.09662837000695312, 0.06141969558211824, 0.06141969558211824, 0.06141969558211824, 0.09703863074327723, 0.09703863074327723, 0.09703863074327723, 0.0813859066714413, 0.0813859066714413, 0.0813859066714413, 0.5576151169859453, 0.5576151169859453, 0.5576151169859453, 0.5432662306217282, 0.5432662306217282, 0.5432662306217282, 0.6131119618190415, 0.6131119618190415, 0.6131119618190415, 0.07839776190098824, 0.07839776190098824, 0.07839776190098824, 0.12171521973063171, 0.12171521973063171, 0.12171521973063171, 0.1253682188528341, 0.1253682188528341, 0.1253682188528341, 0.2042452516768598, 0.2042452516768598, 0.2042452516768598, 0.1318727134843235, 0.1318727134843235, 0.1318727134843235, 0.15571810889409243, 0.15571810889409243, 0.15571810889409243, 0.44308658396802125, 0.44308658396802125, 0.44308658396802125, 0.32488937980389687, 0.32488937980389687, 0.32488937980389687, 0.6251847696253905, 0.6251847696253905, 0.6251847696253905, 0.23570414243796978, 0.23570414243796978, 0.23570414243796978, 0.22251811073833738, 0.22251811073833738, 0.22251811073833738, 0.1980745813762853, 0.1980745813762853, 0.1980745813762853, 0.1866351605194313, 0.1866351605194313, 0.1866351605194313, 0.19685863422874694, 0.19685863422874694, 0.19685863422874694, 0.18773337730815176, 0.18773337730815176, 0.18773337730815176, 0.1947948252888716, 0.1947948252888716, 0.1947948252888716, 0.19408704011923383, 0.19408704011923383, 0.19408704011923383, 0.22342118936827515, 0.22342118936827515, 0.22342118936827515, 0.9083820421314569, 0.9083820421314569, 0.9083820421314569, 0.16360333301819285, 0.16360333301819285, 0.16360333301819285, 0.16764338163665038, 0.16764338163665038, 0.16764338163665038, 0.8376612574162963, 0.8376612574162963, 0.8376612574162963, 0.21158236544859377, 0.21158236544859377, 0.21158236544859377, 0.15599288810820344, 0.15599288810820344, 0.15599288810820344, 0.1808632273546419, 0.1808632273546419, 0.1808632273546419, 0.17444243266200943, 0.17444243266200943, 0.17444243266200943, 0.19386091722445453, 0.19386091722445453, 0.19386091722445453, 0.08841965647362482, 0.08841965647362482, 0.08841965647362482, 0.08279524366931068, 0.08279524366931068, 0.08279524366931068, 0.08251848248729332, 0.08251848248729332, 0.08251848248729332]}, "mutation_prompt": null}
{"id": "26c3eebe-c785-46f2-b010-139a0dc399eb", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "635d2ae5-776b-4738-bfff-e3a68e3de880", "solution": "import numpy as np\n\nclass DynamicHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.initial_de_f = 0.9  # Modified Differential weight\n        self.initial_de_cr = 0.7  # Modified Crossover probability\n        self.initial_pso_w = 0.6  # Modified Inertia weight\n        self.pso_c1 = 1.2  # Modified Cognitive coefficient\n        self.pso_c2 = 1.4  # Modified Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adaptive DE and PSO parameter adjustment\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Enhance diversity by introducing random individuals\n            if self.eval_count >= self.max_evaluations * 0.65:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicHybridDEPSO", "description": "A dynamic hybrid evolutionary algorithm that synergizes Differential Evolution and Particle Swarm Optimization with progressive parameter tuning and diversity promotion for robust search space exploration and exploitation.", "configspace": "", "generation": 57, "fitness": 0.28075565739871655, "feedback": "The algorithm DynamicHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8444924967260083, 0.8444924967260083, 0.8444924967260083, 0.8477212567823249, 0.8477212567823249, 0.8477212567823249, 0.8647171969060286, 0.8647171969060286, 0.8647171969060286, 0.7119266219697693, 0.7119266219697693, 0.7119266219697693, 0.6882774013547291, 0.6882774013547291, 0.6882774013547291, 0.70804120965969, 0.70804120965969, 0.70804120965969, 0.16587012042204574, 0.16587012042204574, 0.16587012042204574, 0.11587994057538986, 0.11587994057538986, 0.11587994057538986, 0.13314762063833263, 0.13314762063833263, 0.13314762063833263, 0.12757369616918623, 0.12757369616918623, 0.12757369616918623, 0.14985933986175315, 0.14985933986175315, 0.14985933986175315, 0.13682624770462992, 0.13682624770462992, 0.13682624770462992, 0.9811930366168005, 0.9811930366168005, 0.9811930366168005, 0.979935481756919, 0.979935481756919, 0.979935481756919, 0.9897450268707985, 0.9897450268707985, 0.9897450268707985, 0.43060296352879346, 0.43060296352879346, 0.43060296352879346, 0.4017260183858623, 0.4017260183858623, 0.4017260183858623, 0.5719215972770348, 0.5719215972770348, 0.5719215972770348, 0.2134355579865781, 0.2134355579865781, 0.2134355579865781, 0.16151992092656653, 0.16151992092656653, 0.16151992092656653, 0.23433693386382293, 0.23433693386382293, 0.23433693386382293, 0.24741339871642476, 0.24741339871642476, 0.24741339871642476, 0.12495324260112917, 0.12495324260112917, 0.12495324260112917, 0.24021815947529823, 0.24021815947529823, 0.24021815947529823, 0.1323820262979083, 0.1323820262979083, 0.1323820262979083, 0.13030694989866132, 0.13030694989866132, 0.13030694989866132, 0.12925895586483438, 0.12925895586483438, 0.12925895586483438, 0.04286523164959799, 0.04286523164959799, 0.04286523164959799, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07759389349562662, 0.07759389349562662, 0.07759389349562662, 0.04613611799412065, 0.04613611799412065, 0.04613611799412065, 0.06833693906635507, 0.06833693906635507, 0.06833693906635507, 0.09767991090633399, 0.09767991090633399, 0.09767991090633399, 0.07159911423412946, 0.07159911423412946, 0.07159911423412946, 0.07770789508104392, 0.07770789508104392, 0.07770789508104392, 0.12138482797822003, 0.12138482797822003, 0.12138482797822003, 0.10052671692449167, 0.10052671692449167, 0.10052671692449167, 0.27870669586194685, 0.27870669586194685, 0.27870669586194685, 0.5266972383635634, 0.5266972383635634, 0.5266972383635634, 0.5528846661728226, 0.5528846661728226, 0.5528846661728226, 0.5871496950683583, 0.5871496950683583, 0.5871496950683583, 0.08723101258235766, 0.08723101258235766, 0.08723101258235766, 0.09189474010173804, 0.09189474010173804, 0.09189474010173804, 0.0809446598032284, 0.0809446598032284, 0.0809446598032284, 0.1834595343269677, 0.1834595343269677, 0.1834595343269677, 0.21655878957687957, 0.21655878957687957, 0.21655878957687957, 0.18139374257747687, 0.18139374257747687, 0.18139374257747687, 0.39048804485779465, 0.39048804485779465, 0.39048804485779465, 0.21687946180521078, 0.21687946180521078, 0.21687946180521078, 0.2772837700378118, 0.2772837700378118, 0.2772837700378118, 0.338429336073901, 0.338429336073901, 0.338429336073901, 0.19054244617669447, 0.19054244617669447, 0.19054244617669447, 0.13722281401263192, 0.13722281401263192, 0.13722281401263192, 0.19361129674167388, 0.19361129674167388, 0.19361129674167388, 0.19514971231192257, 0.19514971231192257, 0.19514971231192257, 0.22821299955134122, 0.22821299955134122, 0.22821299955134122, 0.21107692322497118, 0.21107692322497118, 0.21107692322497118, 0.21361157232588124, 0.21361157232588124, 0.21361157232588124, 0.1897347227747861, 0.1897347227747861, 0.1897347227747861, 0.8837932560898617, 0.8837932560898617, 0.8837932560898617, 0.1589657741083753, 0.1589657741083753, 0.1589657741083753, 0.1523887610175918, 0.1523887610175918, 0.1523887610175918, 0.12131190689037208, 0.12131190689037208, 0.12131190689037208, 0.2104349263081008, 0.2104349263081008, 0.2104349263081008, 0.15717212436401018, 0.15717212436401018, 0.15717212436401018, 0.18765477281705334, 0.18765477281705334, 0.18765477281705334, 0.1694001744974526, 0.1694001744974526, 0.1694001744974526, 0.19105839225503518, 0.19105839225503518, 0.19105839225503518, 0.08232958562574277, 0.08232958562574277, 0.08232958562574277, 0.08102071098451125, 0.08102071098451125, 0.08102071098451125, 0.08240000725228436, 0.08240000725228436, 0.08240000725228436]}, "mutation_prompt": null}
{"id": "0664dfc4-22d4-4201-b4a5-674fcb10a498", "solution": "import numpy as np\n\nclass QuantumAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.initial_de_f = 0.7\n        self.initial_de_cr = 0.9\n        self.initial_pso_w = 0.6\n        self.pso_c1 = 1.5\n        self.pso_c2 = 1.5\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "QuantumAdaptiveDEPSO", "description": "A balanced evolutionary optimizer blending Quantum-inspired Differential Evolution and Adaptive Particle Swarm Optimization for efficient global exploration and local exploitation.", "configspace": "", "generation": 58, "fitness": 0.2950596530495446, "feedback": "The algorithm QuantumAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.27.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8342599013899814, 0.8342599013899814, 0.8342599013899814, 0.8424016551986351, 0.8424016551986351, 0.8424016551986351, 0.8478616821399577, 0.8478616821399577, 0.8478616821399577, 0.7089646391778968, 0.7089646391778968, 0.7089646391778968, 0.6893312753802964, 0.6893312753802964, 0.6893312753802964, 0.7248534239792982, 0.7248534239792982, 0.7248534239792982, 0.14380495907177626, 0.14380495907177626, 0.14380495907177626, 0.07140766897167994, 0.07140766897167994, 0.07140766897167994, 0.12181807936740263, 0.12181807936740263, 0.12181807936740263, 0.21379362922221268, 0.21379362922221268, 0.21379362922221268, 0.10072358434487227, 0.10072358434487227, 0.10072358434487227, 0.13705075204435757, 0.13705075204435757, 0.13705075204435757, 0.9898887161592773, 0.9898887161592773, 0.9898887161592773, 0.9889723093190296, 0.9889723093190296, 0.9889723093190296, 0.9899479439605893, 0.9899479439605893, 0.9899479439605893, 0.38375060829050633, 0.38375060829050633, 0.38375060829050633, 0.408648293082283, 0.408648293082283, 0.408648293082283, 0.49995671076854287, 0.49995671076854287, 0.49995671076854287, 0.35804147826966204, 0.35804147826966204, 0.35804147826966204, 0.1597906025871758, 0.1597906025871758, 0.1597906025871758, 0.7687229287719122, 0.7687229287719122, 0.7687229287719122, 0.2624718764145113, 0.2624718764145113, 0.2624718764145113, 0.12232654353676431, 0.12232654353676431, 0.12232654353676431, 0.23745685116831605, 0.23745685116831605, 0.23745685116831605, 0.2233517147526265, 0.2233517147526265, 0.2233517147526265, 0.25907272231675693, 0.25907272231675693, 0.25907272231675693, 0.1208817786327776, 0.1208817786327776, 0.1208817786327776, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04077409252292363, 0.04077409252292363, 0.04077409252292363, 0.07293097678607097, 0.07293097678607097, 0.07293097678607097, 0.04804785970103531, 0.04804785970103531, 0.04804785970103531, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16739091522087068, 0.16739091522087068, 0.16739091522087068, 0.0668348148949921, 0.0668348148949921, 0.0668348148949921, 0.17206449615346686, 0.17206449615346686, 0.17206449615346686, 0.30591429548182836, 0.30591429548182836, 0.30591429548182836, 0.0803106124487909, 0.0803106124487909, 0.0803106124487909, 0.5721598119447082, 0.5721598119447082, 0.5721598119447082, 0.5404384405369853, 0.5404384405369853, 0.5404384405369853, 0.5709479828023611, 0.5709479828023611, 0.5709479828023611, 0.12794386684452785, 0.12794386684452785, 0.12794386684452785, 0.12009205911630982, 0.12009205911630982, 0.12009205911630982, 0.11933383579311174, 0.11933383579311174, 0.11933383579311174, 0.14034525794644392, 0.14034525794644392, 0.14034525794644392, 0.1541585059589735, 0.1541585059589735, 0.1541585059589735, 0.1788710044168218, 0.1788710044168218, 0.1788710044168218, 0.4554164033833351, 0.4554164033833351, 0.4554164033833351, 0.3521663683940882, 0.3521663683940882, 0.3521663683940882, 0.2890227610695556, 0.2890227610695556, 0.2890227610695556, 0.2026041842406222, 0.2026041842406222, 0.2026041842406222, 0.19588007818352093, 0.19588007818352093, 0.19588007818352093, 0.26003128554317345, 0.26003128554317345, 0.26003128554317345, 0.24396965769651824, 0.24396965769651824, 0.24396965769651824, 0.17925718726898032, 0.17925718726898032, 0.17925718726898032, 0.190565147367726, 0.190565147367726, 0.190565147367726, 0.24515977119585275, 0.24515977119585275, 0.24515977119585275, 0.19718644204012015, 0.19718644204012015, 0.19718644204012015, 0.18676487952836418, 0.18676487952836418, 0.18676487952836418, 0.8747807019082028, 0.8747807019082028, 0.8747807019082028, 0.16682072030384643, 0.16682072030384643, 0.16682072030384643, 0.18990659668360632, 0.18990659668360632, 0.18990659668360632, 0.15408280701887656, 0.15408280701887656, 0.15408280701887656, 0.21118286898111882, 0.21118286898111882, 0.21118286898111882, 0.15655372498059206, 0.15655372498059206, 0.15655372498059206, 0.18267306599549926, 0.18267306599549926, 0.18267306599549926, 0.18588535508869908, 0.18588535508869908, 0.18588535508869908, 0.1965769673669162, 0.1965769673669162, 0.1965769673669162, 0.08957950284589655, 0.08957950284589655, 0.08957950284589655, 0.08182880883502308, 0.08182880883502308, 0.08182880883502308, 0.06788857675775795, 0.06788857675775795, 0.06788857675775795]}, "mutation_prompt": null}
{"id": "e9258c4b-8b75-4f16-abe9-4fe4609435ae", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "f0998a81-bcfd-4549-a347-9fcfe04aaec9", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8\n        self.initial_de_cr = 0.85\n        self.initial_pso_w = 0.5\n        self.pso_c1 = 1.0\n        self.pso_c2 = 1.5  # Adjusted Social coefficient for better social learning\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Initialize velocities randomly\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.7 * progress_ratio  # Smooth transition\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.9 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.60:  # Encourage diversity earlier\n                diversity_count = max(1, int(self.population_size * 0.3))  # Increase diversity\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid algorithm integrating Differential Evolution, Particle Swarm Optimization, and adaptive learning rates to enhance exploration-exploitation balance and maintain diversity in complex search spaces.", "configspace": "", "generation": 60, "fitness": 0.29398872111297336, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.29.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9194990845587934, 0.9194990845587934, 0.9194990845587934, 0.9080072313579717, 0.9080072313579717, 0.9080072313579717, 0.8741176452225281, 0.8741176452225281, 0.8741176452225281, 0.078331168070505, 0.078331168070505, 0.078331168070505, 0.824092413513523, 0.824092413513523, 0.824092413513523, 0.01865385857111379, 0.01865385857111379, 0.01865385857111379, 0.11769493004777942, 0.11769493004777942, 0.11769493004777942, 0.14685018884497802, 0.14685018884497802, 0.14685018884497802, 0.14180004973482851, 0.14180004973482851, 0.14180004973482851, 0.10898585023279994, 0.10898585023279994, 0.10898585023279994, 0.15810072876068748, 0.15810072876068748, 0.15810072876068748, 0.13307245285634595, 0.13307245285634595, 0.13307245285634595, 0.9738750665630779, 0.9738750665630779, 0.9738750665630779, 0.99110594597327, 0.99110594597327, 0.99110594597327, 0.9890816660598977, 0.9890816660598977, 0.9890816660598977, 0.7251866713280106, 0.7251866713280106, 0.7251866713280106, 0.6532460445270125, 0.6532460445270125, 0.6532460445270125, 0.6192690659177869, 0.6192690659177869, 0.6192690659177869, 0.2208191682596169, 0.2208191682596169, 0.2208191682596169, 0.2128145298711337, 0.2128145298711337, 0.2128145298711337, 0.1625387059224822, 0.1625387059224822, 0.1625387059224822, 0.31813544030182606, 0.31813544030182606, 0.31813544030182606, 0.13516783496226803, 0.13516783496226803, 0.13516783496226803, 0.13404911828802102, 0.13404911828802102, 0.13404911828802102, 0.3005825589808363, 0.3005825589808363, 0.3005825589808363, 0.3470055299189997, 0.3470055299189997, 0.3470055299189997, 0.1272328838967316, 0.1272328838967316, 0.1272328838967316, 0.005422077967417671, 0.005422077967417671, 0.005422077967417671, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08493102158733379, 0.08493102158733379, 0.08493102158733379, 0.0606063299975933, 0.0606063299975933, 0.0606063299975933, 0.1303941170454056, 0.1303941170454056, 0.1303941170454056, 0.03742618374962425, 0.03742618374962425, 0.03742618374962425, 0.08198825513749908, 0.08198825513749908, 0.08198825513749908, 0.15137211445346144, 0.15137211445346144, 0.15137211445346144, 0.05550866338310256, 0.05550866338310256, 0.05550866338310256, 0.055478508723076136, 0.055478508723076136, 0.055478508723076136, 0.05004886469839531, 0.05004886469839531, 0.05004886469839531, 0.6150797100798172, 0.6150797100798172, 0.6150797100798172, 0.6394317404518138, 0.6394317404518138, 0.6394317404518138, 0.5939162759137289, 0.5939162759137289, 0.5939162759137289, 0.14955816711792835, 0.14955816711792835, 0.14955816711792835, 0.08621751052123927, 0.08621751052123927, 0.08621751052123927, 0.11216033307589857, 0.11216033307589857, 0.11216033307589857, 0.14178042321549744, 0.14178042321549744, 0.14178042321549744, 0.1541096812174455, 0.1541096812174455, 0.1541096812174455, 0.21995749640232387, 0.21995749640232387, 0.21995749640232387, 0.35275623367268194, 0.35275623367268194, 0.35275623367268194, 0.38817604310600906, 0.38817604310600906, 0.38817604310600906, 0.1777614518320233, 0.1777614518320233, 0.1777614518320233, 0.3225180040926885, 0.3225180040926885, 0.3225180040926885, 0.27816293322298824, 0.27816293322298824, 0.27816293322298824, 0.20903425123803143, 0.20903425123803143, 0.20903425123803143, 0.22207538872537047, 0.22207538872537047, 0.22207538872537047, 0.2174341988485683, 0.2174341988485683, 0.2174341988485683, 0.18905032717493875, 0.18905032717493875, 0.18905032717493875, 0.22891662762242548, 0.22891662762242548, 0.22891662762242548, 0.212197604369597, 0.212197604369597, 0.212197604369597, 0.19181452509524088, 0.19181452509524088, 0.19181452509524088, 0.9436214493476863, 0.9436214493476863, 0.9436214493476863, 0.21224340823258847, 0.21224340823258847, 0.21224340823258847, 0.9385347048883671, 0.9385347048883671, 0.9385347048883671, 0.15684683440014346, 0.15684683440014346, 0.15684683440014346, 0.21291653007441247, 0.21291653007441247, 0.21291653007441247, 0.15528529922894163, 0.15528529922894163, 0.15528529922894163, 0.18281462988633335, 0.18281462988633335, 0.18281462988633335, 0.17254002902924914, 0.17254002902924914, 0.17254002902924914, 0.18101019841622223, 0.18101019841622223, 0.18101019841622223, 0.08878468511511184, 0.08878468511511184, 0.08878468511511184, 0.07869171405407982, 0.07869171405407982, 0.07869171405407982, 0.08909754117895774, 0.08909754117895774, 0.08909754117895774]}, "mutation_prompt": null}
{"id": "fbdff1ca-b4ab-432a-aa15-6efa6178bc4c", "solution": "import numpy as np\n\nclass DynamicHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.2  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.4  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on feedback\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.45 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by intelligently randomizing parts of the population\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicHybridDEPSO", "description": "A dynamic algorithm blending enhanced Differential Evolution and Particle Swarm Optimization with feedback-based parameter tuning and strategic diversity injection for robust black-box optimization.", "configspace": "", "generation": 61, "fitness": 0.2704631204797787, "feedback": "The algorithm DynamicHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.25.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8558585952125939, 0.8558585952125939, 0.8558585952125939, 0.8599739380908585, 0.8599739380908585, 0.8599739380908585, 0.8395241687201044, 0.8395241687201044, 0.8395241687201044, 0.03941872101559618, 0.03941872101559618, 0.03941872101559618, 0.6870887256133249, 0.6870887256133249, 0.6870887256133249, 0.17695108475491228, 0.17695108475491228, 0.17695108475491228, 0.13059495013373668, 0.13059495013373668, 0.13059495013373668, 0.15772048203633748, 0.15772048203633748, 0.15772048203633748, 0.12993007876843843, 0.12993007876843843, 0.12993007876843843, 0.10421819673462851, 0.10421819673462851, 0.10421819673462851, 0.10797436123894077, 0.10797436123894077, 0.10797436123894077, 0.1447920109901063, 0.1447920109901063, 0.1447920109901063, 0.9802932898020464, 0.9802932898020464, 0.9802932898020464, 0.9860101410494463, 0.9860101410494463, 0.9860101410494463, 0.9897073096472637, 0.9897073096472637, 0.9897073096472637, 0.6054707361418896, 0.6054707361418896, 0.6054707361418896, 0.44609086803035736, 0.44609086803035736, 0.44609086803035736, 0.515833066565047, 0.515833066565047, 0.515833066565047, 0.3646659877045326, 0.3646659877045326, 0.3646659877045326, 0.21544836632283593, 0.21544836632283593, 0.21544836632283593, 0.12472656266103277, 0.12472656266103277, 0.12472656266103277, 0.2438825564420809, 0.2438825564420809, 0.2438825564420809, 0.1270784449744069, 0.1270784449744069, 0.1270784449744069, 0.4259375780388791, 0.4259375780388791, 0.4259375780388791, 0.2566481817433941, 0.2566481817433941, 0.2566481817433941, 0.27405902144093686, 0.27405902144093686, 0.27405902144093686, 0.25975812342992644, 0.25975812342992644, 0.25975812342992644, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.027452214305561218, 0.027452214305561218, 0.027452214305561218, 0.03243384933916782, 0.03243384933916782, 0.03243384933916782, 0.06168990542167363, 0.06168990542167363, 0.06168990542167363, 0.036118975539546905, 0.036118975539546905, 0.036118975539546905, 0.11925276335274826, 0.11925276335274826, 0.11925276335274826, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07362533715561626, 0.07362533715561626, 0.07362533715561626, 0.06792760127631225, 0.06792760127631225, 0.06792760127631225, 0.2498305829437616, 0.2498305829437616, 0.2498305829437616, 0.20864550715770636, 0.20864550715770636, 0.20864550715770636, 0.05675925659360259, 0.05675925659360259, 0.05675925659360259, 0.504844620863463, 0.504844620863463, 0.504844620863463, 0.6004824143279628, 0.6004824143279628, 0.6004824143279628, 0.5816092524092371, 0.5816092524092371, 0.5816092524092371, 0.08552082030834207, 0.08552082030834207, 0.08552082030834207, 0.13246108484667896, 0.13246108484667896, 0.13246108484667896, 0.09477594876904061, 0.09477594876904061, 0.09477594876904061, 0.14533516699173343, 0.14533516699173343, 0.14533516699173343, 0.16279828303761557, 0.16279828303761557, 0.16279828303761557, 0.19199315669009576, 0.19199315669009576, 0.19199315669009576, 0.262649906093555, 0.262649906093555, 0.262649906093555, 0.22209724298416533, 0.22209724298416533, 0.22209724298416533, 0.29230674675742485, 0.29230674675742485, 0.29230674675742485, 0.19778421930874623, 0.19778421930874623, 0.19778421930874623, 0.2042511466729774, 0.2042511466729774, 0.2042511466729774, 0.1448099714155584, 0.1448099714155584, 0.1448099714155584, 0.19808480068204004, 0.19808480068204004, 0.19808480068204004, 0.17729281790303064, 0.17729281790303064, 0.17729281790303064, 0.17860617807761414, 0.17860617807761414, 0.17860617807761414, 0.19032673376671605, 0.19032673376671605, 0.19032673376671605, 0.20957069407077933, 0.20957069407077933, 0.20957069407077933, 0.19158570052023027, 0.19158570052023027, 0.19158570052023027, 0.859497876726231, 0.859497876726231, 0.859497876726231, 0.1585216802093855, 0.1585216802093855, 0.1585216802093855, 0.1617752600892821, 0.1617752600892821, 0.1617752600892821, 0.16955191841025752, 0.16955191841025752, 0.16955191841025752, 0.2112089698995604, 0.2112089698995604, 0.2112089698995604, 0.15614950691813156, 0.15614950691813156, 0.15614950691813156, 0.21686030956050062, 0.21686030956050062, 0.21686030956050062, 0.1782032108726317, 0.1782032108726317, 0.1782032108726317, 0.1753077979769776, 0.1753077979769776, 0.1753077979769776, 0.06726848959933085, 0.06726848959933085, 0.06726848959933085, 0.08162110905395226, 0.08162110905395226, 0.08162110905395226, 0.08460009834147009, 0.08460009834147009, 0.08460009834147009]}, "mutation_prompt": null}
{"id": "a8b9c633-b6ab-4aa2-b470-3135d7677896", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO_GM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8\n        self.initial_de_cr = 0.85\n        self.initial_pso_w = 0.5\n        self.pso_c1 = 1.0\n        self.pso_c2 = 1.2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n            # Gaussian Mutation for additional exploration\n            if self.eval_count < self.max_evaluations * 0.90:\n                mutation_count = max(1, int(self.population_size * 0.1))\n                for _ in range(mutation_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        mutated_individual = np.clip(population[idx] + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)\n                        mutated_fitness = func(mutated_individual)\n                        self.eval_count += 1\n                        if mutated_fitness < fitness[idx]:\n                            population[idx] = mutated_individual\n                            fitness[idx] = mutated_fitness\n                            if mutated_fitness < personal_best_fitness[idx]:\n                                personal_best[idx] = mutated_individual\n                                personal_best_fitness[idx] = mutated_fitness\n                                if mutated_fitness < personal_best_fitness[global_best_idx]:\n                                    global_best = mutated_individual\n                                    global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO_GM", "description": "A multi-strategy evolutionary algorithm that adaptively blends Differential Evolution, Particle Swarm Optimization, and Gaussian mutation to effectively balance exploration and exploitation in complex search spaces.", "configspace": "", "generation": 62, "fitness": 0.34468661183446236, "feedback": "The algorithm AdaptiveHybridDEPSO_GM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.31.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9370461106073233, 0.9370461106073233, 0.9370461106073233, 0.924298880075253, 0.924298880075253, 0.924298880075253, 0.9156211718226844, 0.9156211718226844, 0.9156211718226844, 0.8346038344884181, 0.8346038344884181, 0.8346038344884181, 0.8509035842807984, 0.8509035842807984, 0.8509035842807984, 0.8432592344750816, 0.8432592344750816, 0.8432592344750816, 0.13310309184228408, 0.13310309184228408, 0.13310309184228408, 0.12993866416491306, 0.12993866416491306, 0.12993866416491306, 0.1586238716780104, 0.1586238716780104, 0.1586238716780104, 0.10413282517473321, 0.10413282517473321, 0.10413282517473321, 0.10859388752725407, 0.10859388752725407, 0.10859388752725407, 0.10762853471061584, 0.10762853471061584, 0.10762853471061584, 0.9877175766116523, 0.9877175766116523, 0.9877175766116523, 0.9804343694108936, 0.9804343694108936, 0.9804343694108936, 0.9886358671923584, 0.9886358671923584, 0.9886358671923584, 0.8040175104596856, 0.8040175104596856, 0.8040175104596856, 0.7930934971488008, 0.7930934971488008, 0.7930934971488008, 0.7811597608789531, 0.7811597608789531, 0.7811597608789531, 0.22691383544948585, 0.22691383544948585, 0.22691383544948585, 0.1621488382927977, 0.1621488382927977, 0.1621488382927977, 0.23461325940202893, 0.23461325940202893, 0.23461325940202893, 0.20165750960691053, 0.20165750960691053, 0.20165750960691053, 0.1340423403717017, 0.1340423403717017, 0.1340423403717017, 0.3092179976295386, 0.3092179976295386, 0.3092179976295386, 0.2757395293478908, 0.2757395293478908, 0.2757395293478908, 0.29769207123109964, 0.29769207123109964, 0.29769207123109964, 0.24051403887737766, 0.24051403887737766, 0.24051403887737766, 0.01063798931967086, 0.01063798931967086, 0.01063798931967086, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0010702346961670717, 0.0010702346961670717, 0.0010702346961670717, 0.07970958014561969, 0.07970958014561969, 0.07970958014561969, 0.032989718634754306, 0.032989718634754306, 0.032989718634754306, 0.061826971468739056, 0.061826971468739056, 0.061826971468739056, 0.1292597556080033, 0.1292597556080033, 0.1292597556080033, 0.09074825100020811, 0.09074825100020811, 0.09074825100020811, 0.3243749583316743, 0.3243749583316743, 0.3243749583316743, 0.08061723635358942, 0.08061723635358942, 0.08061723635358942, 0.06354210731456134, 0.06354210731456134, 0.06354210731456134, 0.08465012206867162, 0.08465012206867162, 0.08465012206867162, 0.564866062883713, 0.564866062883713, 0.564866062883713, 0.6131970286792847, 0.6131970286792847, 0.6131970286792847, 0.6157041404406586, 0.6157041404406586, 0.6157041404406586, 0.1318890678071648, 0.1318890678071648, 0.1318890678071648, 0.1373455815197805, 0.1373455815197805, 0.1373455815197805, 0.14455805777299668, 0.14455805777299668, 0.14455805777299668, 0.34486864471401735, 0.34486864471401735, 0.34486864471401735, 0.20826023727825482, 0.20826023727825482, 0.20826023727825482, 0.20355164054031216, 0.20355164054031216, 0.20355164054031216, 0.4075274834137409, 0.4075274834137409, 0.4075274834137409, 0.27850318245116634, 0.27850318245116634, 0.27850318245116634, 0.55390267211829, 0.55390267211829, 0.55390267211829, 0.2671069806767521, 0.2671069806767521, 0.2671069806767521, 0.23858928657544165, 0.23858928657544165, 0.23858928657544165, 0.216621648310519, 0.216621648310519, 0.216621648310519, 0.19670524680951074, 0.19670524680951074, 0.19670524680951074, 0.22299347411830417, 0.22299347411830417, 0.22299347411830417, 0.19065801321426112, 0.19065801321426112, 0.19065801321426112, 0.21080830529943306, 0.21080830529943306, 0.21080830529943306, 0.2527646248097245, 0.2527646248097245, 0.2527646248097245, 0.22568383849365348, 0.22568383849365348, 0.22568383849365348, 0.9456517353703027, 0.9456517353703027, 0.9456517353703027, 0.9493781002653474, 0.9493781002653474, 0.9493781002653474, 0.2066883486520793, 0.2066883486520793, 0.2066883486520793, 0.8435392285750933, 0.8435392285750933, 0.8435392285750933, 0.2120483383917614, 0.2120483383917614, 0.2120483383917614, 0.15707101886957353, 0.15707101886957353, 0.15707101886957353, 0.17795830866996765, 0.17795830866996765, 0.17795830866996765, 0.19097057328783795, 0.19097057328783795, 0.19097057328783795, 0.18297839528809345, 0.18297839528809345, 0.18297839528809345, 0.08672222864590973, 0.08672222864590973, 0.08672222864590973, 0.1326761696811073, 0.1326761696811073, 0.1326761696811073, 0.08076977075703595, 0.08076977075703595, 0.08076977075703595]}, "mutation_prompt": null}
{"id": "71bd4da1-26ae-41eb-a22c-3640a33db68f", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.1  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.3  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm that dynamically balances Differential Evolution and Particle Swarm Optimization components with diversity mechanisms for robust exploration and exploitation in varied optimization landscapes.", "configspace": "", "generation": 63, "fitness": 0.29777949185865116, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.27.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8750570601843395, 0.8750570601843395, 0.8750570601843395, 0.8845544153068146, 0.8845544153068146, 0.8845544153068146, 0.8801925283473064, 0.8801925283473064, 0.8801925283473064, 0.03800313466072225, 0.03800313466072225, 0.03800313466072225, 0.7166391034745867, 0.7166391034745867, 0.7166391034745867, 0.7646919975505996, 0.7646919975505996, 0.7646919975505996, 0.1554805258506784, 0.1554805258506784, 0.1554805258506784, 0.11470109898736847, 0.11470109898736847, 0.11470109898736847, 0.15115638983469348, 0.15115638983469348, 0.15115638983469348, 0.16590365765839832, 0.16590365765839832, 0.16590365765839832, 0.10197570894546226, 0.10197570894546226, 0.10197570894546226, 0.11286247862423371, 0.11286247862423371, 0.11286247862423371, 0.9795500471544862, 0.9795500471544862, 0.9795500471544862, 0.9852110994655303, 0.9852110994655303, 0.9852110994655303, 0.9896803525590501, 0.9896803525590501, 0.9896803525590501, 0.5893411093942489, 0.5893411093942489, 0.5893411093942489, 0.6256520151639594, 0.6256520151639594, 0.6256520151639594, 0.10982512130145683, 0.10982512130145683, 0.10982512130145683, 0.3277246189648356, 0.3277246189648356, 0.3277246189648356, 0.21595494201963505, 0.21595494201963505, 0.21595494201963505, 0.14932496175035104, 0.14932496175035104, 0.14932496175035104, 0.29779455165677793, 0.29779455165677793, 0.29779455165677793, 0.28019991212411544, 0.28019991212411544, 0.28019991212411544, 0.26946054917755624, 0.26946054917755624, 0.26946054917755624, 0.2815017283370733, 0.2815017283370733, 0.2815017283370733, 0.31098877094781496, 0.31098877094781496, 0.31098877094781496, 0.3026317563543044, 0.3026317563543044, 0.3026317563543044, 0.03209159277247531, 0.03209159277247531, 0.03209159277247531, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012004633936900988, 0.012004633936900988, 0.012004633936900988, 0.09095400995844372, 0.09095400995844372, 0.09095400995844372, 0.014917053214055565, 0.014917053214055565, 0.014917053214055565, 0.04009637538463162, 0.04009637538463162, 0.04009637538463162, 0.03443752571622294, 0.03443752571622294, 0.03443752571622294, 0.1377534823520773, 0.1377534823520773, 0.1377534823520773, 0.07275042582510838, 0.07275042582510838, 0.07275042582510838, 0.07615943223220079, 0.07615943223220079, 0.07615943223220079, 0.15052035145636566, 0.15052035145636566, 0.15052035145636566, 0.118537482773728, 0.118537482773728, 0.118537482773728, 0.6579653657117851, 0.6579653657117851, 0.6579653657117851, 0.6388463948317432, 0.6388463948317432, 0.6388463948317432, 0.5675681384898971, 0.5675681384898971, 0.5675681384898971, 0.11183181877297943, 0.11183181877297943, 0.11183181877297943, 0.12565218930883526, 0.12565218930883526, 0.12565218930883526, 0.1226413383461864, 0.1226413383461864, 0.1226413383461864, 0.25896567727779907, 0.25896567727779907, 0.25896567727779907, 0.26217270734135645, 0.26217270734135645, 0.26217270734135645, 0.587555032626464, 0.587555032626464, 0.587555032626464, 0.4271106282824869, 0.4271106282824869, 0.4271106282824869, 0.21891143806363456, 0.21891143806363456, 0.21891143806363456, 0.16507818286249853, 0.16507818286249853, 0.16507818286249853, 0.2634842086073935, 0.2634842086073935, 0.2634842086073935, 0.21143053949044233, 0.21143053949044233, 0.21143053949044233, 0.1279982421354533, 0.1279982421354533, 0.1279982421354533, 0.1978773316257021, 0.1978773316257021, 0.1978773316257021, 0.18364161131309042, 0.18364161131309042, 0.18364161131309042, 0.20499509963177887, 0.20499509963177887, 0.20499509963177887, 0.17966909890962302, 0.17966909890962302, 0.17966909890962302, 0.24514894467825765, 0.24514894467825765, 0.24514894467825765, 0.701683695012933, 0.701683695012933, 0.701683695012933, 0.8212791876699537, 0.8212791876699537, 0.8212791876699537, 0.15977405894370367, 0.15977405894370367, 0.15977405894370367, 0.1614164132819853, 0.1614164132819853, 0.1614164132819853, 0.16898753389215604, 0.16898753389215604, 0.16898753389215604, 0.20941850169298204, 0.20941850169298204, 0.20941850169298204, 0.15667099348970182, 0.15667099348970182, 0.15667099348970182, 0.18274825051586152, 0.18274825051586152, 0.18274825051586152, 0.1966740966225149, 0.1966740966225149, 0.1966740966225149, 0.1939451936200296, 0.1939451936200296, 0.1939451936200296, 0.10544753703775878, 0.10544753703775878, 0.10544753703775878, 0.07744598719149764, 0.07744598719149764, 0.07744598719149764, 0.08970597512578404, 0.08970597512578404, 0.08970597512578404]}, "mutation_prompt": null}
{"id": "52bde3b8-94a3-42f1-996b-71e4eca91ec4", "solution": "import numpy as np\n\nclass EvolvedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population for better diversity\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Strategic diversity encouragement\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EvolvedHybridDEPSO", "description": "EvolvedHybridDEPSO: An enhanced hybrid algorithm leveraging evolved differential and particle swarm dynamics with adaptive randomness and targeted diversity for robust exploration and fine-tuned exploitation.", "configspace": "", "generation": 64, "fitness": 0.2721202107326788, "feedback": "The algorithm EvolvedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.25.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8061805859515849, 0.8061805859515849, 0.8061805859515849, 0.8291030398339729, 0.8291030398339729, 0.8291030398339729, 0.7783865607906357, 0.7783865607906357, 0.7783865607906357, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.6754065993840017, 0.6754065993840017, 0.6754065993840017, 0.08553882830431248, 0.08553882830431248, 0.08553882830431248, 0.11817007195527296, 0.11817007195527296, 0.11817007195527296, 0.10838296116312818, 0.10838296116312818, 0.10838296116312818, 0.13587556183337623, 0.13587556183337623, 0.13587556183337623, 0.129031000146135, 0.129031000146135, 0.129031000146135, 0.126834266140342, 0.126834266140342, 0.126834266140342, 0.12236992993701246, 0.12236992993701246, 0.12236992993701246, 0.9811355528319974, 0.9811355528319974, 0.9811355528319974, 0.987706902880375, 0.987706902880375, 0.987706902880375, 0.9897220507005272, 0.9897220507005272, 0.9897220507005272, 0.2383509694378082, 0.2383509694378082, 0.2383509694378082, 0.43513028170558377, 0.43513028170558377, 0.43513028170558377, 0.343555979682145, 0.343555979682145, 0.343555979682145, 0.6653278287134308, 0.6653278287134308, 0.6653278287134308, 0.1604575716387091, 0.1604575716387091, 0.1604575716387091, 0.16901554181292444, 0.16901554181292444, 0.16901554181292444, 0.12271892663785233, 0.12271892663785233, 0.12271892663785233, 0.21007223620584148, 0.21007223620584148, 0.21007223620584148, 0.20509295815017814, 0.20509295815017814, 0.20509295815017814, 0.2297470639663598, 0.2297470639663598, 0.2297470639663598, 0.2679870408934164, 0.2679870408934164, 0.2679870408934164, 0.24330079264327986, 0.24330079264327986, 0.24330079264327986, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03977941681689812, 0.03977941681689812, 0.03977941681689812, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12560897739369326, 0.12560897739369326, 0.12560897739369326, 0.02550559102497485, 0.02550559102497485, 0.02550559102497485, 0.04343040253146968, 0.04343040253146968, 0.04343040253146968, 0.04980442159481413, 0.04980442159481413, 0.04980442159481413, 0.06623588746615983, 0.06623588746615983, 0.06623588746615983, 0.06490342888655087, 0.06490342888655087, 0.06490342888655087, 0.13306294612694258, 0.13306294612694258, 0.13306294612694258, 0.2326587797572437, 0.2326587797572437, 0.2326587797572437, 0.08275407711222382, 0.08275407711222382, 0.08275407711222382, 0.511384258811489, 0.511384258811489, 0.511384258811489, 0.5017264027215089, 0.5017264027215089, 0.5017264027215089, 0.5284849737774326, 0.5284849737774326, 0.5284849737774326, 0.11672512592784112, 0.11672512592784112, 0.11672512592784112, 0.10035401249815334, 0.10035401249815334, 0.10035401249815334, 0.12427463406691819, 0.12427463406691819, 0.12427463406691819, 0.2180053597344066, 0.2180053597344066, 0.2180053597344066, 0.23182803073681746, 0.23182803073681746, 0.23182803073681746, 0.3550514672816023, 0.3550514672816023, 0.3550514672816023, 0.3261400422579006, 0.3261400422579006, 0.3261400422579006, 0.36540273587429306, 0.36540273587429306, 0.36540273587429306, 0.4431995185530464, 0.4431995185530464, 0.4431995185530464, 0.18424108325849986, 0.18424108325849986, 0.18424108325849986, 0.1937394060473301, 0.1937394060473301, 0.1937394060473301, 0.12427115781974096, 0.12427115781974096, 0.12427115781974096, 0.17618476806607375, 0.17618476806607375, 0.17618476806607375, 0.1827527870252137, 0.1827527870252137, 0.1827527870252137, 0.18471290265600104, 0.18471290265600104, 0.18471290265600104, 0.2395774814288989, 0.2395774814288989, 0.2395774814288989, 0.20269929326095104, 0.20269929326095104, 0.20269929326095104, 0.19438510542468423, 0.19438510542468423, 0.19438510542468423, 0.8451591836427575, 0.8451591836427575, 0.8451591836427575, 0.16003493352875264, 0.16003493352875264, 0.16003493352875264, 0.750850398292666, 0.750850398292666, 0.750850398292666, 0.16935986121380953, 0.16935986121380953, 0.16935986121380953, 0.21067463891537208, 0.21067463891537208, 0.21067463891537208, 0.1563448815141142, 0.1563448815141142, 0.1563448815141142, 0.1714522191911121, 0.1714522191911121, 0.1714522191911121, 0.18381130856635963, 0.18381130856635963, 0.18381130856635963, 0.18847015011813129, 0.18847015011813129, 0.18847015011813129, 0.07273981487732539, 0.07273981487732539, 0.07273981487732539, 0.0683642098228705, 0.0683642098228705, 0.0683642098228705, 0.08160799378961947, 0.08160799378961947, 0.08160799378961947]}, "mutation_prompt": null}
{"id": "26f71bee-c941-4d53-b9b7-fdd5a95cb23d", "solution": "import numpy as np\n\nclass DynamicHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 24\n        self.initial_de_f = 0.9\n        self.initial_de_cr = 0.9\n        self.initial_pso_w = 0.6\n        self.pso_c1 = 1.2\n        self.pso_c2 = 1.4\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        temp = np.random.uniform(self.lb, self.ub, self.dim)\n                        temp_fitness = func(temp)\n                        if temp_fitness < personal_best_fitness[idx]:\n                            population[idx] = temp\n                            fitness[idx] = temp_fitness\n                            personal_best[idx] = temp\n                            personal_best_fitness[idx] = temp_fitness\n                            if temp_fitness < personal_best_fitness[global_best_idx]:\n                                global_best = temp\n                                global_best_idx = idx\n                        self.eval_count += 1\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicHybridDEPSO", "description": "A dynamic hybrid optimization algorithm combining DE, PSO, and simulated annealing concepts for adaptive exploration and exploitation with enhanced diversity management.", "configspace": "", "generation": 65, "fitness": 0.3020975264532232, "feedback": "The algorithm DynamicHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.27.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8469936802082856, 0.8469936802082856, 0.8469936802082856, 0.8748332914170573, 0.8748332914170573, 0.8748332914170573, 0.8692303836948149, 0.8692303836948149, 0.8692303836948149, 0.7448002765370381, 0.7448002765370381, 0.7448002765370381, 0.7692899543033234, 0.7692899543033234, 0.7692899543033234, 0.004873506738465538, 0.004873506738465538, 0.004873506738465538, 0.1503398321514422, 0.1503398321514422, 0.1503398321514422, 0.15097548224645674, 0.15097548224645674, 0.15097548224645674, 0.1452123888918011, 0.1452123888918011, 0.1452123888918011, 0.10385196347891468, 0.10385196347891468, 0.10385196347891468, 0.09271408028351857, 0.09271408028351857, 0.09271408028351857, 0.10146801561136021, 0.10146801561136021, 0.10146801561136021, 0.9871507309633328, 0.9871507309633328, 0.9871507309633328, 0.9847525436312274, 0.9847525436312274, 0.9847525436312274, 0.9852574965968145, 0.9852574965968145, 0.9852574965968145, 0.656808570903949, 0.656808570903949, 0.656808570903949, 0.5513539513967249, 0.5513539513967249, 0.5513539513967249, 0.6342991253829101, 0.6342991253829101, 0.6342991253829101, 0.22441307386376397, 0.22441307386376397, 0.22441307386376397, 0.2649701035876122, 0.2649701035876122, 0.2649701035876122, 0.22989875263615567, 0.22989875263615567, 0.22989875263615567, 0.2800754928072491, 0.2800754928072491, 0.2800754928072491, 0.10474335973747206, 0.10474335973747206, 0.10474335973747206, 0.24738461283542557, 0.24738461283542557, 0.24738461283542557, 0.12482578029623781, 0.12482578029623781, 0.12482578029623781, 0.27733953592369653, 0.27733953592369653, 0.27733953592369653, 0.13123863411108505, 0.13123863411108505, 0.13123863411108505, 0.07118474369817618, 0.07118474369817618, 0.07118474369817618, 0.01796616263378259, 0.01796616263378259, 0.01796616263378259, 0.04937944447340692, 0.04937944447340692, 0.04937944447340692, 0.04804945112410364, 0.04804945112410364, 0.04804945112410364, 0.0772140802673239, 0.0772140802673239, 0.0772140802673239, 0.05294082170847725, 0.05294082170847725, 0.05294082170847725, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08758451553329938, 0.08758451553329938, 0.08758451553329938, 0.2002024485953955, 0.2002024485953955, 0.2002024485953955, 0.14465428128635427, 0.14465428128635427, 0.14465428128635427, 0.03856664276853006, 0.03856664276853006, 0.03856664276853006, 0.17694714309418846, 0.17694714309418846, 0.17694714309418846, 0.5339406656006995, 0.5339406656006995, 0.5339406656006995, 0.5324293576708528, 0.5324293576708528, 0.5324293576708528, 0.6042518974146873, 0.6042518974146873, 0.6042518974146873, 0.09398921457072806, 0.09398921457072806, 0.09398921457072806, 0.10622463070413013, 0.10622463070413013, 0.10622463070413013, 0.12466854245425307, 0.12466854245425307, 0.12466854245425307, 0.22137447586637626, 0.22137447586637626, 0.22137447586637626, 0.18853813064309444, 0.18853813064309444, 0.18853813064309444, 0.2178878683996679, 0.2178878683996679, 0.2178878683996679, 0.3753403498322867, 0.3753403498322867, 0.3753403498322867, 0.3474621422847535, 0.3474621422847535, 0.3474621422847535, 0.47411044889199383, 0.47411044889199383, 0.47411044889199383, 0.2858094460639582, 0.2858094460639582, 0.2858094460639582, 0.22161486933130614, 0.22161486933130614, 0.22161486933130614, 0.1372483020821773, 0.1372483020821773, 0.1372483020821773, 0.19388694524295946, 0.19388694524295946, 0.19388694524295946, 0.21369407603340063, 0.21369407603340063, 0.21369407603340063, 0.21610273029600935, 0.21610273029600935, 0.21610273029600935, 0.2330934416949101, 0.2330934416949101, 0.2330934416949101, 0.5725716143434418, 0.5725716143434418, 0.5725716143434418, 0.20996399583103043, 0.20996399583103043, 0.20996399583103043, 0.8179725143504231, 0.8179725143504231, 0.8179725143504231, 0.1657813423663712, 0.1657813423663712, 0.1657813423663712, 0.11154093759245043, 0.11154093759245043, 0.11154093759245043, 0.8448501507308217, 0.8448501507308217, 0.8448501507308217, 0.21082135021295745, 0.21082135021295745, 0.21082135021295745, 0.16710777987568814, 0.16710777987568814, 0.16710777987568814, 0.18639930654139325, 0.18639930654139325, 0.18639930654139325, 0.20590489046630933, 0.20590489046630933, 0.20590489046630933, 0.18283260522971911, 0.18283260522971911, 0.18283260522971911, 0.09016471918110092, 0.09016471918110092, 0.09016471918110092, 0.07813222645533913, 0.07813222645533913, 0.07813222645533913, 0.08142658095760269, 0.08142658095760269, 0.08142658095760269]}, "mutation_prompt": null}
{"id": "2f29fd8d-7c22-4e2e-8aa9-f7d78c894ac6", "solution": "import numpy as np\n\nclass AdvancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(2, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdvancedHybridDEPSO", "description": "An advanced hybrid evolutionary algorithm integrating Differential Evolution and Particle Swarm Optimization with a dynamic strategy adaptation and balance between exploration and exploitation to efficiently solve complex optimization problems.", "configspace": "", "generation": 66, "fitness": 0.3103579227144974, "feedback": "The algorithm AdvancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8623605938385098, 0.8623605938385098, 0.8623605938385098, 0.8932547066168871, 0.8932547066168871, 0.8932547066168871, 0.8722816552751078, 0.8722816552751078, 0.8722816552751078, 0.7699910525179842, 0.7699910525179842, 0.7699910525179842, 0.7741777930071491, 0.7741777930071491, 0.7741777930071491, 0.7271649783865792, 0.7271649783865792, 0.7271649783865792, 0.11708164807094035, 0.11708164807094035, 0.11708164807094035, 0.12951893912930168, 0.12951893912930168, 0.12951893912930168, 0.14762743755972496, 0.14762743755972496, 0.14762743755972496, 0.12471288079514176, 0.12471288079514176, 0.12471288079514176, 0.15167464024730248, 0.15167464024730248, 0.15167464024730248, 0.11593652142426558, 0.11593652142426558, 0.11593652142426558, 0.9849261285893748, 0.9849261285893748, 0.9849261285893748, 0.9814481799772111, 0.9814481799772111, 0.9814481799772111, 0.9887924082879689, 0.9887924082879689, 0.9887924082879689, 0.3282943656591527, 0.3282943656591527, 0.3282943656591527, 0.46480656972997336, 0.46480656972997336, 0.46480656972997336, 0.09921842119053725, 0.09921842119053725, 0.09921842119053725, 0.17157339522019555, 0.17157339522019555, 0.17157339522019555, 0.16099026516889425, 0.16099026516889425, 0.16099026516889425, 0.22828929181654845, 0.22828929181654845, 0.22828929181654845, 0.2513531441191915, 0.2513531441191915, 0.2513531441191915, 0.1253928992877198, 0.1253928992877198, 0.1253928992877198, 0.23813767815845177, 0.23813767815845177, 0.23813767815845177, 0.27093549150940366, 0.27093549150940366, 0.27093549150940366, 0.270688388767636, 0.270688388767636, 0.270688388767636, 0.27212055303333693, 0.27212055303333693, 0.27212055303333693, 0.10070989543992459, 0.10070989543992459, 0.10070989543992459, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04943151166403681, 0.04943151166403681, 0.04943151166403681, 0.0719063412682941, 0.0719063412682941, 0.0719063412682941, 0.010430040744470515, 0.010430040744470515, 0.010430040744470515, 0.08284808521912057, 0.08284808521912057, 0.08284808521912057, 0.035758560492257896, 0.035758560492257896, 0.035758560492257896, 0.07604449117397505, 0.07604449117397505, 0.07604449117397505, 0.10063538216398504, 0.10063538216398504, 0.10063538216398504, 0.0934276769324055, 0.0934276769324055, 0.0934276769324055, 0.03960971536281355, 0.03960971536281355, 0.03960971536281355, 0.09913672512326144, 0.09913672512326144, 0.09913672512326144, 0.6243953499505368, 0.6243953499505368, 0.6243953499505368, 0.5879184394022725, 0.5879184394022725, 0.5879184394022725, 0.5882566571146566, 0.5882566571146566, 0.5882566571146566, 0.10779614829549178, 0.10779614829549178, 0.10779614829549178, 0.17288683157040996, 0.17288683157040996, 0.17288683157040996, 0.10844391701578082, 0.10844391701578082, 0.10844391701578082, 0.16181188884656694, 0.16181188884656694, 0.16181188884656694, 0.17729155033747446, 0.17729155033747446, 0.17729155033747446, 0.18910743687827336, 0.18910743687827336, 0.18910743687827336, 0.3679654350415218, 0.3679654350415218, 0.3679654350415218, 0.3369072074459192, 0.3369072074459192, 0.3369072074459192, 0.6426942055517315, 0.6426942055517315, 0.6426942055517315, 0.18234896274147228, 0.18234896274147228, 0.18234896274147228, 0.20932209134731639, 0.20932209134731639, 0.20932209134731639, 0.19576215842965294, 0.19576215842965294, 0.19576215842965294, 0.2139643002282181, 0.2139643002282181, 0.2139643002282181, 0.18066104332514332, 0.18066104332514332, 0.18066104332514332, 0.2077891511708242, 0.2077891511708242, 0.2077891511708242, 0.22422722565929654, 0.22422722565929654, 0.22422722565929654, 0.558607249975748, 0.558607249975748, 0.558607249975748, 0.22019926575984605, 0.22019926575984605, 0.22019926575984605, 0.9180784615360122, 0.9180784615360122, 0.9180784615360122, 0.1756449581216084, 0.1756449581216084, 0.1756449581216084, 0.1692834443238762, 0.1692834443238762, 0.1692834443238762, 0.8591998200677322, 0.8591998200677322, 0.8591998200677322, 0.21261539075484293, 0.21261539075484293, 0.21261539075484293, 0.684257086310776, 0.684257086310776, 0.684257086310776, 0.18912939267610762, 0.18912939267610762, 0.18912939267610762, 0.16915968144167126, 0.16915968144167126, 0.16915968144167126, 0.1775423861319556, 0.1775423861319556, 0.1775423861319556, 0.07366349580898035, 0.07366349580898035, 0.07366349580898035, 0.1009720401444143, 0.1009720401444143, 0.1009720401444143, 0.0750793090686489, 0.0750793090686489, 0.0750793090686489]}, "mutation_prompt": null}
{"id": "b0e4ab68-df9c-48be-b9b7-d321e43d2312", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adapted Inertia weight\n        self.pso_c1 = 1.3  # Adapted Cognitive coefficient\n        self.pso_c2 = 1.1  # Adapted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.7 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.50:  # diversify earlier\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO2", "description": "An innovative hybrid algorithm integrating dynamic strategies of Differential Evolution and Particle Swarm Optimization with a focus on adaptive parameter tuning and enhanced convergence speed through probabilistic diversity interventions.", "configspace": "", "generation": 67, "fitness": 0.305945287008903, "feedback": "The algorithm AdaptiveHybridDEPSO2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8982531576776998, 0.8982531576776998, 0.8982531576776998, 0.886889478656349, 0.886889478656349, 0.886889478656349, 0.874455620775971, 0.874455620775971, 0.874455620775971, 0.7740377450186576, 0.7740377450186576, 0.7740377450186576, 0.7860077431368307, 0.7860077431368307, 0.7860077431368307, 0.782330608386377, 0.782330608386377, 0.782330608386377, 0.11741568128577184, 0.11741568128577184, 0.11741568128577184, 0.11180080895116185, 0.11180080895116185, 0.11180080895116185, 0.1173122958934869, 0.1173122958934869, 0.1173122958934869, 0.1318645215479386, 0.1318645215479386, 0.1318645215479386, 0.10904312231722946, 0.10904312231722946, 0.10904312231722946, 0.1133607456984127, 0.1133607456984127, 0.1133607456984127, 0.9833460330698572, 0.9833460330698572, 0.9833460330698572, 0.9847009054221614, 0.9847009054221614, 0.9847009054221614, 0.9847217880436285, 0.9847217880436285, 0.9847217880436285, 0.27004146307111976, 0.27004146307111976, 0.27004146307111976, 0.37575451825446393, 0.37575451825446393, 0.37575451825446393, 0.10701500988589396, 0.10701500988589396, 0.10701500988589396, 0.782144213413834, 0.782144213413834, 0.782144213413834, 0.16196514007146912, 0.16196514007146912, 0.16196514007146912, 0.24483842372723463, 0.24483842372723463, 0.24483842372723463, 0.264004444161724, 0.264004444161724, 0.264004444161724, 0.2752811362323847, 0.2752811362323847, 0.2752811362323847, 0.2652694525703635, 0.2652694525703635, 0.2652694525703635, 0.2653109407560722, 0.2653109407560722, 0.2653109407560722, 0.13427448248531204, 0.13427448248531204, 0.13427448248531204, 0.30698234291054305, 0.30698234291054305, 0.30698234291054305, 0.05038679762494447, 0.05038679762494447, 0.05038679762494447, 0.05491789432765959, 0.05491789432765959, 0.05491789432765959, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05536090352648293, 0.05536090352648293, 0.05536090352648293, 0.07035300151973334, 0.07035300151973334, 0.07035300151973334, 0.10608668719912473, 0.10608668719912473, 0.10608668719912473, 0.036225755659454295, 0.036225755659454295, 0.036225755659454295, 0.139365936517871, 0.139365936517871, 0.139365936517871, 0.09851239501909936, 0.09851239501909936, 0.09851239501909936, 0.22011256259627288, 0.22011256259627288, 0.22011256259627288, 0.22578140760689702, 0.22578140760689702, 0.22578140760689702, 0.2416007859961533, 0.2416007859961533, 0.2416007859961533, 0.597331771878045, 0.597331771878045, 0.597331771878045, 0.5694336911524258, 0.5694336911524258, 0.5694336911524258, 0.571308983066499, 0.571308983066499, 0.571308983066499, 0.09495042733594306, 0.09495042733594306, 0.09495042733594306, 0.09469516898438246, 0.09469516898438246, 0.09469516898438246, 0.11371785237501641, 0.11371785237501641, 0.11371785237501641, 0.14256267476574558, 0.14256267476574558, 0.14256267476574558, 0.1306069521648513, 0.1306069521648513, 0.1306069521648513, 0.1543830348268792, 0.1543830348268792, 0.1543830348268792, 0.44141808522776604, 0.44141808522776604, 0.44141808522776604, 0.21419626238736544, 0.21419626238736544, 0.21419626238736544, 0.283629849189022, 0.283629849189022, 0.283629849189022, 0.3249665470438353, 0.3249665470438353, 0.3249665470438353, 0.21287953746900434, 0.21287953746900434, 0.21287953746900434, 0.14082403176140046, 0.14082403176140046, 0.14082403176140046, 0.16641145205452268, 0.16641145205452268, 0.16641145205452268, 0.18466989207632034, 0.18466989207632034, 0.18466989207632034, 0.18561027476647862, 0.18561027476647862, 0.18561027476647862, 0.21258183076852244, 0.21258183076852244, 0.21258183076852244, 0.19414083601708987, 0.19414083601708987, 0.19414083601708987, 0.22280132230512872, 0.22280132230512872, 0.22280132230512872, 0.9470561268180403, 0.9470561268180403, 0.9470561268180403, 0.15838117785494688, 0.15838117785494688, 0.15838117785494688, 0.9149716907443096, 0.9149716907443096, 0.9149716907443096, 0.1652130746486138, 0.1652130746486138, 0.1652130746486138, 0.21158493355304664, 0.21158493355304664, 0.21158493355304664, 0.17652801958411968, 0.17652801958411968, 0.17652801958411968, 0.19412344918588875, 0.19412344918588875, 0.19412344918588875, 0.19378378801115193, 0.19378378801115193, 0.19378378801115193, 0.1868788948957848, 0.1868788948957848, 0.1868788948957848, 0.07885419120149306, 0.07885419120149306, 0.07885419120149306, 0.07144790515341226, 0.07144790515341226, 0.07144790515341226, 0.06889098435832564, 0.06889098435832564, 0.06889098435832564]}, "mutation_prompt": null}
{"id": "2f5fd242-b032-4696-a8ab-f9bc8ab50efc", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for better exploration\n        self.initial_de_f = 0.9  # Enhanced Differential weight\n        self.initial_de_cr = 0.9  # Enhanced Crossover probability\n        self.initial_pso_w = 0.6  # Enhanced Inertia weight\n        self.pso_c1 = 1.1  # Enhanced Cognitive coefficient\n        self.pso_c2 = 1.3  # Enhanced Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm integrating enhanced Differential Evolution and Particle Swarm Optimization with enhanced diversity and strategy adaptation for effective exploration and exploitation of complex search spaces.", "configspace": "", "generation": 68, "fitness": 0.2673583160398485, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.25.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.872114188242028, 0.872114188242028, 0.872114188242028, 0.8772404195652365, 0.8772404195652365, 0.8772404195652365, 0.8553080085055431, 0.8553080085055431, 0.8553080085055431, 0.2459140039730393, 0.2459140039730393, 0.2459140039730393, 0.7675797435088254, 0.7675797435088254, 0.7675797435088254, 0.10315048484164313, 0.10315048484164313, 0.10315048484164313, 0.15511185320884402, 0.15511185320884402, 0.15511185320884402, 0.1435612755690847, 0.1435612755690847, 0.1435612755690847, 0.15562552212635705, 0.15562552212635705, 0.15562552212635705, 0.12163236785849474, 0.12163236785849474, 0.12163236785849474, 0.11763404175466863, 0.11763404175466863, 0.11763404175466863, 0.13719138752214333, 0.13719138752214333, 0.13719138752214333, 0.3503008921489057, 0.3503008921489057, 0.3503008921489057, 0.9800579883149081, 0.9800579883149081, 0.9800579883149081, 0.9897425312758568, 0.9897425312758568, 0.9897425312758568, 0.6372136035476299, 0.6372136035476299, 0.6372136035476299, 0.15133354674288768, 0.15133354674288768, 0.15133354674288768, 0.6581000045730809, 0.6581000045730809, 0.6581000045730809, 0.22378760606577908, 0.22378760606577908, 0.22378760606577908, 0.19038646189721287, 0.19038646189721287, 0.19038646189721287, 0.1177078649347768, 0.1177078649347768, 0.1177078649347768, 0.2860199953068032, 0.2860199953068032, 0.2860199953068032, 0.26748910650114555, 0.26748910650114555, 0.26748910650114555, 0.4098206734134848, 0.4098206734134848, 0.4098206734134848, 0.12110381626888433, 0.12110381626888433, 0.12110381626888433, 0.1346406124965972, 0.1346406124965972, 0.1346406124965972, 0.22589981356716582, 0.22589981356716582, 0.22589981356716582, 0.04258949033901971, 0.04258949033901971, 0.04258949033901971, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12419469186018994, 0.12419469186018994, 0.12419469186018994, 0.06562072607697378, 0.06562072607697378, 0.06562072607697378, 0.06468204152310975, 0.06468204152310975, 0.06468204152310975, 0.07423472659061026, 0.07423472659061026, 0.07423472659061026, 0.10076876709370719, 0.10076876709370719, 0.10076876709370719, 0.07155328057118682, 0.07155328057118682, 0.07155328057118682, 0.1339290099471051, 0.1339290099471051, 0.1339290099471051, 0.03827884107469903, 0.03827884107469903, 0.03827884107469903, 0.00977190056902777, 0.00977190056902777, 0.00977190056902777, 0.5302560251729346, 0.5302560251729346, 0.5302560251729346, 0.5592469533323561, 0.5592469533323561, 0.5592469533323561, 0.5570913300665975, 0.5570913300665975, 0.5570913300665975, 0.10780572449483228, 0.10780572449483228, 0.10780572449483228, 0.10343497167465154, 0.10343497167465154, 0.10343497167465154, 0.12061617277320824, 0.12061617277320824, 0.12061617277320824, 0.2461090454842927, 0.2461090454842927, 0.2461090454842927, 0.1704913624558254, 0.1704913624558254, 0.1704913624558254, 0.1974369207168376, 0.1974369207168376, 0.1974369207168376, 0.3355680298009177, 0.3355680298009177, 0.3355680298009177, 0.2205369301832567, 0.2205369301832567, 0.2205369301832567, 0.6341394107910825, 0.6341394107910825, 0.6341394107910825, 0.2931109918734339, 0.2931109918734339, 0.2931109918734339, 0.19276924986419974, 0.19276924986419974, 0.19276924986419974, 0.14015858915813972, 0.14015858915813972, 0.14015858915813972, 0.2049345801178749, 0.2049345801178749, 0.2049345801178749, 0.19200074487491348, 0.19200074487491348, 0.19200074487491348, 0.21862278297439286, 0.21862278297439286, 0.21862278297439286, 0.24728471495006277, 0.24728471495006277, 0.24728471495006277, 0.19476671394102063, 0.19476671394102063, 0.19476671394102063, 0.19962759753928316, 0.19962759753928316, 0.19962759753928316, 0.8771630697321665, 0.8771630697321665, 0.8771630697321665, 0.20814524532934275, 0.20814524532934275, 0.20814524532934275, 0.1836137542132501, 0.1836137542132501, 0.1836137542132501, 0.1210281313302628, 0.1210281313302628, 0.1210281313302628, 0.21210019476341413, 0.21210019476341413, 0.21210019476341413, 0.15631266155065715, 0.15631266155065715, 0.15631266155065715, 0.1802895452040375, 0.1802895452040375, 0.1802895452040375, 0.1935997880912219, 0.1935997880912219, 0.1935997880912219, 0.18783580665847055, 0.18783580665847055, 0.18783580665847055, 0.08981705020277109, 0.08981705020277109, 0.08981705020277109, 0.07835563113019539, 0.07835563113019539, 0.07835563113019539, 0.07403774504653138, 0.07403774504653138, 0.07403774504653138]}, "mutation_prompt": null}
{"id": "4507df0a-5b1e-4474-a197-1b16f511adf7", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "190d2c4b-4359-4715-bf0f-54a74c96029b", "solution": "import numpy as np\n\nclass DynamicExplorationDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Slightly increased Differential weight\n        self.initial_de_cr = 0.7  # Lower initial Crossover probability for exploration\n        self.initial_pso_w = 0.7  # Increased Inertia weight for better exploration\n        self.pso_c1 = 1.5  # Enhanced Cognitive coefficient\n        self.pso_c2 = 1.5  # Enhanced Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Dynamic adjustment of DE and PSO parameters\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.9 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.2 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Stochastic diversity injection\n            if np.random.rand() < 0.3:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicExplorationDEPSO", "description": "DynamicExplorationDEPSO: A dynamic exploration-enhanced hybrid algorithm merging Differential Evolution and Particle Swarm Optimization with adaptive parameter tuning and stochastic diversity injection for robust optimization.", "configspace": "", "generation": 70, "fitness": 0.2132168386342765, "feedback": "The algorithm DynamicExplorationDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.21.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.4721863578307357, 0.4721863578307357, 0.4721863578307357, 0.5809744794982379, 0.5809744794982379, 0.5809744794982379, 0.5096012275692443, 0.5096012275692443, 0.5096012275692443, 0.14677765034712775, 0.14677765034712775, 0.14677765034712775, 0.016136258204672016, 0.016136258204672016, 0.016136258204672016, 0.14675823504254837, 0.14675823504254837, 0.14675823504254837, 0.09906173161674214, 0.09906173161674214, 0.09906173161674214, 0.11830038043939717, 0.11830038043939717, 0.11830038043939717, 0.11937704010101224, 0.11937704010101224, 0.11937704010101224, 0.0892434236017614, 0.0892434236017614, 0.0892434236017614, 0.1126609920496423, 0.1126609920496423, 0.1126609920496423, 0.09248630948620973, 0.09248630948620973, 0.09248630948620973, 0.9910207801343733, 0.9910207801343733, 0.9910207801343733, 0.9908693918652492, 0.9908693918652492, 0.9908693918652492, 0.9917584764273953, 0.9917584764273953, 0.9917584764273953, 0.24769161378477245, 0.24769161378477245, 0.24769161378477245, 0.14030394812679658, 0.14030394812679658, 0.14030394812679658, 0.20570447750724674, 0.20570447750724674, 0.20570447750724674, 0.197089940067244, 0.197089940067244, 0.197089940067244, 0.29042084666394474, 0.29042084666394474, 0.29042084666394474, 0.15332876310241095, 0.15332876310241095, 0.15332876310241095, 0.14099350304907854, 0.14099350304907854, 0.14099350304907854, 0.09047102345101887, 0.09047102345101887, 0.09047102345101887, 0.1160099401254363, 0.1160099401254363, 0.1160099401254363, 0.14182500707677903, 0.14182500707677903, 0.14182500707677903, 0.08955230975760264, 0.08955230975760264, 0.08955230975760264, 0.11819409141163784, 0.11819409141163784, 0.11819409141163784, 0.0032804324015723862, 0.0032804324015723862, 0.0032804324015723862, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08884807781533277, 0.08884807781533277, 0.08884807781533277, 0.08560247973630342, 0.08560247973630342, 0.08560247973630342, 0.10060474510676798, 0.10060474510676798, 0.10060474510676798, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.035570541553630375, 0.035570541553630375, 0.035570541553630375, 0.040888660194688065, 0.040888660194688065, 0.040888660194688065, 0.03669720507603613, 0.03669720507603613, 0.03669720507603613, 0.08906849958561525, 0.08906849958561525, 0.08906849958561525, 0.041731367224401406, 0.041731367224401406, 0.041731367224401406, 0.41180172853803787, 0.41180172853803787, 0.41180172853803787, 0.4271298514387487, 0.4271298514387487, 0.4271298514387487, 0.3861416724700679, 0.3861416724700679, 0.3861416724700679, 0.08439413563064102, 0.08439413563064102, 0.08439413563064102, 0.08757744215142471, 0.08757744215142471, 0.08757744215142471, 0.09829994096499761, 0.09829994096499761, 0.09829994096499761, 0.1937591186310763, 0.1937591186310763, 0.1937591186310763, 0.18323501249239094, 0.18323501249239094, 0.18323501249239094, 0.17969761894589686, 0.17969761894589686, 0.17969761894589686, 0.2729596576937604, 0.2729596576937604, 0.2729596576937604, 0.27255033190907263, 0.27255033190907263, 0.27255033190907263, 0.32351677402468726, 0.32351677402468726, 0.32351677402468726, 0.22501077780137912, 0.22501077780137912, 0.22501077780137912, 0.1621171531495642, 0.1621171531495642, 0.1621171531495642, 0.21109655265165184, 0.21109655265165184, 0.21109655265165184, 0.17876528465328279, 0.17876528465328279, 0.17876528465328279, 0.1890597183709689, 0.1890597183709689, 0.1890597183709689, 0.18352969093876237, 0.18352969093876237, 0.18352969093876237, 0.19606868275506262, 0.19606868275506262, 0.19606868275506262, 0.17691791525999145, 0.17691791525999145, 0.17691791525999145, 0.17622748381615294, 0.17622748381615294, 0.17622748381615294, 0.4810067278454975, 0.4810067278454975, 0.4810067278454975, 0.4289689799553946, 0.4289689799553946, 0.4289689799553946, 0.509405803523779, 0.509405803523779, 0.509405803523779, 0.14914256615554444, 0.14914256615554444, 0.14914256615554444, 0.24249287814082776, 0.24249287814082776, 0.24249287814082776, 0.21259417303927508, 0.21259417303927508, 0.21259417303927508, 0.17973788324045836, 0.17973788324045836, 0.17973788324045836, 0.1866679914061894, 0.1866679914061894, 0.1866679914061894, 0.19800856848858983, 0.19800856848858983, 0.19800856848858983, 0.07674197835774144, 0.07674197835774144, 0.07674197835774144, 0.06752865017923015, 0.06752865017923015, 0.06752865017923015, 0.06806943001509602, 0.06806943001509602, 0.06806943001509602]}, "mutation_prompt": null}
{"id": "9e60f454-4780-44d6-aca4-228791eed070", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8\n        self.initial_de_cr = 0.85\n        self.initial_pso_w = 0.5\n        self.pso_c1 = 1.0\n        self.pso_c2 = 1.2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.65:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A dynamically adaptive algorithm integrating Differential Evolution (DE) and Particle Swarm Optimization (PSO) with a probabilistic approach to enhance exploration-exploitation balance throughout the optimization process.", "configspace": "", "generation": 71, "fitness": 0.35464351652459986, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.32.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9273539334063186, 0.9273539334063186, 0.9273539334063186, 0.9295454137533984, 0.9295454137533984, 0.9295454137533984, 0.9318577542796118, 0.9318577542796118, 0.9318577542796118, 0.8408668148779803, 0.8408668148779803, 0.8408668148779803, 0.8579506945505551, 0.8579506945505551, 0.8579506945505551, 0.055893858704747834, 0.055893858704747834, 0.055893858704747834, 0.14787543412152937, 0.14787543412152937, 0.14787543412152937, 0.1603028110189505, 0.1603028110189505, 0.1603028110189505, 0.15498517740109385, 0.15498517740109385, 0.15498517740109385, 0.13191416391469923, 0.13191416391469923, 0.13191416391469923, 0.1585853232137211, 0.1585853232137211, 0.1585853232137211, 0.09027351703489406, 0.09027351703489406, 0.09027351703489406, 0.9889014232132185, 0.9889014232132185, 0.9889014232132185, 0.9871532933026772, 0.9871532933026772, 0.9871532933026772, 0.9880386738526277, 0.9880386738526277, 0.9880386738526277, 0.8305496829511221, 0.8305496829511221, 0.8305496829511221, 0.7322174030377602, 0.7322174030377602, 0.7322174030377602, 0.8237278706354088, 0.8237278706354088, 0.8237278706354088, 0.2142127043602945, 0.2142127043602945, 0.2142127043602945, 0.19335128338530116, 0.19335128338530116, 0.19335128338530116, 0.9416482621452924, 0.9416482621452924, 0.9416482621452924, 0.2217788798120236, 0.2217788798120236, 0.2217788798120236, 0.12879268184800674, 0.12879268184800674, 0.12879268184800674, 0.320809250899212, 0.320809250899212, 0.320809250899212, 0.27929394670701657, 0.27929394670701657, 0.27929394670701657, 0.31568368574244476, 0.31568368574244476, 0.31568368574244476, 0.31427440032106113, 0.31427440032106113, 0.31427440032106113, 0.08806182538950436, 0.08806182538950436, 0.08806182538950436, 0.020523632959793425, 0.020523632959793425, 0.020523632959793425, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09156707095986327, 0.09156707095986327, 0.09156707095986327, 0.0021786579448555, 0.0021786579448555, 0.0021786579448555, 0.09237152135704307, 0.09237152135704307, 0.09237152135704307, 0.12441138566842824, 0.12441138566842824, 0.12441138566842824, 0.082713360194419, 0.082713360194419, 0.082713360194419, 0.07708177871319277, 0.07708177871319277, 0.07708177871319277, 0.15928662990914744, 0.15928662990914744, 0.15928662990914744, 0.039812995910592175, 0.039812995910592175, 0.039812995910592175, 0.16257535204162377, 0.16257535204162377, 0.16257535204162377, 0.5646998362875959, 0.5646998362875959, 0.5646998362875959, 0.5845958449796169, 0.5845958449796169, 0.5845958449796169, 0.6661287751323148, 0.6661287751323148, 0.6661287751323148, 0.13157252553825471, 0.13157252553825471, 0.13157252553825471, 0.06299692989638028, 0.06299692989638028, 0.06299692989638028, 0.12543782748551535, 0.12543782748551535, 0.12543782748551535, 0.1986920173374278, 0.1986920173374278, 0.1986920173374278, 0.20159793030843398, 0.20159793030843398, 0.20159793030843398, 0.16331448192813658, 0.16331448192813658, 0.16331448192813658, 0.43234969388583333, 0.43234969388583333, 0.43234969388583333, 0.2496831451615763, 0.2496831451615763, 0.2496831451615763, 0.58562229495654, 0.58562229495654, 0.58562229495654, 0.21539718191972046, 0.21539718191972046, 0.21539718191972046, 0.32665240689247943, 0.32665240689247943, 0.32665240689247943, 0.20373157037206557, 0.20373157037206557, 0.20373157037206557, 0.19665489352026366, 0.19665489352026366, 0.19665489352026366, 0.21635218078010376, 0.21635218078010376, 0.21635218078010376, 0.21564643842775733, 0.21564643842775733, 0.21564643842775733, 0.2112554243288134, 0.2112554243288134, 0.2112554243288134, 0.2262708708351585, 0.2262708708351585, 0.2262708708351585, 0.1984055982160985, 0.1984055982160985, 0.1984055982160985, 0.9515217609708838, 0.9515217609708838, 0.9515217609708838, 0.9442859206274443, 0.9442859206274443, 0.9442859206274443, 0.9324488305344564, 0.9324488305344564, 0.9324488305344564, 0.8711287330099795, 0.8711287330099795, 0.8711287330099795, 0.21192232831923563, 0.21192232831923563, 0.21192232831923563, 0.17024455937056449, 0.17024455937056449, 0.17024455937056449, 0.19476244306578328, 0.19476244306578328, 0.19476244306578328, 0.194954956441741, 0.194954956441741, 0.194954956441741, 0.18599881628800452, 0.18599881628800452, 0.18599881628800452, 0.07115657654926744, 0.07115657654926744, 0.07115657654926744, 0.1327198659385196, 0.1327198659385196, 0.1327198659385196, 0.08760798092579192, 0.08760798092579192, 0.08760798092579192]}, "mutation_prompt": null}
{"id": "c748ff36-79e1-4db1-b11d-785290019032", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Adjusted Differential weight\n        self.initial_de_cr = 0.75  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.1  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.3  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.65:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with dynamic parameter adjustment and targeted diversity injections to efficiently navigate complex search spaces.", "configspace": "", "generation": 72, "fitness": 0.3082361532778375, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.29.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8943336835591279, 0.8943336835591279, 0.8943336835591279, 0.8882336914890588, 0.8882336914890588, 0.8882336914890588, 0.888584121983537, 0.888584121983537, 0.888584121983537, 0.04473192105400592, 0.04473192105400592, 0.04473192105400592, 0.7682315067477661, 0.7682315067477661, 0.7682315067477661, 0.8135567346370792, 0.8135567346370792, 0.8135567346370792, 0.12092882384639103, 0.12092882384639103, 0.12092882384639103, 0.10233202173210088, 0.10233202173210088, 0.10233202173210088, 0.12443155658902505, 0.12443155658902505, 0.12443155658902505, 0.14798639624683185, 0.14798639624683185, 0.14798639624683185, 0.16341407334470182, 0.16341407334470182, 0.16341407334470182, 0.11019971914974835, 0.11019971914974835, 0.11019971914974835, 0.9904622958802997, 0.9904622958802997, 0.9904622958802997, 0.9881218099633703, 0.9881218099633703, 0.9881218099633703, 0.9915780974528692, 0.9915780974528692, 0.9915780974528692, 0.5268987422303982, 0.5268987422303982, 0.5268987422303982, 0.5588121226116611, 0.5588121226116611, 0.5588121226116611, 0.5389724889715078, 0.5389724889715078, 0.5389724889715078, 0.7658502985082327, 0.7658502985082327, 0.7658502985082327, 0.35403706748888486, 0.35403706748888486, 0.35403706748888486, 0.12492355153864987, 0.12492355153864987, 0.12492355153864987, 0.13259279096590249, 0.13259279096590249, 0.13259279096590249, 0.13102981320234308, 0.13102981320234308, 0.13102981320234308, 0.31748382382308415, 0.31748382382308415, 0.31748382382308415, 0.269765541588207, 0.269765541588207, 0.269765541588207, 0.29699970996109804, 0.29699970996109804, 0.29699970996109804, 0.29670728497871757, 0.29670728497871757, 0.29670728497871757, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005822271533815537, 0.005822271533815537, 0.005822271533815537, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16965290954737755, 0.16965290954737755, 0.16965290954737755, 0.030694061195664424, 0.030694061195664424, 0.030694061195664424, 0.06858039418836381, 0.06858039418836381, 0.06858039418836381, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07777142342385612, 0.07777142342385612, 0.07777142342385612, 0.12114205434015712, 0.12114205434015712, 0.12114205434015712, 0.13008844220333649, 0.13008844220333649, 0.13008844220333649, 0.0628866036795589, 0.0628866036795589, 0.0628866036795589, 0.05743949108549806, 0.05743949108549806, 0.05743949108549806, 0.5786389398350769, 0.5786389398350769, 0.5786389398350769, 0.562238869906815, 0.562238869906815, 0.562238869906815, 0.5812645381615726, 0.5812645381615726, 0.5812645381615726, 0.10316312488008461, 0.10316312488008461, 0.10316312488008461, 0.10133873608513999, 0.10133873608513999, 0.10133873608513999, 0.11069504811386488, 0.11069504811386488, 0.11069504811386488, 0.1502579659191633, 0.1502579659191633, 0.1502579659191633, 0.1865667543388544, 0.1865667543388544, 0.1865667543388544, 0.7271503046558615, 0.7271503046558615, 0.7271503046558615, 0.44066456547869215, 0.44066456547869215, 0.44066456547869215, 0.34160550474883233, 0.34160550474883233, 0.34160550474883233, 0.214652569955889, 0.214652569955889, 0.214652569955889, 0.2206219429282147, 0.2206219429282147, 0.2206219429282147, 0.19146278067791622, 0.19146278067791622, 0.19146278067791622, 0.12869863260771686, 0.12869863260771686, 0.12869863260771686, 0.20146006473106237, 0.20146006473106237, 0.20146006473106237, 0.20476660250313306, 0.20476660250313306, 0.20476660250313306, 0.19436022258976404, 0.19436022258976404, 0.19436022258976404, 0.19083689223842148, 0.19083689223842148, 0.19083689223842148, 0.24502553301119212, 0.24502553301119212, 0.24502553301119212, 0.2378752381357886, 0.2378752381357886, 0.2378752381357886, 0.9307011319368265, 0.9307011319368265, 0.9307011319368265, 0.15920833903713916, 0.15920833903713916, 0.15920833903713916, 0.16870671599999387, 0.16870671599999387, 0.16870671599999387, 0.7254251223440817, 0.7254251223440817, 0.7254251223440817, 0.2117212033652519, 0.2117212033652519, 0.2117212033652519, 0.20393557702852583, 0.20393557702852583, 0.20393557702852583, 0.1876094558298137, 0.1876094558298137, 0.1876094558298137, 0.1816666629292899, 0.1816666629292899, 0.1816666629292899, 0.1897573088806509, 0.1897573088806509, 0.1897573088806509, 0.08360086007439516, 0.08360086007439516, 0.08360086007439516, 0.08701142225267922, 0.08701142225267922, 0.08701142225267922, 0.07473706408036673, 0.07473706408036673, 0.07473706408036673]}, "mutation_prompt": null}
{"id": "24ba4a60-50cf-4f98-8b2d-e19b7ab7bb32", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSOLA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8\n        self.initial_de_cr = 0.85\n        self.initial_pso_w = 0.5\n        self.pso_c1 = 1.0\n        self.pso_c2 = 1.2\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n        self.learning_rate = 0.1\n        self.strategies_prob = np.array([0.5, 0.5])  # DE, PSO\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            strategy_choice = np.random.choice([0, 1], p=self.strategies_prob)\n            \n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n\n                if strategy_choice == 0:  # Differential Evolution\n                    idxs = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                    cross_points = np.random.rand(self.dim) < de_cr\n                    if not np.any(cross_points):\n                        cross_points[np.random.randint(0, self.dim)] = True\n                    trial = np.where(cross_points, mutant, population[i])\n                    trial_fitness = func(trial)\n                    self.eval_count += 1\n                    if trial_fitness < fitness[i]:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[i]:\n                            personal_best[i] = trial\n                            personal_best_fitness[i] = trial_fitness\n                            if trial_fitness < personal_best_fitness[global_best_idx]:\n                                global_best = trial\n                                global_best_idx = i\n\n                else:  # Particle Swarm Optimization\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    velocity[i] = (pso_w * velocity[i] +\n                                   self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                                   self.pso_c2 * r2 * (global_best - population[i]))\n                    population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                    fitness[i] = func(population[i])\n                    self.eval_count += 1\n                    if fitness[i] < personal_best_fitness[i]:\n                        personal_best[i] = population[i]\n                        personal_best_fitness[i] = fitness[i]\n                        if fitness[i] < personal_best_fitness[global_best_idx]:\n                            global_best = population[i]\n                            global_best_idx = i\n\n            # Encourage diversity\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n            # Update strategy probabilities using Learning Automata\n            best_strategy = np.argmin([np.min(fitness), np.min(fitness)])\n            self.strategies_prob = np.clip(self.strategies_prob + self.learning_rate * (1 - self.strategies_prob[best_strategy]), 0, 1)\n            self.strategies_prob /= np.sum(self.strategies_prob)\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSOLA", "description": "An adaptive blend of Differential Evolution, Particle Swarm Optimization, and Learning Automata to optimize exploration and exploitation phases dynamically based on performance feedback.", "configspace": "", "generation": 73, "fitness": 0.33254493276741925, "feedback": "The algorithm AdaptiveHybridDEPSOLA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.31.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9330997283078242, 0.9330997283078242, 0.9330997283078242, 0.9229973515753878, 0.9229973515753878, 0.9229973515753878, 0.9189896969751566, 0.9189896969751566, 0.9189896969751566, 0.8460821244803787, 0.8460821244803787, 0.8460821244803787, 0.8406118039915748, 0.8406118039915748, 0.8406118039915748, 0.019337169355882367, 0.019337169355882367, 0.019337169355882367, 0.11488720493435356, 0.11488720493435356, 0.11488720493435356, 0.13260211490919938, 0.13260211490919938, 0.13260211490919938, 0.16487626205686934, 0.16487626205686934, 0.16487626205686934, 0.09598554054622876, 0.09598554054622876, 0.09598554054622876, 0.1854504884444731, 0.1854504884444731, 0.1854504884444731, 0.08455118259896666, 0.08455118259896666, 0.08455118259896666, 0.9813159474293162, 0.9813159474293162, 0.9813159474293162, 0.9824084017386447, 0.9824084017386447, 0.9824084017386447, 0.9838200425621113, 0.9838200425621113, 0.9838200425621113, 0.7982669830151388, 0.7982669830151388, 0.7982669830151388, 0.8262380485547522, 0.8262380485547522, 0.8262380485547522, 0.7904242657229955, 0.7904242657229955, 0.7904242657229955, 0.22819325298193915, 0.22819325298193915, 0.22819325298193915, 0.16250922789065736, 0.16250922789065736, 0.16250922789065736, 0.47388965906389946, 0.47388965906389946, 0.47388965906389946, 0.2916964161415565, 0.2916964161415565, 0.2916964161415565, 0.10770719141899465, 0.10770719141899465, 0.10770719141899465, 0.2815141633694851, 0.2815141633694851, 0.2815141633694851, 0.2765152823336835, 0.2765152823336835, 0.2765152823336835, 0.25561857964916457, 0.25561857964916457, 0.25561857964916457, 0.32032896040634273, 0.32032896040634273, 0.32032896040634273, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07686849562178455, 0.07686849562178455, 0.07686849562178455, 0.1074960001654155, 0.1074960001654155, 0.1074960001654155, 0.08743038141039017, 0.08743038141039017, 0.08743038141039017, 0.05043413911583572, 0.05043413911583572, 0.05043413911583572, 0.09225986042320422, 0.09225986042320422, 0.09225986042320422, 0.1037124419201938, 0.1037124419201938, 0.1037124419201938, 0.04391107334588562, 0.04391107334588562, 0.04391107334588562, 0.17303638784443243, 0.17303638784443243, 0.17303638784443243, 0.05856124875162272, 0.05856124875162272, 0.05856124875162272, 0.6280640288957435, 0.6280640288957435, 0.6280640288957435, 0.5712244050640435, 0.5712244050640435, 0.5712244050640435, 0.6479868116098343, 0.6479868116098343, 0.6479868116098343, 0.08837082771259519, 0.08837082771259519, 0.08837082771259519, 0.10323635527275332, 0.10323635527275332, 0.10323635527275332, 0.08472867258966676, 0.08472867258966676, 0.08472867258966676, 0.23266233053097396, 0.23266233053097396, 0.23266233053097396, 0.20431276801119846, 0.20431276801119846, 0.20431276801119846, 0.3998620075927586, 0.3998620075927586, 0.3998620075927586, 0.4121998913884489, 0.4121998913884489, 0.4121998913884489, 0.4069243726831586, 0.4069243726831586, 0.4069243726831586, 0.32436879010718145, 0.32436879010718145, 0.32436879010718145, 0.26923771806361696, 0.26923771806361696, 0.26923771806361696, 0.1869376266752829, 0.1869376266752829, 0.1869376266752829, 0.20912315091024802, 0.20912315091024802, 0.20912315091024802, 0.21123598541644328, 0.21123598541644328, 0.21123598541644328, 0.2157032827805091, 0.2157032827805091, 0.2157032827805091, 0.1707461423239156, 0.1707461423239156, 0.1707461423239156, 0.18063290759280803, 0.18063290759280803, 0.18063290759280803, 0.19716546786816003, 0.19716546786816003, 0.19716546786816003, 0.18316724396089668, 0.18316724396089668, 0.18316724396089668, 0.9535916461660021, 0.9535916461660021, 0.9535916461660021, 0.9496002598208027, 0.9496002598208027, 0.9496002598208027, 0.14642380710787417, 0.14642380710787417, 0.14642380710787417, 0.9100328938146193, 0.9100328938146193, 0.9100328938146193, 0.21231046025499123, 0.21231046025499123, 0.21231046025499123, 0.15706472888167844, 0.15706472888167844, 0.15706472888167844, 0.21521716427787296, 0.21521716427787296, 0.21521716427787296, 0.19048798837519976, 0.19048798837519976, 0.19048798837519976, 0.20832026966067219, 0.20832026966067219, 0.20832026966067219, 0.09460147258377327, 0.09460147258377327, 0.09460147258377327, 0.08208831243957515, 0.08208831243957515, 0.08208831243957515, 0.08167824976715032, 0.08167824976715032, 0.08167824976715032]}, "mutation_prompt": null}
{"id": "c6af2ee6-62d5-4127-9151-4c90845a073b", "solution": "import numpy as np\n\nclass DynamicAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.initial_de_f = 0.9  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.2  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.4  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.60:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicAdaptiveHybridDEPSO", "description": "A dynamically adaptive hybrid algorithm combining Differential Evolution, Particle Swarm Optimization, and Adaptive Parameter Adjustment to efficiently explore and exploit diverse search spaces.", "configspace": "", "generation": 74, "fitness": 0.2744421792445371, "feedback": "The algorithm DynamicAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.25.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8455049787373289, 0.8455049787373289, 0.8455049787373289, 0.8617418809299393, 0.8617418809299393, 0.8617418809299393, 0.8345579952812989, 0.8345579952812989, 0.8345579952812989, 0.23319495259837064, 0.23319495259837064, 0.23319495259837064, 0.061843813707055606, 0.061843813707055606, 0.061843813707055606, 0.700717997394259, 0.700717997394259, 0.700717997394259, 0.12674831095634254, 0.12674831095634254, 0.12674831095634254, 0.1358043719847718, 0.1358043719847718, 0.1358043719847718, 0.13341309543908353, 0.13341309543908353, 0.13341309543908353, 0.12708697765018928, 0.12708697765018928, 0.12708697765018928, 0.16306383635002408, 0.16306383635002408, 0.16306383635002408, 0.10883002210755244, 0.10883002210755244, 0.10883002210755244, 0.9897962676934792, 0.9897962676934792, 0.9897962676934792, 0.9847208998088266, 0.9847208998088266, 0.9847208998088266, 0.9895568224958412, 0.9895568224958412, 0.9895568224958412, 0.32580680021758623, 0.32580680021758623, 0.32580680021758623, 0.31677519761245365, 0.31677519761245365, 0.31677519761245365, 0.4001187641297501, 0.4001187641297501, 0.4001187641297501, 0.7330846825178856, 0.7330846825178856, 0.7330846825178856, 0.21142216375745326, 0.21142216375745326, 0.21142216375745326, 0.17656984613297155, 0.17656984613297155, 0.17656984613297155, 0.23359125275846626, 0.23359125275846626, 0.23359125275846626, 0.11007104808065338, 0.11007104808065338, 0.11007104808065338, 0.24035110964264406, 0.24035110964264406, 0.24035110964264406, 0.27422935576818275, 0.27422935576818275, 0.27422935576818275, 0.2465434758357078, 0.2465434758357078, 0.2465434758357078, 0.16750649212050506, 0.16750649212050506, 0.16750649212050506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0069234108613546175, 0.0069234108613546175, 0.0069234108613546175, 0.09080885210086287, 0.09080885210086287, 0.09080885210086287, 0.07133673864752077, 0.07133673864752077, 0.07133673864752077, 0.0923017513651081, 0.0923017513651081, 0.0923017513651081, 0.04786300677281563, 0.04786300677281563, 0.04786300677281563, 0.3043291378197306, 0.3043291378197306, 0.3043291378197306, 0.27472758240768924, 0.27472758240768924, 0.27472758240768924, 0.06759544862500189, 0.06759544862500189, 0.06759544862500189, 0.03864229787544882, 0.03864229787544882, 0.03864229787544882, 0.0823140768410896, 0.0823140768410896, 0.0823140768410896, 0.5623085213255621, 0.5623085213255621, 0.5623085213255621, 0.540271710136901, 0.540271710136901, 0.540271710136901, 0.5360095943515243, 0.5360095943515243, 0.5360095943515243, 0.09403421939182444, 0.09403421939182444, 0.09403421939182444, 0.10578290148006486, 0.10578290148006486, 0.10578290148006486, 0.1655722943756358, 0.1655722943756358, 0.1655722943756358, 0.13383231460298817, 0.13383231460298817, 0.13383231460298817, 0.14620605229980377, 0.14620605229980377, 0.14620605229980377, 0.21880404530984932, 0.21880404530984932, 0.21880404530984932, 0.4116810134674934, 0.4116810134674934, 0.4116810134674934, 0.20749883659226276, 0.20749883659226276, 0.20749883659226276, 0.21402387470758777, 0.21402387470758777, 0.21402387470758777, 0.27414226660753216, 0.27414226660753216, 0.27414226660753216, 0.2552546438532629, 0.2552546438532629, 0.2552546438532629, 0.3260794746819107, 0.3260794746819107, 0.3260794746819107, 0.20128330464562305, 0.20128330464562305, 0.20128330464562305, 0.1968957996332723, 0.1968957996332723, 0.1968957996332723, 0.19109738994669467, 0.19109738994669467, 0.19109738994669467, 0.21449307971497278, 0.21449307971497278, 0.21449307971497278, 0.20229942766738995, 0.20229942766738995, 0.20229942766738995, 0.19393645277247507, 0.19393645277247507, 0.19393645277247507, 0.8775309966015572, 0.8775309966015572, 0.8775309966015572, 0.16435137589832138, 0.16435137589832138, 0.16435137589832138, 0.1836974078467981, 0.1836974078467981, 0.1836974078467981, 0.16907761957799872, 0.16907761957799872, 0.16907761957799872, 0.2077781631640293, 0.2077781631640293, 0.2077781631640293, 0.15559803591422827, 0.15559803591422827, 0.15559803591422827, 0.1773784078820969, 0.1773784078820969, 0.1773784078820969, 0.18209560190920004, 0.18209560190920004, 0.18209560190920004, 0.21184575551166185, 0.21184575551166185, 0.21184575551166185, 0.07267843692145148, 0.07267843692145148, 0.07267843692145148, 0.08437542473274584, 0.08437542473274584, 0.08437542473274584, 0.0722277470567082, 0.0722277470567082, 0.0722277470567082]}, "mutation_prompt": null}
{"id": "4ccd59e2-0fc6-4040-aa44-256d71f52266", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size for better exploration\n        self.initial_de_f = 0.9  # Increased Differential weight for stronger mutations\n        self.initial_de_cr = 0.9  # Increased Crossover probability for more trials\n        self.initial_pso_w = 0.6  # Increased Inertia weight for better momentum\n        self.pso_c1 = 1.1  # Slightly increased Cognitive coefficient\n        self.pso_c2 = 1.3  # Slightly increased Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio  # Adjusted adaptation\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio  # Adjusted adaptation\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio  # Adjusted adaptation\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.7:\n                diversity_count = max(1, int(self.population_size * 0.3))  # Increased diversity\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "RefinedHybridDEPSO", "description": "A refined hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with dynamic parameter tuning and enhanced diversity measures for improved exploration and exploitation.", "configspace": "", "generation": 75, "fitness": 0.3015550896008421, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8374069044319288, 0.8374069044319288, 0.8374069044319288, 0.8190593645956828, 0.8190593645956828, 0.8190593645956828, 0.8098423503790544, 0.8098423503790544, 0.8098423503790544, 0.07347844740919007, 0.07347844740919007, 0.07347844740919007, 0.6537581081333194, 0.6537581081333194, 0.6537581081333194, 0.6707546067686156, 0.6707546067686156, 0.6707546067686156, 0.13522561594769034, 0.13522561594769034, 0.13522561594769034, 0.12707746561928468, 0.12707746561928468, 0.12707746561928468, 0.12898693164817088, 0.12898693164817088, 0.12898693164817088, 0.12775675677640652, 0.12775675677640652, 0.12775675677640652, 0.12377684392067945, 0.12377684392067945, 0.12377684392067945, 0.1442742918561849, 0.1442742918561849, 0.1442742918561849, 0.9820691453397027, 0.9820691453397027, 0.9820691453397027, 0.9871813549015127, 0.9871813549015127, 0.9871813549015127, 0.9872132549420387, 0.9872132549420387, 0.9872132549420387, 0.4277626349960324, 0.4277626349960324, 0.4277626349960324, 0.4111212344608671, 0.4111212344608671, 0.4111212344608671, 0.4227518916586569, 0.4227518916586569, 0.4227518916586569, 0.21464966163941013, 0.21464966163941013, 0.21464966163941013, 0.7604924575700929, 0.7604924575700929, 0.7604924575700929, 0.5197982650359145, 0.5197982650359145, 0.5197982650359145, 0.2795635786954309, 0.2795635786954309, 0.2795635786954309, 0.12829429099176903, 0.12829429099176903, 0.12829429099176903, 0.22069307928557236, 0.22069307928557236, 0.22069307928557236, 0.2461628759660769, 0.2461628759660769, 0.2461628759660769, 0.2725513769154698, 0.2725513769154698, 0.2725513769154698, 0.2732625665582441, 0.2732625665582441, 0.2732625665582441, 0.009620641612351433, 0.009620641612351433, 0.009620641612351433, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.035992897392270295, 0.035992897392270295, 0.035992897392270295, 0.07907176779323033, 0.07907176779323033, 0.07907176779323033, 0.004643460417728784, 0.004643460417728784, 0.004643460417728784, 0.0724074812220652, 0.0724074812220652, 0.0724074812220652, 0.24791156598595843, 0.24791156598595843, 0.24791156598595843, 0.1158141969190507, 0.1158141969190507, 0.1158141969190507, 0.08021658249321884, 0.08021658249321884, 0.08021658249321884, 0.12056774967938033, 0.12056774967938033, 0.12056774967938033, 0.11638559849334595, 0.11638559849334595, 0.11638559849334595, 0.08093146205589385, 0.08093146205589385, 0.08093146205589385, 0.5410216263041419, 0.5410216263041419, 0.5410216263041419, 0.5494145994881144, 0.5494145994881144, 0.5494145994881144, 0.5471535564144212, 0.5471535564144212, 0.5471535564144212, 0.0958190074259615, 0.0958190074259615, 0.0958190074259615, 0.11859460122706444, 0.11859460122706444, 0.11859460122706444, 0.17203325194270835, 0.17203325194270835, 0.17203325194270835, 0.15709742812921557, 0.15709742812921557, 0.15709742812921557, 0.18377576499501114, 0.18377576499501114, 0.18377576499501114, 0.1524687543470098, 0.1524687543470098, 0.1524687543470098, 0.436503340728004, 0.436503340728004, 0.436503340728004, 0.36946887552393626, 0.36946887552393626, 0.36946887552393626, 0.48665256013263924, 0.48665256013263924, 0.48665256013263924, 0.3479436056548899, 0.3479436056548899, 0.3479436056548899, 0.20644568135732266, 0.20644568135732266, 0.20644568135732266, 0.21345231407162635, 0.21345231407162635, 0.21345231407162635, 0.18026250851807057, 0.18026250851807057, 0.18026250851807057, 0.220451677420742, 0.220451677420742, 0.220451677420742, 0.1946837418218238, 0.1946837418218238, 0.1946837418218238, 0.19701517786939715, 0.19701517786939715, 0.19701517786939715, 0.19783262614697428, 0.19783262614697428, 0.19783262614697428, 0.1854562636645115, 0.1854562636645115, 0.1854562636645115, 0.8616952496048403, 0.8616952496048403, 0.8616952496048403, 0.15906545033367525, 0.15906545033367525, 0.15906545033367525, 0.1774515525091208, 0.1774515525091208, 0.1774515525091208, 0.16705149037918532, 0.16705149037918532, 0.16705149037918532, 0.20879751254012147, 0.20879751254012147, 0.20879751254012147, 0.8264646264454613, 0.8264646264454613, 0.8264646264454613, 0.17207909698920087, 0.17207909698920087, 0.17207909698920087, 0.17704212312916756, 0.17704212312916756, 0.17704212312916756, 0.18846050892913524, 0.18846050892913524, 0.18846050892913524, 0.09575848631873574, 0.09575848631873574, 0.09575848631873574, 0.08195533296179436, 0.08195533296179436, 0.08195533296179436, 0.09396929742911686, 0.09396929742911686, 0.09396929742911686]}, "mutation_prompt": null}
{"id": "58ddbdeb-a0ce-4468-8e7f-c1cf5805612a", "solution": "import numpy as np\n\nclass ProgressiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Adjust Differential weight to enhance exploration\n        self.initial_de_cr = 0.9  # Adjust Crossover probability for more mixing\n        self.initial_pso_w = 0.4  # Adjust Inertia weight to stabilize convergence\n        self.pso_c1 = 1.2  # Increased Cognitive coefficient for stronger exploration\n        self.pso_c2 = 1.0  # Slightly reduced Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Randomized initial velocities\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "ProgressiveHybridDEPSO", "description": "A progressive hybrid evolution strategy combining elements of Differential Evolution, Particle Swarm Optimization, and adaptive dynamic adjustments to balance exploration and exploitation efficiently in diverse problem landscapes.", "configspace": "", "generation": 76, "fitness": 0.32881746368459486, "feedback": "The algorithm ProgressiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.30.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9271199148638918, 0.9271199148638918, 0.9271199148638918, 0.9440526993556893, 0.9440526993556893, 0.9440526993556893, 0.947345355135892, 0.947345355135892, 0.947345355135892, 0.8605338687015389, 0.8605338687015389, 0.8605338687015389, 0.8943786190901833, 0.8943786190901833, 0.8943786190901833, 0.8147377190007548, 0.8147377190007548, 0.8147377190007548, 0.13025959112610885, 0.13025959112610885, 0.13025959112610885, 0.12874275794677703, 0.12874275794677703, 0.12874275794677703, 0.1896721617596816, 0.1896721617596816, 0.1896721617596816, 0.14465428114555634, 0.14465428114555634, 0.14465428114555634, 0.11595721232834943, 0.11595721232834943, 0.11595721232834943, 0.12233051852013122, 0.12233051852013122, 0.12233051852013122, 0.981292480929518, 0.981292480929518, 0.981292480929518, 0.9839872921051551, 0.9839872921051551, 0.9839872921051551, 0.9837928650471024, 0.9837928650471024, 0.9837928650471024, 0.8731593985642749, 0.8731593985642749, 0.8731593985642749, 0.694185602674621, 0.694185602674621, 0.694185602674621, 0.8708258533510161, 0.8708258533510161, 0.8708258533510161, 0.18263692488322703, 0.18263692488322703, 0.18263692488322703, 0.21475429002102853, 0.21475429002102853, 0.21475429002102853, 0.18724373953686413, 0.18724373953686413, 0.18724373953686413, 0.2274828208153752, 0.2274828208153752, 0.2274828208153752, 0.17732217055248622, 0.17732217055248622, 0.17732217055248622, 0.18860699628105582, 0.18860699628105582, 0.18860699628105582, 0.13539473350674358, 0.13539473350674358, 0.13539473350674358, 0.20202621929330555, 0.20202621929330555, 0.20202621929330555, 0.12951551305736209, 0.12951551305736209, 0.12951551305736209, 0.012654888463624281, 0.012654888463624281, 0.012654888463624281, 0.020840268342200763, 0.020840268342200763, 0.020840268342200763, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09800476764139099, 0.09800476764139099, 0.09800476764139099, 0.07323633828575238, 0.07323633828575238, 0.07323633828575238, 0.05678602148617684, 0.05678602148617684, 0.05678602148617684, 0.06335413111460497, 0.06335413111460497, 0.06335413111460497, 0.09836062614482965, 0.09836062614482965, 0.09836062614482965, 0.18409198315908137, 0.18409198315908137, 0.18409198315908137, 0.19545927740296087, 0.19545927740296087, 0.19545927740296087, 0.3301846122862184, 0.3301846122862184, 0.3301846122862184, 0.23941124210454467, 0.23941124210454467, 0.23941124210454467, 0.6669795124641862, 0.6669795124641862, 0.6669795124641862, 0.6111796855136973, 0.6111796855136973, 0.6111796855136973, 0.5930876415469883, 0.5930876415469883, 0.5930876415469883, 0.10179757884585816, 0.10179757884585816, 0.10179757884585816, 0.15602805264068575, 0.15602805264068575, 0.15602805264068575, 0.12874912890166668, 0.12874912890166668, 0.12874912890166668, 0.30766937104135306, 0.30766937104135306, 0.30766937104135306, 0.20652797554781954, 0.20652797554781954, 0.20652797554781954, 0.13148278310851835, 0.13148278310851835, 0.13148278310851835, 0.3044459950632843, 0.3044459950632843, 0.3044459950632843, 0.32917344431809037, 0.32917344431809037, 0.32917344431809037, 0.6884622762145624, 0.6884622762145624, 0.6884622762145624, 0.36595084233123254, 0.36595084233123254, 0.36595084233123254, 0.47091208905998616, 0.47091208905998616, 0.47091208905998616, 0.11716495080342881, 0.11716495080342881, 0.11716495080342881, 0.2134080810977329, 0.2134080810977329, 0.2134080810977329, 0.20639017544747862, 0.20639017544747862, 0.20639017544747862, 0.18709610315175462, 0.18709610315175462, 0.18709610315175462, 0.2033363140165203, 0.2033363140165203, 0.2033363140165203, 0.1816257634627182, 0.1816257634627182, 0.1816257634627182, 0.21249793483609514, 0.21249793483609514, 0.21249793483609514, 0.9670966221763988, 0.9670966221763988, 0.9670966221763988, 0.1589497248881082, 0.1589497248881082, 0.1589497248881082, 0.1747123564790034, 0.1747123564790034, 0.1747123564790034, 0.16980932288518613, 0.16980932288518613, 0.16980932288518613, 0.1698649904857833, 0.1698649904857833, 0.1698649904857833, 0.15699052163915317, 0.15699052163915317, 0.15699052163915317, 0.17993629710712744, 0.17993629710712744, 0.17993629710712744, 0.19235828513386122, 0.19235828513386122, 0.19235828513386122, 0.1948852022063412, 0.1948852022063412, 0.1948852022063412, 0.09287327791139321, 0.09287327791139321, 0.09287327791139321, 0.11800801846616416, 0.11800801846616416, 0.11800801846616416, 0.09091131047357481, 0.09091131047357481, 0.09091131047357481]}, "mutation_prompt": null}
{"id": "97255067-8a50-484b-a2c9-d049f69ec55f", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "eb36d52a-c6e4-4ab1-9d5f-f9c9ac7719c0", "solution": "import numpy as np\n\nclass EnhancedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.3  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))  # Non-zero initial velocities\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedAdaptiveHybridDEPSO", "description": "An enhanced adaptive hybrid evolutionary algorithm integrating Differential Evolution, Particle Swarm Optimization, and adaptive learning to more effectively balance exploration and exploitation in diverse optimization landscapes.", "configspace": "", "generation": 78, "fitness": 0.3221317189422407, "feedback": "The algorithm EnhancedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.28.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8820825024317142, 0.8820825024317142, 0.8820825024317142, 0.875053907497567, 0.875053907497567, 0.875053907497567, 0.8490482358802542, 0.8490482358802542, 0.8490482358802542, 0.72518591415065, 0.72518591415065, 0.72518591415065, 0.7492746741359493, 0.7492746741359493, 0.7492746741359493, 0.7071641594911781, 0.7071641594911781, 0.7071641594911781, 0.17376758736211217, 0.17376758736211217, 0.17376758736211217, 0.11346043062420541, 0.11346043062420541, 0.11346043062420541, 0.14078422995103756, 0.14078422995103756, 0.14078422995103756, 0.1473548585967206, 0.1473548585967206, 0.1473548585967206, 0.12277424209300991, 0.12277424209300991, 0.12277424209300991, 0.11082226799699801, 0.11082226799699801, 0.11082226799699801, 0.9896871557597755, 0.9896871557597755, 0.9896871557597755, 0.9852540029220485, 0.9852540029220485, 0.9852540029220485, 0.9852710404007164, 0.9852710404007164, 0.9852710404007164, 0.597819811530593, 0.597819811530593, 0.597819811530593, 0.6238695472869116, 0.6238695472869116, 0.6238695472869116, 0.6726771190660041, 0.6726771190660041, 0.6726771190660041, 0.7460882634395722, 0.7460882634395722, 0.7460882634395722, 0.21164562706743417, 0.21164562706743417, 0.21164562706743417, 0.1729750084660776, 0.1729750084660776, 0.1729750084660776, 0.2548511990946255, 0.2548511990946255, 0.2548511990946255, 0.2614851753634456, 0.2614851753634456, 0.2614851753634456, 0.2670941728075241, 0.2670941728075241, 0.2670941728075241, 0.2527852085800858, 0.2527852085800858, 0.2527852085800858, 0.259159832958058, 0.259159832958058, 0.259159832958058, 0.272197093691547, 0.272197093691547, 0.272197093691547, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012878195456712094, 0.012878195456712094, 0.012878195456712094, 0.0048415005376840625, 0.0048415005376840625, 0.0048415005376840625, 0.0641605621249588, 0.0641605621249588, 0.0641605621249588, 0.03214898224834217, 0.03214898224834217, 0.03214898224834217, 0.04699418794089849, 0.04699418794089849, 0.04699418794089849, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07051399505712086, 0.07051399505712086, 0.07051399505712086, 0.07068945681385375, 0.07068945681385375, 0.07068945681385375, 0.1484643833007243, 0.1484643833007243, 0.1484643833007243, 0.07902407578592097, 0.07902407578592097, 0.07902407578592097, 0.11222800199113192, 0.11222800199113192, 0.11222800199113192, 0.5438085668701724, 0.5438085668701724, 0.5438085668701724, 0.5742044184309361, 0.5742044184309361, 0.5742044184309361, 0.5627878011351038, 0.5627878011351038, 0.5627878011351038, 0.10479265818573935, 0.10479265818573935, 0.10479265818573935, 0.09215485156781233, 0.09215485156781233, 0.09215485156781233, 0.11648713214113282, 0.11648713214113282, 0.11648713214113282, 0.39898395012457477, 0.39898395012457477, 0.39898395012457477, 0.163870404996169, 0.163870404996169, 0.163870404996169, 0.2376607723682621, 0.2376607723682621, 0.2376607723682621, 0.29438290043913906, 0.29438290043913906, 0.29438290043913906, 0.3438855420613729, 0.3438855420613729, 0.3438855420613729, 0.45363695556077277, 0.45363695556077277, 0.45363695556077277, 0.25081471985433323, 0.25081471985433323, 0.25081471985433323, 0.21828366121464826, 0.21828366121464826, 0.21828366121464826, 0.27265305488027125, 0.27265305488027125, 0.27265305488027125, 0.1887039859771068, 0.1887039859771068, 0.1887039859771068, 0.20172841815226006, 0.20172841815226006, 0.20172841815226006, 0.18006845840204988, 0.18006845840204988, 0.18006845840204988, 0.6526607459792408, 0.6526607459792408, 0.6526607459792408, 0.1935252330576005, 0.1935252330576005, 0.1935252330576005, 0.7423800509993093, 0.7423800509993093, 0.7423800509993093, 0.9185449910989282, 0.9185449910989282, 0.9185449910989282, 0.1668099498354041, 0.1668099498354041, 0.1668099498354041, 0.19638615114514624, 0.19638615114514624, 0.19638615114514624, 0.16248889664942945, 0.16248889664942945, 0.16248889664942945, 0.20732451194200885, 0.20732451194200885, 0.20732451194200885, 0.1556216508179319, 0.1556216508179319, 0.1556216508179319, 0.1798555584505348, 0.1798555584505348, 0.1798555584505348, 0.19046138226572262, 0.19046138226572262, 0.19046138226572262, 0.18665604878111908, 0.18665604878111908, 0.18665604878111908, 0.08757997302085219, 0.08757997302085219, 0.08757997302085219, 0.07537972898045753, 0.07537972898045753, 0.07537972898045753, 0.08712402855262424, 0.08712402855262424, 0.08712402855262424]}, "mutation_prompt": null}
{"id": "696aeb5f-3aeb-4288-abe5-f2a9e8fa15c0", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size for more diversity\n        self.de_f = 0.7  # Differential weight\n        self.de_cr = 0.9  # Crossover probability\n        self.pso_w = 0.6  # Inertia weight\n        self.pso_c1 = 1.5  # Cognitive coefficient\n        self.pso_c2 = 1.5  # Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adaptive DE parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Adaptive clustering for exploration\n            if self.eval_count >= self.max_evaluations * 0.75:\n                cluster_size = max(1, int(self.population_size * 0.3))\n                for _ in range(cluster_size):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        cluster_center = np.mean(population, axis=0)\n                        population[idx] = np.clip(cluster_center + np.random.normal(0, 1, self.dim), self.lb, self.ub)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid optimizing algorithm that integrates adaptive Differential Evolution with Particle Swarm Optimization, incorporating adaptive mutation strategies and population clustering to better balance exploration and exploitation.", "configspace": "", "generation": 79, "fitness": 0.24913300685917783, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.25.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.7463536285078987, 0.7463536285078987, 0.7463536285078987, 0.8001683866290824, 0.8001683866290824, 0.8001683866290824, 0.7983171015441446, 0.7983171015441446, 0.7983171015441446, 0.5866943063206371, 0.5866943063206371, 0.5866943063206371, 0.5578204448335833, 0.5578204448335833, 0.5578204448335833, 0.6149929681567283, 0.6149929681567283, 0.6149929681567283, 0.08548186168499139, 0.08548186168499139, 0.08548186168499139, 0.07728462288338811, 0.07728462288338811, 0.07728462288338811, 0.08953530649445152, 0.08953530649445152, 0.08953530649445152, 0.08900686484182274, 0.08900686484182274, 0.08900686484182274, 0.08143860504737055, 0.08143860504737055, 0.08143860504737055, 0.08219397074323953, 0.08219397074323953, 0.08219397074323953, 0.9834699302610154, 0.9834699302610154, 0.9834699302610154, 0.9871948668115301, 0.9871948668115301, 0.9871948668115301, 0.9880621309531368, 0.9880621309531368, 0.9880621309531368, 0.21954410335233254, 0.21954410335233254, 0.21954410335233254, 0.1958610919804542, 0.1958610919804542, 0.1958610919804542, 0.2317434100538185, 0.2317434100538185, 0.2317434100538185, 0.18926456752083987, 0.18926456752083987, 0.18926456752083987, 0.2183350861248753, 0.2183350861248753, 0.2183350861248753, 0.26476726793879435, 0.26476726793879435, 0.26476726793879435, 0.17819664892645126, 0.17819664892645126, 0.17819664892645126, 0.10092772585036236, 0.10092772585036236, 0.10092772585036236, 0.18673756768455319, 0.18673756768455319, 0.18673756768455319, 0.18936990518521013, 0.18936990518521013, 0.18936990518521013, 0.1589478784726005, 0.1589478784726005, 0.1589478784726005, 0.19664200418527966, 0.19664200418527966, 0.19664200418527966, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.052738552378330805, 0.052738552378330805, 0.052738552378330805, 0.03565791405401175, 0.03565791405401175, 0.03565791405401175, 0.048223774406999875, 0.048223774406999875, 0.048223774406999875, 0.03685083928673172, 0.03685083928673172, 0.03685083928673172, 0.04805478200527502, 0.04805478200527502, 0.04805478200527502, 0.05887082822377632, 0.05887082822377632, 0.05887082822377632, 0.0820238066874972, 0.0820238066874972, 0.0820238066874972, 0.17648373841408938, 0.17648373841408938, 0.17648373841408938, 0.0823691322375335, 0.0823691322375335, 0.0823691322375335, 0.5132790049873931, 0.5132790049873931, 0.5132790049873931, 0.4401559002362062, 0.4401559002362062, 0.4401559002362062, 0.4456442837216682, 0.4456442837216682, 0.4456442837216682, 0.08506462957621352, 0.08506462957621352, 0.08506462957621352, 0.0778843580509625, 0.0778843580509625, 0.0778843580509625, 0.08388986901389939, 0.08388986901389939, 0.08388986901389939, 0.14653675997112037, 0.14653675997112037, 0.14653675997112037, 0.1492519205717846, 0.1492519205717846, 0.1492519205717846, 0.1341866164683363, 0.1341866164683363, 0.1341866164683363, 0.2668314380443494, 0.2668314380443494, 0.2668314380443494, 0.30013141447223624, 0.30013141447223624, 0.30013141447223624, 0.2897882535942877, 0.2897882535942877, 0.2897882535942877, 0.22009516392377393, 0.22009516392377393, 0.22009516392377393, 0.1609918260839609, 0.1609918260839609, 0.1609918260839609, 0.20760636421926515, 0.20760636421926515, 0.20760636421926515, 0.17658531071807304, 0.17658531071807304, 0.17658531071807304, 0.17176400378376033, 0.17176400378376033, 0.17176400378376033, 0.17546399138490998, 0.17546399138490998, 0.17546399138490998, 0.18835062725298657, 0.18835062725298657, 0.18835062725298657, 0.17658607832636375, 0.17658607832636375, 0.17658607832636375, 0.1770920524149585, 0.1770920524149585, 0.1770920524149585, 0.8071010784900009, 0.8071010784900009, 0.8071010784900009, 0.16692045083243068, 0.16692045083243068, 0.16692045083243068, 0.17676655877697356, 0.17676655877697356, 0.17676655877697356, 0.5139408359845874, 0.5139408359845874, 0.5139408359845874, 0.2054728590594196, 0.2054728590594196, 0.2054728590594196, 0.20812267026643516, 0.20812267026643516, 0.20812267026643516, 0.19598566653766314, 0.19598566653766314, 0.19598566653766314, 0.17724032389515743, 0.17724032389515743, 0.17724032389515743, 0.18079861647625095, 0.18079861647625095, 0.18079861647625095, 0.06322467223501549, 0.06322467223501549, 0.06322467223501549, 0.06671191214882166, 0.06671191214882166, 0.06671191214882166, 0.06818536165870026, 0.06818536165870026, 0.06818536165870026]}, "mutation_prompt": null}
{"id": "02ecb1bf-eaf1-4645-b76f-8e2a86eafcc9", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Slightly increased Differential weight\n        self.initial_de_cr = 0.9  # Slightly increased Crossover probability\n        self.initial_pso_w = 0.6  # Slightly higher Inertia weight\n        self.pso_c1 = 1.1  # Increased Cognitive coefficient\n        self.pso_c2 = 1.3  # Increased Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.5 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "RefinedHybridDEPSO", "description": "A refined hybrid evolutionary algorithm, integrating Differential Evolution and Particle Swarm Optimization, enhanced by dynamic parameter tuning and population diversity, to adeptly navigate and optimize complex search landscapes.", "configspace": "", "generation": 80, "fitness": 0.2988838478308804, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.28.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.897992514682375, 0.897992514682375, 0.897992514682375, 0.8991671311938094, 0.8991671311938094, 0.8991671311938094, 0.8605548430695746, 0.8605548430695746, 0.8605548430695746, 0.789358536988939, 0.789358536988939, 0.789358536988939, 0.7153769479325125, 0.7153769479325125, 0.7153769479325125, 0.051616224744466255, 0.051616224744466255, 0.051616224744466255, 0.1731369379818951, 0.1731369379818951, 0.1731369379818951, 0.12256632001758572, 0.12256632001758572, 0.12256632001758572, 0.12368025572731056, 0.12368025572731056, 0.12368025572731056, 0.13327196565742216, 0.13327196565742216, 0.13327196565742216, 0.11360886622887678, 0.11360886622887678, 0.11360886622887678, 0.08844735528296566, 0.08844735528296566, 0.08844735528296566, 0.9873917611345101, 0.9873917611345101, 0.9873917611345101, 0.9851869375545763, 0.9851869375545763, 0.9851869375545763, 0.9890951913460005, 0.9890951913460005, 0.9890951913460005, 0.6303657144700735, 0.6303657144700735, 0.6303657144700735, 0.32837903017970504, 0.32837903017970504, 0.32837903017970504, 0.3698289001196974, 0.3698289001196974, 0.3698289001196974, 0.37416537540510686, 0.37416537540510686, 0.37416537540510686, 0.16254137929432932, 0.16254137929432932, 0.16254137929432932, 0.26448742105848366, 0.26448742105848366, 0.26448742105848366, 0.13091275687948434, 0.13091275687948434, 0.13091275687948434, 0.12538772272709353, 0.12538772272709353, 0.12538772272709353, 0.13242724830009955, 0.13242724830009955, 0.13242724830009955, 0.13216551769029627, 0.13216551769029627, 0.13216551769029627, 0.321607381198034, 0.321607381198034, 0.321607381198034, 0.3103103110074321, 0.3103103110074321, 0.3103103110074321, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11976488074848113, 0.11976488074848113, 0.11976488074848113, 0.04501043755702516, 0.04501043755702516, 0.04501043755702516, 0.039845203905257365, 0.039845203905257365, 0.039845203905257365, 0.03670000964059961, 0.03670000964059961, 0.03670000964059961, 0.11395999391085843, 0.11395999391085843, 0.11395999391085843, 0.14020430301077502, 0.14020430301077502, 0.14020430301077502, 0.04356875358564061, 0.04356875358564061, 0.04356875358564061, 0.07885339514862733, 0.07885339514862733, 0.07885339514862733, 0.14668563995257156, 0.14668563995257156, 0.14668563995257156, 0.5804764171157344, 0.5804764171157344, 0.5804764171157344, 0.570253031808232, 0.570253031808232, 0.570253031808232, 0.5673661533124709, 0.5673661533124709, 0.5673661533124709, 0.10791157349739955, 0.10791157349739955, 0.10791157349739955, 0.12238003721509871, 0.12238003721509871, 0.12238003721509871, 0.1104996278499284, 0.1104996278499284, 0.1104996278499284, 0.15286066876799764, 0.15286066876799764, 0.15286066876799764, 0.1624325086588948, 0.1624325086588948, 0.1624325086588948, 0.20448736461855666, 0.20448736461855666, 0.20448736461855666, 0.3785797197730252, 0.3785797197730252, 0.3785797197730252, 0.44786727008193994, 0.44786727008193994, 0.44786727008193994, 0.2806443415821549, 0.2806443415821549, 0.2806443415821549, 0.3937376451639495, 0.3937376451639495, 0.3937376451639495, 0.2159090314732811, 0.2159090314732811, 0.2159090314732811, 0.14261912077923844, 0.14261912077923844, 0.14261912077923844, 0.23603311482159883, 0.23603311482159883, 0.23603311482159883, 0.2043314024934202, 0.2043314024934202, 0.2043314024934202, 0.1950259639728089, 0.1950259639728089, 0.1950259639728089, 0.694323450501795, 0.694323450501795, 0.694323450501795, 0.20485981290052702, 0.20485981290052702, 0.20485981290052702, 0.24258472570337275, 0.24258472570337275, 0.24258472570337275, 0.911660386944893, 0.911660386944893, 0.911660386944893, 0.8917876073780234, 0.8917876073780234, 0.8917876073780234, 0.1768294301854194, 0.1768294301854194, 0.1768294301854194, 0.16363857594578335, 0.16363857594578335, 0.16363857594578335, 0.20953404407038834, 0.20953404407038834, 0.20953404407038834, 0.1352563141805695, 0.1352563141805695, 0.1352563141805695, 0.1903970639172693, 0.1903970639172693, 0.1903970639172693, 0.20014041815421146, 0.20014041815421146, 0.20014041815421146, 0.18703588634578705, 0.18703588634578705, 0.18703588634578705, 0.09246570918006258, 0.09246570918006258, 0.09246570918006258, 0.08886743626991955, 0.08886743626991955, 0.08886743626991955, 0.07891802382714797, 0.07891802382714797, 0.07891802382714797]}, "mutation_prompt": null}
{"id": "ef66b3ee-883d-413a-a229-40c129fd6999", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8\n        self.initial_de_cr = 0.85\n        self.initial_pso_w = 0.6  # slightly increased inertia weight for balance\n        self.pso_c1 = 1.2  # adjusted cognitive component for better convergence\n        self.pso_c2 = 1.0  # reduced social component for stability\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Adaptive diversity control with noise handling\n            diversity_threshold = 0.3 + 0.2 * np.random.rand()\n            if self.eval_count >= self.max_evaluations * diversity_threshold:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A dynamic adaptation of Differential Evolution and Particle Swarm Optimization with noise-resistant evaluation and adaptive diversity control for robust exploration.", "configspace": "", "generation": 81, "fitness": 0.31895141565364116, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.29.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9162774525132145, 0.9162774525132145, 0.9162774525132145, 0.903962616854362, 0.903962616854362, 0.903962616854362, 0.9044800182692337, 0.9044800182692337, 0.9044800182692337, 0.12037258031517029, 0.12037258031517029, 0.12037258031517029, 0.8272567424123781, 0.8272567424123781, 0.8272567424123781, 0.8183392937797032, 0.8183392937797032, 0.8183392937797032, 0.12924976620587858, 0.12924976620587858, 0.12924976620587858, 0.1220916319226899, 0.1220916319226899, 0.1220916319226899, 0.1679799080521771, 0.1679799080521771, 0.1679799080521771, 0.10114154561051414, 0.10114154561051414, 0.10114154561051414, 0.13554108987970281, 0.13554108987970281, 0.13554108987970281, 0.10740816511685647, 0.10740816511685647, 0.10740816511685647, 0.9802282246771278, 0.9802282246771278, 0.9802282246771278, 0.9847997830378675, 0.9847997830378675, 0.9847997830378675, 0.9848040195205259, 0.9848040195205259, 0.9848040195205259, 0.4778991954118611, 0.4778991954118611, 0.4778991954118611, 0.47745265047865315, 0.47745265047865315, 0.47745265047865315, 0.3913273565085529, 0.3913273565085529, 0.3913273565085529, 0.2105005730810019, 0.2105005730810019, 0.2105005730810019, 0.21510758900456772, 0.21510758900456772, 0.21510758900456772, 0.257547980082533, 0.257547980082533, 0.257547980082533, 0.2520244979159887, 0.2520244979159887, 0.2520244979159887, 0.24387518269867015, 0.24387518269867015, 0.24387518269867015, 0.23317236803577823, 0.23317236803577823, 0.23317236803577823, 0.2580486704258398, 0.2580486704258398, 0.2580486704258398, 0.2097542322077115, 0.2097542322077115, 0.2097542322077115, 0.27220740204123983, 0.27220740204123983, 0.27220740204123983, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07529962294629788, 0.07529962294629788, 0.07529962294629788, 0.009985512207672631, 0.009985512207672631, 0.009985512207672631, 0.09519825421763162, 0.09519825421763162, 0.09519825421763162, 0.03588045276622032, 0.03588045276622032, 0.03588045276622032, 0.07771655541163014, 0.07771655541163014, 0.07771655541163014, 0.10214829797345482, 0.10214829797345482, 0.10214829797345482, 0.0534835635661548, 0.0534835635661548, 0.0534835635661548, 0.18837775947585655, 0.18837775947585655, 0.18837775947585655, 0.08684707557556814, 0.08684707557556814, 0.08684707557556814, 0.5837605499752276, 0.5837605499752276, 0.5837605499752276, 0.6085216089059109, 0.6085216089059109, 0.6085216089059109, 0.5844080224361057, 0.5844080224361057, 0.5844080224361057, 0.13805708765423075, 0.13805708765423075, 0.13805708765423075, 0.1029903878743027, 0.1029903878743027, 0.1029903878743027, 0.11810097734347635, 0.11810097734347635, 0.11810097734347635, 0.18619316797646546, 0.18619316797646546, 0.18619316797646546, 0.14337113612550767, 0.14337113612550767, 0.14337113612550767, 0.16290073165992014, 0.16290073165992014, 0.16290073165992014, 0.26248860081292524, 0.26248860081292524, 0.26248860081292524, 0.3990787637358185, 0.3990787637358185, 0.3990787637358185, 0.5697585165045205, 0.5697585165045205, 0.5697585165045205, 0.24668084532628887, 0.24668084532628887, 0.24668084532628887, 0.3196970524759849, 0.3196970524759849, 0.3196970524759849, 0.20200557664708774, 0.20200557664708774, 0.20200557664708774, 0.1869997233613374, 0.1869997233613374, 0.1869997233613374, 0.19576244425628586, 0.19576244425628586, 0.19576244425628586, 0.19518286701796783, 0.19518286701796783, 0.19518286701796783, 0.22536825933373672, 0.22536825933373672, 0.22536825933373672, 0.8055315585487784, 0.8055315585487784, 0.8055315585487784, 0.1982586431403267, 0.1982586431403267, 0.1982586431403267, 0.9301638098305619, 0.9301638098305619, 0.9301638098305619, 0.931154163920723, 0.931154163920723, 0.931154163920723, 0.16770673892484667, 0.16770673892484667, 0.16770673892484667, 0.8536808895494251, 0.8536808895494251, 0.8536808895494251, 0.21230295692536105, 0.21230295692536105, 0.21230295692536105, 0.15707689774146583, 0.15707689774146583, 0.15707689774146583, 0.17981857723279082, 0.17981857723279082, 0.17981857723279082, 0.23390624776840452, 0.23390624776840452, 0.23390624776840452, 0.18563630944247567, 0.18563630944247567, 0.18563630944247567, 0.08526886737005612, 0.08526886737005612, 0.08526886737005612, 0.08712998285741291, 0.08712998285741291, 0.08712998285741291, 0.07745233418614428, 0.07745233418614428, 0.07745233418614428]}, "mutation_prompt": null}
{"id": "98a68163-8d7d-4d51-b0ab-a3cfc084e152", "solution": "import numpy as np\n\nclass RefinedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for better exploration\n        self.initial_de_f = 0.85  # Fine-tuned Differential weight for mutation\n        self.initial_de_cr = 0.9  # Fine-tuned Crossover probability\n        self.initial_pso_w = 0.6  # Fine-tuned Inertia weight for balance\n        self.pso_c1 = 1.1  # Fine-tuned Cognitive coefficient\n        self.pso_c2 = 1.4  # Fine-tuned Social coefficient for convergence\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.65:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "RefinedHybridDEPSO", "description": "A hybrid evolutionary algorithm integrating Differential Evolution and Particle Swarm Optimization with adaptive parameter tuning and diversity reinforcement for enhanced exploration and exploitation.", "configspace": "", "generation": 82, "fitness": 0.28854264643271743, "feedback": "The algorithm RefinedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.27.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8452816894958214, 0.8452816894958214, 0.8452816894958214, 0.8470430715498855, 0.8470430715498855, 0.8470430715498855, 0.8677610723608344, 0.8677610723608344, 0.8677610723608344, 0.7165377934620791, 0.7165377934620791, 0.7165377934620791, 0.6805261515720306, 0.6805261515720306, 0.6805261515720306, 0.7073365221521493, 0.7073365221521493, 0.7073365221521493, 0.16283946822754647, 0.16283946822754647, 0.16283946822754647, 0.13205631950473762, 0.13205631950473762, 0.13205631950473762, 0.12442462704094448, 0.12442462704094448, 0.12442462704094448, 0.13369362215555414, 0.13369362215555414, 0.13369362215555414, 0.08862988359150203, 0.08862988359150203, 0.08862988359150203, 0.12252543332545063, 0.12252543332545063, 0.12252543332545063, 0.9756223184970452, 0.9756223184970452, 0.9756223184970452, 0.9859628418040476, 0.9859628418040476, 0.9859628418040476, 0.9897637071856421, 0.9897637071856421, 0.9897637071856421, 0.6448368352143765, 0.6448368352143765, 0.6448368352143765, 0.15972542955730695, 0.15972542955730695, 0.15972542955730695, 0.621632364020378, 0.621632364020378, 0.621632364020378, 0.2243073815275527, 0.2243073815275527, 0.2243073815275527, 0.2055434039095183, 0.2055434039095183, 0.2055434039095183, 0.23360803847134437, 0.23360803847134437, 0.23360803847134437, 0.26670430886159247, 0.26670430886159247, 0.26670430886159247, 0.12474864055570323, 0.12474864055570323, 0.12474864055570323, 0.25551296811015023, 0.25551296811015023, 0.25551296811015023, 0.24823804812583916, 0.24823804812583916, 0.24823804812583916, 0.29153160293383185, 0.29153160293383185, 0.29153160293383185, 0.12319852522437613, 0.12319852522437613, 0.12319852522437613, 0.02741182064257497, 0.02741182064257497, 0.02741182064257497, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05662966090216037, 0.05662966090216037, 0.05662966090216037, 0.12760096355940276, 0.12760096355940276, 0.12760096355940276, 0.0722821155098402, 0.0722821155098402, 0.0722821155098402, 0.028249937442664685, 0.028249937442664685, 0.028249937442664685, 0.09287152857438818, 0.09287152857438818, 0.09287152857438818, 0.07588603573919739, 0.07588603573919739, 0.07588603573919739, 0.06671047053933565, 0.06671047053933565, 0.06671047053933565, 0.2557479691438508, 0.2557479691438508, 0.2557479691438508, 0.03851979427049157, 0.03851979427049157, 0.03851979427049157, 0.06990369380669437, 0.06990369380669437, 0.06990369380669437, 0.5741794853482838, 0.5741794853482838, 0.5741794853482838, 0.5521481657639344, 0.5521481657639344, 0.5521481657639344, 0.5636347697963848, 0.5636347697963848, 0.5636347697963848, 0.11924138981698484, 0.11924138981698484, 0.11924138981698484, 0.11318230420249364, 0.11318230420249364, 0.11318230420249364, 0.11138392866817903, 0.11138392866817903, 0.11138392866817903, 0.16197289713136032, 0.16197289713136032, 0.16197289713136032, 0.21431031777474563, 0.21431031777474563, 0.21431031777474563, 0.19314148832584455, 0.19314148832584455, 0.19314148832584455, 0.44777271596002133, 0.44777271596002133, 0.44777271596002133, 0.21880419645087912, 0.21880419645087912, 0.21880419645087912, 0.48129594175865, 0.48129594175865, 0.48129594175865, 0.24772583272187265, 0.24772583272187265, 0.24772583272187265, 0.1456356839175803, 0.1456356839175803, 0.1456356839175803, 0.13260633828361512, 0.13260633828361512, 0.13260633828361512, 0.19343618811667662, 0.19343618811667662, 0.19343618811667662, 0.19209207468291445, 0.19209207468291445, 0.19209207468291445, 0.20655307334721795, 0.20655307334721795, 0.20655307334721795, 0.2133808936577809, 0.2133808936577809, 0.2133808936577809, 0.23947849935292798, 0.23947849935292798, 0.23947849935292798, 0.24601189487693886, 0.24601189487693886, 0.24601189487693886, 0.8785825465181851, 0.8785825465181851, 0.8785825465181851, 0.1592690441403114, 0.1592690441403114, 0.1592690441403114, 0.1604424098515428, 0.1604424098515428, 0.1604424098515428, 0.1343516322870899, 0.1343516322870899, 0.1343516322870899, 0.21103192750436728, 0.21103192750436728, 0.21103192750436728, 0.15628646342064734, 0.15628646342064734, 0.15628646342064734, 0.18219008913381818, 0.18219008913381818, 0.18219008913381818, 0.19830362379909816, 0.19830362379909816, 0.19830362379909816, 0.18426539915767437, 0.18426539915767437, 0.18426539915767437, 0.08635118013042975, 0.08635118013042975, 0.08635118013042975, 0.08982970113105204, 0.08982970113105204, 0.08982970113105204, 0.07467238755831118, 0.07467238755831118, 0.07467238755831118]}, "mutation_prompt": null}
{"id": "a85e3c10-eafc-4265-9520-1b7beac2aa44", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "fcda5f7b-0563-4633-898f-ca883ae927ee", "solution": "import numpy as np\n\nclass DynamicMultiStrategyOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Adjusted Differential weight\n        self.initial_de_cr = 0.8  # Adjusted Crossover probability\n        self.initial_pso_w = 0.7  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.65:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicMultiStrategyOptimizer", "description": "A dynamic multi-strategy optimization algorithm combining Differential Evolution, Particle Swarm Optimization, and random perturbations to efficiently explore and exploit complex search spaces.", "configspace": "", "generation": 84, "fitness": 0.27113435472807373, "feedback": "The algorithm DynamicMultiStrategyOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8081587383199462, 0.8081587383199462, 0.8081587383199462, 0.810430341090655, 0.810430341090655, 0.810430341090655, 0.8153523764275945, 0.8153523764275945, 0.8153523764275945, 0.61959727063291, 0.61959727063291, 0.61959727063291, 0.19323148638027154, 0.19323148638027154, 0.19323148638027154, 0.6272752366005188, 0.6272752366005188, 0.6272752366005188, 0.12472332388715424, 0.12472332388715424, 0.12472332388715424, 0.13533952929611082, 0.13533952929611082, 0.13533952929611082, 0.11620377784638336, 0.11620377784638336, 0.11620377784638336, 0.15829949508147967, 0.15829949508147967, 0.15829949508147967, 0.10129673834442599, 0.10129673834442599, 0.10129673834442599, 0.0978095890165318, 0.0978095890165318, 0.0978095890165318, 0.9903931768282142, 0.9903931768282142, 0.9903931768282142, 0.9908977165778405, 0.9908977165778405, 0.9908977165778405, 0.9916858071250939, 0.9916858071250939, 0.9916858071250939, 0.34449511909209374, 0.34449511909209374, 0.34449511909209374, 0.2873660044609019, 0.2873660044609019, 0.2873660044609019, 0.4528916329849493, 0.4528916329849493, 0.4528916329849493, 0.5470749871005824, 0.5470749871005824, 0.5470749871005824, 0.20815763581710545, 0.20815763581710545, 0.20815763581710545, 0.126099866291286, 0.126099866291286, 0.126099866291286, 0.22999017550355916, 0.22999017550355916, 0.22999017550355916, 0.08878692291116952, 0.08878692291116952, 0.08878692291116952, 0.16327814333110258, 0.16327814333110258, 0.16327814333110258, 0.21242575577648526, 0.21242575577648526, 0.21242575577648526, 0.12027017784848704, 0.12027017784848704, 0.12027017784848704, 0.1980690097157931, 0.1980690097157931, 0.1980690097157931, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.057273356286028476, 0.057273356286028476, 0.057273356286028476, 0.07465744080218151, 0.07465744080218151, 0.07465744080218151, 0.011020161199282286, 0.011020161199282286, 0.011020161199282286, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06647350833932542, 0.06647350833932542, 0.06647350833932542, 0.08897584529053859, 0.08897584529053859, 0.08897584529053859, 0.07697018493427532, 0.07697018493427532, 0.07697018493427532, 0.07927011103721249, 0.07927011103721249, 0.07927011103721249, 0.07827123743175379, 0.07827123743175379, 0.07827123743175379, 0.5136249326120841, 0.5136249326120841, 0.5136249326120841, 0.5435959458917243, 0.5435959458917243, 0.5435959458917243, 0.5282628890336294, 0.5282628890336294, 0.5282628890336294, 0.07369247173508653, 0.07369247173508653, 0.07369247173508653, 0.08412599667054221, 0.08412599667054221, 0.08412599667054221, 0.129783759208142, 0.129783759208142, 0.129783759208142, 0.17570274509619543, 0.17570274509619543, 0.17570274509619543, 0.14709524823856612, 0.14709524823856612, 0.14709524823856612, 0.23649699957451908, 0.23649699957451908, 0.23649699957451908, 0.3423406124322955, 0.3423406124322955, 0.3423406124322955, 0.31215915824092344, 0.31215915824092344, 0.31215915824092344, 0.5001231528134258, 0.5001231528134258, 0.5001231528134258, 0.18348991975901607, 0.18348991975901607, 0.18348991975901607, 0.1783168776155004, 0.1783168776155004, 0.1783168776155004, 0.12790803644444404, 0.12790803644444404, 0.12790803644444404, 0.2372248019357559, 0.2372248019357559, 0.2372248019357559, 0.19088030564279457, 0.19088030564279457, 0.19088030564279457, 0.17239149058424597, 0.17239149058424597, 0.17239149058424597, 0.20850585212186845, 0.20850585212186845, 0.20850585212186845, 0.2010064770555018, 0.2010064770555018, 0.2010064770555018, 0.23141598609826486, 0.23141598609826486, 0.23141598609826486, 0.7829949883347742, 0.7829949883347742, 0.7829949883347742, 0.795261262431337, 0.795261262431337, 0.795261262431337, 0.18258868032194564, 0.18258868032194564, 0.18258868032194564, 0.13558190841721096, 0.13558190841721096, 0.13558190841721096, 0.20392957325731054, 0.20392957325731054, 0.20392957325731054, 0.20477944937700276, 0.20477944937700276, 0.20477944937700276, 0.2059822333515562, 0.2059822333515562, 0.2059822333515562, 0.18062177873508956, 0.18062177873508956, 0.18062177873508956, 0.18909239282942458, 0.18909239282942458, 0.18909239282942458, 0.08876146657103179, 0.08876146657103179, 0.08876146657103179, 0.06812753398679194, 0.06812753398679194, 0.06812753398679194, 0.07289673439406508, 0.07289673439406508, 0.07289673439406508]}, "mutation_prompt": null}
{"id": "53d36ada-71f8-40c4-8112-732f156356ce", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "c62e90c5-620f-4637-af1f-b11d767cb03e", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.1  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.3  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm blending Differential Evolution, Particle Swarm Optimization, and adaptive mutation to enhance search efficiency and solution diversity.", "configspace": "", "generation": 86, "fitness": 0.3122775086667873, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.28.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9011940633966641, 0.9011940633966641, 0.9011940633966641, 0.8875577623537324, 0.8875577623537324, 0.8875577623537324, 0.893894740438234, 0.893894740438234, 0.893894740438234, 0.7803297856175927, 0.7803297856175927, 0.7803297856175927, 0.06750291820714849, 0.06750291820714849, 0.06750291820714849, 0.050745062548206765, 0.050745062548206765, 0.050745062548206765, 0.1534552184110809, 0.1534552184110809, 0.1534552184110809, 0.14988679031949304, 0.14988679031949304, 0.14988679031949304, 0.1745176055519405, 0.1745176055519405, 0.1745176055519405, 0.1398194399483449, 0.1398194399483449, 0.1398194399483449, 0.14105683250163692, 0.14105683250163692, 0.14105683250163692, 0.11617142593074081, 0.11617142593074081, 0.11617142593074081, 0.9873911083564529, 0.9873911083564529, 0.9873911083564529, 0.9851837268567564, 0.9851837268567564, 0.9851837268567564, 0.9890947995575218, 0.9890947995575218, 0.9890947995575218, 0.6528728447948564, 0.6528728447948564, 0.6528728447948564, 0.6516648062039391, 0.6516648062039391, 0.6516648062039391, 0.6656060863455676, 0.6656060863455676, 0.6656060863455676, 0.37279848848279784, 0.37279848848279784, 0.37279848848279784, 0.16254875288195403, 0.16254875288195403, 0.16254875288195403, 0.12506704740110086, 0.12506704740110086, 0.12506704740110086, 0.301722950258986, 0.301722950258986, 0.301722950258986, 0.38503632228102014, 0.38503632228102014, 0.38503632228102014, 0.13334619841261897, 0.13334619841261897, 0.13334619841261897, 0.24408403757212338, 0.24408403757212338, 0.24408403757212338, 0.34041006749448266, 0.34041006749448266, 0.34041006749448266, 0.12951449014699212, 0.12951449014699212, 0.12951449014699212, 0.0471513233989741, 0.0471513233989741, 0.0471513233989741, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00920497696173428, 0.00920497696173428, 0.00920497696173428, 0.14309117530955684, 0.14309117530955684, 0.14309117530955684, 0.07349032349660178, 0.07349032349660178, 0.07349032349660178, 0.08559979899892844, 0.08559979899892844, 0.08559979899892844, 0.03850522701181913, 0.03850522701181913, 0.03850522701181913, 0.11692413376715971, 0.11692413376715971, 0.11692413376715971, 0.17704134065333876, 0.17704134065333876, 0.17704134065333876, 0.04300879463464258, 0.04300879463464258, 0.04300879463464258, 0.12067823040296932, 0.12067823040296932, 0.12067823040296932, 0.18008023187429867, 0.18008023187429867, 0.18008023187429867, 0.553431325030961, 0.553431325030961, 0.553431325030961, 0.6452600754686029, 0.6452600754686029, 0.6452600754686029, 0.5992404349734034, 0.5992404349734034, 0.5992404349734034, 0.14146034644289562, 0.14146034644289562, 0.14146034644289562, 0.14140152194675992, 0.14140152194675992, 0.14140152194675992, 0.12240069900789763, 0.12240069900789763, 0.12240069900789763, 0.1873533587813433, 0.1873533587813433, 0.1873533587813433, 0.17884201780046882, 0.17884201780046882, 0.17884201780046882, 0.1937183536304916, 0.1937183536304916, 0.1937183536304916, 0.30206059501531257, 0.30206059501531257, 0.30206059501531257, 0.29339345426206986, 0.29339345426206986, 0.29339345426206986, 0.28713579826656976, 0.28713579826656976, 0.28713579826656976, 0.24018907820058955, 0.24018907820058955, 0.24018907820058955, 0.2503078747119988, 0.2503078747119988, 0.2503078747119988, 0.14328662772616152, 0.14328662772616152, 0.14328662772616152, 0.2102560905232913, 0.2102560905232913, 0.2102560905232913, 0.20025429064528255, 0.20025429064528255, 0.20025429064528255, 0.19221013988680757, 0.19221013988680757, 0.19221013988680757, 0.713674172964099, 0.713674172964099, 0.713674172964099, 0.22115581458030764, 0.22115581458030764, 0.22115581458030764, 0.6867020835810824, 0.6867020835810824, 0.6867020835810824, 0.9356053454157084, 0.9356053454157084, 0.9356053454157084, 0.8935336114387245, 0.8935336114387245, 0.8935336114387245, 0.16713945187835744, 0.16713945187835744, 0.16713945187835744, 0.1641836795555197, 0.1641836795555197, 0.1641836795555197, 0.21003115768359226, 0.21003115768359226, 0.21003115768359226, 0.1552404359550248, 0.1552404359550248, 0.1552404359550248, 0.17997118674895973, 0.17997118674895973, 0.17997118674895973, 0.1971589877608898, 0.1971589877608898, 0.1971589877608898, 0.18129938251368516, 0.18129938251368516, 0.18129938251368516, 0.09230118557309541, 0.09230118557309541, 0.09230118557309541, 0.09977827980527798, 0.09977827980527798, 0.09977827980527798, 0.08665483745144287, 0.08665483745144287, 0.08665483745144287]}, "mutation_prompt": null}
{"id": "f6a6f7af-ce9a-46fe-a0e0-93f9e38fedc0", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "011756ed-b5d1-4432-8ca2-d03f61516595", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.7  # Modified Differential weight\n        self.initial_de_cr = 0.9  # Modified Crossover probability\n        self.initial_pso_w = 0.6  # Modified Inertia weight\n        self.pso_c1 = 1.2  # Modified Cognitive coefficient\n        self.pso_c2 = 1.5  # Modified Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adaptive DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.4 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.6 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Dynamic diversity injection\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid evolutionary algorithm blending Differential Evolution and Particle Swarm Optimization with adaptive parameter tuning and dynamic diversity injection for efficient global and local search.", "configspace": "", "generation": 88, "fitness": 0.3142053419575801, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.29.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8511466018630056, 0.8511466018630056, 0.8511466018630056, 0.865642234756294, 0.865642234756294, 0.865642234756294, 0.8876571185223067, 0.8876571185223067, 0.8876571185223067, 0.18655019251204152, 0.18655019251204152, 0.18655019251204152, 0.6853952267470074, 0.6853952267470074, 0.6853952267470074, 0.08241647852798484, 0.08241647852798484, 0.08241647852798484, 0.12449627243669892, 0.12449627243669892, 0.12449627243669892, 0.11815453747718152, 0.11815453747718152, 0.11815453747718152, 0.15508847018256877, 0.15508847018256877, 0.15508847018256877, 0.12542608621354845, 0.12542608621354845, 0.12542608621354845, 0.11311985560364224, 0.11311985560364224, 0.11311985560364224, 0.10551049124895584, 0.10551049124895584, 0.10551049124895584, 0.9887592036126365, 0.9887592036126365, 0.9887592036126365, 0.9907034540939397, 0.9907034540939397, 0.9907034540939397, 0.9893180698631221, 0.9893180698631221, 0.9893180698631221, 0.5390949873162436, 0.5390949873162436, 0.5390949873162436, 0.45313552178460004, 0.45313552178460004, 0.45313552178460004, 0.4809616656493274, 0.4809616656493274, 0.4809616656493274, 0.22670967318751012, 0.22670967318751012, 0.22670967318751012, 0.21274938781079622, 0.21274938781079622, 0.21274938781079622, 0.8362313561111442, 0.8362313561111442, 0.8362313561111442, 0.2319982240007219, 0.2319982240007219, 0.2319982240007219, 0.2688128237687585, 0.2688128237687585, 0.2688128237687585, 0.25095677647308146, 0.25095677647308146, 0.25095677647308146, 0.12851461523161456, 0.12851461523161456, 0.12851461523161456, 0.13237148040123825, 0.13237148040123825, 0.13237148040123825, 0.25706057623840295, 0.25706057623840295, 0.25706057623840295, 0.009463651803480078, 0.009463651803480078, 0.009463651803480078, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07131934500192039, 0.07131934500192039, 0.07131934500192039, 0.16103764111922647, 0.16103764111922647, 0.16103764111922647, 0.07008466011113434, 0.07008466011113434, 0.07008466011113434, 0.09103001756552054, 0.09103001756552054, 0.09103001756552054, 0.030821458512932276, 0.030821458512932276, 0.030821458512932276, 0.07139136751312236, 0.07139136751312236, 0.07139136751312236, 0.10029889024313399, 0.10029889024313399, 0.10029889024313399, 0.04293040609240617, 0.04293040609240617, 0.04293040609240617, 0.03921378324172442, 0.03921378324172442, 0.03921378324172442, 0.048601482361271375, 0.048601482361271375, 0.048601482361271375, 0.532664683257476, 0.532664683257476, 0.532664683257476, 0.5511522352515061, 0.5511522352515061, 0.5511522352515061, 0.5480613964069587, 0.5480613964069587, 0.5480613964069587, 0.08349640114497392, 0.08349640114497392, 0.08349640114497392, 0.12311677821624689, 0.12311677821624689, 0.12311677821624689, 0.1260776965107685, 0.1260776965107685, 0.1260776965107685, 0.18055520089528532, 0.18055520089528532, 0.18055520089528532, 0.181436992941705, 0.181436992941705, 0.181436992941705, 0.25030084614864023, 0.25030084614864023, 0.25030084614864023, 0.37816229959859593, 0.37816229959859593, 0.37816229959859593, 0.34999438233435887, 0.34999438233435887, 0.34999438233435887, 0.5650716812517422, 0.5650716812517422, 0.5650716812517422, 0.24103786508286562, 0.24103786508286562, 0.24103786508286562, 0.18532643289235406, 0.18532643289235406, 0.18532643289235406, 0.14205332060669118, 0.14205332060669118, 0.14205332060669118, 0.17146018931084694, 0.17146018931084694, 0.17146018931084694, 0.17154855960702076, 0.17154855960702076, 0.17154855960702076, 0.19033777154875697, 0.19033777154875697, 0.19033777154875697, 0.20208360941657755, 0.20208360941657755, 0.20208360941657755, 0.21636655340095567, 0.21636655340095567, 0.21636655340095567, 0.6822757507954672, 0.6822757507954672, 0.6822757507954672, 0.8761425965066648, 0.8761425965066648, 0.8761425965066648, 0.9155136412084024, 0.9155136412084024, 0.9155136412084024, 0.16787344391430592, 0.16787344391430592, 0.16787344391430592, 0.7596352601322544, 0.7596352601322544, 0.7596352601322544, 0.21038498133262018, 0.21038498133262018, 0.21038498133262018, 0.8148034587305995, 0.8148034587305995, 0.8148034587305995, 0.18015771971466, 0.18015771971466, 0.18015771971466, 0.18719495185859547, 0.18719495185859547, 0.18719495185859547, 0.1956508577113697, 0.1956508577113697, 0.1956508577113697, 0.06900065786144916, 0.06900065786144916, 0.06900065786144916, 0.0738844403237201, 0.0738844403237201, 0.0738844403237201, 0.07568787983108793, 0.07568787983108793, 0.07568787983108793]}, "mutation_prompt": null}
{"id": "87ee730c-5e81-4b51-9c3f-6a272cc507fc", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "5d04a330-4625-4810-81bd-949c55d23437", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for diversity\n        self.initial_de_f = 0.7  # Adjusted Differential weight for better exploration\n        self.initial_de_cr = 0.9  # Increased Crossover probability for diversity\n        self.initial_pso_w = 0.6  # Increased Inertia weight for better convergence\n        self.pso_c1 = 1.2  # Increased Cognitive coefficient for individual learning\n        self.pso_c2 = 1.5  # Increased Social coefficient for global learning\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.4 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An Adaptive Differential Evolution and Particle Swarm Optimization hybrid algorithm with dynamic parameter tuning and enhanced exploration-exploitation balance.", "configspace": "", "generation": 90, "fitness": 0.30285196529509406, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8554597422699154, 0.8554597422699154, 0.8554597422699154, 0.8750744681155178, 0.8750744681155178, 0.8750744681155178, 0.8601325412989054, 0.8601325412989054, 0.8601325412989054, 0.6527040312375867, 0.6527040312375867, 0.6527040312375867, 0.7339659092157154, 0.7339659092157154, 0.7339659092157154, 0.7234267623229977, 0.7234267623229977, 0.7234267623229977, 0.14306758253275853, 0.14306758253275853, 0.14306758253275853, 0.4918743699224769, 0.4918743699224769, 0.4918743699224769, 0.12796787469483772, 0.12796787469483772, 0.12796787469483772, 0.12271971574913076, 0.12271971574913076, 0.12271971574913076, 0.13923260706160168, 0.13923260706160168, 0.13923260706160168, 0.14404610538156026, 0.14404610538156026, 0.14404610538156026, 0.981134644354775, 0.981134644354775, 0.981134644354775, 0.9877023455413931, 0.9877023455413931, 0.9877023455413931, 0.9897215486255213, 0.9897215486255213, 0.9897215486255213, 0.5440386542990157, 0.5440386542990157, 0.5440386542990157, 0.5743179636212572, 0.5743179636212572, 0.5743179636212572, 0.47174724799485135, 0.47174724799485135, 0.47174724799485135, 0.3463192318457926, 0.3463192318457926, 0.3463192318457926, 0.16094380891200255, 0.16094380891200255, 0.16094380891200255, 0.15126480871818204, 0.15126480871818204, 0.15126480871818204, 0.20986968675190587, 0.20986968675190587, 0.20986968675190587, 0.24295873008565527, 0.24295873008565527, 0.24295873008565527, 0.24351672938814395, 0.24351672938814395, 0.24351672938814395, 0.25076209933268523, 0.25076209933268523, 0.25076209933268523, 0.13190356464304254, 0.13190356464304254, 0.13190356464304254, 0.29246392477480077, 0.29246392477480077, 0.29246392477480077, 0.05370109445794147, 0.05370109445794147, 0.05370109445794147, 0.0005170138503907129, 0.0005170138503907129, 0.0005170138503907129, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13547831001740962, 0.13547831001740962, 0.13547831001740962, 0.037265820295571905, 0.037265820295571905, 0.037265820295571905, 0.04484173640780498, 0.04484173640780498, 0.04484173640780498, 0.08837189828777814, 0.08837189828777814, 0.08837189828777814, 0.07436443925754865, 0.07436443925754865, 0.07436443925754865, 0.0709361992607428, 0.0709361992607428, 0.0709361992607428, 0.13536366333375138, 0.13536366333375138, 0.13536366333375138, 0.09305430003775039, 0.09305430003775039, 0.09305430003775039, 0.21997294557104774, 0.21997294557104774, 0.21997294557104774, 0.5323597292047006, 0.5323597292047006, 0.5323597292047006, 0.6132772993834837, 0.6132772993834837, 0.6132772993834837, 0.5737242359256983, 0.5737242359256983, 0.5737242359256983, 0.12132949419314809, 0.12132949419314809, 0.12132949419314809, 0.14204719816156552, 0.14204719816156552, 0.14204719816156552, 0.13351161916043763, 0.13351161916043763, 0.13351161916043763, 0.1359893760822768, 0.1359893760822768, 0.1359893760822768, 0.16344400161547035, 0.16344400161547035, 0.16344400161547035, 0.3637630726763058, 0.3637630726763058, 0.3637630726763058, 0.3955348772149432, 0.3955348772149432, 0.3955348772149432, 0.24305832140704653, 0.24305832140704653, 0.24305832140704653, 0.5928256078986953, 0.5928256078986953, 0.5928256078986953, 0.19113081080274696, 0.19113081080274696, 0.19113081080274696, 0.20563708794542357, 0.20563708794542357, 0.20563708794542357, 0.19767847224249935, 0.19767847224249935, 0.19767847224249935, 0.18345491113888468, 0.18345491113888468, 0.18345491113888468, 0.18025084256861612, 0.18025084256861612, 0.18025084256861612, 0.20983783855358595, 0.20983783855358595, 0.20983783855358595, 0.20541254614213555, 0.20541254614213555, 0.20541254614213555, 0.2126745487720344, 0.2126745487720344, 0.2126745487720344, 0.24360604533041508, 0.24360604533041508, 0.24360604533041508, 0.8713690554286609, 0.8713690554286609, 0.8713690554286609, 0.158632919689227, 0.158632919689227, 0.158632919689227, 0.1399426731205058, 0.1399426731205058, 0.1399426731205058, 0.16683871863128863, 0.16683871863128863, 0.16683871863128863, 0.20906759968580013, 0.20906759968580013, 0.20906759968580013, 0.15631163556739502, 0.15631163556739502, 0.15631163556739502, 0.18268391314336607, 0.18268391314336607, 0.18268391314336607, 0.1978650551982183, 0.1978650551982183, 0.1978650551982183, 0.19337933216877368, 0.19337933216877368, 0.19337933216877368, 0.11214847687101814, 0.11214847687101814, 0.11214847687101814, 0.0814486556267271, 0.0814486556267271, 0.0814486556267271, 0.09280141022591692, 0.09280141022591692, 0.09280141022591692]}, "mutation_prompt": null}
{"id": "5481300c-7c93-48bd-8ee2-988d3faf06bd", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for more diversity\n        self.initial_de_f = 0.9  # Slightly increased Differential weight\n        self.initial_de_cr = 0.8  # Slightly lowered Crossover probability for more exploration\n        self.initial_pso_w = 0.4  # Lowered Inertia weight for quicker convergence\n        self.pso_c1 = 1.1  # Increased Cognitive coefficient for better personal exploration\n        self.pso_c2 = 1.3  # Increased Social coefficient for stronger attraction to global best\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Initialize with random velocities\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.3))  # Increased diversity count\n                randomized_indices = np.random.choice(self.population_size, diversity_count, replace=False)\n                for idx in randomized_indices:\n                    population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                    fitness[idx] = func(population[idx])\n                    self.eval_count += 1\n                    if fitness[idx] < personal_best_fitness[idx]:\n                        personal_best[idx] = population[idx]\n                        personal_best_fitness[idx] = fitness[idx]\n                        if fitness[idx] < personal_best_fitness[global_best_idx]:\n                            global_best = population[idx]\n                            global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedHybridDEPSO", "description": "A novel algorithm leveraging an adaptive hybrid of Differential Evolution and Particle Swarm Optimization with dynamic parameter balancing, diversity boosting, and local search enhancement for robust convergence.", "configspace": "", "generation": 91, "fitness": 0.32560700556247313, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.30.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9255970833039854, 0.9255970833039854, 0.9255970833039854, 0.9300548193781005, 0.9300548193781005, 0.9300548193781005, 0.9274131583776687, 0.9274131583776687, 0.9274131583776687, 0.8613405405580469, 0.8613405405580469, 0.8613405405580469, 0.8606008346713638, 0.8606008346713638, 0.8606008346713638, 0.8428128347756263, 0.8428128347756263, 0.8428128347756263, 0.10154597774152685, 0.10154597774152685, 0.10154597774152685, 0.11613905498448585, 0.11613905498448585, 0.11613905498448585, 0.16019950201197097, 0.16019950201197097, 0.16019950201197097, 0.06950383951221173, 0.06950383951221173, 0.06950383951221173, 0.14043719859116588, 0.14043719859116588, 0.14043719859116588, 0.1109487127546741, 0.1109487127546741, 0.1109487127546741, 0.9889778271945532, 0.9889778271945532, 0.9889778271945532, 0.9815718463365444, 0.9815718463365444, 0.9815718463365444, 0.9841202727047488, 0.9841202727047488, 0.9841202727047488, 0.7854031924908866, 0.7854031924908866, 0.7854031924908866, 0.780999315302681, 0.780999315302681, 0.780999315302681, 0.8206955206525335, 0.8206955206525335, 0.8206955206525335, 0.38237502912730703, 0.38237502912730703, 0.38237502912730703, 0.16394429831030688, 0.16394429831030688, 0.16394429831030688, 0.2528231678758667, 0.2528231678758667, 0.2528231678758667, 0.2512229218495411, 0.2512229218495411, 0.2512229218495411, 0.12410207259752826, 0.12410207259752826, 0.12410207259752826, 0.2797900000513148, 0.2797900000513148, 0.2797900000513148, 0.26680921297452664, 0.26680921297452664, 0.26680921297452664, 0.2861750446647974, 0.2861750446647974, 0.2861750446647974, 0.28030433892589424, 0.28030433892589424, 0.28030433892589424, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030761357167133796, 0.030761357167133796, 0.030761357167133796, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06392865646461743, 0.06392865646461743, 0.06392865646461743, 0.12856613285620255, 0.12856613285620255, 0.12856613285620255, 0.12604964575696942, 0.12604964575696942, 0.12604964575696942, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13772677680731082, 0.13772677680731082, 0.13772677680731082, 0.07660389241728116, 0.07660389241728116, 0.07660389241728116, 0.045272628786285685, 0.045272628786285685, 0.045272628786285685, 0.03912298495191224, 0.03912298495191224, 0.03912298495191224, 0.04986700064701821, 0.04986700064701821, 0.04986700064701821, 0.5616706005156238, 0.5616706005156238, 0.5616706005156238, 0.5767669826896481, 0.5767669826896481, 0.5767669826896481, 0.6672046214125611, 0.6672046214125611, 0.6672046214125611, 0.11583961741978543, 0.11583961741978543, 0.11583961741978543, 0.13910516967220088, 0.13910516967220088, 0.13910516967220088, 0.15475047088043414, 0.15475047088043414, 0.15475047088043414, 0.272750970320112, 0.272750970320112, 0.272750970320112, 0.19574413898257426, 0.19574413898257426, 0.19574413898257426, 0.1477865913697386, 0.1477865913697386, 0.1477865913697386, 0.5412927547285928, 0.5412927547285928, 0.5412927547285928, 0.20787411159779345, 0.20787411159779345, 0.20787411159779345, 0.5553229687150871, 0.5553229687150871, 0.5553229687150871, 0.3294135821546501, 0.3294135821546501, 0.3294135821546501, 0.33955270662710557, 0.33955270662710557, 0.33955270662710557, 0.1732994601251877, 0.1732994601251877, 0.1732994601251877, 0.23678377132049244, 0.23678377132049244, 0.23678377132049244, 0.24105424189198943, 0.24105424189198943, 0.24105424189198943, 0.22130026620607657, 0.22130026620607657, 0.22130026620607657, 0.25636025938731777, 0.25636025938731777, 0.25636025938731777, 0.22708768244150623, 0.22708768244150623, 0.22708768244150623, 0.21041257729022533, 0.21041257729022533, 0.21041257729022533, 0.943881093325472, 0.943881093325472, 0.943881093325472, 0.158950250271098, 0.158950250271098, 0.158950250271098, 0.17127139109799971, 0.17127139109799971, 0.17127139109799971, 0.21309611449587507, 0.21309611449587507, 0.21309611449587507, 0.21249390929173995, 0.21249390929173995, 0.21249390929173995, 0.15929128926710312, 0.15929128926710312, 0.15929128926710312, 0.18446312817366128, 0.18446312817366128, 0.18446312817366128, 0.17681724183585124, 0.17681724183585124, 0.17681724183585124, 0.20672456475955947, 0.20672456475955947, 0.20672456475955947, 0.0922669694713768, 0.0922669694713768, 0.0922669694713768, 0.09217709237656924, 0.09217709237656924, 0.09217709237656924, 0.08679111680846441, 0.08679111680846441, 0.08679111680846441]}, "mutation_prompt": null}
{"id": "94c80a23-eedd-4f7d-acfa-a290315991d2", "solution": "import numpy as np\n\nclass RefinedAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Adjusted Differential weight\n        self.initial_de_cr = 0.8  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.2  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.4  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.75:\n                diversity_count = max(1, int(self.population_size * 0.25))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "RefinedAdaptiveHybridDEPSO", "description": "A refined adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with enhanced selection strategies for improved exploration and exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.31421889794677, "feedback": "The algorithm RefinedAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.29.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.868011225736239, 0.868011225736239, 0.868011225736239, 0.8748110645952648, 0.8748110645952648, 0.8748110645952648, 0.8788141801664424, 0.8788141801664424, 0.8788141801664424, 0.7805179076754833, 0.7805179076754833, 0.7805179076754833, 0.7536621265347612, 0.7536621265347612, 0.7536621265347612, 0.06525271953846701, 0.06525271953846701, 0.06525271953846701, 0.10837305963228205, 0.10837305963228205, 0.10837305963228205, 0.7385004032142197, 0.7385004032142197, 0.7385004032142197, 0.5774358891458744, 0.5774358891458744, 0.5774358891458744, 0.10909082762221389, 0.10909082762221389, 0.10909082762221389, 0.10976294092898575, 0.10976294092898575, 0.10976294092898575, 0.09616346808867615, 0.09616346808867615, 0.09616346808867615, 0.9902956258713165, 0.9902956258713165, 0.9902956258713165, 0.9881822697179566, 0.9881822697179566, 0.9881822697179566, 0.9916597533934549, 0.9916597533934549, 0.9916597533934549, 0.6446866953242134, 0.6446866953242134, 0.6446866953242134, 0.6397454224193757, 0.6397454224193757, 0.6397454224193757, 0.6729414007738498, 0.6729414007738498, 0.6729414007738498, 0.21884679520625572, 0.21884679520625572, 0.21884679520625572, 0.2751237875030247, 0.2751237875030247, 0.2751237875030247, 0.1287915509159362, 0.1287915509159362, 0.1287915509159362, 0.2989368684883712, 0.2989368684883712, 0.2989368684883712, 0.1143675832299823, 0.1143675832299823, 0.1143675832299823, 0.24090532521762098, 0.24090532521762098, 0.24090532521762098, 0.2678216106671887, 0.2678216106671887, 0.2678216106671887, 0.28720594356210105, 0.28720594356210105, 0.28720594356210105, 0.17089985042834543, 0.17089985042834543, 0.17089985042834543, 0.033132148121569505, 0.033132148121569505, 0.033132148121569505, 0.032604283948398316, 0.032604283948398316, 0.032604283948398316, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12724233924272899, 0.12724233924272899, 0.12724233924272899, 0.10231814323209965, 0.10231814323209965, 0.10231814323209965, 0.06483707374899661, 0.06483707374899661, 0.06483707374899661, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07743403880844923, 0.07743403880844923, 0.07743403880844923, 0.23021444756260168, 0.23021444756260168, 0.23021444756260168, 0.04345169178429953, 0.04345169178429953, 0.04345169178429953, 0.03930018379360556, 0.03930018379360556, 0.03930018379360556, 0.08302150135905961, 0.08302150135905961, 0.08302150135905961, 0.5529693833046796, 0.5529693833046796, 0.5529693833046796, 0.5391337555911397, 0.5391337555911397, 0.5391337555911397, 0.5701198432650582, 0.5701198432650582, 0.5701198432650582, 0.1298033058127145, 0.1298033058127145, 0.1298033058127145, 0.10171442411532639, 0.10171442411532639, 0.10171442411532639, 0.08501677282260967, 0.08501677282260967, 0.08501677282260967, 0.22897892399866082, 0.22897892399866082, 0.22897892399866082, 0.18094472626813995, 0.18094472626813995, 0.18094472626813995, 0.23615058629936347, 0.23615058629936347, 0.23615058629936347, 0.5191346337111424, 0.5191346337111424, 0.5191346337111424, 0.20487730547211236, 0.20487730547211236, 0.20487730547211236, 0.386255834130086, 0.386255834130086, 0.386255834130086, 0.31045346944955954, 0.31045346944955954, 0.31045346944955954, 0.23653008387017782, 0.23653008387017782, 0.23653008387017782, 0.17575593333720085, 0.17575593333720085, 0.17575593333720085, 0.1813147208282081, 0.1813147208282081, 0.1813147208282081, 0.1930343233473817, 0.1930343233473817, 0.1930343233473817, 0.20240858064839162, 0.20240858064839162, 0.20240858064839162, 0.2205006563454499, 0.2205006563454499, 0.2205006563454499, 0.19666853163201392, 0.19666853163201392, 0.19666853163201392, 0.1981857357265212, 0.1981857357265212, 0.1981857357265212, 0.9098823939030714, 0.9098823939030714, 0.9098823939030714, 0.1770277333644612, 0.1770277333644612, 0.1770277333644612, 0.17042098725015042, 0.17042098725015042, 0.17042098725015042, 0.1192979932546514, 0.1192979932546514, 0.1192979932546514, 0.8449359819344877, 0.8449359819344877, 0.8449359819344877, 0.21242118478314265, 0.21242118478314265, 0.21242118478314265, 0.1947251910509864, 0.1947251910509864, 0.1947251910509864, 0.17096239761300236, 0.17096239761300236, 0.17096239761300236, 0.19288327858997956, 0.19288327858997956, 0.19288327858997956, 0.07184934788519237, 0.07184934788519237, 0.07184934788519237, 0.10152332626057392, 0.10152332626057392, 0.10152332626057392, 0.08331715910208781, 0.08331715910208781, 0.08331715910208781]}, "mutation_prompt": null}
{"id": "46f97e8e-fe14-4d4f-bbdd-75e18cfe6221", "solution": "import numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.9  # Adjusted Differential weight for better exploration\n        self.initial_de_cr = 0.8  # Adjusted Crossover probability for more varied trials\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight to balance exploration and exploitation\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient for stronger individual learning\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.4 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Stochastic restarts for enhanced diversity after substantial progress\n            if self.eval_count >= self.max_evaluations * 0.75:\n                restart_count = max(1, int(self.population_size * 0.3))\n                for _ in range(restart_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedHybridDEPSO", "description": "An enhanced hybrid evolutionary algorithm blending Differential Evolution and Particle Swarm Optimization with adaptive parameter tuning and stochastic restarts to effectively navigate diverse optimization landscapes.", "configspace": "", "generation": 93, "fitness": 0.32530099602858303, "feedback": "The algorithm EnhancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.29.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8897810452466529, 0.8897810452466529, 0.8897810452466529, 0.8833627702482583, 0.8833627702482583, 0.8833627702482583, 0.8862771512717593, 0.8862771512717593, 0.8862771512717593, 0.7538878455311917, 0.7538878455311917, 0.7538878455311917, 0.7662376547082799, 0.7662376547082799, 0.7662376547082799, 0.7171747782800844, 0.7171747782800844, 0.7171747782800844, 0.37935364607460065, 0.37935364607460065, 0.37935364607460065, 0.15190547844933322, 0.15190547844933322, 0.15190547844933322, 0.1687926839768652, 0.1687926839768652, 0.1687926839768652, 0.10653782049046645, 0.10653782049046645, 0.10653782049046645, 0.14394250228364414, 0.14394250228364414, 0.14394250228364414, 0.10378755387296368, 0.10378755387296368, 0.10378755387296368, 0.990522450445975, 0.990522450445975, 0.990522450445975, 0.9873685819350636, 0.9873685819350636, 0.9873685819350636, 0.9903582571491775, 0.9903582571491775, 0.9903582571491775, 0.6863457229592158, 0.6863457229592158, 0.6863457229592158, 0.618648547808109, 0.618648547808109, 0.618648547808109, 0.6708662570661685, 0.6708662570661685, 0.6708662570661685, 0.8126997258187452, 0.8126997258187452, 0.8126997258187452, 0.16200418247698511, 0.16200418247698511, 0.16200418247698511, 0.13742193927164859, 0.13742193927164859, 0.13742193927164859, 0.2748744755218476, 0.2748744755218476, 0.2748744755218476, 0.26741625724716267, 0.26741625724716267, 0.26741625724716267, 0.2676651509512049, 0.2676651509512049, 0.2676651509512049, 0.2506202302435858, 0.2506202302435858, 0.2506202302435858, 0.26456463628903715, 0.26456463628903715, 0.26456463628903715, 0.2892595692078095, 0.2892595692078095, 0.2892595692078095, 0.005517755668306035, 0.005517755668306035, 0.005517755668306035, 0.010110903813753791, 0.010110903813753791, 0.010110903813753791, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.057992621363589514, 0.057992621363589514, 0.057992621363589514, 0.042049238178407, 0.042049238178407, 0.042049238178407, 0.1095162403114871, 0.1095162403114871, 0.1095162403114871, 0.03892821504268851, 0.03892821504268851, 0.03892821504268851, 0.08021523717705781, 0.08021523717705781, 0.08021523717705781, 0.10403498798588406, 0.10403498798588406, 0.10403498798588406, 0.046429897066401105, 0.046429897066401105, 0.046429897066401105, 0.039040320713684795, 0.039040320713684795, 0.039040320713684795, 0.08296079483873675, 0.08296079483873675, 0.08296079483873675, 0.5379205364849734, 0.5379205364849734, 0.5379205364849734, 0.5774288118433354, 0.5774288118433354, 0.5774288118433354, 0.5611644144768542, 0.5611644144768542, 0.5611644144768542, 0.09883842564434131, 0.09883842564434131, 0.09883842564434131, 0.11515934516478377, 0.11515934516478377, 0.11515934516478377, 0.12665686227415585, 0.12665686227415585, 0.12665686227415585, 0.15896775797891183, 0.15896775797891183, 0.15896775797891183, 0.17045656574027324, 0.17045656574027324, 0.17045656574027324, 0.2622373176862669, 0.2622373176862669, 0.2622373176862669, 0.4954936522168748, 0.4954936522168748, 0.4954936522168748, 0.4419107394230174, 0.4419107394230174, 0.4419107394230174, 0.6053611731358648, 0.6053611731358648, 0.6053611731358648, 0.12193684741043687, 0.12193684741043687, 0.12193684741043687, 0.1930018757542019, 0.1930018757542019, 0.1930018757542019, 0.20386340563317285, 0.20386340563317285, 0.20386340563317285, 0.18082055444823508, 0.18082055444823508, 0.18082055444823508, 0.18783585756074406, 0.18783585756074406, 0.18783585756074406, 0.16453825130092192, 0.16453825130092192, 0.16453825130092192, 0.20604152802818299, 0.20604152802818299, 0.20604152802818299, 0.20655081582301105, 0.20655081582301105, 0.20655081582301105, 0.19278062692689668, 0.19278062692689668, 0.19278062692689668, 0.9053958516282743, 0.9053958516282743, 0.9053958516282743, 0.8740984443710237, 0.8740984443710237, 0.8740984443710237, 0.16732694975607632, 0.16732694975607632, 0.16732694975607632, 0.20874180735214387, 0.20874180735214387, 0.20874180735214387, 0.21099018188023977, 0.21099018188023977, 0.21099018188023977, 0.21007540183275664, 0.21007540183275664, 0.21007540183275664, 0.1775717326081765, 0.1775717326081765, 0.1775717326081765, 0.17649107284493692, 0.17649107284493692, 0.17649107284493692, 0.17767373797927943, 0.17767373797927943, 0.17767373797927943, 0.07498035825026272, 0.07498035825026272, 0.07498035825026272, 0.10842760948418706, 0.10842760948418706, 0.10842760948418706, 0.08236007412933466, 0.08236007412933466, 0.08236007412933466]}, "mutation_prompt": null}
{"id": "63611af3-0d7f-4243-94ea-456bb8a32674", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8  # Adjusted Differential weight\n        self.initial_de_cr = 0.85  # Adjusted Crossover probability\n        self.initial_pso_w = 0.5  # Adjusted Inertia weight\n        self.pso_c1 = 1.0  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.2  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Adjust DE and PSO parameters based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity by randomizing part of the population\n            if self.eval_count >= self.max_evaluations * 0.70:\n                diversity_count = max(1, int(self.population_size * 0.2))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "An adaptive hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization with diversity enhancement and strategy adaptation to effectively explore and exploit complex search spaces.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9232487185623751, 0.9232487185623751, 0.9232487185623751, 0.9240353324442977, 0.9240353324442977, 0.9240353324442977, 0.9282410184770217, 0.9282410184770217, 0.9282410184770217, 0.8437605446934444, 0.8437605446934444, 0.8437605446934444, 0.8629778222665359, 0.8629778222665359, 0.8629778222665359, 0.055139695687251855, 0.055139695687251855, 0.055139695687251855, 0.18408250545421057, 0.18408250545421057, 0.18408250545421057, 0.14504108970579366, 0.14504108970579366, 0.14504108970579366, 0.15081951858532316, 0.15081951858532316, 0.15081951858532316, 0.14388073803367374, 0.14388073803367374, 0.14388073803367374, 0.10340428141839098, 0.10340428141839098, 0.10340428141839098, 0.13233200049488658, 0.13233200049488658, 0.13233200049488658, 0.9889021253005585, 0.9889021253005585, 0.9889021253005585, 0.9871536052837072, 0.9871536052837072, 0.9871536052837072, 0.9880389742642087, 0.9880389742642087, 0.9880389742642087, 0.8202139016944434, 0.8202139016944434, 0.8202139016944434, 0.7851796383452052, 0.7851796383452052, 0.7851796383452052, 0.7450997900464497, 0.7450997900464497, 0.7450997900464497, 0.8864138434272425, 0.8864138434272425, 0.8864138434272425, 0.27776856216130674, 0.27776856216130674, 0.27776856216130674, 0.37532500090017784, 0.37532500090017784, 0.37532500090017784, 0.31431700809349017, 0.31431700809349017, 0.31431700809349017, 0.10868392601941412, 0.10868392601941412, 0.10868392601941412, 0.31555544104604094, 0.31555544104604094, 0.31555544104604094, 0.2865868975403426, 0.2865868975403426, 0.2865868975403426, 0.337153958085495, 0.337153958085495, 0.337153958085495, 0.3155630707350974, 0.3155630707350974, 0.3155630707350974, 0.08749667874605349, 0.08749667874605349, 0.08749667874605349, 0.017889600195097555, 0.017889600195097555, 0.017889600195097555, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09982780792109702, 0.09982780792109702, 0.09982780792109702, 0.0056802079821663964, 0.0056802079821663964, 0.0056802079821663964, 0.08718647954492065, 0.08718647954492065, 0.08718647954492065, 0.10371260014238759, 0.10371260014238759, 0.10371260014238759, 0.08178539280250663, 0.08178539280250663, 0.08178539280250663, 0.08829464467934012, 0.08829464467934012, 0.08829464467934012, 0.2579964918908486, 0.2579964918908486, 0.2579964918908486, 0.03984513863242134, 0.03984513863242134, 0.03984513863242134, 0.15360476533396972, 0.15360476533396972, 0.15360476533396972, 0.5763958891715322, 0.5763958891715322, 0.5763958891715322, 0.6025201252930145, 0.6025201252930145, 0.6025201252930145, 0.6199077093515191, 0.6199077093515191, 0.6199077093515191, 0.10865541009370172, 0.10865541009370172, 0.10865541009370172, 0.09058859593096114, 0.09058859593096114, 0.09058859593096114, 0.11781030493064826, 0.11781030493064826, 0.11781030493064826, 0.33135620750280015, 0.33135620750280015, 0.33135620750280015, 0.15921576856505637, 0.15921576856505637, 0.15921576856505637, 0.3486889007572679, 0.3486889007572679, 0.3486889007572679, 0.42609372642196053, 0.42609372642196053, 0.42609372642196053, 0.23369742964263307, 0.23369742964263307, 0.23369742964263307, 0.6189363045520331, 0.6189363045520331, 0.6189363045520331, 0.2513747233204553, 0.2513747233204553, 0.2513747233204553, 0.3102681464194529, 0.3102681464194529, 0.3102681464194529, 0.2205438431098219, 0.2205438431098219, 0.2205438431098219, 0.2054755209378113, 0.2054755209378113, 0.2054755209378113, 0.20524299031420323, 0.20524299031420323, 0.20524299031420323, 0.22614146771536148, 0.22614146771536148, 0.22614146771536148, 0.22757452784274823, 0.22757452784274823, 0.22757452784274823, 0.22755878502392257, 0.22755878502392257, 0.22755878502392257, 0.20474435453582251, 0.20474435453582251, 0.20474435453582251, 0.9507780589281276, 0.9507780589281276, 0.9507780589281276, 0.9471120895321204, 0.9471120895321204, 0.9471120895321204, 0.9283874531560279, 0.9283874531560279, 0.9283874531560279, 0.8940770949951848, 0.8940770949951848, 0.8940770949951848, 0.21184385190475385, 0.21184385190475385, 0.21184385190475385, 0.15698005198731713, 0.15698005198731713, 0.15698005198731713, 0.1794676187310421, 0.1794676187310421, 0.1794676187310421, 0.19830510284789837, 0.19830510284789837, 0.19830510284789837, 0.18461638660957047, 0.18461638660957047, 0.18461638660957047, 0.07913084811951898, 0.07913084811951898, 0.07913084811951898, 0.0968542798195674, 0.0968542798195674, 0.0968542798195674, 0.08900117425218468, 0.08900117425218468, 0.08900117425218468]}, "mutation_prompt": null}
{"id": "9b59e3a1-dbe7-45ca-8ce6-727925f6f77c", "solution": "import numpy as np\n\nclass DynamicAdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for better exploration\n        self.initial_de_f = 0.7  # Adjusted Differential weight\n        self.initial_de_cr = 0.9  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.5  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.5 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.60:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicAdaptiveHybridDEPSO", "description": "A dynamically adaptive hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with enhanced diversity maintenance and convergence strategy for efficient exploration of complex landscapes.", "configspace": "", "generation": 95, "fitness": 0.2804988045735333, "feedback": "The algorithm DynamicAdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8307715170202344, 0.8307715170202344, 0.8307715170202344, 0.8440868960758027, 0.8440868960758027, 0.8440868960758027, 0.8563169189604867, 0.8563169189604867, 0.8563169189604867, 0.6702110400615451, 0.6702110400615451, 0.6702110400615451, 0.6966277159733527, 0.6966277159733527, 0.6966277159733527, 0.6942870151876082, 0.6942870151876082, 0.6942870151876082, 0.1111200291100437, 0.1111200291100437, 0.1111200291100437, 0.1480515425231077, 0.1480515425231077, 0.1480515425231077, 0.1536376131697751, 0.1536376131697751, 0.1536376131697751, 0.12732677688443472, 0.12732677688443472, 0.12732677688443472, 0.11992895053341868, 0.11992895053341868, 0.11992895053341868, 0.1182342585854943, 0.1182342585854943, 0.1182342585854943, 0.981134644354775, 0.981134644354775, 0.981134644354775, 0.9877023455413931, 0.9877023455413931, 0.9877023455413931, 0.9897215486255213, 0.9897215486255213, 0.9897215486255213, 0.4118343960851052, 0.4118343960851052, 0.4118343960851052, 0.416211397175121, 0.416211397175121, 0.416211397175121, 0.47558045084883693, 0.47558045084883693, 0.47558045084883693, 0.36222745155128433, 0.36222745155128433, 0.36222745155128433, 0.16122707129771896, 0.16122707129771896, 0.16122707129771896, 0.17588920720219015, 0.17588920720219015, 0.17588920720219015, 0.17277652375480723, 0.17277652375480723, 0.17277652375480723, 0.2204159296628062, 0.2204159296628062, 0.2204159296628062, 0.22354892509470548, 0.22354892509470548, 0.22354892509470548, 0.19291217652571513, 0.19291217652571513, 0.19291217652571513, 0.2517054282073674, 0.2517054282073674, 0.2517054282073674, 0.2618604660909808, 0.2618604660909808, 0.2618604660909808, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03839850928170507, 0.03839850928170507, 0.03839850928170507, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09909554322318148, 0.09909554322318148, 0.09909554322318148, 0.019757688519568495, 0.019757688519568495, 0.019757688519568495, 0.045912323529223587, 0.045912323529223587, 0.045912323529223587, 0.03122579661425462, 0.03122579661425462, 0.03122579661425462, 0.07636653444922681, 0.07636653444922681, 0.07636653444922681, 0.06659952637737643, 0.06659952637737643, 0.06659952637737643, 0.14618195208824014, 0.14618195208824014, 0.14618195208824014, 0.15209322696306593, 0.15209322696306593, 0.15209322696306593, 0.08218555398976901, 0.08218555398976901, 0.08218555398976901, 0.5279046859527878, 0.5279046859527878, 0.5279046859527878, 0.5363528364593148, 0.5363528364593148, 0.5363528364593148, 0.5422661048236015, 0.5422661048236015, 0.5422661048236015, 0.10575898809638618, 0.10575898809638618, 0.10575898809638618, 0.09428731254191103, 0.09428731254191103, 0.09428731254191103, 0.08852618120512667, 0.08852618120512667, 0.08852618120512667, 0.13016560237368036, 0.13016560237368036, 0.13016560237368036, 0.16914493031183553, 0.16914493031183553, 0.16914493031183553, 0.2852938186711118, 0.2852938186711118, 0.2852938186711118, 0.374351543283886, 0.374351543283886, 0.374351543283886, 0.21837389142946295, 0.21837389142946295, 0.21837389142946295, 0.286637072467266, 0.286637072467266, 0.286637072467266, 0.1279572661953916, 0.1279572661953916, 0.1279572661953916, 0.16247851094277443, 0.16247851094277443, 0.16247851094277443, 0.3002983919062081, 0.3002983919062081, 0.3002983919062081, 0.20692843401227634, 0.20692843401227634, 0.20692843401227634, 0.23313481841156813, 0.23313481841156813, 0.23313481841156813, 0.20244889432487967, 0.20244889432487967, 0.20244889432487967, 0.23196566332744673, 0.23196566332744673, 0.23196566332744673, 0.2278399525171142, 0.2278399525171142, 0.2278399525171142, 0.20422841508930378, 0.20422841508930378, 0.20422841508930378, 0.8928161806367929, 0.8928161806367929, 0.8928161806367929, 0.15840326086722123, 0.15840326086722123, 0.15840326086722123, 0.13872843074685137, 0.13872843074685137, 0.13872843074685137, 0.19248011513201113, 0.19248011513201113, 0.19248011513201113, 0.20384915906954015, 0.20384915906954015, 0.20384915906954015, 0.1565170242250049, 0.1565170242250049, 0.1565170242250049, 0.1780821328108021, 0.1780821328108021, 0.1780821328108021, 0.1920183885122163, 0.1920183885122163, 0.1920183885122163, 0.1763149965373605, 0.1763149965373605, 0.1763149965373605, 0.088070685768737, 0.088070685768737, 0.088070685768737, 0.08231051970327974, 0.08231051970327974, 0.08231051970327974, 0.06661482980200584, 0.06661482980200584, 0.06661482980200584]}, "mutation_prompt": null}
{"id": "b3379e2a-2441-4511-8048-0fdd4f7779d7", "solution": "import numpy as np\n\nclass AdaptiveHybridDESAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.8\n        self.initial_de_cr = 0.85\n        self.initial_pso_w = 0.5\n        self.pso_c1 = 1.0\n        self.pso_c2 = 1.2\n        self.sa_temperature = 100.0  # Initial temperature for Simulated Annealing\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.5 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.6 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.4 * progress_ratio\n            sa_temp = self.sa_temperature * (1 - progress_ratio)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Simulated Annealing adjustment for diversification\n            if np.random.rand() < 0.2:\n                idx = np.random.randint(0, self.population_size)\n                neighbor = np.clip(population[idx] + np.random.normal(0, sa_temp, self.dim), self.lb, self.ub)\n                neighbor_fitness = func(neighbor)\n                self.eval_count += 1\n                if neighbor_fitness < fitness[idx] or np.exp((fitness[idx] - neighbor_fitness) / sa_temp) > np.random.rand():\n                    population[idx] = neighbor\n                    fitness[idx] = neighbor_fitness\n                    if neighbor_fitness < personal_best_fitness[idx]:\n                        personal_best[idx] = neighbor\n                        personal_best_fitness[idx] = neighbor_fitness\n                        if neighbor_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = neighbor\n                            global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDESAPSO", "description": "A novel adaptive hybrid evolutionary algorithm combining Differential Evolution, Particle Swarm Optimization, and Simulated Annealing for enhanced exploration and exploitation strategies in complex search spaces.", "configspace": "", "generation": 96, "fitness": 0.346056696703194, "feedback": "The algorithm AdaptiveHybridDESAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.32.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.9242863607094249, 0.9242863607094249, 0.9242863607094249, 0.9249244995646193, 0.9249244995646193, 0.9249244995646193, 0.9307609537302475, 0.9307609537302475, 0.9307609537302475, 0.8516043038440241, 0.8516043038440241, 0.8516043038440241, 0.8351301205170947, 0.8351301205170947, 0.8351301205170947, 0.05465876159176519, 0.05465876159176519, 0.05465876159176519, 0.14407305455828134, 0.14407305455828134, 0.14407305455828134, 0.14351957822550632, 0.14351957822550632, 0.14351957822550632, 0.152129632673058, 0.152129632673058, 0.152129632673058, 0.13211432401321999, 0.13211432401321999, 0.13211432401321999, 0.07951439493293622, 0.07951439493293622, 0.07951439493293622, 0.1012172028346282, 0.1012172028346282, 0.1012172028346282, 0.9887072480384606, 0.9887072480384606, 0.9887072480384606, 0.9872713918286216, 0.9872713918286216, 0.9872713918286216, 0.9875056307698966, 0.9875056307698966, 0.9875056307698966, 0.791721515562421, 0.791721515562421, 0.791721515562421, 0.8045837370547131, 0.8045837370547131, 0.8045837370547131, 0.7846630101845031, 0.7846630101845031, 0.7846630101845031, 0.9270321243482702, 0.9270321243482702, 0.9270321243482702, 0.22100241152624367, 0.22100241152624367, 0.22100241152624367, 0.8153020067314355, 0.8153020067314355, 0.8153020067314355, 0.13461610777069344, 0.13461610777069344, 0.13461610777069344, 0.12868781465946943, 0.12868781465946943, 0.12868781465946943, 0.34941473642899123, 0.34941473642899123, 0.34941473642899123, 0.1352680944296677, 0.1352680944296677, 0.1352680944296677, 0.34786931790997033, 0.34786931790997033, 0.34786931790997033, 0.34084397146718715, 0.34084397146718715, 0.34084397146718715, 0.08799974691507528, 0.08799974691507528, 0.08799974691507528, 0.07868616917051074, 0.07868616917051074, 0.07868616917051074, 0.0008086636270121517, 0.0008086636270121517, 0.0008086636270121517, 0.09475676808125422, 0.09475676808125422, 0.09475676808125422, 0.014496284469673437, 0.014496284469673437, 0.014496284469673437, 0.07664877671525028, 0.07664877671525028, 0.07664877671525028, 0.037529307029496195, 0.037529307029496195, 0.037529307029496195, 0.09406985745868246, 0.09406985745868246, 0.09406985745868246, 0.16718535957334535, 0.16718535957334535, 0.16718535957334535, 0.04399757912651625, 0.04399757912651625, 0.04399757912651625, 0.03967920099572653, 0.03967920099572653, 0.03967920099572653, 0.08915916234086396, 0.08915916234086396, 0.08915916234086396, 0.5618147667947753, 0.5618147667947753, 0.5618147667947753, 0.6096106061245432, 0.6096106061245432, 0.6096106061245432, 0.6764880505166606, 0.6764880505166606, 0.6764880505166606, 0.11409313260442178, 0.11409313260442178, 0.11409313260442178, 0.14543305587088196, 0.14543305587088196, 0.14543305587088196, 0.13672804736071853, 0.13672804736071853, 0.13672804736071853, 0.13875115071827548, 0.13875115071827548, 0.13875115071827548, 0.1794613753351052, 0.1794613753351052, 0.1794613753351052, 0.23034612006090693, 0.23034612006090693, 0.23034612006090693, 0.429532853253642, 0.429532853253642, 0.429532853253642, 0.2686886670734919, 0.2686886670734919, 0.2686886670734919, 0.2415086788283517, 0.2415086788283517, 0.2415086788283517, 0.264731455119394, 0.264731455119394, 0.264731455119394, 0.2711256149259573, 0.2711256149259573, 0.2711256149259573, 0.2853767517220034, 0.2853767517220034, 0.2853767517220034, 0.21937237126089504, 0.21937237126089504, 0.21937237126089504, 0.2168784375728463, 0.2168784375728463, 0.2168784375728463, 0.22030695638378406, 0.22030695638378406, 0.22030695638378406, 0.22438757180800906, 0.22438757180800906, 0.22438757180800906, 0.2245204980273744, 0.2245204980273744, 0.2245204980273744, 0.2539540915697823, 0.2539540915697823, 0.2539540915697823, 0.9413158515240819, 0.9413158515240819, 0.9413158515240819, 0.95846514465047, 0.95846514465047, 0.95846514465047, 0.16845764896172621, 0.16845764896172621, 0.16845764896172621, 0.8729539294383832, 0.8729539294383832, 0.8729539294383832, 0.21272986133584826, 0.21272986133584826, 0.21272986133584826, 0.15688809997625863, 0.15688809997625863, 0.15688809997625863, 0.17943609152173812, 0.17943609152173812, 0.17943609152173812, 0.19101187252367902, 0.19101187252367902, 0.19101187252367902, 0.19853245109232454, 0.19853245109232454, 0.19853245109232454, 0.08160177723724138, 0.08160177723724138, 0.08160177723724138, 0.11477940852771806, 0.11477940852771806, 0.11477940852771806, 0.08336059149991926, 0.08336059149991926, 0.08336059149991926]}, "mutation_prompt": null}
{"id": "5b662cb2-1f4a-45d7-82c8-2597b0e6d696", "solution": "import numpy as np\n\nclass DynamicBalancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.initial_de_f = 0.85  # Adjusted Differential weight\n        self.initial_de_cr = 0.75  # Adjusted Crossover probability\n        self.initial_pso_w = 0.6  # Adjusted Inertia weight\n        self.pso_c1 = 1.2  # Adjusted Cognitive coefficient\n        self.pso_c2 = 1.5  # Adjusted Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            # Dynamic parameter adjustment based on progress\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.7 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            # Particle Swarm Optimization velocity and position update\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            # Encourage diversity and explore new areas\n            if self.eval_count >= self.max_evaluations * 0.60:\n                diversity_count = max(1, int(self.population_size * 0.3))\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "DynamicBalancedHybridDEPSO", "description": "A dynamically balanced hybrid evolutionary algorithm combining Differential Evolution and Particle Swarm Optimization, incorporating progress-aware parameter tuning and enhanced diversity to efficiently navigate diverse search landscapes.", "configspace": "", "generation": 97, "fitness": 0.2911112280094564, "feedback": "The algorithm DynamicBalancedHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.28.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8698723469859615, 0.8698723469859615, 0.8698723469859615, 0.8942174252381052, 0.8942174252381052, 0.8942174252381052, 0.8799218651471324, 0.8799218651471324, 0.8799218651471324, 0.7310840922614142, 0.7310840922614142, 0.7310840922614142, 0.7093850332082297, 0.7093850332082297, 0.7093850332082297, 0.01857073522463848, 0.01857073522463848, 0.01857073522463848, 0.12278015815622456, 0.12278015815622456, 0.12278015815622456, 0.12581584573965976, 0.12581584573965976, 0.12581584573965976, 0.16833214617401626, 0.16833214617401626, 0.16833214617401626, 0.10890152911484308, 0.10890152911484308, 0.10890152911484308, 0.10889960630068618, 0.10889960630068618, 0.10889960630068618, 0.02505443350506975, 0.02505443350506975, 0.02505443350506975, 0.9923689482817574, 0.9923689482817574, 0.9923689482817574, 0.9908743130066263, 0.9908743130066263, 0.9908743130066263, 0.9917222123592149, 0.9917222123592149, 0.9917222123592149, 0.5515481725495592, 0.5515481725495592, 0.5515481725495592, 0.1483347754355736, 0.1483347754355736, 0.1483347754355736, 0.12220212664404517, 0.12220212664404517, 0.12220212664404517, 0.8389632593831665, 0.8389632593831665, 0.8389632593831665, 0.21492270171839178, 0.21492270171839178, 0.21492270171839178, 0.13563608532679805, 0.13563608532679805, 0.13563608532679805, 0.28236044692971085, 0.28236044692971085, 0.28236044692971085, 0.23947572641708814, 0.23947572641708814, 0.23947572641708814, 0.2676445730372209, 0.2676445730372209, 0.2676445730372209, 0.2876726932650998, 0.2876726932650998, 0.2876726932650998, 0.2782162475479688, 0.2782162475479688, 0.2782162475479688, 0.135620780106812, 0.135620780106812, 0.135620780106812, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11322268167636262, 0.11322268167636262, 0.11322268167636262, 0.09127331245562287, 0.09127331245562287, 0.09127331245562287, 0.027721151010475342, 0.027721151010475342, 0.027721151010475342, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07683709689493246, 0.07683709689493246, 0.07683709689493246, 0.0999032451777837, 0.0999032451777837, 0.0999032451777837, 0.07074167260649433, 0.07074167260649433, 0.07074167260649433, 0.10343712889852086, 0.10343712889852086, 0.10343712889852086, 0.05030185946458965, 0.05030185946458965, 0.05030185946458965, 0.5393269431670862, 0.5393269431670862, 0.5393269431670862, 0.5746004674164792, 0.5746004674164792, 0.5746004674164792, 0.6155282610714496, 0.6155282610714496, 0.6155282610714496, 0.12890761099630088, 0.12890761099630088, 0.12890761099630088, 0.11257258435418549, 0.11257258435418549, 0.11257258435418549, 0.08490640726259968, 0.08490640726259968, 0.08490640726259968, 0.15852068147795695, 0.15852068147795695, 0.15852068147795695, 0.14015034662856363, 0.14015034662856363, 0.14015034662856363, 0.1679428346621087, 0.1679428346621087, 0.1679428346621087, 0.297482941479705, 0.297482941479705, 0.297482941479705, 0.5531955125791859, 0.5531955125791859, 0.5531955125791859, 0.2826272881508749, 0.2826272881508749, 0.2826272881508749, 0.32567122720024666, 0.32567122720024666, 0.32567122720024666, 0.2170691677728399, 0.2170691677728399, 0.2170691677728399, 0.2976485692989962, 0.2976485692989962, 0.2976485692989962, 0.18840417024594192, 0.18840417024594192, 0.18840417024594192, 0.19193721970759536, 0.19193721970759536, 0.19193721970759536, 0.21885733912128813, 0.21885733912128813, 0.21885733912128813, 0.21275025861366637, 0.21275025861366637, 0.21275025861366637, 0.2229894113094537, 0.2229894113094537, 0.2229894113094537, 0.21217870337537992, 0.21217870337537992, 0.21217870337537992, 0.8932757986583713, 0.8932757986583713, 0.8932757986583713, 0.8785303196303069, 0.8785303196303069, 0.8785303196303069, 0.21070209564110276, 0.21070209564110276, 0.21070209564110276, 0.12742311415977292, 0.12742311415977292, 0.12742311415977292, 0.21140042187611585, 0.21140042187611585, 0.21140042187611585, 0.19923683839298234, 0.19923683839298234, 0.19923683839298234, 0.18910107729675085, 0.18910107729675085, 0.18910107729675085, 0.1785886735776787, 0.1785886735776787, 0.1785886735776787, 0.19532835812789462, 0.19532835812789462, 0.19532835812789462, 0.07997883549596485, 0.07997883549596485, 0.07997883549596485, 0.09355886464463636, 0.09355886464463636, 0.09355886464463636, 0.08537964603758097, 0.08537964603758097, 0.08537964603758097]}, "mutation_prompt": null}
{"id": "3efe2018-269a-4674-ad5f-587e5e702f26", "solution": "import numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size for better diversity\n        self.initial_de_f = 0.85  # Slightly increased Differential weight\n        self.initial_de_cr = 0.9  # Slightly increased Crossover probability\n        self.initial_pso_w = 0.6  # Increased inertia weight for better exploration\n        self.pso_c1 = 1.5  # Increased Cognitive coefficient to enhance local search\n        self.pso_c2 = 1.5  # Balanced Social coefficient for global search\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.3 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.4 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.3 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.80:  # Smaller threshold to introduce diversity earlier\n                diversity_count = max(1, int(self.population_size * 0.25))  # Increased diversity count\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "AdaptiveHybridDEPSO", "description": "A self-adaptive hybrid optimization algorithm combining Differential Evolution and Particle Swarm Optimization with dynamic adaptation and diversity-promoting strategies for robust exploration and exploitation.", "configspace": "", "generation": 98, "fitness": 0.2865454344488428, "feedback": "The algorithm AdaptiveHybridDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.26.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.8102134831536093, 0.8102134831536093, 0.8102134831536093, 0.833407316151305, 0.833407316151305, 0.833407316151305, 0.791204868883768, 0.791204868883768, 0.791204868883768, 0.6570760954726673, 0.6570760954726673, 0.6570760954726673, 0.6819863864824867, 0.6819863864824867, 0.6819863864824867, 0.6489692624346364, 0.6489692624346364, 0.6489692624346364, 0.08830826467377628, 0.08830826467377628, 0.08830826467377628, 0.06359655522412655, 0.06359655522412655, 0.06359655522412655, 0.08781016224178106, 0.08781016224178106, 0.08781016224178106, 0.08921828311971736, 0.08921828311971736, 0.08921828311971736, 0.09438263519493317, 0.09438263519493317, 0.09438263519493317, 0.09203863362116749, 0.09203863362116749, 0.09203863362116749, 0.9829200269374481, 0.9829200269374481, 0.9829200269374481, 0.9870738308706395, 0.9870738308706395, 0.9870738308706395, 0.9872626742850005, 0.9872626742850005, 0.9872626742850005, 0.38148159237628143, 0.38148159237628143, 0.38148159237628143, 0.3271447377325668, 0.3271447377325668, 0.3271447377325668, 0.31750715220134096, 0.31750715220134096, 0.31750715220134096, 0.39789729949485053, 0.39789729949485053, 0.39789729949485053, 0.500469183923801, 0.500469183923801, 0.500469183923801, 0.442960845233517, 0.442960845233517, 0.442960845233517, 0.19477054370738778, 0.19477054370738778, 0.19477054370738778, 0.21897864497884245, 0.21897864497884245, 0.21897864497884245, 0.21759414307877933, 0.21759414307877933, 0.21759414307877933, 0.20773718367594296, 0.20773718367594296, 0.20773718367594296, 0.22596503179067862, 0.22596503179067862, 0.22596503179067862, 0.242844481931062, 0.242844481931062, 0.242844481931062, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.042476468251118615, 0.042476468251118615, 0.042476468251118615, 0.055730512048351, 0.055730512048351, 0.055730512048351, 0.03505265868175178, 0.03505265868175178, 0.03505265868175178, 0.045106125905251204, 0.045106125905251204, 0.045106125905251204, 0.08653392632370671, 0.08653392632370671, 0.08653392632370671, 0.06714219034755675, 0.06714219034755675, 0.06714219034755675, 0.10738956432765667, 0.10738956432765667, 0.10738956432765667, 0.1084867548189784, 0.1084867548189784, 0.1084867548189784, 0.07993290039021339, 0.07993290039021339, 0.07993290039021339, 0.495752239575189, 0.495752239575189, 0.495752239575189, 0.4773458710570895, 0.4773458710570895, 0.4773458710570895, 0.5022973064631395, 0.5022973064631395, 0.5022973064631395, 0.06124099608201683, 0.06124099608201683, 0.06124099608201683, 0.09055984626008218, 0.09055984626008218, 0.09055984626008218, 0.0920888766372171, 0.0920888766372171, 0.0920888766372171, 0.34082973341513056, 0.34082973341513056, 0.34082973341513056, 0.15909154991894647, 0.15909154991894647, 0.15909154991894647, 0.1715170794866373, 0.1715170794866373, 0.1715170794866373, 0.3745215800023851, 0.3745215800023851, 0.3745215800023851, 0.33249875777101057, 0.33249875777101057, 0.33249875777101057, 0.41584682306994425, 0.41584682306994425, 0.41584682306994425, 0.2064167760241452, 0.2064167760241452, 0.2064167760241452, 0.20672282896063676, 0.20672282896063676, 0.20672282896063676, 0.2393073912653012, 0.2393073912653012, 0.2393073912653012, 0.1859653257907089, 0.1859653257907089, 0.1859653257907089, 0.1790755288581486, 0.1790755288581486, 0.1790755288581486, 0.17763130456500498, 0.17763130456500498, 0.17763130456500498, 0.1929659965699343, 0.1929659965699343, 0.1929659965699343, 0.18155072869263134, 0.18155072869263134, 0.18155072869263134, 0.1864041177282193, 0.1864041177282193, 0.1864041177282193, 0.8694126941470813, 0.8694126941470813, 0.8694126941470813, 0.18775739765891308, 0.18775739765891308, 0.18775739765891308, 0.17937647018549763, 0.17937647018549763, 0.17937647018549763, 0.3673519870154527, 0.3673519870154527, 0.3673519870154527, 0.20998262478164043, 0.20998262478164043, 0.20998262478164043, 0.5793448995953686, 0.5793448995953686, 0.5793448995953686, 0.18881550890664978, 0.18881550890664978, 0.18881550890664978, 0.18803629496182162, 0.18803629496182162, 0.18803629496182162, 0.17845353738260095, 0.17845353738260095, 0.17845353738260095, 0.07230267039200367, 0.07230267039200367, 0.07230267039200367, 0.07177348434219655, 0.07177348434219655, 0.07177348434219655, 0.07006263278723801, 0.07006263278723801, 0.07006263278723801]}, "mutation_prompt": null}
{"id": "7f7c53c7-015d-4bcd-a45a-dbeafbe124e2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Adjusted population size\n        self.initial_de_f = 0.85  # Enhanced Differential weight\n        self.initial_de_cr = 0.9  # Enhanced Crossover probability\n        self.initial_pso_w = 0.6  # Enhanced Inertia weight\n        self.pso_c1 = 1.5  # Enhanced Cognitive coefficient\n        self.pso_c2 = 1.5  # Enhanced Social coefficient\n        self.lb = -5.0\n        self.ub = 5.0\n        self.max_evaluations = budget\n        self.eval_count = 0\n\n    def __call__(self, func):\n        np.random.seed(42)\n        self.eval_count = 0\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))  # Initialized velocity\n        fitness = np.array([func(ind) for ind in population])\n        self.eval_count += self.population_size\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        global_best_idx = np.argmin(fitness)\n        global_best = population[global_best_idx]\n\n        while self.eval_count < self.max_evaluations:\n            progress_ratio = self.eval_count / self.max_evaluations\n            de_f = self.initial_de_f * (1 - progress_ratio) + 0.6 * progress_ratio\n            de_cr = self.initial_de_cr * (1 - progress_ratio) + 0.65 * progress_ratio\n            pso_w = self.initial_pso_w * (1 - progress_ratio) + 0.45 * progress_ratio\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + de_f * (b - c), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < de_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < personal_best_fitness[i]:\n                        personal_best[i] = trial\n                        personal_best_fitness[i] = trial_fitness\n                        if trial_fitness < personal_best_fitness[global_best_idx]:\n                            global_best = trial\n                            global_best_idx = i\n\n            for i in range(self.population_size):\n                if self.eval_count >= self.max_evaluations:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity[i] = (pso_w * velocity[i] +\n                               self.pso_c1 * r1 * (personal_best[i] - population[i]) +\n                               self.pso_c2 * r2 * (global_best - population[i]))\n                population[i] = np.clip(population[i] + velocity[i], self.lb, self.ub)\n                fitness[i] = func(population[i])\n                self.eval_count += 1\n                if fitness[i] < personal_best_fitness[i]:\n                    personal_best[i] = population[i]\n                    personal_best_fitness[i] = fitness[i]\n                    if fitness[i] < personal_best_fitness[global_best_idx]:\n                        global_best = population[i]\n                        global_best_idx = i\n\n            if self.eval_count >= self.max_evaluations * 0.60:  # Earlier diversity encouragement\n                diversity_count = max(1, int(self.population_size * 0.25))  # Increased diversity count\n                for _ in range(diversity_count):\n                    if self.eval_count < self.max_evaluations:\n                        idx = np.random.randint(0, self.population_size)\n                        population[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                        fitness[idx] = func(population[idx])\n                        self.eval_count += 1\n                        if fitness[idx] < personal_best_fitness[idx]:\n                            personal_best[idx] = population[idx]\n                            personal_best_fitness[idx] = fitness[idx]\n                            if fitness[idx] < personal_best_fitness[global_best_idx]:\n                                global_best = population[idx]\n                                global_best_idx = idx\n\n        return global_best, personal_best_fitness[global_best_idx]", "name": "EnhancedAdaptiveDEPSO", "description": "An enhanced adaptive algorithm that integrates Differential Evolution and Particle Swarm Optimization with a stochastic diversity mechanism and dynamic parameter tuning to efficiently navigate variable search landscapes.", "configspace": "", "generation": 99, "fitness": 0.2709168222271288, "feedback": "The algorithm EnhancedAdaptiveDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.25.", "error": "", "parent_id": "b796ae28-8cdb-4e78-bc4d-4499390f5bd4", "metadata": {"aucs": [0.7927190912444786, 0.7927190912444786, 0.7927190912444786, 0.8121005892807568, 0.8121005892807568, 0.8121005892807568, 0.8229854796105862, 0.8229854796105862, 0.8229854796105862, 0.3256690031699816, 0.3256690031699816, 0.3256690031699816, 0.6402697743576695, 0.6402697743576695, 0.6402697743576695, 0.6664043685986125, 0.6664043685986125, 0.6664043685986125, 0.1609072997592157, 0.1609072997592157, 0.1609072997592157, 0.34754747222030824, 0.34754747222030824, 0.34754747222030824, 0.10913523332587516, 0.10913523332587516, 0.10913523332587516, 0.13242869054526052, 0.13242869054526052, 0.13242869054526052, 0.1107915744011696, 0.1107915744011696, 0.1107915744011696, 0.09246675206394961, 0.09246675206394961, 0.09246675206394961, 0.9898815329224315, 0.9898815329224315, 0.9898815329224315, 0.9854720291321352, 0.9854720291321352, 0.9854720291321352, 0.9896560651200704, 0.9896560651200704, 0.9896560651200704, 0.3414252726103134, 0.3414252726103134, 0.3414252726103134, 0.14895428209610673, 0.14895428209610673, 0.14895428209610673, 0.3265259745238209, 0.3265259745238209, 0.3265259745238209, 0.3288455212541336, 0.3288455212541336, 0.3288455212541336, 0.1608018587056158, 0.1608018587056158, 0.1608018587056158, 0.11876512518166127, 0.11876512518166127, 0.11876512518166127, 0.17999830469144995, 0.17999830469144995, 0.17999830469144995, 0.12261380757107421, 0.12261380757107421, 0.12261380757107421, 0.19490969781547907, 0.19490969781547907, 0.19490969781547907, 0.22094770593414825, 0.22094770593414825, 0.22094770593414825, 0.2410356122129087, 0.2410356122129087, 0.2410356122129087, 0.1277178245781232, 0.1277178245781232, 0.1277178245781232, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012420495862920489, 0.012420495862920489, 0.012420495862920489, 0.0740322842879535, 0.0740322842879535, 0.0740322842879535, 0.04129456479397542, 0.04129456479397542, 0.04129456479397542, 0.04286334822035465, 0.04286334822035465, 0.04286334822035465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.29500991738127846, 0.29500991738127846, 0.29500991738127846, 0.07095547060070317, 0.07095547060070317, 0.07095547060070317, 0.2000218202206343, 0.2000218202206343, 0.2000218202206343, 0.07754946649249339, 0.07754946649249339, 0.07754946649249339, 0.08165565940258657, 0.08165565940258657, 0.08165565940258657, 0.5256467698991387, 0.5256467698991387, 0.5256467698991387, 0.5464779002020611, 0.5464779002020611, 0.5464779002020611, 0.5277854916183212, 0.5277854916183212, 0.5277854916183212, 0.10929285811390732, 0.10929285811390732, 0.10929285811390732, 0.11110474336480569, 0.11110474336480569, 0.11110474336480569, 0.08183803288138625, 0.08183803288138625, 0.08183803288138625, 0.12864380198565561, 0.12864380198565561, 0.12864380198565561, 0.195910482710562, 0.195910482710562, 0.195910482710562, 0.15627131394387483, 0.15627131394387483, 0.15627131394387483, 0.36711592838455476, 0.36711592838455476, 0.36711592838455476, 0.3420898170029085, 0.3420898170029085, 0.3420898170029085, 0.4286325210262991, 0.4286325210262991, 0.4286325210262991, 0.2496292202907241, 0.2496292202907241, 0.2496292202907241, 0.18824523156583417, 0.18824523156583417, 0.18824523156583417, 0.16095760337271314, 0.16095760337271314, 0.16095760337271314, 0.2162668391524355, 0.2162668391524355, 0.2162668391524355, 0.19203046164121162, 0.19203046164121162, 0.19203046164121162, 0.19249578936866885, 0.19249578936866885, 0.19249578936866885, 0.40137093334510987, 0.40137093334510987, 0.40137093334510987, 0.1879842385596171, 0.1879842385596171, 0.1879842385596171, 0.21418906857145026, 0.21418906857145026, 0.21418906857145026, 0.8797455175269552, 0.8797455175269552, 0.8797455175269552, 0.19164259572488618, 0.19164259572488618, 0.19164259572488618, 0.1771375175994715, 0.1771375175994715, 0.1771375175994715, 0.16955614206119063, 0.16955614206119063, 0.16955614206119063, 0.20847259267113283, 0.20847259267113283, 0.20847259267113283, 0.1554392624823524, 0.1554392624823524, 0.1554392624823524, 0.19489375045652546, 0.19489375045652546, 0.19489375045652546, 0.18548477621243342, 0.18548477621243342, 0.18548477621243342, 0.1897554757139498, 0.1897554757139498, 0.1897554757139498, 0.07345145284306942, 0.07345145284306942, 0.07345145284306942, 0.08027657054290627, 0.08027657054290627, 0.08027657054290627, 0.08909752932692627, 0.08909752932692627, 0.08909752932692627]}, "mutation_prompt": null}

{"id": "ce4669f1-a40b-4e55-a3dd-e9413ff0533a", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 10.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n                \n                # Clip velocity\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                # Update position\n                particles[i] += velocities[i]\n                \n                # Boundary check\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Adaptive mutation\n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Evaluate\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                # Update global best\n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                # Stop if budget is reached\n                if evaluations >= self.budget:\n                    break\n        \n        return self.global_best_value", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm combining particle swarm intelligence with adaptive mutation for enhanced exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.2285655423007635, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": null, "metadata": {"aucs": [0.4189574076169609, 0.4189574076169609, 0.4189574076169609, 0.4430505405904216, 0.4430505405904216, 0.4430505405904216, 0.41807432317454485, 0.41807432317454485, 0.41807432317454485, 0.029338274624448824, 0.029338274624448824, 0.029338274624448824, 0.057028605201398075, 0.057028605201398075, 0.057028605201398075, 0.04255100841029669, 0.04255100841029669, 0.04255100841029669, 0.1381173598976786, 0.1381173598976786, 0.1381173598976786, 0.13915749935789012, 0.13915749935789012, 0.13915749935789012, 0.094966597689913, 0.094966597689913, 0.094966597689913, 0.09553970345194485, 0.09553970345194485, 0.09553970345194485, 0.08689619376645585, 0.08689619376645585, 0.08689619376645585, 0.1001895477844249, 0.1001895477844249, 0.1001895477844249, 0.9039057996004544, 0.9039057996004544, 0.9039057996004544, 0.9195438124846562, 0.9195438124846562, 0.9195438124846562, 0.9265346169925663, 0.9265346169925663, 0.9265346169925663, 0.28314503525617984, 0.28314503525617984, 0.28314503525617984, 0.3048164460489492, 0.3048164460489492, 0.3048164460489492, 0.2967509689815292, 0.2967509689815292, 0.2967509689815292, 0.33609770780770964, 0.33609770780770964, 0.33609770780770964, 0.26907951315374223, 0.26907951315374223, 0.26907951315374223, 0.2872926829459743, 0.2872926829459743, 0.2872926829459743, 0.1722006516913116, 0.1722006516913116, 0.1722006516913116, 0.1514998563386455, 0.1514998563386455, 0.1514998563386455, 0.15467254864544233, 0.15467254864544233, 0.15467254864544233, 0.122934281372304, 0.122934281372304, 0.122934281372304, 0.11746562124567717, 0.11746562124567717, 0.11746562124567717, 0.15198179220760843, 0.15198179220760843, 0.15198179220760843, 0.009595521115756345, 0.009595521115756345, 0.009595521115756345, 0.0037432874541466488, 0.0037432874541466488, 0.0037432874541466488, 0.01765990669072104, 0.01765990669072104, 0.01765990669072104, 0.08302838519720668, 0.08302838519720668, 0.08302838519720668, 0.04450181352533289, 0.04450181352533289, 0.04450181352533289, 0.1529694969867711, 0.1529694969867711, 0.1529694969867711, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08574922658869089, 0.08574922658869089, 0.08574922658869089, 0.10020707805749318, 0.10020707805749318, 0.10020707805749318, 0.10254845418706282, 0.10254845418706282, 0.10254845418706282, 0.4104379659435864, 0.4104379659435864, 0.4104379659435864, 0.39484454328299956, 0.39484454328299956, 0.39484454328299956, 0.43389133853704687, 0.43389133853704687, 0.43389133853704687, 0.12406674513432114, 0.12406674513432114, 0.12406674513432114, 0.12169661225597428, 0.12169661225597428, 0.12169661225597428, 0.10065951556744546, 0.10065951556744546, 0.10065951556744546, 0.26446726403999743, 0.26446726403999743, 0.26446726403999743, 0.24476333207925938, 0.24476333207925938, 0.24476333207925938, 0.24720082863894177, 0.24720082863894177, 0.24720082863894177, 0.30418312999943975, 0.30418312999943975, 0.30418312999943975, 0.26997468071523245, 0.26997468071523245, 0.26997468071523245, 0.2725573349002539, 0.2725573349002539, 0.2725573349002539, 0.25522298473154414, 0.25522298473154414, 0.25522298473154414, 0.22198920636390906, 0.22198920636390906, 0.22198920636390906, 0.15802874588628257, 0.15802874588628257, 0.15802874588628257, 0.22673820010763912, 0.22673820010763912, 0.22673820010763912, 0.20947931703613665, 0.20947931703613665, 0.20947931703613665, 0.21786093907598703, 0.21786093907598703, 0.21786093907598703, 0.21200779593463348, 0.21200779593463348, 0.21200779593463348, 0.20688981475202428, 0.20688981475202428, 0.20688981475202428, 0.20226206712655925, 0.20226206712655925, 0.20226206712655925, 0.7751890297518275, 0.7751890297518275, 0.7751890297518275, 0.1640789604032501, 0.1640789604032501, 0.1640789604032501, 0.5541298592785134, 0.5541298592785134, 0.5541298592785134, 0.6375572802057567, 0.6375572802057567, 0.6375572802057567, 0.20697813634643503, 0.20697813634643503, 0.20697813634643503, 0.12749050708678733, 0.12749050708678733, 0.12749050708678733, 0.173709768714993, 0.173709768714993, 0.173709768714993, 0.1813048405981723, 0.1813048405981723, 0.1813048405981723, 0.18263988410258003, 0.18263988410258003, 0.18263988410258003, 0.0926984347425458, 0.0926984347425458, 0.0926984347425458, 0.08578115582297285, 0.08578115582297285, 0.08578115582297285, 0.11384726034961279, 0.11384726034961279, 0.11384726034961279]}, "mutation_prompt": null}
{"id": "49db1ee3-dbdf-43aa-82ce-4bccadd8e3b6", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.7  # Adjusted to increase social influence\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 10.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity with stochastic component\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                stochastic_factor = np.random.rand(self.dim) * 0.2  # Adding stochastic factor\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]) +\n                                 stochastic_factor)\n                \n                # Clip velocity\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                # Update position\n                particles[i] += velocities[i]\n                \n                # Boundary check\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Adaptive mutation\n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.05, self.dim)  # Adjusted mutation scale\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Evaluate\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                # Update global best\n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                # Stop if budget is reached\n                if evaluations >= self.budget:\n                    break\n        \n        return self.global_best_value", "name": "AdaptiveSwarmOptimizer", "description": "An adaptive swarm-based optimization algorithm integrating particle swarm intelligence with stochastic velocity adjustments and adaptive mutation for optimized global search.", "configspace": "", "generation": 1, "fitness": 0.20408626723941414, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "ce4669f1-a40b-4e55-a3dd-e9413ff0533a", "metadata": {"aucs": [0.35131178539137187, 0.35131178539137187, 0.35131178539137187, 0.3599646968018867, 0.3599646968018867, 0.3599646968018867, 0.3667588947164776, 0.3667588947164776, 0.3667588947164776, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10790234423242673, 0.10790234423242673, 0.10790234423242673, 0.10937627681852213, 0.10937627681852213, 0.10937627681852213, 0.07632783807110555, 0.07632783807110555, 0.07632783807110555, 0.09161687854587053, 0.09161687854587053, 0.09161687854587053, 0.08718441455674564, 0.08718441455674564, 0.08718441455674564, 0.1098586022717094, 0.1098586022717094, 0.1098586022717094, 0.9160716554698599, 0.9160716554698599, 0.9160716554698599, 0.9184720051119477, 0.9184720051119477, 0.9184720051119477, 0.9154457077779405, 0.9154457077779405, 0.9154457077779405, 0.24416002360753253, 0.24416002360753253, 0.24416002360753253, 0.22212633369200663, 0.22212633369200663, 0.22212633369200663, 0.22791887076418393, 0.22791887076418393, 0.22791887076418393, 0.2603331257370054, 0.2603331257370054, 0.2603331257370054, 0.2085345459395166, 0.2085345459395166, 0.2085345459395166, 0.23016121464992212, 0.23016121464992212, 0.23016121464992212, 0.13445005132345234, 0.13445005132345234, 0.13445005132345234, 0.12213437734337806, 0.12213437734337806, 0.12213437734337806, 0.14215906083218366, 0.14215906083218366, 0.14215906083218366, 0.14819444434694706, 0.14819444434694706, 0.14819444434694706, 0.14267305474752978, 0.14267305474752978, 0.14267305474752978, 0.14004832779198062, 0.14004832779198062, 0.14004832779198062, 0.023495360371988183, 0.023495360371988183, 0.023495360371988183, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01687756149629227, 0.01687756149629227, 0.01687756149629227, 0.07850724563302902, 0.07850724563302902, 0.07850724563302902, 0.08127484150109487, 0.08127484150109487, 0.08127484150109487, 0.1192383498697287, 0.1192383498697287, 0.1192383498697287, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.060895246327351216, 0.060895246327351216, 0.060895246327351216, 0.07695781791507617, 0.07695781791507617, 0.07695781791507617, 0.05636532392050175, 0.05636532392050175, 0.05636532392050175, 0.3425316014245121, 0.3425316014245121, 0.3425316014245121, 0.32824422137198594, 0.32824422137198594, 0.32824422137198594, 0.3525327014832741, 0.3525327014832741, 0.3525327014832741, 0.10804566494872037, 0.10804566494872037, 0.10804566494872037, 0.11200888395101061, 0.11200888395101061, 0.11200888395101061, 0.08124511092355258, 0.08124511092355258, 0.08124511092355258, 0.17451936399963108, 0.17451936399963108, 0.17451936399963108, 0.18303562892066216, 0.18303562892066216, 0.18303562892066216, 0.18697535346374716, 0.18697535346374716, 0.18697535346374716, 0.22256361080819365, 0.22256361080819365, 0.22256361080819365, 0.2732006041080258, 0.2732006041080258, 0.2732006041080258, 0.243877299695616, 0.243877299695616, 0.243877299695616, 0.17668904052278955, 0.17668904052278955, 0.17668904052278955, 0.2089631009479338, 0.2089631009479338, 0.2089631009479338, 0.1853561344419581, 0.1853561344419581, 0.1853561344419581, 0.2099559040529162, 0.2099559040529162, 0.2099559040529162, 0.21338448734231164, 0.21338448734231164, 0.21338448734231164, 0.22265452061729962, 0.22265452061729962, 0.22265452061729962, 0.19084401512288707, 0.19084401512288707, 0.19084401512288707, 0.18102460887827188, 0.18102460887827188, 0.18102460887827188, 0.1852778663398167, 0.1852778663398167, 0.1852778663398167, 0.45532504211402614, 0.45532504211402614, 0.45532504211402614, 0.16452702776981565, 0.16452702776981565, 0.16452702776981565, 0.511980057851288, 0.511980057851288, 0.511980057851288, 0.5914794104816827, 0.5914794104816827, 0.5914794104816827, 0.20841014624183662, 0.20841014624183662, 0.20841014624183662, 0.4209103116444546, 0.4209103116444546, 0.4209103116444546, 0.18484391831390634, 0.18484391831390634, 0.18484391831390634, 0.18436287158108722, 0.18436287158108722, 0.18436287158108722, 0.17223699091720268, 0.17223699091720268, 0.17223699091720268, 0.0844431470967949, 0.0844431470967949, 0.0844431470967949, 0.0963457765724719, 0.0963457765724719, 0.0963457765724719, 0.08892053971156821, 0.08892053971156821, 0.08892053971156821]}, "mutation_prompt": null}
{"id": "de3e864d-9556-491d-b4c2-a3e44602452e", "solution": "import numpy as np\n\nclass VelocityControlledSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.729\n        self.cognitive_weight = 1.49\n        self.social_weight = 1.49\n        self.mutation_prob = 0.15\n        self.vel_bound = (self.ub - self.lb) / 5.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n                \n                # Clip velocity\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                # Update position\n                particles[i] += velocities[i]\n                \n                # Boundary check\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Adaptive mutation\n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Evaluate\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                # Update global best\n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                # Stop if budget is reached\n                if evaluations >= self.budget:\n                    break\n        \n        return self.global_best_value", "name": "VelocityControlledSwarmOptimizer", "description": "A velocity-controlled dynamic swarm optimization algorithm utilizing adaptive mutation and diversity preservation for enhanced performance.", "configspace": "", "generation": 2, "fitness": 0.1982553053139452, "feedback": "The algorithm VelocityControlledSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "ce4669f1-a40b-4e55-a3dd-e9413ff0533a", "metadata": {"aucs": [0.31064620593231573, 0.31064620593231573, 0.31064620593231573, 0.3649444153823057, 0.3649444153823057, 0.3649444153823057, 0.373095937383245, 0.373095937383245, 0.373095937383245, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01597782097290179, 0.01597782097290179, 0.01597782097290179, 0.0400631531894432, 0.0400631531894432, 0.0400631531894432, 0.09726918390659922, 0.09726918390659922, 0.09726918390659922, 0.0941094064565765, 0.0941094064565765, 0.0941094064565765, 0.1010767491158685, 0.1010767491158685, 0.1010767491158685, 0.08820923698803962, 0.08820923698803962, 0.08820923698803962, 0.08913752057916768, 0.08913752057916768, 0.08913752057916768, 0.09057860949848728, 0.09057860949848728, 0.09057860949848728, 0.9558629355185542, 0.9558629355185542, 0.9558629355185542, 0.9582975422779123, 0.9582975422779123, 0.9582975422779123, 0.9633643389755848, 0.9633643389755848, 0.9633643389755848, 0.2514891018226386, 0.2514891018226386, 0.2514891018226386, 0.2147251708706821, 0.2147251708706821, 0.2147251708706821, 0.22776373879540446, 0.22776373879540446, 0.22776373879540446, 0.23587742645160326, 0.23587742645160326, 0.23587742645160326, 0.20551953844410098, 0.20551953844410098, 0.20551953844410098, 0.24861596970707422, 0.24861596970707422, 0.24861596970707422, 0.09994521321653771, 0.09994521321653771, 0.09994521321653771, 0.13712277375750748, 0.13712277375750748, 0.13712277375750748, 0.18235527840837118, 0.18235527840837118, 0.18235527840837118, 0.09460736421580018, 0.09460736421580018, 0.09460736421580018, 0.11321638298709602, 0.11321638298709602, 0.11321638298709602, 0.1298140093011413, 0.1298140093011413, 0.1298140093011413, 0.02517508483194486, 0.02517508483194486, 0.02517508483194486, 0.009057236315106132, 0.009057236315106132, 0.009057236315106132, 0.010848734900242518, 0.010848734900242518, 0.010848734900242518, 0.033683924318778535, 0.033683924318778535, 0.033683924318778535, 0.09318330998569013, 0.09318330998569013, 0.09318330998569013, 0.08462097548971492, 0.08462097548971492, 0.08462097548971492, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05802532154449147, 0.05802532154449147, 0.05802532154449147, 0.05839558850973714, 0.05839558850973714, 0.05839558850973714, 0.04326190371008887, 0.04326190371008887, 0.04326190371008887, 0.33809378073220264, 0.33809378073220264, 0.33809378073220264, 0.3435911540656119, 0.3435911540656119, 0.3435911540656119, 0.3433055441042613, 0.3433055441042613, 0.3433055441042613, 0.12083326931452898, 0.12083326931452898, 0.12083326931452898, 0.08214542848159012, 0.08214542848159012, 0.08214542848159012, 0.0855385146862262, 0.0855385146862262, 0.0855385146862262, 0.17704307656131824, 0.17704307656131824, 0.17704307656131824, 0.17209100155340662, 0.17209100155340662, 0.17209100155340662, 0.18528284610286982, 0.18528284610286982, 0.18528284610286982, 0.24219200111782624, 0.24219200111782624, 0.24219200111782624, 0.26073840280997285, 0.26073840280997285, 0.26073840280997285, 0.24950654965241803, 0.24950654965241803, 0.24950654965241803, 0.20097007458055094, 0.20097007458055094, 0.20097007458055094, 0.17479020902298814, 0.17479020902298814, 0.17479020902298814, 0.1859226703214486, 0.1859226703214486, 0.1859226703214486, 0.20105250370324013, 0.20105250370324013, 0.20105250370324013, 0.21138933815404393, 0.21138933815404393, 0.21138933815404393, 0.23028431628791068, 0.23028431628791068, 0.23028431628791068, 0.18667801246111249, 0.18667801246111249, 0.18667801246111249, 0.19058558302135842, 0.19058558302135842, 0.19058558302135842, 0.18970226109487298, 0.18970226109487298, 0.18970226109487298, 0.4380405374269698, 0.4380405374269698, 0.4380405374269698, 0.1562412539671133, 0.1562412539671133, 0.1562412539671133, 0.49667913080111425, 0.49667913080111425, 0.49667913080111425, 0.38071463617749635, 0.38071463617749635, 0.38071463617749635, 0.20144822707202759, 0.20144822707202759, 0.20144822707202759, 0.34050630539672755, 0.34050630539672755, 0.34050630539672755, 0.1807336632494213, 0.1807336632494213, 0.1807336632494213, 0.17331131555839108, 0.17331131555839108, 0.17331131555839108, 0.18718653119177198, 0.18718653119177198, 0.18718653119177198, 0.08185242643054025, 0.08185242643054025, 0.08185242643054025, 0.0794404029032707, 0.0794404029032707, 0.0794404029032707, 0.0861539108387005, 0.0861539108387005, 0.0861539108387005]}, "mutation_prompt": null}
{"id": "271996ea-5b05-4c72-9265-28fa03b48159", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 10.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n                \n                # Clip velocity\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                # Update position\n                particles[i] += velocities[i]\n                \n                # Boundary check\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Adaptive mutation\n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Evaluate\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                # Update global best\n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                # Stop if budget is reached\n                if evaluations >= self.budget:\n                    break\n        \n        return self.global_best_value", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm combining particle swarm intelligence with adaptive mutation for enhanced exploration and exploitation.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ce4669f1-a40b-4e55-a3dd-e9413ff0533a", "metadata": {"aucs": [0.4189574076169609, 0.4189574076169609, 0.4189574076169609, 0.4430505405904216, 0.4430505405904216, 0.4430505405904216, 0.41807432317454485, 0.41807432317454485, 0.41807432317454485, 0.029338274624448824, 0.029338274624448824, 0.029338274624448824, 0.057028605201398075, 0.057028605201398075, 0.057028605201398075, 0.04255100841029669, 0.04255100841029669, 0.04255100841029669, 0.1381173598976786, 0.1381173598976786, 0.1381173598976786, 0.13915749935789012, 0.13915749935789012, 0.13915749935789012, 0.094966597689913, 0.094966597689913, 0.094966597689913, 0.09553970345194485, 0.09553970345194485, 0.09553970345194485, 0.08689619376645585, 0.08689619376645585, 0.08689619376645585, 0.1001895477844249, 0.1001895477844249, 0.1001895477844249, 0.9039057996004544, 0.9039057996004544, 0.9039057996004544, 0.9195438124846562, 0.9195438124846562, 0.9195438124846562, 0.9265346169925663, 0.9265346169925663, 0.9265346169925663, 0.28314503525617984, 0.28314503525617984, 0.28314503525617984, 0.3048164460489492, 0.3048164460489492, 0.3048164460489492, 0.2967509689815292, 0.2967509689815292, 0.2967509689815292, 0.33609770780770964, 0.33609770780770964, 0.33609770780770964, 0.26907951315374223, 0.26907951315374223, 0.26907951315374223, 0.2872926829459743, 0.2872926829459743, 0.2872926829459743, 0.1722006516913116, 0.1722006516913116, 0.1722006516913116, 0.1514998563386455, 0.1514998563386455, 0.1514998563386455, 0.15467254864544233, 0.15467254864544233, 0.15467254864544233, 0.122934281372304, 0.122934281372304, 0.122934281372304, 0.11746562124567717, 0.11746562124567717, 0.11746562124567717, 0.15198179220760843, 0.15198179220760843, 0.15198179220760843, 0.009595521115756345, 0.009595521115756345, 0.009595521115756345, 0.0037432874541466488, 0.0037432874541466488, 0.0037432874541466488, 0.01765990669072104, 0.01765990669072104, 0.01765990669072104, 0.08302838519720668, 0.08302838519720668, 0.08302838519720668, 0.04450181352533289, 0.04450181352533289, 0.04450181352533289, 0.1529694969867711, 0.1529694969867711, 0.1529694969867711, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08574922658869089, 0.08574922658869089, 0.08574922658869089, 0.10020707805749318, 0.10020707805749318, 0.10020707805749318, 0.10254845418706282, 0.10254845418706282, 0.10254845418706282, 0.4104379659435864, 0.4104379659435864, 0.4104379659435864, 0.39484454328299956, 0.39484454328299956, 0.39484454328299956, 0.43389133853704687, 0.43389133853704687, 0.43389133853704687, 0.12406674513432114, 0.12406674513432114, 0.12406674513432114, 0.12169661225597428, 0.12169661225597428, 0.12169661225597428, 0.10065951556744546, 0.10065951556744546, 0.10065951556744546, 0.26446726403999743, 0.26446726403999743, 0.26446726403999743, 0.24476333207925938, 0.24476333207925938, 0.24476333207925938, 0.24720082863894177, 0.24720082863894177, 0.24720082863894177, 0.30418312999943975, 0.30418312999943975, 0.30418312999943975, 0.26997468071523245, 0.26997468071523245, 0.26997468071523245, 0.2725573349002539, 0.2725573349002539, 0.2725573349002539, 0.25522298473154414, 0.25522298473154414, 0.25522298473154414, 0.22198920636390906, 0.22198920636390906, 0.22198920636390906, 0.15802874588628257, 0.15802874588628257, 0.15802874588628257, 0.22673820010763912, 0.22673820010763912, 0.22673820010763912, 0.20947931703613665, 0.20947931703613665, 0.20947931703613665, 0.21786093907598703, 0.21786093907598703, 0.21786093907598703, 0.21200779593463348, 0.21200779593463348, 0.21200779593463348, 0.20688981475202428, 0.20688981475202428, 0.20688981475202428, 0.20226206712655925, 0.20226206712655925, 0.20226206712655925, 0.7751890297518275, 0.7751890297518275, 0.7751890297518275, 0.1640789604032501, 0.1640789604032501, 0.1640789604032501, 0.5541298592785134, 0.5541298592785134, 0.5541298592785134, 0.6375572802057567, 0.6375572802057567, 0.6375572802057567, 0.20697813634643503, 0.20697813634643503, 0.20697813634643503, 0.12749050708678733, 0.12749050708678733, 0.12749050708678733, 0.173709768714993, 0.173709768714993, 0.173709768714993, 0.1813048405981723, 0.1813048405981723, 0.1813048405981723, 0.18263988410258003, 0.18263988410258003, 0.18263988410258003, 0.0926984347425458, 0.0926984347425458, 0.0926984347425458, 0.08578115582297285, 0.08578115582297285, 0.08578115582297285, 0.11384726034961279, 0.11384726034961279, 0.11384726034961279]}, "mutation_prompt": null}
{"id": "0b5f2c49-ae94-4a4e-9261-e9672a1bfd81", "solution": "import numpy as np\n\nclass RefinedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.6  # Slightly reduced inertia for increased exploration\n        self.cognitive_weight = 1.6  # Enhanced cognitive trust\n        self.social_weight = 1.4  # Reduced social influence to enhance diversity\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 10.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity with adaptive strategy\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n                \n                # Clip velocity\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                # Update position\n                particles[i] += velocities[i]\n                \n                # Stochastic boundary reflection strategy\n                particles[i] = np.where(particles[i] < self.lb, self.lb + np.random.rand(self.dim) * (self.ub - self.lb), particles[i])\n                particles[i] = np.where(particles[i] > self.ub, self.ub - np.random.rand(self.dim) * (self.ub - self.lb), particles[i])\n\n                # Adaptive mutation\n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Evaluate\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                # Update global best\n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                # Stop if budget is reached\n                if evaluations >= self.budget:\n                    break\n        \n        return self.global_best_value", "name": "RefinedDynamicSwarmOptimizer", "description": "A refined dynamic swarm-based optimizer that integrates adaptive velocity adjustment with stochastic boundary reflection for enhanced solution diversity and convergence.", "configspace": "", "generation": 4, "fitness": 0.22232024940107972, "feedback": "The algorithm RefinedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.16.", "error": "", "parent_id": "ce4669f1-a40b-4e55-a3dd-e9413ff0533a", "metadata": {"aucs": [0.5253788817748347, 0.5253788817748347, 0.5253788817748347, 0.47124503513612603, 0.47124503513612603, 0.47124503513612603, 0.4835267455585034, 0.4835267455585034, 0.4835267455585034, 0.08225337017255807, 0.08225337017255807, 0.08225337017255807, 0.14029518261298057, 0.14029518261298057, 0.14029518261298057, 0.1996035263144974, 0.1996035263144974, 0.1996035263144974, 0.141367030478309, 0.141367030478309, 0.141367030478309, 0.133864542316539, 0.133864542316539, 0.133864542316539, 0.12275138416599207, 0.12275138416599207, 0.12275138416599207, 0.09966032909208533, 0.09966032909208533, 0.09966032909208533, 0.08913917241275016, 0.08913917241275016, 0.08913917241275016, 0.10296617155992005, 0.10296617155992005, 0.10296617155992005, 0.09317142751060381, 0.09317142751060381, 0.09317142751060381, 0.08814938151963869, 0.08814938151963869, 0.08814938151963869, 0.09356253380941837, 0.09356253380941837, 0.09356253380941837, 0.38384246030839464, 0.38384246030839464, 0.38384246030839464, 0.3040033927268474, 0.3040033927268474, 0.3040033927268474, 0.34412481066604594, 0.34412481066604594, 0.34412481066604594, 0.21980507527910642, 0.21980507527910642, 0.21980507527910642, 0.27137555064445695, 0.27137555064445695, 0.27137555064445695, 0.4753574774885647, 0.4753574774885647, 0.4753574774885647, 0.22122152525786198, 0.22122152525786198, 0.22122152525786198, 0.22482283757451882, 0.22482283757451882, 0.22482283757451882, 0.21767016825026775, 0.21767016825026775, 0.21767016825026775, 0.2032939283205184, 0.2032939283205184, 0.2032939283205184, 0.1698763395561711, 0.1698763395561711, 0.1698763395561711, 0.17121248718426052, 0.17121248718426052, 0.17121248718426052, 0.09090401982458585, 0.09090401982458585, 0.09090401982458585, 0.07818063757896176, 0.07818063757896176, 0.07818063757896176, 0.04380341017687839, 0.04380341017687839, 0.04380341017687839, 0.09742739844982573, 0.09742739844982573, 0.09742739844982573, 0.04624654078752466, 0.04624654078752466, 0.04624654078752466, 0.07715760238634362, 0.07715760238634362, 0.07715760238634362, 0.009518104744187461, 0.009518104744187461, 0.009518104744187461, 0.025800338560573954, 0.025800338560573954, 0.025800338560573954, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11889005003613762, 0.11889005003613762, 0.11889005003613762, 0.12027006146782993, 0.12027006146782993, 0.12027006146782993, 0.13906092924306612, 0.13906092924306612, 0.13906092924306612, 0.47068216139386154, 0.47068216139386154, 0.47068216139386154, 0.4499101464709383, 0.4499101464709383, 0.4499101464709383, 0.4749969747959625, 0.4749969747959625, 0.4749969747959625, 0.12407954816727529, 0.12407954816727529, 0.12407954816727529, 0.12059130801338869, 0.12059130801338869, 0.12059130801338869, 0.10338491317429599, 0.10338491317429599, 0.10338491317429599, 0.2060574444805956, 0.2060574444805956, 0.2060574444805956, 0.14725851611163, 0.14725851611163, 0.14725851611163, 0.2867096492218395, 0.2867096492218395, 0.2867096492218395, 0.3322310814281758, 0.3322310814281758, 0.3322310814281758, 0.29600816815616104, 0.29600816815616104, 0.29600816815616104, 0.24825333215375112, 0.24825333215375112, 0.24825333215375112, 0.23276760385046447, 0.23276760385046447, 0.23276760385046447, 0.26007803740642843, 0.26007803740642843, 0.26007803740642843, 0.20027168965927344, 0.20027168965927344, 0.20027168965927344, 0.3043714816149913, 0.3043714816149913, 0.3043714816149913, 0.2356140607680659, 0.2356140607680659, 0.2356140607680659, 0.19904687125971754, 0.19904687125971754, 0.19904687125971754, 0.2166197993595711, 0.2166197993595711, 0.2166197993595711, 0.1886253963505944, 0.1886253963505944, 0.1886253963505944, 0.18124675669576318, 0.18124675669576318, 0.18124675669576318, 0.791813565965586, 0.791813565965586, 0.791813565965586, 0.16268642924241283, 0.16268642924241283, 0.16268642924241283, 0.789398689319779, 0.789398689319779, 0.789398689319779, 0.5764754394099902, 0.5764754394099902, 0.5764754394099902, 0.2112055349317037, 0.2112055349317037, 0.2112055349317037, 0.4597397500693179, 0.4597397500693179, 0.4597397500693179, 0.1996170922819963, 0.1996170922819963, 0.1996170922819963, 0.1799900263985008, 0.1799900263985008, 0.1799900263985008, 0.18476262113003994, 0.18476262113003994, 0.18476262113003994, 0.08779098117309692, 0.08779098117309692, 0.08779098117309692, 0.09275813340402106, 0.09275813340402106, 0.09275813340402106, 0.07111489207086119, 0.07111489207086119, 0.07111489207086119]}, "mutation_prompt": null}
{"id": "40bd27b9-fe62-41a5-bd8e-2d525c17fb93", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 10.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n                \n                # Clip velocity\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                # Update position\n                particles[i] += velocities[i]\n                \n                # Boundary check\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Adaptive mutation\n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Evaluate\n                current_value = func(particles[i])\n                evaluations += 1\n\n                # Update personal best\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                # Update global best\n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                # Stop if budget is reached\n                if evaluations >= self.budget:\n                    break\n        \n        return self.global_best_value", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm combining particle swarm intelligence with adaptive mutation for enhanced exploration and exploitation.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ce4669f1-a40b-4e55-a3dd-e9413ff0533a", "metadata": {"aucs": [0.4189574076169609, 0.4189574076169609, 0.4189574076169609, 0.4430505405904216, 0.4430505405904216, 0.4430505405904216, 0.41807432317454485, 0.41807432317454485, 0.41807432317454485, 0.029338274624448824, 0.029338274624448824, 0.029338274624448824, 0.057028605201398075, 0.057028605201398075, 0.057028605201398075, 0.04255100841029669, 0.04255100841029669, 0.04255100841029669, 0.1381173598976786, 0.1381173598976786, 0.1381173598976786, 0.13915749935789012, 0.13915749935789012, 0.13915749935789012, 0.094966597689913, 0.094966597689913, 0.094966597689913, 0.09553970345194485, 0.09553970345194485, 0.09553970345194485, 0.08689619376645585, 0.08689619376645585, 0.08689619376645585, 0.1001895477844249, 0.1001895477844249, 0.1001895477844249, 0.9039057996004544, 0.9039057996004544, 0.9039057996004544, 0.9195438124846562, 0.9195438124846562, 0.9195438124846562, 0.9265346169925663, 0.9265346169925663, 0.9265346169925663, 0.28314503525617984, 0.28314503525617984, 0.28314503525617984, 0.3048164460489492, 0.3048164460489492, 0.3048164460489492, 0.2967509689815292, 0.2967509689815292, 0.2967509689815292, 0.33609770780770964, 0.33609770780770964, 0.33609770780770964, 0.26907951315374223, 0.26907951315374223, 0.26907951315374223, 0.2872926829459743, 0.2872926829459743, 0.2872926829459743, 0.1722006516913116, 0.1722006516913116, 0.1722006516913116, 0.1514998563386455, 0.1514998563386455, 0.1514998563386455, 0.15467254864544233, 0.15467254864544233, 0.15467254864544233, 0.122934281372304, 0.122934281372304, 0.122934281372304, 0.11746562124567717, 0.11746562124567717, 0.11746562124567717, 0.15198179220760843, 0.15198179220760843, 0.15198179220760843, 0.009595521115756345, 0.009595521115756345, 0.009595521115756345, 0.0037432874541466488, 0.0037432874541466488, 0.0037432874541466488, 0.01765990669072104, 0.01765990669072104, 0.01765990669072104, 0.08302838519720668, 0.08302838519720668, 0.08302838519720668, 0.04450181352533289, 0.04450181352533289, 0.04450181352533289, 0.1529694969867711, 0.1529694969867711, 0.1529694969867711, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08574922658869089, 0.08574922658869089, 0.08574922658869089, 0.10020707805749318, 0.10020707805749318, 0.10020707805749318, 0.10254845418706282, 0.10254845418706282, 0.10254845418706282, 0.4104379659435864, 0.4104379659435864, 0.4104379659435864, 0.39484454328299956, 0.39484454328299956, 0.39484454328299956, 0.43389133853704687, 0.43389133853704687, 0.43389133853704687, 0.12406674513432114, 0.12406674513432114, 0.12406674513432114, 0.12169661225597428, 0.12169661225597428, 0.12169661225597428, 0.10065951556744546, 0.10065951556744546, 0.10065951556744546, 0.26446726403999743, 0.26446726403999743, 0.26446726403999743, 0.24476333207925938, 0.24476333207925938, 0.24476333207925938, 0.24720082863894177, 0.24720082863894177, 0.24720082863894177, 0.30418312999943975, 0.30418312999943975, 0.30418312999943975, 0.26997468071523245, 0.26997468071523245, 0.26997468071523245, 0.2725573349002539, 0.2725573349002539, 0.2725573349002539, 0.25522298473154414, 0.25522298473154414, 0.25522298473154414, 0.22198920636390906, 0.22198920636390906, 0.22198920636390906, 0.15802874588628257, 0.15802874588628257, 0.15802874588628257, 0.22673820010763912, 0.22673820010763912, 0.22673820010763912, 0.20947931703613665, 0.20947931703613665, 0.20947931703613665, 0.21786093907598703, 0.21786093907598703, 0.21786093907598703, 0.21200779593463348, 0.21200779593463348, 0.21200779593463348, 0.20688981475202428, 0.20688981475202428, 0.20688981475202428, 0.20226206712655925, 0.20226206712655925, 0.20226206712655925, 0.7751890297518275, 0.7751890297518275, 0.7751890297518275, 0.1640789604032501, 0.1640789604032501, 0.1640789604032501, 0.5541298592785134, 0.5541298592785134, 0.5541298592785134, 0.6375572802057567, 0.6375572802057567, 0.6375572802057567, 0.20697813634643503, 0.20697813634643503, 0.20697813634643503, 0.12749050708678733, 0.12749050708678733, 0.12749050708678733, 0.173709768714993, 0.173709768714993, 0.173709768714993, 0.1813048405981723, 0.1813048405981723, 0.1813048405981723, 0.18263988410258003, 0.18263988410258003, 0.18263988410258003, 0.0926984347425458, 0.0926984347425458, 0.0926984347425458, 0.08578115582297285, 0.08578115582297285, 0.08578115582297285, 0.11384726034961279, 0.11384726034961279, 0.11384726034961279]}, "mutation_prompt": null}
{"id": "d6fe8d88-f95c-48df-9d70-a8fc3796c9db", "solution": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 2.0  # Increased cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 8.0  # Adjusted velocity bound for broader exploration\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99  # Added learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedDynamicSwarmOptimizer", "description": "An enhanced dynamic swarm optimizer using adaptive learning rates and elitist strategy for improved convergence and robustness.", "configspace": "", "generation": 6, "fitness": 0.28666236991463045, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.23.", "error": "", "parent_id": "ce4669f1-a40b-4e55-a3dd-e9413ff0533a", "metadata": {"aucs": [0.6910855547625283, 0.6910855547625283, 0.6910855547625283, 0.6072731446846168, 0.6072731446846168, 0.6072731446846168, 0.6361171702338471, 0.6361171702338471, 0.6361171702338471, 0.3148351074361452, 0.3148351074361452, 0.3148351074361452, 0.19290422830075038, 0.19290422830075038, 0.19290422830075038, 0.0784189531799242, 0.0784189531799242, 0.0784189531799242, 0.14056904390105707, 0.14056904390105707, 0.14056904390105707, 0.1364424753951463, 0.1364424753951463, 0.1364424753951463, 0.13757669947037443, 0.13757669947037443, 0.13757669947037443, 0.12799057943369951, 0.12799057943369951, 0.12799057943369951, 0.10951632133936673, 0.10951632133936673, 0.10951632133936673, 0.11037457067114587, 0.11037457067114587, 0.11037457067114587, 0.9197058493053173, 0.9197058493053173, 0.9197058493053173, 0.9353549433723188, 0.9353549433723188, 0.9353549433723188, 0.9420802730756312, 0.9420802730756312, 0.9420802730756312, 0.48249921938274287, 0.48249921938274287, 0.48249921938274287, 0.3768610211516378, 0.3768610211516378, 0.3768610211516378, 0.44104147666604354, 0.44104147666604354, 0.44104147666604354, 0.21970115041115168, 0.21970115041115168, 0.21970115041115168, 0.2704090703471125, 0.2704090703471125, 0.2704090703471125, 0.5908826451702883, 0.5908826451702883, 0.5908826451702883, 0.16835590465609274, 0.16835590465609274, 0.16835590465609274, 0.175573869136187, 0.175573869136187, 0.175573869136187, 0.18174801559403464, 0.18174801559403464, 0.18174801559403464, 0.1902524424886768, 0.1902524424886768, 0.1902524424886768, 0.16199192447560595, 0.16199192447560595, 0.16199192447560595, 0.21708296007159877, 0.21708296007159877, 0.21708296007159877, 0.07133450912354133, 0.07133450912354133, 0.07133450912354133, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030938951793604397, 0.030938951793604397, 0.030938951793604397, 0.0893546578772837, 0.0893546578772837, 0.0893546578772837, 0.058798302054177465, 0.058798302054177465, 0.058798302054177465, 0.20025893841780174, 0.20025893841780174, 0.20025893841780174, 0.03395404072182495, 0.03395404072182495, 0.03395404072182495, 0.05348674221151828, 0.05348674221151828, 0.05348674221151828, 0.07460572930227005, 0.07460572930227005, 0.07460572930227005, 0.25452361528878, 0.25452361528878, 0.25452361528878, 0.13617886437894666, 0.13617886437894666, 0.13617886437894666, 0.12357680843430097, 0.12357680843430097, 0.12357680843430097, 0.4705841440139187, 0.4705841440139187, 0.4705841440139187, 0.49213132838593243, 0.49213132838593243, 0.49213132838593243, 0.49288183066831703, 0.49288183066831703, 0.49288183066831703, 0.1573523637306523, 0.1573523637306523, 0.1573523637306523, 0.14872678048333432, 0.14872678048333432, 0.14872678048333432, 0.10567824980793872, 0.10567824980793872, 0.10567824980793872, 0.46856193471471963, 0.46856193471471963, 0.46856193471471963, 0.33802816626876886, 0.33802816626876886, 0.33802816626876886, 0.2284126467019164, 0.2284126467019164, 0.2284126467019164, 0.3830677876851838, 0.3830677876851838, 0.3830677876851838, 0.35494874929167064, 0.35494874929167064, 0.35494874929167064, 0.3533592197344445, 0.3533592197344445, 0.3533592197344445, 0.27251479305245285, 0.27251479305245285, 0.27251479305245285, 0.3041661195294175, 0.3041661195294175, 0.3041661195294175, 0.21853820522075906, 0.21853820522075906, 0.21853820522075906, 0.21787978040295808, 0.21787978040295808, 0.21787978040295808, 0.2660736942141402, 0.2660736942141402, 0.2660736942141402, 0.2662221917181179, 0.2662221917181179, 0.2662221917181179, 0.23365734518469794, 0.23365734518469794, 0.23365734518469794, 0.2375948552550754, 0.2375948552550754, 0.2375948552550754, 0.23955770808101073, 0.23955770808101073, 0.23955770808101073, 0.8046241069284619, 0.8046241069284619, 0.8046241069284619, 0.163438317376582, 0.163438317376582, 0.163438317376582, 0.823518001415465, 0.823518001415465, 0.823518001415465, 0.6022591267479256, 0.6022591267479256, 0.6022591267479256, 0.20757467276023522, 0.20757467276023522, 0.20757467276023522, 0.22063469894925125, 0.22063469894925125, 0.22063469894925125, 0.1959214763278062, 0.1959214763278062, 0.1959214763278062, 0.19877655719697562, 0.19877655719697562, 0.19877655719697562, 0.18560294078197803, 0.18560294078197803, 0.18560294078197803, 0.09666560622659903, 0.09666560622659903, 0.09666560622659903, 0.08946862847305415, 0.08946862847305415, 0.08946862847305415, 0.11751283280654135, 0.11751283280654135, 0.11751283280654135]}, "mutation_prompt": null}
{"id": "8394468e-ce93-4763-975e-12439206cb88", "solution": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Slightly decreased cognitive weight for balance\n        self.social_weight = 1.6  # Slightly increased social weight\n        self.mutation_prob = 0.12  # Increased mutation probability\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Broader velocity bounds\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Larger mutation steps\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedDynamicSwarmOptimizer", "description": "An enhanced dynamic swarm optimizer using adaptive velocities and a hybrid mutation strategy for improved exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.28587597892068156, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "d6fe8d88-f95c-48df-9d70-a8fc3796c9db", "metadata": {"aucs": [0.7462857725074963, 0.7462857725074963, 0.7462857725074963, 0.738724060932841, 0.738724060932841, 0.738724060932841, 0.7599437955219873, 0.7599437955219873, 0.7599437955219873, 0.05553475217228898, 0.05553475217228898, 0.05553475217228898, 0.10131366260199315, 0.10131366260199315, 0.10131366260199315, 0.13564895606622718, 0.13564895606622718, 0.13564895606622718, 0.1656252577648536, 0.1656252577648536, 0.1656252577648536, 0.11820880883655682, 0.11820880883655682, 0.11820880883655682, 0.08161212379173444, 0.08161212379173444, 0.08161212379173444, 0.1347038979443661, 0.1347038979443661, 0.1347038979443661, 0.12001241797648221, 0.12001241797648221, 0.12001241797648221, 0.1094225021256281, 0.1094225021256281, 0.1094225021256281, 0.9469656107902568, 0.9469656107902568, 0.9469656107902568, 0.9522422076943577, 0.9522422076943577, 0.9522422076943577, 0.9573824659971294, 0.9573824659971294, 0.9573824659971294, 0.44530073231519096, 0.44530073231519096, 0.44530073231519096, 0.42024953264703047, 0.42024953264703047, 0.42024953264703047, 0.45869989007307965, 0.45869989007307965, 0.45869989007307965, 0.21541340803135034, 0.21541340803135034, 0.21541340803135034, 0.2698224829077249, 0.2698224829077249, 0.2698224829077249, 0.22882866644836652, 0.22882866644836652, 0.22882866644836652, 0.17385793217832857, 0.17385793217832857, 0.17385793217832857, 0.16151360776511847, 0.16151360776511847, 0.16151360776511847, 0.16111522190346272, 0.16111522190346272, 0.16111522190346272, 0.12503885806222514, 0.12503885806222514, 0.12503885806222514, 0.21376004903517942, 0.21376004903517942, 0.21376004903517942, 0.18010834702022238, 0.18010834702022238, 0.18010834702022238, 0.11455363116952089, 0.11455363116952089, 0.11455363116952089, 0.08521301782569612, 0.08521301782569612, 0.08521301782569612, 0.04632947029262946, 0.04632947029262946, 0.04632947029262946, 0.047241436663958636, 0.047241436663958636, 0.047241436663958636, 0.07036920155024218, 0.07036920155024218, 0.07036920155024218, 0.16553072743790986, 0.16553072743790986, 0.16553072743790986, 0.04006695833078355, 0.04006695833078355, 0.04006695833078355, 0.08605798252248587, 0.08605798252248587, 0.08605798252248587, 0.06786669293601466, 0.06786669293601466, 0.06786669293601466, 0.1413901551538962, 0.1413901551538962, 0.1413901551538962, 0.10689718345423427, 0.10689718345423427, 0.10689718345423427, 0.051490465269730334, 0.051490465269730334, 0.051490465269730334, 0.5025840033054036, 0.5025840033054036, 0.5025840033054036, 0.48572361863196745, 0.48572361863196745, 0.48572361863196745, 0.5074721646856724, 0.5074721646856724, 0.5074721646856724, 0.14984412157067362, 0.14984412157067362, 0.14984412157067362, 0.14671299807608262, 0.14671299807608262, 0.14671299807608262, 0.10367362200821828, 0.10367362200821828, 0.10367362200821828, 0.3138250511388214, 0.3138250511388214, 0.3138250511388214, 0.3204899397173041, 0.3204899397173041, 0.3204899397173041, 0.26217153404748994, 0.26217153404748994, 0.26217153404748994, 0.41415996267934385, 0.41415996267934385, 0.41415996267934385, 0.3648809588354228, 0.3648809588354228, 0.3648809588354228, 0.4247053685408959, 0.4247053685408959, 0.4247053685408959, 0.28181600491749537, 0.28181600491749537, 0.28181600491749537, 0.28981149266265094, 0.28981149266265094, 0.28981149266265094, 0.20978976867301757, 0.20978976867301757, 0.20978976867301757, 0.20639845863446005, 0.20639845863446005, 0.20639845863446005, 0.2894543320593288, 0.2894543320593288, 0.2894543320593288, 0.26909305203476097, 0.26909305203476097, 0.26909305203476097, 0.18847043353328963, 0.18847043353328963, 0.18847043353328963, 0.20386311732985807, 0.20386311732985807, 0.20386311732985807, 0.21897597819600811, 0.21897597819600811, 0.21897597819600811, 0.8580028222921356, 0.8580028222921356, 0.8580028222921356, 0.15757778222933672, 0.15757778222933672, 0.15757778222933672, 0.8117624469537678, 0.8117624469537678, 0.8117624469537678, 0.7942177747385123, 0.7942177747385123, 0.7942177747385123, 0.2081780168808397, 0.2081780168808397, 0.2081780168808397, 0.515429169387541, 0.515429169387541, 0.515429169387541, 0.19117300137808102, 0.19117300137808102, 0.19117300137808102, 0.19827496537199263, 0.19827496537199263, 0.19827496537199263, 0.2058454065456179, 0.2058454065456179, 0.2058454065456179, 0.09585662091387148, 0.09585662091387148, 0.09585662091387148, 0.07780607394065431, 0.07780607394065431, 0.07780607394065431, 0.11468847665997839, 0.11468847665997839, 0.11468847665997839]}, "mutation_prompt": null}
{"id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.2880989785307695, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_id": "d6fe8d88-f95c-48df-9d70-a8fc3796c9db", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "ab7d2f0e-1b47-4dc3-8bea-20556eba0a63", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "4eb8008d-9343-4275-a9e3-5618ac37383c", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "542863a6-1fcc-4604-b922-ab5f2dbee808", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "10a76496-80ee-4dbf-a687-ba89935afe59", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "9920b2b3-fde5-4953-9daa-50ee7e2c3fba", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "83e2c2d6-db65-4420-ba3f-037ea85640d0", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "ec0edbe0-c44a-47db-ba51-7ce974cf2d49", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "b06e0f77-d106-4300-aadf-21b2cd7b16b7", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "9edf30d4-b8d7-47fc-bfa0-cf8d766600ee", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "0a0db21e-6831-4084-9b90-df8d0d0de20e", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "a1accded-b363-4116-a6b5-cc5965f2c6b5", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "31dfb309-fb44-4e9f-b9a3-394a448867f4", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "62d0dfa8-622d-40c1-bbc9-15d8695c9b82", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "b4f237f3-e9f4-4e50-81ba-82007d33458f", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8  # Adjusted cognitive weight\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0  # Adjust velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98  # Adjusted learning rate decay\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, 0.2, self.dim)  # Increased mutation variance\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            # Apply learning rate decay\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizer", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.7803329630101392, 0.7803329630101392, 0.7803329630101392, 0.7115501375784026, 0.7115501375784026, 0.7115501375784026, 0.765114237067624, 0.765114237067624, 0.765114237067624, 0.12691712040501735, 0.12691712040501735, 0.12691712040501735, 0.028456561275606473, 0.028456561275606473, 0.028456561275606473, 0.11544221993138948, 0.11544221993138948, 0.11544221993138948, 0.1692976724553118, 0.1692976724553118, 0.1692976724553118, 0.16720015559590118, 0.16720015559590118, 0.16720015559590118, 0.13265092033576298, 0.13265092033576298, 0.13265092033576298, 0.12591584917740106, 0.12591584917740106, 0.12591584917740106, 0.14604525114883526, 0.14604525114883526, 0.14604525114883526, 0.13045804075261258, 0.13045804075261258, 0.13045804075261258, 0.9379041509979588, 0.9379041509979588, 0.9379041509979588, 0.9538019244616547, 0.9538019244616547, 0.9538019244616547, 0.9561894525214556, 0.9561894525214556, 0.9561894525214556, 0.46530000035926045, 0.46530000035926045, 0.46530000035926045, 0.39737848483241733, 0.39737848483241733, 0.39737848483241733, 0.4618446778800287, 0.4618446778800287, 0.4618446778800287, 0.7344117234332566, 0.7344117234332566, 0.7344117234332566, 0.18988979349517354, 0.18988979349517354, 0.18988979349517354, 0.22924944643955658, 0.22924944643955658, 0.22924944643955658, 0.16083621630976763, 0.16083621630976763, 0.16083621630976763, 0.24119507711466026, 0.24119507711466026, 0.24119507711466026, 0.16240713209634106, 0.16240713209634106, 0.16240713209634106, 0.11702444163767944, 0.11702444163767944, 0.11702444163767944, 0.17361988422781982, 0.17361988422781982, 0.17361988422781982, 0.1700209507267446, 0.1700209507267446, 0.1700209507267446, 0.03979945152944764, 0.03979945152944764, 0.03979945152944764, 0.03287712378184593, 0.03287712378184593, 0.03287712378184593, 0.034017818333679006, 0.034017818333679006, 0.034017818333679006, 0.1495489393991376, 0.1495489393991376, 0.1495489393991376, 0.06665299335646158, 0.06665299335646158, 0.06665299335646158, 0.10793681620711704, 0.10793681620711704, 0.10793681620711704, 0.03907861943835256, 0.03907861943835256, 0.03907861943835256, 0.0668400585552188, 0.0668400585552188, 0.0668400585552188, 0.15130915984912008, 0.15130915984912008, 0.15130915984912008, 0.14805683009870574, 0.14805683009870574, 0.14805683009870574, 0.11636919975184168, 0.11636919975184168, 0.11636919975184168, 0.12746512267356958, 0.12746512267356958, 0.12746512267356958, 0.48712152281799104, 0.48712152281799104, 0.48712152281799104, 0.5334631600749704, 0.5334631600749704, 0.5334631600749704, 0.5669749549195948, 0.5669749549195948, 0.5669749549195948, 0.12025420749091498, 0.12025420749091498, 0.12025420749091498, 0.1022262152986474, 0.1022262152986474, 0.1022262152986474, 0.10032182179366811, 0.10032182179366811, 0.10032182179366811, 0.188751429378742, 0.188751429378742, 0.188751429378742, 0.2244336857874938, 0.2244336857874938, 0.2244336857874938, 0.3072063134113433, 0.3072063134113433, 0.3072063134113433, 0.33096924212445333, 0.33096924212445333, 0.33096924212445333, 0.3359403967771295, 0.3359403967771295, 0.3359403967771295, 0.4078472163443404, 0.4078472163443404, 0.4078472163443404, 0.26382749053163157, 0.26382749053163157, 0.26382749053163157, 0.26753801708804903, 0.26753801708804903, 0.26753801708804903, 0.1964157812425047, 0.1964157812425047, 0.1964157812425047, 0.23985753877382643, 0.23985753877382643, 0.23985753877382643, 0.24538135079425782, 0.24538135079425782, 0.24538135079425782, 0.2160167625806073, 0.2160167625806073, 0.2160167625806073, 0.17836713517051317, 0.17836713517051317, 0.17836713517051317, 0.1867112825801035, 0.1867112825801035, 0.1867112825801035, 0.19698336120491744, 0.19698336120491744, 0.19698336120491744, 0.8689687895402194, 0.8689687895402194, 0.8689687895402194, 0.15698186800968872, 0.15698186800968872, 0.15698186800968872, 0.8382285501488616, 0.8382285501488616, 0.8382285501488616, 0.5492890696135982, 0.5492890696135982, 0.5492890696135982, 0.20988333786536628, 0.20988333786536628, 0.20988333786536628, 0.6685995357368726, 0.6685995357368726, 0.6685995357368726, 0.20545138877831748, 0.20545138877831748, 0.20545138877831748, 0.18301300671587528, 0.18301300671587528, 0.18301300671587528, 0.20665182954595107, 0.20665182954595107, 0.20665182954595107, 0.12656889117915449, 0.12656889117915449, 0.12656889117915449, 0.0930142818850338, 0.0930142818850338, 0.0930142818850338, 0.10946040076848584, 0.10946040076848584, 0.10946040076848584]}, "mutation_prompt": null}
{"id": "39a33976-97ac-403a-b617-8163ffceb7a6", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithElitism:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05  # Introducing elitism ratio\n        self.mutation_scale = 0.2\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * (self.budget - evaluations) / self.budget, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithElitism", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence, incorporating elitism and adaptive mutation scaling.", "configspace": "", "generation": 23, "fitness": 0.3029048905849652, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithElitism got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "77a33fe6-a0bb-42d2-b29d-fe10cb35297d", "metadata": {"aucs": [0.8123339310660977, 0.8123339310660977, 0.8123339310660977, 0.7988876402563798, 0.7988876402563798, 0.7988876402563798, 0.8085550271112101, 0.8085550271112101, 0.8085550271112101, 0.08793523955095917, 0.08793523955095917, 0.08793523955095917, 0.14758670699588605, 0.14758670699588605, 0.14758670699588605, 0.052996169010614325, 0.052996169010614325, 0.052996169010614325, 0.14762145039509778, 0.14762145039509778, 0.14762145039509778, 0.12509590080440125, 0.12509590080440125, 0.12509590080440125, 0.11533466797729819, 0.11533466797729819, 0.11533466797729819, 0.13251741264322914, 0.13251741264322914, 0.13251741264322914, 0.15056702680690703, 0.15056702680690703, 0.15056702680690703, 0.1312736374630853, 0.1312736374630853, 0.1312736374630853, 0.9470740592553027, 0.9470740592553027, 0.9470740592553027, 0.957130849872375, 0.957130849872375, 0.957130849872375, 0.9555503632383818, 0.9555503632383818, 0.9555503632383818, 0.48205189899941325, 0.48205189899941325, 0.48205189899941325, 0.494519155855079, 0.494519155855079, 0.494519155855079, 0.447121426813313, 0.447121426813313, 0.447121426813313, 0.7696093639671187, 0.7696093639671187, 0.7696093639671187, 0.2710431952170417, 0.2710431952170417, 0.2710431952170417, 0.7944760090666895, 0.7944760090666895, 0.7944760090666895, 0.12579560817544155, 0.12579560817544155, 0.12579560817544155, 0.1283611211684178, 0.1283611211684178, 0.1283611211684178, 0.181272137015835, 0.181272137015835, 0.181272137015835, 0.17495816054198055, 0.17495816054198055, 0.17495816054198055, 0.14834932829226732, 0.14834932829226732, 0.14834932829226732, 0.20410537880845414, 0.20410537880845414, 0.20410537880845414, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05487661469663885, 0.05487661469663885, 0.05487661469663885, 0.06986229624756468, 0.06986229624756468, 0.06986229624756468, 0.04038466694137677, 0.04038466694137677, 0.04038466694137677, 0.10378045524083168, 0.10378045524083168, 0.10378045524083168, 0.11862202338818517, 0.11862202338818517, 0.11862202338818517, 0.21701542367172943, 0.21701542367172943, 0.21701542367172943, 0.06221794428222471, 0.06221794428222471, 0.06221794428222471, 0.11860320260728241, 0.11860320260728241, 0.11860320260728241, 0.21778605112108662, 0.21778605112108662, 0.21778605112108662, 0.08292893979884153, 0.08292893979884153, 0.08292893979884153, 0.4489869076624453, 0.4489869076624453, 0.4489869076624453, 0.5403136194963951, 0.5403136194963951, 0.5403136194963951, 0.5391743794275532, 0.5391743794275532, 0.5391743794275532, 0.10644015474535118, 0.10644015474535118, 0.10644015474535118, 0.13138093769761383, 0.13138093769761383, 0.13138093769761383, 0.10815858493513208, 0.10815858493513208, 0.10815858493513208, 0.24775359913710704, 0.24775359913710704, 0.24775359913710704, 0.3724922789437777, 0.3724922789437777, 0.3724922789437777, 0.186858936151022, 0.186858936151022, 0.186858936151022, 0.3204845460589547, 0.3204845460589547, 0.3204845460589547, 0.4157300805088763, 0.4157300805088763, 0.4157300805088763, 0.3656436147887674, 0.3656436147887674, 0.3656436147887674, 0.20591483472553251, 0.20591483472553251, 0.20591483472553251, 0.2652690159247796, 0.2652690159247796, 0.2652690159247796, 0.29727589083045947, 0.29727589083045947, 0.29727589083045947, 0.2161047189705736, 0.2161047189705736, 0.2161047189705736, 0.21166407513318275, 0.21166407513318275, 0.21166407513318275, 0.2280370160366072, 0.2280370160366072, 0.2280370160366072, 0.20322382979937748, 0.20322382979937748, 0.20322382979937748, 0.21804681078612342, 0.21804681078612342, 0.21804681078612342, 0.24208233033835458, 0.24208233033835458, 0.24208233033835458, 0.8643485704235917, 0.8643485704235917, 0.8643485704235917, 0.1580409086830501, 0.1580409086830501, 0.1580409086830501, 0.8417760789506824, 0.8417760789506824, 0.8417760789506824, 0.7857140507874443, 0.7857140507874443, 0.7857140507874443, 0.21101201721433294, 0.21101201721433294, 0.21101201721433294, 0.5178355592777903, 0.5178355592777903, 0.5178355592777903, 0.19497603772842687, 0.19497603772842687, 0.19497603772842687, 0.2084812505329905, 0.2084812505329905, 0.2084812505329905, 0.18206422845200942, 0.18206422845200942, 0.18206422845200942, 0.08156059306631103, 0.08156059306631103, 0.08156059306631103, 0.10383109062383022, 0.10383109062383022, 0.10383109062383022, 0.11007508991501291, 0.11007508991501291, 0.11007508991501291]}, "mutation_prompt": null}
{"id": "c96ae2d9-f8b2-4963-81c1-92f525517ed4", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithElitism:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05  # Introducing elitism ratio\n        self.mutation_scale = 0.2\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * (self.budget - evaluations) / self.budget, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithElitism", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling and probabilistic diversity injection for enhanced exploration and convergence, incorporating elitism and adaptive mutation scaling.", "configspace": "", "generation": 24, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "39a33976-97ac-403a-b617-8163ffceb7a6", "metadata": {"aucs": [0.8123339310660977, 0.8123339310660977, 0.8123339310660977, 0.7988876402563798, 0.7988876402563798, 0.7988876402563798, 0.8085550271112101, 0.8085550271112101, 0.8085550271112101, 0.08793523955095917, 0.08793523955095917, 0.08793523955095917, 0.14758670699588605, 0.14758670699588605, 0.14758670699588605, 0.052996169010614325, 0.052996169010614325, 0.052996169010614325, 0.14762145039509778, 0.14762145039509778, 0.14762145039509778, 0.12509590080440125, 0.12509590080440125, 0.12509590080440125, 0.11533466797729819, 0.11533466797729819, 0.11533466797729819, 0.13251741264322914, 0.13251741264322914, 0.13251741264322914, 0.15056702680690703, 0.15056702680690703, 0.15056702680690703, 0.1312736374630853, 0.1312736374630853, 0.1312736374630853, 0.9470740592553027, 0.9470740592553027, 0.9470740592553027, 0.957130849872375, 0.957130849872375, 0.957130849872375, 0.9555503632383818, 0.9555503632383818, 0.9555503632383818, 0.48205189899941325, 0.48205189899941325, 0.48205189899941325, 0.494519155855079, 0.494519155855079, 0.494519155855079, 0.447121426813313, 0.447121426813313, 0.447121426813313, 0.7696093639671187, 0.7696093639671187, 0.7696093639671187, 0.2710431952170417, 0.2710431952170417, 0.2710431952170417, 0.7944760090666895, 0.7944760090666895, 0.7944760090666895, 0.12579560817544155, 0.12579560817544155, 0.12579560817544155, 0.1283611211684178, 0.1283611211684178, 0.1283611211684178, 0.181272137015835, 0.181272137015835, 0.181272137015835, 0.17495816054198055, 0.17495816054198055, 0.17495816054198055, 0.14834932829226732, 0.14834932829226732, 0.14834932829226732, 0.20410537880845414, 0.20410537880845414, 0.20410537880845414, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05487661469663885, 0.05487661469663885, 0.05487661469663885, 0.06986229624756468, 0.06986229624756468, 0.06986229624756468, 0.04038466694137677, 0.04038466694137677, 0.04038466694137677, 0.10378045524083168, 0.10378045524083168, 0.10378045524083168, 0.11862202338818517, 0.11862202338818517, 0.11862202338818517, 0.21701542367172943, 0.21701542367172943, 0.21701542367172943, 0.06221794428222471, 0.06221794428222471, 0.06221794428222471, 0.11860320260728241, 0.11860320260728241, 0.11860320260728241, 0.21778605112108662, 0.21778605112108662, 0.21778605112108662, 0.08292893979884153, 0.08292893979884153, 0.08292893979884153, 0.4489869076624453, 0.4489869076624453, 0.4489869076624453, 0.5403136194963951, 0.5403136194963951, 0.5403136194963951, 0.5391743794275532, 0.5391743794275532, 0.5391743794275532, 0.10644015474535118, 0.10644015474535118, 0.10644015474535118, 0.13138093769761383, 0.13138093769761383, 0.13138093769761383, 0.10815858493513208, 0.10815858493513208, 0.10815858493513208, 0.24775359913710704, 0.24775359913710704, 0.24775359913710704, 0.3724922789437777, 0.3724922789437777, 0.3724922789437777, 0.186858936151022, 0.186858936151022, 0.186858936151022, 0.3204845460589547, 0.3204845460589547, 0.3204845460589547, 0.4157300805088763, 0.4157300805088763, 0.4157300805088763, 0.3656436147887674, 0.3656436147887674, 0.3656436147887674, 0.20591483472553251, 0.20591483472553251, 0.20591483472553251, 0.2652690159247796, 0.2652690159247796, 0.2652690159247796, 0.29727589083045947, 0.29727589083045947, 0.29727589083045947, 0.2161047189705736, 0.2161047189705736, 0.2161047189705736, 0.21166407513318275, 0.21166407513318275, 0.21166407513318275, 0.2280370160366072, 0.2280370160366072, 0.2280370160366072, 0.20322382979937748, 0.20322382979937748, 0.20322382979937748, 0.21804681078612342, 0.21804681078612342, 0.21804681078612342, 0.24208233033835458, 0.24208233033835458, 0.24208233033835458, 0.8643485704235917, 0.8643485704235917, 0.8643485704235917, 0.1580409086830501, 0.1580409086830501, 0.1580409086830501, 0.8417760789506824, 0.8417760789506824, 0.8417760789506824, 0.7857140507874443, 0.7857140507874443, 0.7857140507874443, 0.21101201721433294, 0.21101201721433294, 0.21101201721433294, 0.5178355592777903, 0.5178355592777903, 0.5178355592777903, 0.19497603772842687, 0.19497603772842687, 0.19497603772842687, 0.2084812505329905, 0.2084812505329905, 0.2084812505329905, 0.18206422845200942, 0.18206422845200942, 0.18206422845200942, 0.08156059306631103, 0.08156059306631103, 0.08156059306631103, 0.10383109062383022, 0.10383109062383022, 0.10383109062383022, 0.11007508991501291, 0.11007508991501291, 0.11007508991501291]}, "mutation_prompt": null}
{"id": "3493444f-cd97-4f60-93e3-2bc31476b2c6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.15  # Increased mutation probability for diversity\n        self.vel_bound = (self.ub - self.lb) / 5.0  # Adjusted velocity boundary\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.95  # Modified decay rate\n        self.elitism_ratio = 0.1  # Increased elitism ratio\n        self.mutation_scale = 0.25  # Modified mutation scale\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * (self.budget - evaluations) / self.budget, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedAdaptiveVelocitySwarmOptimizer", "description": "An adaptive particle swarm optimizer with dynamic velocity control, elite retention, and adaptive mutation for robust exploration and faster convergence across diverse optimization landscapes.", "configspace": "", "generation": 25, "fitness": 0.26557318729571944, "feedback": "The algorithm EnhancedAdaptiveVelocitySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.25.", "error": "", "parent_id": "39a33976-97ac-403a-b617-8163ffceb7a6", "metadata": {"aucs": [0.6450991603089093, 0.6450991603089093, 0.6450991603089093, 0.7320582832307865, 0.7320582832307865, 0.7320582832307865, 0.7872212052175673, 0.7872212052175673, 0.7872212052175673, 0.04741198584380946, 0.04741198584380946, 0.04741198584380946, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0010780668186353148, 0.0010780668186353148, 0.0010780668186353148, 0.13692193482676462, 0.13692193482676462, 0.13692193482676462, 0.09354840719969382, 0.09354840719969382, 0.09354840719969382, 0.10682629749694339, 0.10682629749694339, 0.10682629749694339, 0.11942289192030497, 0.11942289192030497, 0.11942289192030497, 0.10664989395926316, 0.10664989395926316, 0.10664989395926316, 0.11166577783044507, 0.11166577783044507, 0.11166577783044507, 0.9556316055997152, 0.9556316055997152, 0.9556316055997152, 0.9597805465548889, 0.9597805465548889, 0.9597805465548889, 0.9631323642126972, 0.9631323642126972, 0.9631323642126972, 0.43490400948766605, 0.43490400948766605, 0.43490400948766605, 0.2516810641698084, 0.2516810641698084, 0.2516810641698084, 0.32123229866629355, 0.32123229866629355, 0.32123229866629355, 0.22454976906354707, 0.22454976906354707, 0.22454976906354707, 0.19155419167704013, 0.19155419167704013, 0.19155419167704013, 0.1666304216894492, 0.1666304216894492, 0.1666304216894492, 0.16870819088134925, 0.16870819088134925, 0.16870819088134925, 0.14170481223977027, 0.14170481223977027, 0.14170481223977027, 0.14074749361461603, 0.14074749361461603, 0.14074749361461603, 0.1342110723125286, 0.1342110723125286, 0.1342110723125286, 0.1233086474594165, 0.1233086474594165, 0.1233086474594165, 0.12771910843322198, 0.12771910843322198, 0.12771910843322198, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11292672307760854, 0.11292672307760854, 0.11292672307760854, 0.08617380406098585, 0.08617380406098585, 0.08617380406098585, 0.07990524249023456, 0.07990524249023456, 0.07990524249023456, 0.12010660958122532, 0.12010660958122532, 0.12010660958122532, 0.08835606525284423, 0.08835606525284423, 0.08835606525284423, 0.10694218824616963, 0.10694218824616963, 0.10694218824616963, 0.13807987834359592, 0.13807987834359592, 0.13807987834359592, 0.18795660097498046, 0.18795660097498046, 0.18795660097498046, 0.16551633014742362, 0.16551633014742362, 0.16551633014742362, 0.11851182196560239, 0.11851182196560239, 0.11851182196560239, 0.4881816413227754, 0.4881816413227754, 0.4881816413227754, 0.5220480171000221, 0.5220480171000221, 0.5220480171000221, 0.5126203775621712, 0.5126203775621712, 0.5126203775621712, 0.14270562902180373, 0.14270562902180373, 0.14270562902180373, 0.1328925478082752, 0.1328925478082752, 0.1328925478082752, 0.15422452615551296, 0.15422452615551296, 0.15422452615551296, 0.34809264073198354, 0.34809264073198354, 0.34809264073198354, 0.16957681422881576, 0.16957681422881576, 0.16957681422881576, 0.3055003689766116, 0.3055003689766116, 0.3055003689766116, 0.24866694036711035, 0.24866694036711035, 0.24866694036711035, 0.33824265065705095, 0.33824265065705095, 0.33824265065705095, 0.4434995687393556, 0.4434995687393556, 0.4434995687393556, 0.16878739601778803, 0.16878739601778803, 0.16878739601778803, 0.27057276368461713, 0.27057276368461713, 0.27057276368461713, 0.1951603549215476, 0.1951603549215476, 0.1951603549215476, 0.2766630377774646, 0.2766630377774646, 0.2766630377774646, 0.20221787309476325, 0.20221787309476325, 0.20221787309476325, 0.2429977417396202, 0.2429977417396202, 0.2429977417396202, 0.22051747745509753, 0.22051747745509753, 0.22051747745509753, 0.22081905755891862, 0.22081905755891862, 0.22081905755891862, 0.17624620220380127, 0.17624620220380127, 0.17624620220380127, 0.879640098372035, 0.879640098372035, 0.879640098372035, 0.15815672007672532, 0.15815672007672532, 0.15815672007672532, 0.879123791925984, 0.879123791925984, 0.879123791925984, 0.8918437979547403, 0.8918437979547403, 0.8918437979547403, 0.21016655534770456, 0.21016655534770456, 0.21016655534770456, 0.12705090727710266, 0.12705090727710266, 0.12705090727710266, 0.166941872198634, 0.166941872198634, 0.166941872198634, 0.19640568017526094, 0.19640568017526094, 0.19640568017526094, 0.18919301596072458, 0.18919301596072458, 0.18919301596072458, 0.08921639238808443, 0.08921639238808443, 0.08921639238808443, 0.07708994386027335, 0.07708994386027335, 0.07708994386027335, 0.0780323177736223, 0.0780323177736223, 0.0780323177736223]}, "mutation_prompt": null}
{"id": "b05a52a0-4a4c-42a9-aa67-1e3c29a41e71", "solution": "import numpy as np\n\nclass EnhancedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.2\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * ((self.budget - evaluations) / self.budget)**2, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedSwarmOptimizer", "description": "An enhanced particle swarm optimization with adaptive velocity scaling, elitism, and non-uniform mutation for robust exploration and convergence control.", "configspace": "", "generation": 26, "fitness": 0.29608660120475383, "feedback": "The algorithm EnhancedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "39a33976-97ac-403a-b617-8163ffceb7a6", "metadata": {"aucs": [0.7015360047702743, 0.7015360047702743, 0.7015360047702743, 0.696610861866023, 0.696610861866023, 0.696610861866023, 0.6811006397486019, 0.6811006397486019, 0.6811006397486019, 0.3036335963354, 0.3036335963354, 0.3036335963354, 0.07404038612284125, 0.07404038612284125, 0.07404038612284125, 0.21470746389908923, 0.21470746389908923, 0.21470746389908923, 0.14198901030919064, 0.14198901030919064, 0.14198901030919064, 0.15189200316164075, 0.15189200316164075, 0.15189200316164075, 0.16609932430711105, 0.16609932430711105, 0.16609932430711105, 0.1248784021099636, 0.1248784021099636, 0.1248784021099636, 0.1038597523107645, 0.1038597523107645, 0.1038597523107645, 0.10580688133635119, 0.10580688133635119, 0.10580688133635119, 0.9471194233080119, 0.9471194233080119, 0.9471194233080119, 0.9572101002713672, 0.9572101002713672, 0.9572101002713672, 0.9559529363314302, 0.9559529363314302, 0.9559529363314302, 0.5055633248978836, 0.5055633248978836, 0.5055633248978836, 0.4919485206687204, 0.4919485206687204, 0.4919485206687204, 0.4553115928192428, 0.4553115928192428, 0.4553115928192428, 0.2227669841253992, 0.2227669841253992, 0.2227669841253992, 0.2597518269607998, 0.2597518269607998, 0.2597518269607998, 0.776163339808327, 0.776163339808327, 0.776163339808327, 0.11795250705786908, 0.11795250705786908, 0.11795250705786908, 0.1435365164215069, 0.1435365164215069, 0.1435365164215069, 0.19682485895054902, 0.19682485895054902, 0.19682485895054902, 0.17799707887416316, 0.17799707887416316, 0.17799707887416316, 0.17999703591878025, 0.17999703591878025, 0.17999703591878025, 0.20155439230251815, 0.20155439230251815, 0.20155439230251815, 0.0075196133909767315, 0.0075196133909767315, 0.0075196133909767315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.054373852209394724, 0.054373852209394724, 0.054373852209394724, 0.0682325416957068, 0.0682325416957068, 0.0682325416957068, 0.0489728583474327, 0.0489728583474327, 0.0489728583474327, 0.13262249917464397, 0.13262249917464397, 0.13262249917464397, 0.08746899366325633, 0.08746899366325633, 0.08746899366325633, 0.17478923494497045, 0.17478923494497045, 0.17478923494497045, 0.054049737182788715, 0.054049737182788715, 0.054049737182788715, 0.06321311421939702, 0.06321311421939702, 0.06321311421939702, 0.13409001971525936, 0.13409001971525936, 0.13409001971525936, 0.05353846419144137, 0.05353846419144137, 0.05353846419144137, 0.4776328516504178, 0.4776328516504178, 0.4776328516504178, 0.4933654124206862, 0.4933654124206862, 0.4933654124206862, 0.491795421880338, 0.491795421880338, 0.491795421880338, 0.1171705684702965, 0.1171705684702965, 0.1171705684702965, 0.1026858626987327, 0.1026858626987327, 0.1026858626987327, 0.1172433956243556, 0.1172433956243556, 0.1172433956243556, 0.19954161001507442, 0.19954161001507442, 0.19954161001507442, 0.3497484190569129, 0.3497484190569129, 0.3497484190569129, 0.46469641215396007, 0.46469641215396007, 0.46469641215396007, 0.2833646207740691, 0.2833646207740691, 0.2833646207740691, 0.3633664290173163, 0.3633664290173163, 0.3633664290173163, 0.3980833499521801, 0.3980833499521801, 0.3980833499521801, 0.24101178670416523, 0.24101178670416523, 0.24101178670416523, 0.28788552629557673, 0.28788552629557673, 0.28788552629557673, 0.24448430500427765, 0.24448430500427765, 0.24448430500427765, 0.1975228312685059, 0.1975228312685059, 0.1975228312685059, 0.25199367988474497, 0.25199367988474497, 0.25199367988474497, 0.22558728197005995, 0.22558728197005995, 0.22558728197005995, 0.23570159296433835, 0.23570159296433835, 0.23570159296433835, 0.20421069995878072, 0.20421069995878072, 0.20421069995878072, 0.23702613922807358, 0.23702613922807358, 0.23702613922807358, 0.8391504594596992, 0.8391504594596992, 0.8391504594596992, 0.15780579637610115, 0.15780579637610115, 0.15780579637610115, 0.8037117292363497, 0.8037117292363497, 0.8037117292363497, 0.7857276365438906, 0.7857276365438906, 0.7857276365438906, 0.20994866675554713, 0.20994866675554713, 0.20994866675554713, 0.6856506373869089, 0.6856506373869089, 0.6856506373869089, 0.20501490010185164, 0.20501490010185164, 0.20501490010185164, 0.20593311894554023, 0.20593311894554023, 0.20593311894554023, 0.187988766655367, 0.187988766655367, 0.187988766655367, 0.09842966136313158, 0.09842966136313158, 0.09842966136313158, 0.10106729667458636, 0.10106729667458636, 0.10106729667458636, 0.11891272652135176, 0.11891272652135176, 0.11891272652135176]}, "mutation_prompt": null}
{"id": "f8263330-f5f4-4cd8-9c10-3b11024e4889", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithElitism:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.2\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * (self.budget - evaluations) / self.budget, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithElitism", "description": "An enhanced particle swarm optimizer with elite retention, adaptive velocity scaling, and stochastic exploration adjustments for robust solution finding.", "configspace": "", "generation": 27, "fitness": 0.3029048905849652, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithElitism got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "39a33976-97ac-403a-b617-8163ffceb7a6", "metadata": {"aucs": [0.8123339310660977, 0.8123339310660977, 0.8123339310660977, 0.7988876402563798, 0.7988876402563798, 0.7988876402563798, 0.8085550271112101, 0.8085550271112101, 0.8085550271112101, 0.08793523955095917, 0.08793523955095917, 0.08793523955095917, 0.14758670699588605, 0.14758670699588605, 0.14758670699588605, 0.052996169010614325, 0.052996169010614325, 0.052996169010614325, 0.14762145039509778, 0.14762145039509778, 0.14762145039509778, 0.12509590080440125, 0.12509590080440125, 0.12509590080440125, 0.11533466797729819, 0.11533466797729819, 0.11533466797729819, 0.13251741264322914, 0.13251741264322914, 0.13251741264322914, 0.15056702680690703, 0.15056702680690703, 0.15056702680690703, 0.1312736374630853, 0.1312736374630853, 0.1312736374630853, 0.9470740592553027, 0.9470740592553027, 0.9470740592553027, 0.957130849872375, 0.957130849872375, 0.957130849872375, 0.9555503632383818, 0.9555503632383818, 0.9555503632383818, 0.48205189899941325, 0.48205189899941325, 0.48205189899941325, 0.494519155855079, 0.494519155855079, 0.494519155855079, 0.447121426813313, 0.447121426813313, 0.447121426813313, 0.7696093639671187, 0.7696093639671187, 0.7696093639671187, 0.2710431952170417, 0.2710431952170417, 0.2710431952170417, 0.7944760090666895, 0.7944760090666895, 0.7944760090666895, 0.12579560817544155, 0.12579560817544155, 0.12579560817544155, 0.1283611211684178, 0.1283611211684178, 0.1283611211684178, 0.181272137015835, 0.181272137015835, 0.181272137015835, 0.17495816054198055, 0.17495816054198055, 0.17495816054198055, 0.14834932829226732, 0.14834932829226732, 0.14834932829226732, 0.20410537880845414, 0.20410537880845414, 0.20410537880845414, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05487661469663885, 0.05487661469663885, 0.05487661469663885, 0.06986229624756468, 0.06986229624756468, 0.06986229624756468, 0.04038466694137677, 0.04038466694137677, 0.04038466694137677, 0.10378045524083168, 0.10378045524083168, 0.10378045524083168, 0.11862202338818517, 0.11862202338818517, 0.11862202338818517, 0.21701542367172943, 0.21701542367172943, 0.21701542367172943, 0.06221794428222471, 0.06221794428222471, 0.06221794428222471, 0.11860320260728241, 0.11860320260728241, 0.11860320260728241, 0.21778605112108662, 0.21778605112108662, 0.21778605112108662, 0.08292893979884153, 0.08292893979884153, 0.08292893979884153, 0.4489869076624453, 0.4489869076624453, 0.4489869076624453, 0.5403136194963951, 0.5403136194963951, 0.5403136194963951, 0.5391743794275532, 0.5391743794275532, 0.5391743794275532, 0.10644015474535118, 0.10644015474535118, 0.10644015474535118, 0.13138093769761383, 0.13138093769761383, 0.13138093769761383, 0.10815858493513208, 0.10815858493513208, 0.10815858493513208, 0.24775359913710704, 0.24775359913710704, 0.24775359913710704, 0.3724922789437777, 0.3724922789437777, 0.3724922789437777, 0.186858936151022, 0.186858936151022, 0.186858936151022, 0.3204845460589547, 0.3204845460589547, 0.3204845460589547, 0.4157300805088763, 0.4157300805088763, 0.4157300805088763, 0.3656436147887674, 0.3656436147887674, 0.3656436147887674, 0.20591483472553251, 0.20591483472553251, 0.20591483472553251, 0.2652690159247796, 0.2652690159247796, 0.2652690159247796, 0.29727589083045947, 0.29727589083045947, 0.29727589083045947, 0.2161047189705736, 0.2161047189705736, 0.2161047189705736, 0.21166407513318275, 0.21166407513318275, 0.21166407513318275, 0.2280370160366072, 0.2280370160366072, 0.2280370160366072, 0.20322382979937748, 0.20322382979937748, 0.20322382979937748, 0.21804681078612342, 0.21804681078612342, 0.21804681078612342, 0.24208233033835458, 0.24208233033835458, 0.24208233033835458, 0.8643485704235917, 0.8643485704235917, 0.8643485704235917, 0.1580409086830501, 0.1580409086830501, 0.1580409086830501, 0.8417760789506824, 0.8417760789506824, 0.8417760789506824, 0.7857140507874443, 0.7857140507874443, 0.7857140507874443, 0.21101201721433294, 0.21101201721433294, 0.21101201721433294, 0.5178355592777903, 0.5178355592777903, 0.5178355592777903, 0.19497603772842687, 0.19497603772842687, 0.19497603772842687, 0.2084812505329905, 0.2084812505329905, 0.2084812505329905, 0.18206422845200942, 0.18206422845200942, 0.18206422845200942, 0.08156059306631103, 0.08156059306631103, 0.08156059306631103, 0.10383109062383022, 0.10383109062383022, 0.10383109062383022, 0.11007508991501291, 0.11007508991501291, 0.11007508991501291]}, "mutation_prompt": null}
{"id": "3d64d16f-2904-4d88-8ea8-f3d396c94cd1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveParticleSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.8\n        self.mutation_prob = 0.2\n        self.vel_bound = (self.ub - self.lb) / 5.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.95\n        self.elitism_ratio = 0.1  # Adjusted elitism ratio\n        self.mutation_scale = 0.3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * (self.budget - evaluations) / self.budget, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedAdaptiveParticleSwarmOptimizer", "description": "An enhanced adaptive particle swarm optimizer with dynamic neighborhood search and selective elitism for improved convergence and robustness.", "configspace": "", "generation": 28, "fitness": 0.25753148962013794, "feedback": "The algorithm EnhancedAdaptiveParticleSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.23.", "error": "", "parent_id": "39a33976-97ac-403a-b617-8163ffceb7a6", "metadata": {"aucs": [0.6131200542879081, 0.6131200542879081, 0.6131200542879081, 0.6209376552316171, 0.6209376552316171, 0.6209376552316171, 0.6078687515203751, 0.6078687515203751, 0.6078687515203751, 0.0491469732929527, 0.0491469732929527, 0.0491469732929527, 0.10826143071942751, 0.10826143071942751, 0.10826143071942751, 0.03533168214104476, 0.03533168214104476, 0.03533168214104476, 0.10733779419395617, 0.10733779419395617, 0.10733779419395617, 0.12965398853385635, 0.12965398853385635, 0.12965398853385635, 0.09990691685465414, 0.09990691685465414, 0.09990691685465414, 0.15295486145243065, 0.15295486145243065, 0.15295486145243065, 0.10418480715335976, 0.10418480715335976, 0.10418480715335976, 0.08331751342567584, 0.08331751342567584, 0.08331751342567584, 0.9567930627652285, 0.9567930627652285, 0.9567930627652285, 0.9585367633228886, 0.9585367633228886, 0.9585367633228886, 0.9627417923337499, 0.9627417923337499, 0.9627417923337499, 0.4308560206029871, 0.4308560206029871, 0.4308560206029871, 0.4011024657590362, 0.4011024657590362, 0.4011024657590362, 0.40330410292748253, 0.40330410292748253, 0.40330410292748253, 0.22595118641944223, 0.22595118641944223, 0.22595118641944223, 0.19048440526497723, 0.19048440526497723, 0.19048440526497723, 0.16562797726231326, 0.16562797726231326, 0.16562797726231326, 0.14604056240473184, 0.14604056240473184, 0.14604056240473184, 0.14892862228644466, 0.14892862228644466, 0.14892862228644466, 0.14455951876827167, 0.14455951876827167, 0.14455951876827167, 0.19009797140532014, 0.19009797140532014, 0.19009797140532014, 0.1583291210702864, 0.1583291210702864, 0.1583291210702864, 0.1491799165477694, 0.1491799165477694, 0.1491799165477694, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07696123517997444, 0.07696123517997444, 0.07696123517997444, 0.03791102192141893, 0.03791102192141893, 0.03791102192141893, 0.11926860690507113, 0.11926860690507113, 0.11926860690507113, 0.06847867113548634, 0.06847867113548634, 0.06847867113548634, 0.12084241677353713, 0.12084241677353713, 0.12084241677353713, 0.10479122627406579, 0.10479122627406579, 0.10479122627406579, 0.1154015586973628, 0.1154015586973628, 0.1154015586973628, 0.010835203540464633, 0.010835203540464633, 0.010835203540464633, 0.13346780838948658, 0.13346780838948658, 0.13346780838948658, 0.06668087432331249, 0.06668087432331249, 0.06668087432331249, 0.13930873880985384, 0.13930873880985384, 0.13930873880985384, 0.4979103693147111, 0.4979103693147111, 0.4979103693147111, 0.46433460912774127, 0.46433460912774127, 0.46433460912774127, 0.5062850642184534, 0.5062850642184534, 0.5062850642184534, 0.10295167199959265, 0.10295167199959265, 0.10295167199959265, 0.1790870711130279, 0.1790870711130279, 0.1790870711130279, 0.13832195638067368, 0.13832195638067368, 0.13832195638067368, 0.1874487550452506, 0.1874487550452506, 0.1874487550452506, 0.19215508763476874, 0.19215508763476874, 0.19215508763476874, 0.1689871538055886, 0.1689871538055886, 0.1689871538055886, 0.285302412349163, 0.285302412349163, 0.285302412349163, 0.4074054900385866, 0.4074054900385866, 0.4074054900385866, 0.3323272209922574, 0.3323272209922574, 0.3323272209922574, 0.22386385293131805, 0.22386385293131805, 0.22386385293131805, 0.21337602094620212, 0.21337602094620212, 0.21337602094620212, 0.15856183856023987, 0.15856183856023987, 0.15856183856023987, 0.2579759194297184, 0.2579759194297184, 0.2579759194297184, 0.2343092815320823, 0.2343092815320823, 0.2343092815320823, 0.2124396076171965, 0.2124396076171965, 0.2124396076171965, 0.19553981427122147, 0.19553981427122147, 0.19553981427122147, 0.22573782157873445, 0.22573782157873445, 0.22573782157873445, 0.19566796767298666, 0.19566796767298666, 0.19566796767298666, 0.8521048747418835, 0.8521048747418835, 0.8521048747418835, 0.15848835386032312, 0.15848835386032312, 0.15848835386032312, 0.8774187376215429, 0.8774187376215429, 0.8774187376215429, 0.4641247119852394, 0.4641247119852394, 0.4641247119852394, 0.20709169747426426, 0.20709169747426426, 0.20709169747426426, 0.3528189860817209, 0.3528189860817209, 0.3528189860817209, 0.22136316100210063, 0.22136316100210063, 0.22136316100210063, 0.18677048139879393, 0.18677048139879393, 0.18677048139879393, 0.19109702436327414, 0.19109702436327414, 0.19109702436327414, 0.10514824674598111, 0.10514824674598111, 0.10514824674598111, 0.08466396739404003, 0.08466396739404003, 0.08466396739404003, 0.1225847435230295, 0.1225847435230295, 0.1225847435230295]}, "mutation_prompt": null}
{"id": "fe58ba44-e9bc-4670-bb0f-25364c755564", "solution": "import numpy as np\n\nclass EnhancedDynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.cognitive_weight = 1.7\n        self.social_weight = 1.4\n        self.mutation_prob = 0.15  # Increased mutation probability\n        self.vel_bound = (self.ub - self.lb) / 5.0  # Modified velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.97  # Slightly adjusted decay rate\n        self.elitism_ratio = 0.1  # Increased elitism ratio\n        self.mutation_scale = 0.25  # Increased mutation scale\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * (self.budget - evaluations) / self.budget, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            progress = evaluations / self.budget\n            self.inertia_weight = 0.9 * (1 - progress) + 0.4 * progress  # Dynamic inertia weight\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedDynamicSwarmOptimizer", "description": "An enhanced dynamic particle swarm optimizer with adaptive velocity, elitism, and mutation strategies, incorporating a dynamic inertia weight based on convergence progress.", "configspace": "", "generation": 29, "fitness": 0.23711132753682176, "feedback": "The algorithm EnhancedDynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.22.", "error": "", "parent_id": "39a33976-97ac-403a-b617-8163ffceb7a6", "metadata": {"aucs": [0.529568522693123, 0.529568522693123, 0.529568522693123, 0.5129251871087865, 0.5129251871087865, 0.5129251871087865, 0.5458306296256272, 0.5458306296256272, 0.5458306296256272, 0.0709799306039568, 0.0709799306039568, 0.0709799306039568, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05169399854447221, 0.05169399854447221, 0.05169399854447221, 0.11965360467767183, 0.11965360467767183, 0.11965360467767183, 0.13603560272826487, 0.13603560272826487, 0.13603560272826487, 0.11710782037452849, 0.11710782037452849, 0.11710782037452849, 0.1171250951814502, 0.1171250951814502, 0.1171250951814502, 0.1022988246168195, 0.1022988246168195, 0.1022988246168195, 0.09327137456130008, 0.09327137456130008, 0.09327137456130008, 0.9567346750549515, 0.9567346750549515, 0.9567346750549515, 0.9622391934605516, 0.9622391934605516, 0.9622391934605516, 0.9683947242681563, 0.9683947242681563, 0.9683947242681563, 0.34712204352096565, 0.34712204352096565, 0.34712204352096565, 0.3608469569434064, 0.3608469569434064, 0.3608469569434064, 0.33467376396175785, 0.33467376396175785, 0.33467376396175785, 0.2014486745739329, 0.2014486745739329, 0.2014486745739329, 0.15727224299216358, 0.15727224299216358, 0.15727224299216358, 0.2005891915653234, 0.2005891915653234, 0.2005891915653234, 0.11573858080743049, 0.11573858080743049, 0.11573858080743049, 0.10563757767946902, 0.10563757767946902, 0.10563757767946902, 0.1771398575489609, 0.1771398575489609, 0.1771398575489609, 0.0982186355297523, 0.0982186355297523, 0.0982186355297523, 0.11131136373343742, 0.11131136373343742, 0.11131136373343742, 0.11276485577773232, 0.11276485577773232, 0.11276485577773232, 0.03599348365081401, 0.03599348365081401, 0.03599348365081401, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08465304011208552, 0.08465304011208552, 0.08465304011208552, 0.09874547859865401, 0.09874547859865401, 0.09874547859865401, 0.06109183975846022, 0.06109183975846022, 0.06109183975846022, 0.09170699300222951, 0.09170699300222951, 0.09170699300222951, 0.027262518666262947, 0.027262518666262947, 0.027262518666262947, 0.07605339189637339, 0.07605339189637339, 0.07605339189637339, 0.06196665633479059, 0.06196665633479059, 0.06196665633479059, 0.1163659501295391, 0.1163659501295391, 0.1163659501295391, 0.07538680933542474, 0.07538680933542474, 0.07538680933542474, 0.06747306835767153, 0.06747306835767153, 0.06747306835767153, 0.4263056721706816, 0.4263056721706816, 0.4263056721706816, 0.4468637237445551, 0.4468637237445551, 0.4468637237445551, 0.4029289228991344, 0.4029289228991344, 0.4029289228991344, 0.09137604018670498, 0.09137604018670498, 0.09137604018670498, 0.1374955913284308, 0.1374955913284308, 0.1374955913284308, 0.10754359575239836, 0.10754359575239836, 0.10754359575239836, 0.1587138882280864, 0.1587138882280864, 0.1587138882280864, 0.29317275063583037, 0.29317275063583037, 0.29317275063583037, 0.18574120676835204, 0.18574120676835204, 0.18574120676835204, 0.28909164614871175, 0.28909164614871175, 0.28909164614871175, 0.34920613161337044, 0.34920613161337044, 0.34920613161337044, 0.2519443905121681, 0.2519443905121681, 0.2519443905121681, 0.23113318052077192, 0.23113318052077192, 0.23113318052077192, 0.25214755069569916, 0.25214755069569916, 0.25214755069569916, 0.19759292947720974, 0.19759292947720974, 0.19759292947720974, 0.21148500666083803, 0.21148500666083803, 0.21148500666083803, 0.21255302205569893, 0.21255302205569893, 0.21255302205569893, 0.18834059179184237, 0.18834059179184237, 0.18834059179184237, 0.18765018959315782, 0.18765018959315782, 0.18765018959315782, 0.19181885066191728, 0.19181885066191728, 0.19181885066191728, 0.2105423189229786, 0.2105423189229786, 0.2105423189229786, 0.74088340205097, 0.74088340205097, 0.74088340205097, 0.16682682880540267, 0.16682682880540267, 0.16682682880540267, 0.6860988912600201, 0.6860988912600201, 0.6860988912600201, 0.6100379568627428, 0.6100379568627428, 0.6100379568627428, 0.2039098652989917, 0.2039098652989917, 0.2039098652989917, 0.3984341875355546, 0.3984341875355546, 0.3984341875355546, 0.18020655455757573, 0.18020655455757573, 0.18020655455757573, 0.20758109299704874, 0.20758109299704874, 0.20758109299704874, 0.18152962036964726, 0.18152962036964726, 0.18152962036964726, 0.08678212101681115, 0.08678212101681115, 0.08678212101681115, 0.08868214640809857, 0.08868214640809857, 0.08868214640809857, 0.09387355714346335, 0.09387355714346335, 0.09387355714346335]}, "mutation_prompt": null}
{"id": "fd8d4f19-6250-4a4a-8e05-f13c56b1c484", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.initial_population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.97\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.2\n        self.dynamic_population_factor = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        population_size = self.initial_population_size\n        particles = np.random.uniform(self.lb, self.ub, (population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n\n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * population_size)\n\n            for i in range(population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * (self.budget - evaluations) / self.budget, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n            \n            # Dynamic adjustment of the population size\n            population_size = max(10, int(self.initial_population_size - self.dynamic_population_factor * evaluations))\n\n        return self.global_best_value", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhanced Particle Swarm Optimizer with Adaptive Learning Rates, Dynamic Population Resizing, and Stochastic Mutation Strategy.", "configspace": "", "generation": 30, "fitness": 0.2611947979868785, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.24.", "error": "", "parent_id": "39a33976-97ac-403a-b617-8163ffceb7a6", "metadata": {"aucs": [0.6906674230326793, 0.6906674230326793, 0.6906674230326793, 0.6216651520570415, 0.6216651520570415, 0.6216651520570415, 0.7688625995333912, 0.7688625995333912, 0.7688625995333912, 0.04634047871655678, 0.04634047871655678, 0.04634047871655678, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1409234735004118, 0.1409234735004118, 0.1409234735004118, 0.18250581842261482, 0.18250581842261482, 0.18250581842261482, 0.11505114962284801, 0.11505114962284801, 0.11505114962284801, 0.09775542078700505, 0.09775542078700505, 0.09775542078700505, 0.10042913621406735, 0.10042913621406735, 0.10042913621406735, 0.09345305518501679, 0.09345305518501679, 0.09345305518501679, 0.9531287045603574, 0.9531287045603574, 0.9531287045603574, 0.9574220437899007, 0.9574220437899007, 0.9574220437899007, 0.9573208626552839, 0.9573208626552839, 0.9573208626552839, 0.4167906527937507, 0.4167906527937507, 0.4167906527937507, 0.42607030961253234, 0.42607030961253234, 0.42607030961253234, 0.38492633966556655, 0.38492633966556655, 0.38492633966556655, 0.22593328229597742, 0.22593328229597742, 0.22593328229597742, 0.27204687738795597, 0.27204687738795597, 0.27204687738795597, 0.2425034107224756, 0.2425034107224756, 0.2425034107224756, 0.11983400576176806, 0.11983400576176806, 0.11983400576176806, 0.18295397057651497, 0.18295397057651497, 0.18295397057651497, 0.1046482111478777, 0.1046482111478777, 0.1046482111478777, 0.12603818575262815, 0.12603818575262815, 0.12603818575262815, 0.16600021184907487, 0.16600021184907487, 0.16600021184907487, 0.17234847774274853, 0.17234847774274853, 0.17234847774274853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07216146816864544, 0.07216146816864544, 0.07216146816864544, 0.0627925637019845, 0.0627925637019845, 0.0627925637019845, 0.030821848569750676, 0.030821848569750676, 0.030821848569750676, 0.10129368799595995, 0.10129368799595995, 0.10129368799595995, 0.11392833114252732, 0.11392833114252732, 0.11392833114252732, 0.07631999980246873, 0.07631999980246873, 0.07631999980246873, 0.0857539679804995, 0.0857539679804995, 0.0857539679804995, 0.08867786531330335, 0.08867786531330335, 0.08867786531330335, 0.05357279639610624, 0.05357279639610624, 0.05357279639610624, 0.1740243782274169, 0.1740243782274169, 0.1740243782274169, 0.5122223085843522, 0.5122223085843522, 0.5122223085843522, 0.48984925015777303, 0.48984925015777303, 0.48984925015777303, 0.495182961419524, 0.495182961419524, 0.495182961419524, 0.09212446168710353, 0.09212446168710353, 0.09212446168710353, 0.15304243392589945, 0.15304243392589945, 0.15304243392589945, 0.10681302575614138, 0.10681302575614138, 0.10681302575614138, 0.23368438508049183, 0.23368438508049183, 0.23368438508049183, 0.21085535207492467, 0.21085535207492467, 0.21085535207492467, 0.23362166320664568, 0.23362166320664568, 0.23362166320664568, 0.3561996599080657, 0.3561996599080657, 0.3561996599080657, 0.33313291690795355, 0.33313291690795355, 0.33313291690795355, 0.20715604168239787, 0.20715604168239787, 0.20715604168239787, 0.1975698042091808, 0.1975698042091808, 0.1975698042091808, 0.28187993493062935, 0.28187993493062935, 0.28187993493062935, 0.20150438904240742, 0.20150438904240742, 0.20150438904240742, 0.2069539869914554, 0.2069539869914554, 0.2069539869914554, 0.19492382128964914, 0.19492382128964914, 0.19492382128964914, 0.2566503026006651, 0.2566503026006651, 0.2566503026006651, 0.20881433542058225, 0.20881433542058225, 0.20881433542058225, 0.18432796886569247, 0.18432796886569247, 0.18432796886569247, 0.2469015106390997, 0.2469015106390997, 0.2469015106390997, 0.912332614282314, 0.912332614282314, 0.912332614282314, 0.14646865968285416, 0.14646865968285416, 0.14646865968285416, 0.9064986514024176, 0.9064986514024176, 0.9064986514024176, 0.4664474060339314, 0.4664474060339314, 0.4664474060339314, 0.2117406044797684, 0.2117406044797684, 0.2117406044797684, 0.5091732264083622, 0.5091732264083622, 0.5091732264083622, 0.16838510604185852, 0.16838510604185852, 0.16838510604185852, 0.19349610705769582, 0.19349610705769582, 0.19349610705769582, 0.17930401142551367, 0.17930401142551367, 0.17930401142551367, 0.09519866918805397, 0.09519866918805397, 0.09519866918805397, 0.08138067728280007, 0.08138067728280007, 0.08138067728280007, 0.10682304670434273, 0.10682304670434273, 0.10682304670434273]}, "mutation_prompt": null}
{"id": "a84b4a10-b09d-45bc-93cd-e209fd650472", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithQuadraticMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.2\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale ** 2 * ((self.budget - evaluations) / self.budget) ** 2, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithQuadraticMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel quadratic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 31, "fitness": 0.30698970314496027, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithQuadraticMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "39a33976-97ac-403a-b617-8163ffceb7a6", "metadata": {"aucs": [0.8283928673496865, 0.8283928673496865, 0.8283928673496865, 0.7979395604613008, 0.7979395604613008, 0.7979395604613008, 0.807887158980587, 0.807887158980587, 0.807887158980587, 0.10907707537543188, 0.10907707537543188, 0.10907707537543188, 0.3599426906466311, 0.3599426906466311, 0.3599426906466311, 0.06292533309932713, 0.06292533309932713, 0.06292533309932713, 0.17041068092897826, 0.17041068092897826, 0.17041068092897826, 0.13214910307563388, 0.13214910307563388, 0.13214910307563388, 0.14932183576933256, 0.14932183576933256, 0.14932183576933256, 0.1313715991268184, 0.1313715991268184, 0.1313715991268184, 0.13550972620882917, 0.13550972620882917, 0.13550972620882917, 0.0772216523485928, 0.0772216523485928, 0.0772216523485928, 0.9463550467612611, 0.9463550467612611, 0.9463550467612611, 0.9569991494856651, 0.9569991494856651, 0.9569991494856651, 0.9559168815137399, 0.9559168815137399, 0.9559168815137399, 0.5864308559732289, 0.5864308559732289, 0.5864308559732289, 0.5367218287770055, 0.5367218287770055, 0.5367218287770055, 0.5231350441408809, 0.5231350441408809, 0.5231350441408809, 0.8198968767218678, 0.8198968767218678, 0.8198968767218678, 0.26763214854129114, 0.26763214854129114, 0.26763214854129114, 0.2127998237725678, 0.2127998237725678, 0.2127998237725678, 0.17280157018480347, 0.17280157018480347, 0.17280157018480347, 0.1725866905605471, 0.1725866905605471, 0.1725866905605471, 0.18138561857570767, 0.18138561857570767, 0.18138561857570767, 0.11932210079396066, 0.11932210079396066, 0.11932210079396066, 0.1430119596411229, 0.1430119596411229, 0.1430119596411229, 0.12415455486053184, 0.12415455486053184, 0.12415455486053184, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00016428676310897838, 0.00016428676310897838, 0.00016428676310897838, 0.08368745628560714, 0.08368745628560714, 0.08368745628560714, 0.09282850074236981, 0.09282850074236981, 0.09282850074236981, 0.08863255613750665, 0.08863255613750665, 0.08863255613750665, 0.12186667954728769, 0.12186667954728769, 0.12186667954728769, 0.09945454365222428, 0.09945454365222428, 0.09945454365222428, 0.14460510237225133, 0.14460510237225133, 0.14460510237225133, 0.08543537710145432, 0.08543537710145432, 0.08543537710145432, 0.0716507205843564, 0.0716507205843564, 0.0716507205843564, 0.10603297339316797, 0.10603297339316797, 0.10603297339316797, 0.053921109409713286, 0.053921109409713286, 0.053921109409713286, 0.553242738203497, 0.553242738203497, 0.553242738203497, 0.5050350008030713, 0.5050350008030713, 0.5050350008030713, 0.49373623298531466, 0.49373623298531466, 0.49373623298531466, 0.14976098171740448, 0.14976098171740448, 0.14976098171740448, 0.17244676931635572, 0.17244676931635572, 0.17244676931635572, 0.1230178175101615, 0.1230178175101615, 0.1230178175101615, 0.2563431730061918, 0.2563431730061918, 0.2563431730061918, 0.23230986468797588, 0.23230986468797588, 0.23230986468797588, 0.2885606018140532, 0.2885606018140532, 0.2885606018140532, 0.48074263433933506, 0.48074263433933506, 0.48074263433933506, 0.5258655763413074, 0.5258655763413074, 0.5258655763413074, 0.28381389097740484, 0.28381389097740484, 0.28381389097740484, 0.23690840173267202, 0.23690840173267202, 0.23690840173267202, 0.3415222941683925, 0.3415222941683925, 0.3415222941683925, 0.27033171886226115, 0.27033171886226115, 0.27033171886226115, 0.2384578933767887, 0.2384578933767887, 0.2384578933767887, 0.23979029711078736, 0.23979029711078736, 0.23979029711078736, 0.23879153753037163, 0.23879153753037163, 0.23879153753037163, 0.22372556872115312, 0.22372556872115312, 0.22372556872115312, 0.24073944383254586, 0.24073944383254586, 0.24073944383254586, 0.21678581664696672, 0.21678581664696672, 0.21678581664696672, 0.8707016583019804, 0.8707016583019804, 0.8707016583019804, 0.15802062162640518, 0.15802062162640518, 0.15802062162640518, 0.8561390156202678, 0.8561390156202678, 0.8561390156202678, 0.8216185415810312, 0.8216185415810312, 0.8216185415810312, 0.2101736117182621, 0.2101736117182621, 0.2101736117182621, 0.5511443743342113, 0.5511443743342113, 0.5511443743342113, 0.18853358497419526, 0.18853358497419526, 0.18853358497419526, 0.20323793519305278, 0.20323793519305278, 0.20323793519305278, 0.18927206610950476, 0.18927206610950476, 0.18927206610950476, 0.10028462234683466, 0.10028462234683466, 0.10028462234683466, 0.0991093509100125, 0.0991093509100125, 0.0991093509100125, 0.11341625037298997, 0.11341625037298997, 0.11341625037298997]}, "mutation_prompt": null}
{"id": "5c2a238f-6285-41fd-9325-6a71bfa5c214", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithQuadraticMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.2\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale ** 2 * ((self.budget - evaluations) / self.budget) ** 2, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithQuadraticMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel quadratic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 32, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "a84b4a10-b09d-45bc-93cd-e209fd650472", "metadata": {"aucs": [0.8283928673496865, 0.8283928673496865, 0.8283928673496865, 0.7979395604613008, 0.7979395604613008, 0.7979395604613008, 0.807887158980587, 0.807887158980587, 0.807887158980587, 0.10907707537543188, 0.10907707537543188, 0.10907707537543188, 0.3599426906466311, 0.3599426906466311, 0.3599426906466311, 0.06292533309932713, 0.06292533309932713, 0.06292533309932713, 0.17041068092897826, 0.17041068092897826, 0.17041068092897826, 0.13214910307563388, 0.13214910307563388, 0.13214910307563388, 0.14932183576933256, 0.14932183576933256, 0.14932183576933256, 0.1313715991268184, 0.1313715991268184, 0.1313715991268184, 0.13550972620882917, 0.13550972620882917, 0.13550972620882917, 0.0772216523485928, 0.0772216523485928, 0.0772216523485928, 0.9463550467612611, 0.9463550467612611, 0.9463550467612611, 0.9569991494856651, 0.9569991494856651, 0.9569991494856651, 0.9559168815137399, 0.9559168815137399, 0.9559168815137399, 0.5864308559732289, 0.5864308559732289, 0.5864308559732289, 0.5367218287770055, 0.5367218287770055, 0.5367218287770055, 0.5231350441408809, 0.5231350441408809, 0.5231350441408809, 0.8198968767218678, 0.8198968767218678, 0.8198968767218678, 0.26763214854129114, 0.26763214854129114, 0.26763214854129114, 0.2127998237725678, 0.2127998237725678, 0.2127998237725678, 0.17280157018480347, 0.17280157018480347, 0.17280157018480347, 0.1725866905605471, 0.1725866905605471, 0.1725866905605471, 0.18138561857570767, 0.18138561857570767, 0.18138561857570767, 0.11932210079396066, 0.11932210079396066, 0.11932210079396066, 0.1430119596411229, 0.1430119596411229, 0.1430119596411229, 0.12415455486053184, 0.12415455486053184, 0.12415455486053184, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00016428676310897838, 0.00016428676310897838, 0.00016428676310897838, 0.08368745628560714, 0.08368745628560714, 0.08368745628560714, 0.09282850074236981, 0.09282850074236981, 0.09282850074236981, 0.08863255613750665, 0.08863255613750665, 0.08863255613750665, 0.12186667954728769, 0.12186667954728769, 0.12186667954728769, 0.09945454365222428, 0.09945454365222428, 0.09945454365222428, 0.14460510237225133, 0.14460510237225133, 0.14460510237225133, 0.08543537710145432, 0.08543537710145432, 0.08543537710145432, 0.0716507205843564, 0.0716507205843564, 0.0716507205843564, 0.10603297339316797, 0.10603297339316797, 0.10603297339316797, 0.053921109409713286, 0.053921109409713286, 0.053921109409713286, 0.553242738203497, 0.553242738203497, 0.553242738203497, 0.5050350008030713, 0.5050350008030713, 0.5050350008030713, 0.49373623298531466, 0.49373623298531466, 0.49373623298531466, 0.14976098171740448, 0.14976098171740448, 0.14976098171740448, 0.17244676931635572, 0.17244676931635572, 0.17244676931635572, 0.1230178175101615, 0.1230178175101615, 0.1230178175101615, 0.2563431730061918, 0.2563431730061918, 0.2563431730061918, 0.23230986468797588, 0.23230986468797588, 0.23230986468797588, 0.2885606018140532, 0.2885606018140532, 0.2885606018140532, 0.48074263433933506, 0.48074263433933506, 0.48074263433933506, 0.5258655763413074, 0.5258655763413074, 0.5258655763413074, 0.28381389097740484, 0.28381389097740484, 0.28381389097740484, 0.23690840173267202, 0.23690840173267202, 0.23690840173267202, 0.3415222941683925, 0.3415222941683925, 0.3415222941683925, 0.27033171886226115, 0.27033171886226115, 0.27033171886226115, 0.2384578933767887, 0.2384578933767887, 0.2384578933767887, 0.23979029711078736, 0.23979029711078736, 0.23979029711078736, 0.23879153753037163, 0.23879153753037163, 0.23879153753037163, 0.22372556872115312, 0.22372556872115312, 0.22372556872115312, 0.24073944383254586, 0.24073944383254586, 0.24073944383254586, 0.21678581664696672, 0.21678581664696672, 0.21678581664696672, 0.8707016583019804, 0.8707016583019804, 0.8707016583019804, 0.15802062162640518, 0.15802062162640518, 0.15802062162640518, 0.8561390156202678, 0.8561390156202678, 0.8561390156202678, 0.8216185415810312, 0.8216185415810312, 0.8216185415810312, 0.2101736117182621, 0.2101736117182621, 0.2101736117182621, 0.5511443743342113, 0.5511443743342113, 0.5511443743342113, 0.18853358497419526, 0.18853358497419526, 0.18853358497419526, 0.20323793519305278, 0.20323793519305278, 0.20323793519305278, 0.18927206610950476, 0.18927206610950476, 0.18927206610950476, 0.10028462234683466, 0.10028462234683466, 0.10028462234683466, 0.0991093509100125, 0.0991093509100125, 0.0991093509100125, 0.11341625037298997, 0.11341625037298997, 0.11341625037298997]}, "mutation_prompt": null}
{"id": "8dae20f4-9dfc-4006-bc13-3e863b232d0e", "solution": "import numpy as np\n\nclass ConvergenceAcceleratedSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.729  # Modified to a more stable value\n        self.cognitive_weight = 1.494\n        self.social_weight = 1.494\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 5.0  # Slightly increased velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99  # Increased decay for faster convergence\n        self.elitism_ratio = 0.1  # Increased elitism ratio\n        self.mutation_scale = 0.3  # Increased mutation scale\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "ConvergenceAcceleratedSwarmOptimizer", "description": "A convergence-accelerated swarm optimizer using adaptive velocity adjustment and Gaussian mutation for enhanced search efficiency.", "configspace": "", "generation": 33, "fitness": 0.2796276046195243, "feedback": "The algorithm ConvergenceAcceleratedSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.24.", "error": "", "parent_id": "a84b4a10-b09d-45bc-93cd-e209fd650472", "metadata": {"aucs": [0.6645746322459185, 0.6645746322459185, 0.6645746322459185, 0.6433325393082077, 0.6433325393082077, 0.6433325393082077, 0.6717326291905906, 0.6717326291905906, 0.6717326291905906, 0.16352348041921527, 0.16352348041921527, 0.16352348041921527, 0.09994255646594552, 0.09994255646594552, 0.09994255646594552, 0.20154714934930407, 0.20154714934930407, 0.20154714934930407, 0.14371735589596324, 0.14371735589596324, 0.14371735589596324, 0.12264490877799727, 0.12264490877799727, 0.12264490877799727, 0.15370031345713564, 0.15370031345713564, 0.15370031345713564, 0.14099165332064623, 0.14099165332064623, 0.14099165332064623, 0.10842457361854396, 0.10842457361854396, 0.10842457361854396, 0.13421835596811305, 0.13421835596811305, 0.13421835596811305, 0.9559144316099955, 0.9559144316099955, 0.9559144316099955, 0.9603962440007475, 0.9603962440007475, 0.9603962440007475, 0.9657045999605065, 0.9657045999605065, 0.9657045999605065, 0.4222148876965127, 0.4222148876965127, 0.4222148876965127, 0.40970997092809236, 0.40970997092809236, 0.40970997092809236, 0.47882160523248796, 0.47882160523248796, 0.47882160523248796, 0.3410238678779729, 0.3410238678779729, 0.3410238678779729, 0.2642565935304987, 0.2642565935304987, 0.2642565935304987, 0.31158015832134356, 0.31158015832134356, 0.31158015832134356, 0.09518039638725873, 0.09518039638725873, 0.09518039638725873, 0.17873151795022857, 0.17873151795022857, 0.17873151795022857, 0.15877985350014712, 0.15877985350014712, 0.15877985350014712, 0.19548047532320512, 0.19548047532320512, 0.19548047532320512, 0.11823159047019194, 0.11823159047019194, 0.11823159047019194, 0.20152965890185748, 0.20152965890185748, 0.20152965890185748, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012407734783917101, 0.012407734783917101, 0.012407734783917101, 0.062402005186183995, 0.062402005186183995, 0.062402005186183995, 0.06679642212530801, 0.06679642212530801, 0.06679642212530801, 0.10947764253707826, 0.10947764253707826, 0.10947764253707826, 0.031386838978338716, 0.031386838978338716, 0.031386838978338716, 0.05514693307368057, 0.05514693307368057, 0.05514693307368057, 0.06791358615104037, 0.06791358615104037, 0.06791358615104037, 0.14359041206532042, 0.14359041206532042, 0.14359041206532042, 0.17706933666848312, 0.17706933666848312, 0.17706933666848312, 0.12894570220675483, 0.12894570220675483, 0.12894570220675483, 0.4573583411831248, 0.4573583411831248, 0.4573583411831248, 0.4738059000323642, 0.4738059000323642, 0.4738059000323642, 0.47918367991445876, 0.47918367991445876, 0.47918367991445876, 0.08425596986958628, 0.08425596986958628, 0.08425596986958628, 0.1416807413349951, 0.1416807413349951, 0.1416807413349951, 0.12680330832264264, 0.12680330832264264, 0.12680330832264264, 0.32391773606839525, 0.32391773606839525, 0.32391773606839525, 0.2653205256491221, 0.2653205256491221, 0.2653205256491221, 0.2531759727189353, 0.2531759727189353, 0.2531759727189353, 0.3501749084305006, 0.3501749084305006, 0.3501749084305006, 0.35631405774563263, 0.35631405774563263, 0.35631405774563263, 0.37048214186801953, 0.37048214186801953, 0.37048214186801953, 0.23598591885514342, 0.23598591885514342, 0.23598591885514342, 0.2938616430097214, 0.2938616430097214, 0.2938616430097214, 0.18330617350683742, 0.18330617350683742, 0.18330617350683742, 0.22484594663260282, 0.22484594663260282, 0.22484594663260282, 0.23141393337104188, 0.23141393337104188, 0.23141393337104188, 0.22184075790452384, 0.22184075790452384, 0.22184075790452384, 0.19136130975788435, 0.19136130975788435, 0.19136130975788435, 0.2061043834597004, 0.2061043834597004, 0.2061043834597004, 0.23497029708952866, 0.23497029708952866, 0.23497029708952866, 0.7991245509491323, 0.7991245509491323, 0.7991245509491323, 0.15683624867669566, 0.15683624867669566, 0.15683624867669566, 0.8118889177924195, 0.8118889177924195, 0.8118889177924195, 0.7338144089173049, 0.7338144089173049, 0.7338144089173049, 0.20669988690496188, 0.20669988690496188, 0.20669988690496188, 0.6177943878619667, 0.6177943878619667, 0.6177943878619667, 0.2028055467561659, 0.2028055467561659, 0.2028055467561659, 0.1959425342603044, 0.1959425342603044, 0.1959425342603044, 0.209861202724264, 0.209861202724264, 0.209861202724264, 0.12673470954804322, 0.12673470954804322, 0.12673470954804322, 0.09158157036810899, 0.09158157036810899, 0.09158157036810899, 0.11269730763688968, 0.11269730763688968, 0.11269730763688968]}, "mutation_prompt": null}
{"id": "c96ec20d-2439-4bdb-969a-c2e5697b1a99", "solution": "import numpy as np\n\nclass HybridAdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99\n        self.elitism_ratio = 0.1\n        self.mutation_scale = 0.3\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    chaotic_factor = np.sin(np.pi * evaluations / self.budget)\n                    mutation_vector = np.random.normal(0, self.mutation_scale * chaotic_factor, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "HybridAdaptiveVelocitySwarmOptimizer", "description": "A hybrid adaptive velocity particle swarm optimizer with chaotic mutation and elite preservation for enhanced exploration and faster convergence.", "configspace": "", "generation": 34, "fitness": 0.28825062576922017, "feedback": "The algorithm HybridAdaptiveVelocitySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "a84b4a10-b09d-45bc-93cd-e209fd650472", "metadata": {"aucs": [0.7342527771357135, 0.7342527771357135, 0.7342527771357135, 0.7159381748021386, 0.7159381748021386, 0.7159381748021386, 0.6312162380486741, 0.6312162380486741, 0.6312162380486741, 0.17703337983978762, 0.17703337983978762, 0.17703337983978762, 0.2743863374053138, 0.2743863374053138, 0.2743863374053138, 0.248444672218066, 0.248444672218066, 0.248444672218066, 0.16753445173793624, 0.16753445173793624, 0.16753445173793624, 0.12832537332402683, 0.12832537332402683, 0.12832537332402683, 0.15275653336901684, 0.15275653336901684, 0.15275653336901684, 0.10357068640679767, 0.10357068640679767, 0.10357068640679767, 0.11598496277549508, 0.11598496277549508, 0.11598496277549508, 0.14203050856601407, 0.14203050856601407, 0.14203050856601407, 0.9433753375851968, 0.9433753375851968, 0.9433753375851968, 0.949731547596327, 0.949731547596327, 0.949731547596327, 0.9581754282421101, 0.9581754282421101, 0.9581754282421101, 0.4696809665472087, 0.4696809665472087, 0.4696809665472087, 0.4610971071430705, 0.4610971071430705, 0.4610971071430705, 0.5118473253797642, 0.5118473253797642, 0.5118473253797642, 0.21795668466762186, 0.21795668466762186, 0.21795668466762186, 0.7209147101682554, 0.7209147101682554, 0.7209147101682554, 0.42312360358959533, 0.42312360358959533, 0.42312360358959533, 0.16042780869423856, 0.16042780869423856, 0.16042780869423856, 0.20636959526175858, 0.20636959526175858, 0.20636959526175858, 0.17662661747748842, 0.17662661747748842, 0.17662661747748842, 0.12342685174133583, 0.12342685174133583, 0.12342685174133583, 0.17417767773139525, 0.17417767773139525, 0.17417767773139525, 0.18926425066709152, 0.18926425066709152, 0.18926425066709152, 0.07468746499228696, 0.07468746499228696, 0.07468746499228696, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04518436249669211, 0.04518436249669211, 0.04518436249669211, 0.08066800619340198, 0.08066800619340198, 0.08066800619340198, 0.03572906841337531, 0.03572906841337531, 0.03572906841337531, 0.14245391136610375, 0.14245391136610375, 0.14245391136610375, 0.027167140256790456, 0.027167140256790456, 0.027167140256790456, 0.08983624345342944, 0.08983624345342944, 0.08983624345342944, 0.07713155456109833, 0.07713155456109833, 0.07713155456109833, 0.13696917868309988, 0.13696917868309988, 0.13696917868309988, 0.154909988271817, 0.154909988271817, 0.154909988271817, 0.21581019108722255, 0.21581019108722255, 0.21581019108722255, 0.5034752594190629, 0.5034752594190629, 0.5034752594190629, 0.5208574592615465, 0.5208574592615465, 0.5208574592615465, 0.496309978094169, 0.496309978094169, 0.496309978094169, 0.13305498827666307, 0.13305498827666307, 0.13305498827666307, 0.13151030809876207, 0.13151030809876207, 0.13151030809876207, 0.09972718071832709, 0.09972718071832709, 0.09972718071832709, 0.2803277321288167, 0.2803277321288167, 0.2803277321288167, 0.3028190910346418, 0.3028190910346418, 0.3028190910346418, 0.25355894741883644, 0.25355894741883644, 0.25355894741883644, 0.32617789073788706, 0.32617789073788706, 0.32617789073788706, 0.3505554722579841, 0.3505554722579841, 0.3505554722579841, 0.4269457612210512, 0.4269457612210512, 0.4269457612210512, 0.30772438212809317, 0.30772438212809317, 0.30772438212809317, 0.27375728155343215, 0.27375728155343215, 0.27375728155343215, 0.20986435472776233, 0.20986435472776233, 0.20986435472776233, 0.21866079682806783, 0.21866079682806783, 0.21866079682806783, 0.22765717731806268, 0.22765717731806268, 0.22765717731806268, 0.1983818242776414, 0.1983818242776414, 0.1983818242776414, 0.1727774388794946, 0.1727774388794946, 0.1727774388794946, 0.19453263122847242, 0.19453263122847242, 0.19453263122847242, 0.21072725829003214, 0.21072725829003214, 0.21072725829003214, 0.8273335871326484, 0.8273335871326484, 0.8273335871326484, 0.1575062640077045, 0.1575062640077045, 0.1575062640077045, 0.8088346997269557, 0.8088346997269557, 0.8088346997269557, 0.5681382324644082, 0.5681382324644082, 0.5681382324644082, 0.2093229831111315, 0.2093229831111315, 0.2093229831111315, 0.12742943666743545, 0.12742943666743545, 0.12742943666743545, 0.19884109961057517, 0.19884109961057517, 0.19884109961057517, 0.1822100236357127, 0.1822100236357127, 0.1822100236357127, 0.20058769320385095, 0.20058769320385095, 0.20058769320385095, 0.08669707337989752, 0.08669707337989752, 0.08669707337989752, 0.08355545118307894, 0.08355545118307894, 0.08355545118307894, 0.10586857946488581, 0.10586857946488581, 0.10586857946488581]}, "mutation_prompt": null}
{"id": "5750a18c-8351-4c43-ba46-884d43ed3182", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 35, "fitness": 0.30976930265760383, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.27.", "error": "", "parent_id": "a84b4a10-b09d-45bc-93cd-e209fd650472", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "9046fd89-5871-43ec-93c7-c35ed379bbc8", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithGaussianMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithGaussianMutation", "description": "An adaptive particle swarm optimizer with dynamic velocity scaling, elitism, and Gaussian mutation for robust exploration and fast convergence.", "configspace": "", "generation": 36, "fitness": 0.30105276937902503, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithGaussianMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.8134119347193128, 0.8134119347193128, 0.8134119347193128, 0.7674716257221654, 0.7674716257221654, 0.7674716257221654, 0.7618987519704391, 0.7618987519704391, 0.7618987519704391, 0.10947775296823548, 0.10947775296823548, 0.10947775296823548, 0.3399397833306692, 0.3399397833306692, 0.3399397833306692, 0.09127686064548401, 0.09127686064548401, 0.09127686064548401, 0.1393353258074308, 0.1393353258074308, 0.1393353258074308, 0.14883803047054756, 0.14883803047054756, 0.14883803047054756, 0.1288451998424427, 0.1288451998424427, 0.1288451998424427, 0.13045690053489234, 0.13045690053489234, 0.13045690053489234, 0.148573129789481, 0.148573129789481, 0.148573129789481, 0.1316410947964809, 0.1316410947964809, 0.1316410947964809, 0.9449660136419548, 0.9449660136419548, 0.9449660136419548, 0.9570411788711023, 0.9570411788711023, 0.9570411788711023, 0.9555894821483185, 0.9555894821483185, 0.9555894821483185, 0.45258586912963006, 0.45258586912963006, 0.45258586912963006, 0.5351889650343724, 0.5351889650343724, 0.5351889650343724, 0.448958264896248, 0.448958264896248, 0.448958264896248, 0.22191269863565644, 0.22191269863565644, 0.22191269863565644, 0.2645575087897021, 0.2645575087897021, 0.2645575087897021, 0.3254944828187437, 0.3254944828187437, 0.3254944828187437, 0.18538185983988342, 0.18538185983988342, 0.18538185983988342, 0.16718184729434415, 0.16718184729434415, 0.16718184729434415, 0.1599542892577006, 0.1599542892577006, 0.1599542892577006, 0.21071708860563065, 0.21071708860563065, 0.21071708860563065, 0.14358433435736206, 0.14358433435736206, 0.14358433435736206, 0.1595022531665401, 0.1595022531665401, 0.1595022531665401, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0022193319796457445, 0.0022193319796457445, 0.0022193319796457445, 0.05450739954957062, 0.05450739954957062, 0.05450739954957062, 0.05807771157265129, 0.05807771157265129, 0.05807771157265129, 0.04036597237518669, 0.04036597237518669, 0.04036597237518669, 0.11756253056934551, 0.11756253056934551, 0.11756253056934551, 0.10751003953482563, 0.10751003953482563, 0.10751003953482563, 0.2904771721922663, 0.2904771721922663, 0.2904771721922663, 0.08151583005339058, 0.08151583005339058, 0.08151583005339058, 0.09657248130865992, 0.09657248130865992, 0.09657248130865992, 0.13072893412377817, 0.13072893412377817, 0.13072893412377817, 0.05432270111977744, 0.05432270111977744, 0.05432270111977744, 0.4906627073669295, 0.4906627073669295, 0.4906627073669295, 0.51034309673751, 0.51034309673751, 0.51034309673751, 0.49213021981495664, 0.49213021981495664, 0.49213021981495664, 0.13613473795446085, 0.13613473795446085, 0.13613473795446085, 0.10933544241162796, 0.10933544241162796, 0.10933544241162796, 0.13616192795978332, 0.13616192795978332, 0.13616192795978332, 0.28993147922052476, 0.28993147922052476, 0.28993147922052476, 0.30596066257152155, 0.30596066257152155, 0.30596066257152155, 0.4085616835100957, 0.4085616835100957, 0.4085616835100957, 0.3817914724837774, 0.3817914724837774, 0.3817914724837774, 0.3333133549065337, 0.3333133549065337, 0.3333133549065337, 0.32746778858877945, 0.32746778858877945, 0.32746778858877945, 0.2152969570349923, 0.2152969570349923, 0.2152969570349923, 0.35752729389776927, 0.35752729389776927, 0.35752729389776927, 0.24676269053906263, 0.24676269053906263, 0.24676269053906263, 0.23362851409080854, 0.23362851409080854, 0.23362851409080854, 0.23336941952589274, 0.23336941952589274, 0.23336941952589274, 0.2081456813993685, 0.2081456813993685, 0.2081456813993685, 0.20789557565546357, 0.20789557565546357, 0.20789557565546357, 0.2411997827640624, 0.2411997827640624, 0.2411997827640624, 0.6216346842917808, 0.6216346842917808, 0.6216346842917808, 0.8667187714870527, 0.8667187714870527, 0.8667187714870527, 0.15801401213602873, 0.15801401213602873, 0.15801401213602873, 0.8329289308382047, 0.8329289308382047, 0.8329289308382047, 0.8483402767112511, 0.8483402767112511, 0.8483402767112511, 0.210824953046716, 0.210824953046716, 0.210824953046716, 0.524806524306259, 0.524806524306259, 0.524806524306259, 0.1939363680622278, 0.1939363680622278, 0.1939363680622278, 0.19344821411468915, 0.19344821411468915, 0.19344821411468915, 0.19884753131631028, 0.19884753131631028, 0.19884753131631028, 0.09447022817986439, 0.09447022817986439, 0.09447022817986439, 0.09058176969591603, 0.09058176969591603, 0.09058176969591603, 0.09788401120571033, 0.09788401120571033, 0.09788401120571033]}, "mutation_prompt": null}
{"id": "22eed965-cb59-495f-989e-8ae537482bd3", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithCosineMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.cos((evaluations / self.budget) * np.pi), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithCosineMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a cosine-based mutation strategy for enhanced exploration and convergence.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {}, "mutation_prompt": null}
{"id": "ad25e559-2e86-46ec-bdff-c4e993ecaf98", "solution": "import numpy as np\n\nclass EnhancedSwarmOptimizerWithExponentialMutationDecay:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n\n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n\n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.exp(-0.1 * (evaluations / self.budget)), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n\n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n\n        return self.global_best_value", "name": "EnhancedSwarmOptimizerWithExponentialMutationDecay", "description": "An enhanced swarm optimizer with adaptive velocity, elitism, and exponential mutation decay for balanced exploration and convergence.", "configspace": "", "generation": 38, "fitness": 0.2992352351625955, "feedback": "The algorithm EnhancedSwarmOptimizerWithExponentialMutationDecay got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.8108380295287588, 0.8108380295287588, 0.8108380295287588, 0.760628583668552, 0.760628583668552, 0.760628583668552, 0.7944228536025814, 0.7944228536025814, 0.7944228536025814, 0.11144724988612709, 0.11144724988612709, 0.11144724988612709, 0.2570616853536478, 0.2570616853536478, 0.2570616853536478, 0.08356310681792423, 0.08356310681792423, 0.08356310681792423, 0.1393748236857404, 0.1393748236857404, 0.1393748236857404, 0.1368672691725431, 0.1368672691725431, 0.1368672691725431, 0.12876357744854527, 0.12876357744854527, 0.12876357744854527, 0.13442537631649643, 0.13442537631649643, 0.13442537631649643, 0.1486782212836515, 0.1486782212836515, 0.1486782212836515, 0.13145796480094885, 0.13145796480094885, 0.13145796480094885, 0.9449660669969758, 0.9449660669969758, 0.9449660669969758, 0.9570410516856599, 0.9570410516856599, 0.9570410516856599, 0.9555895996275541, 0.9555895996275541, 0.9555895996275541, 0.46781072010160807, 0.46781072010160807, 0.46781072010160807, 0.530693634086612, 0.530693634086612, 0.530693634086612, 0.46253616449161583, 0.46253616449161583, 0.46253616449161583, 0.3532651962603057, 0.3532651962603057, 0.3532651962603057, 0.20938732676398564, 0.20938732676398564, 0.20938732676398564, 0.23057158034885694, 0.23057158034885694, 0.23057158034885694, 0.18535302975043533, 0.18535302975043533, 0.18535302975043533, 0.17611389381416698, 0.17611389381416698, 0.17611389381416698, 0.16408251363760973, 0.16408251363760973, 0.16408251363760973, 0.19268612591800172, 0.19268612591800172, 0.19268612591800172, 0.16011916713904306, 0.16011916713904306, 0.16011916713904306, 0.14469824891654426, 0.14469824891654426, 0.14469824891654426, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0028442005478723775, 0.0028442005478723775, 0.0028442005478723775, 0.06290388303872274, 0.06290388303872274, 0.06290388303872274, 0.06022117472310706, 0.06022117472310706, 0.06022117472310706, 0.036694605965849614, 0.036694605965849614, 0.036694605965849614, 0.10138965503773434, 0.10138965503773434, 0.10138965503773434, 0.11183860328573991, 0.11183860328573991, 0.11183860328573991, 0.3264955022120116, 0.3264955022120116, 0.3264955022120116, 0.08311461165408418, 0.08311461165408418, 0.08311461165408418, 0.09567124081573908, 0.09567124081573908, 0.09567124081573908, 0.13432645079089256, 0.13432645079089256, 0.13432645079089256, 0.054373758849163956, 0.054373758849163956, 0.054373758849163956, 0.47444147499870426, 0.47444147499870426, 0.47444147499870426, 0.4861885661099875, 0.4861885661099875, 0.4861885661099875, 0.5136819872723611, 0.5136819872723611, 0.5136819872723611, 0.13638368921596267, 0.13638368921596267, 0.13638368921596267, 0.10933880749099467, 0.10933880749099467, 0.10933880749099467, 0.1362450989514431, 0.1362450989514431, 0.1362450989514431, 0.43933372195266684, 0.43933372195266684, 0.43933372195266684, 0.3303478058941468, 0.3303478058941468, 0.3303478058941468, 0.34786052772933285, 0.34786052772933285, 0.34786052772933285, 0.3017305499507359, 0.3017305499507359, 0.3017305499507359, 0.3457823987464098, 0.3457823987464098, 0.3457823987464098, 0.3111391371355269, 0.3111391371355269, 0.3111391371355269, 0.2104268140220158, 0.2104268140220158, 0.2104268140220158, 0.33544866089989234, 0.33544866089989234, 0.33544866089989234, 0.23405141010027364, 0.23405141010027364, 0.23405141010027364, 0.2465293946990379, 0.2465293946990379, 0.2465293946990379, 0.21111284057542445, 0.21111284057542445, 0.21111284057542445, 0.21467895325144515, 0.21467895325144515, 0.21467895325144515, 0.20783262761003285, 0.20783262761003285, 0.20783262761003285, 0.241189612850631, 0.241189612850631, 0.241189612850631, 0.5751326245029503, 0.5751326245029503, 0.5751326245029503, 0.8691362100713282, 0.8691362100713282, 0.8691362100713282, 0.15803010868709466, 0.15803010868709466, 0.15803010868709466, 0.8377615741092752, 0.8377615741092752, 0.8377615741092752, 0.851988928319626, 0.851988928319626, 0.851988928319626, 0.21082504590622586, 0.21082504590622586, 0.21082504590622586, 0.5061978062028337, 0.5061978062028337, 0.5061978062028337, 0.19310310828368948, 0.19310310828368948, 0.19310310828368948, 0.19483130579499452, 0.19483130579499452, 0.19483130579499452, 0.19476501571660787, 0.19476501571660787, 0.19476501571660787, 0.08908796431706201, 0.08908796431706201, 0.08908796431706201, 0.09078411621874782, 0.09078411621874782, 0.09078411621874782, 0.09713229609400464, 0.09713229609400464, 0.09713229609400464]}, "mutation_prompt": null}
{"id": "5921a38e-dd99-4a36-8f08-3f96a28910f4", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithHyperbolicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale / (1 + (evaluations / self.budget)), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithHyperbolicMutation", "description": "A dynamic particle swarm optimizer using adaptive velocity scaling, elitism, and a novel hyperbolic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 39, "fitness": 0.30650798634736764, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithHyperbolicMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.7969880626199771, 0.7969880626199771, 0.7969880626199771, 0.806574738659379, 0.806574738659379, 0.806574738659379, 0.7875218929122708, 0.7875218929122708, 0.7875218929122708, 0.35162471206489376, 0.35162471206489376, 0.35162471206489376, 0.23574282612431285, 0.23574282612431285, 0.23574282612431285, 0.06376758567235685, 0.06376758567235685, 0.06376758567235685, 0.13919001583569657, 0.13919001583569657, 0.13919001583569657, 0.1336375172094717, 0.1336375172094717, 0.1336375172094717, 0.10454174028319807, 0.10454174028319807, 0.10454174028319807, 0.1241098134025227, 0.1241098134025227, 0.1241098134025227, 0.165124045083187, 0.165124045083187, 0.165124045083187, 0.12777135698269304, 0.12777135698269304, 0.12777135698269304, 0.944966529690612, 0.944966529690612, 0.944966529690612, 0.957039929550473, 0.957039929550473, 0.957039929550473, 0.9555906597668371, 0.9555906597668371, 0.9555906597668371, 0.5011902717571649, 0.5011902717571649, 0.5011902717571649, 0.48582376477646505, 0.48582376477646505, 0.48582376477646505, 0.5089995836490053, 0.5089995836490053, 0.5089995836490053, 0.219658655736802, 0.219658655736802, 0.219658655736802, 0.2097257140399139, 0.2097257140399139, 0.2097257140399139, 0.7709414482379905, 0.7709414482379905, 0.7709414482379905, 0.12008935065563275, 0.12008935065563275, 0.12008935065563275, 0.12399391417072603, 0.12399391417072603, 0.12399391417072603, 0.1689809027968262, 0.1689809027968262, 0.1689809027968262, 0.18533156117809169, 0.18533156117809169, 0.18533156117809169, 0.15521279959223755, 0.15521279959223755, 0.15521279959223755, 0.18909455092324357, 0.18909455092324357, 0.18909455092324357, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013566943396082443, 0.013566943396082443, 0.013566943396082443, 0.09425511652867846, 0.09425511652867846, 0.09425511652867846, 0.034354297589960336, 0.034354297589960336, 0.034354297589960336, 0.09844423229451893, 0.09844423229451893, 0.09844423229451893, 0.11457568994063472, 0.11457568994063472, 0.11457568994063472, 0.32495660849581565, 0.32495660849581565, 0.32495660849581565, 0.08570114166559328, 0.08570114166559328, 0.08570114166559328, 0.08964757781779353, 0.08964757781779353, 0.08964757781779353, 0.15254550462578986, 0.15254550462578986, 0.15254550462578986, 0.05449057720453532, 0.05449057720453532, 0.05449057720453532, 0.5127026560361831, 0.5127026560361831, 0.5127026560361831, 0.5510652567253622, 0.5510652567253622, 0.5510652567253622, 0.5406245389700735, 0.5406245389700735, 0.5406245389700735, 0.13637025956640647, 0.13637025956640647, 0.13637025956640647, 0.13132798819303348, 0.13132798819303348, 0.13132798819303348, 0.13781695961130935, 0.13781695961130935, 0.13781695961130935, 0.2214974217934692, 0.2214974217934692, 0.2214974217934692, 0.3015828146556053, 0.3015828146556053, 0.3015828146556053, 0.279350261844576, 0.279350261844576, 0.279350261844576, 0.39129104620036037, 0.39129104620036037, 0.39129104620036037, 0.45597900383430545, 0.45597900383430545, 0.45597900383430545, 0.4931332688714991, 0.4931332688714991, 0.4931332688714991, 0.21216779848598488, 0.21216779848598488, 0.21216779848598488, 0.25360829373610927, 0.25360829373610927, 0.25360829373610927, 0.2465068230092483, 0.2465068230092483, 0.2465068230092483, 0.2293876603443411, 0.2293876603443411, 0.2293876603443411, 0.20791816168495258, 0.20791816168495258, 0.20791816168495258, 0.22954042300985078, 0.22954042300985078, 0.22954042300985078, 0.2077651617998183, 0.2077651617998183, 0.2077651617998183, 0.23685441653471517, 0.23685441653471517, 0.23685441653471517, 0.5555326523626357, 0.5555326523626357, 0.5555326523626357, 0.8728758105956994, 0.8728758105956994, 0.8728758105956994, 0.15802347431412023, 0.15802347431412023, 0.15802347431412023, 0.8434655851268951, 0.8434655851268951, 0.8434655851268951, 0.6536650760843494, 0.6536650760843494, 0.6536650760843494, 0.21082753058538173, 0.21082753058538173, 0.21082753058538173, 0.5114077115387476, 0.5114077115387476, 0.5114077115387476, 0.20460234149172374, 0.20460234149172374, 0.20460234149172374, 0.1937608039957196, 0.1937608039957196, 0.1937608039957196, 0.18906528989487015, 0.18906528989487015, 0.18906528989487015, 0.09092929535774896, 0.09092929535774896, 0.09092929535774896, 0.09807598053383859, 0.09807598053383859, 0.09807598053383859, 0.11388161729015323, 0.11388161729015323, 0.11388161729015323]}, "mutation_prompt": null}
{"id": "5440359a-23af-4250-b498-aa0bfbe4ba2b", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "9f0f9841-aa46-413d-9b78-7d30462682e8", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "96a838a7-539c-4551-af6f-bd8909a6a69e", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "b5e0858c-2d06-47de-be7a-d721108602ed", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "6efb1a97-98b9-4907-b37c-608f6ea6cf92", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "75737de6-cd3a-4904-bada-ad22949aab3d", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "1f0a6bb7-3ace-434e-aef0-b4ac27564fa8", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerWithRandomRestarts:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n        self.restart_prob = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                    \n                if np.random.rand() < self.restart_prob:\n                    particles[i] = np.random.uniform(self.lb, self.ub, self.dim)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "HybridSwarmOptimizerWithRandomRestarts", "description": "A hybrid particle swarm optimizer combining adaptive velocities, elitism, and dynamic mutation scaling with random restarts for enhanced exploration.", "configspace": "", "generation": 46, "fitness": 0.24821971713760696, "feedback": "The algorithm HybridSwarmOptimizerWithRandomRestarts got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.22.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.5628549452882001, 0.5628549452882001, 0.5628549452882001, 0.5693403504220461, 0.5693403504220461, 0.5693403504220461, 0.4930153108570884, 0.4930153108570884, 0.4930153108570884, 0.004687271230241485, 0.004687271230241485, 0.004687271230241485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05229236290684125, 0.05229236290684125, 0.05229236290684125, 0.1298931747993678, 0.1298931747993678, 0.1298931747993678, 0.12503864434463963, 0.12503864434463963, 0.12503864434463963, 0.08272146434311767, 0.08272146434311767, 0.08272146434311767, 0.1055094341358066, 0.1055094341358066, 0.1055094341358066, 0.10071022134273155, 0.10071022134273155, 0.10071022134273155, 0.11662424393555049, 0.11662424393555049, 0.11662424393555049, 0.9447865432539745, 0.9447865432539745, 0.9447865432539745, 0.9507682128550168, 0.9507682128550168, 0.9507682128550168, 0.9636049099821005, 0.9636049099821005, 0.9636049099821005, 0.3017946320492624, 0.3017946320492624, 0.3017946320492624, 0.2864772124674221, 0.2864772124674221, 0.2864772124674221, 0.2509527048832967, 0.2509527048832967, 0.2509527048832967, 0.20825719325721925, 0.20825719325721925, 0.20825719325721925, 0.24908712114326714, 0.24908712114326714, 0.24908712114326714, 0.5069507940352257, 0.5069507940352257, 0.5069507940352257, 0.14128730303069748, 0.14128730303069748, 0.14128730303069748, 0.15274320736501212, 0.15274320736501212, 0.15274320736501212, 0.11874062317775846, 0.11874062317775846, 0.11874062317775846, 0.12188353665122942, 0.12188353665122942, 0.12188353665122942, 0.17479785424149907, 0.17479785424149907, 0.17479785424149907, 0.19015850552914548, 0.19015850552914548, 0.19015850552914548, 0.08092362377510887, 0.08092362377510887, 0.08092362377510887, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.060761307338777826, 0.060761307338777826, 0.060761307338777826, 0.13169217624461438, 0.13169217624461438, 0.13169217624461438, 0.09286456962681244, 0.09286456962681244, 0.09286456962681244, 0.1514045024346482, 0.1514045024346482, 0.1514045024346482, 0.03378988036185604, 0.03378988036185604, 0.03378988036185604, 0.09267580178865864, 0.09267580178865864, 0.09267580178865864, 0.03965511208673578, 0.03965511208673578, 0.03965511208673578, 0.0887029398653949, 0.0887029398653949, 0.0887029398653949, 0.20323934658123854, 0.20323934658123854, 0.20323934658123854, 0.07748364883408354, 0.07748364883408354, 0.07748364883408354, 0.4779684093255713, 0.4779684093255713, 0.4779684093255713, 0.36279820148763964, 0.36279820148763964, 0.36279820148763964, 0.432409308037473, 0.432409308037473, 0.432409308037473, 0.11034082326245642, 0.11034082326245642, 0.11034082326245642, 0.11021397861867066, 0.11021397861867066, 0.11021397861867066, 0.10380438853973117, 0.10380438853973117, 0.10380438853973117, 0.13280839674733902, 0.13280839674733902, 0.13280839674733902, 0.20469039833785496, 0.20469039833785496, 0.20469039833785496, 0.19188581463900534, 0.19188581463900534, 0.19188581463900534, 0.3085932969621068, 0.3085932969621068, 0.3085932969621068, 0.3547591920714094, 0.3547591920714094, 0.3547591920714094, 0.3425321967832118, 0.3425321967832118, 0.3425321967832118, 0.24280164571397433, 0.24280164571397433, 0.24280164571397433, 0.22323110845928062, 0.22323110845928062, 0.22323110845928062, 0.22211189962900202, 0.22211189962900202, 0.22211189962900202, 0.20812912952015772, 0.20812912952015772, 0.20812912952015772, 0.25888935673988045, 0.25888935673988045, 0.25888935673988045, 0.21967811048067099, 0.21967811048067099, 0.21967811048067099, 0.1998672213751823, 0.1998672213751823, 0.1998672213751823, 0.18763149004856028, 0.18763149004856028, 0.18763149004856028, 0.20434869783883025, 0.20434869783883025, 0.20434869783883025, 0.646322338626778, 0.646322338626778, 0.646322338626778, 0.15895797744766949, 0.15895797744766949, 0.15895797744766949, 0.8114805096502189, 0.8114805096502189, 0.8114805096502189, 0.5904393841617074, 0.5904393841617074, 0.5904393841617074, 0.31940996543424405, 0.31940996543424405, 0.31940996543424405, 0.4659193349735319, 0.4659193349735319, 0.4659193349735319, 0.1757370588514725, 0.1757370588514725, 0.1757370588514725, 0.19328761251003101, 0.19328761251003101, 0.19328761251003101, 0.18062743682604032, 0.18062743682604032, 0.18062743682604032, 0.08716001242926263, 0.08716001242926263, 0.08716001242926263, 0.08438173914459624, 0.08438173914459624, 0.08438173914459624, 0.10023251276845091, 0.10023251276845091, 0.10023251276845091]}, "mutation_prompt": null}
{"id": "907d6167-3328-4ff7-9b63-89c189705c17", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithGaussianMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 5.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.95\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithGaussianMutation", "description": "An adaptive particle swarm optimizer incorporating dynamic parameter tuning, elitism, and Gaussian mutation for enhanced convergence and exploration.", "configspace": "", "generation": 47, "fitness": 0.2618612057300615, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithGaussianMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.23.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.7425783538388971, 0.7425783538388971, 0.7425783538388971, 0.6816261934731218, 0.6816261934731218, 0.6816261934731218, 0.801826969333957, 0.801826969333957, 0.801826969333957, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07245259216384148, 0.07245259216384148, 0.07245259216384148, 0.048532535149140466, 0.048532535149140466, 0.048532535149140466, 0.15196299928882995, 0.15196299928882995, 0.15196299928882995, 0.15377883815651694, 0.15377883815651694, 0.15377883815651694, 0.45067598230779815, 0.45067598230779815, 0.45067598230779815, 0.08211916366118077, 0.08211916366118077, 0.08211916366118077, 0.10638117425804428, 0.10638117425804428, 0.10638117425804428, 0.13670439199911888, 0.13670439199911888, 0.13670439199911888, 0.9577560620173774, 0.9577560620173774, 0.9577560620173774, 0.9581892079984201, 0.9581892079984201, 0.9581892079984201, 0.9598084018415125, 0.9598084018415125, 0.9598084018415125, 0.4444728155577804, 0.4444728155577804, 0.4444728155577804, 0.25746126779773026, 0.25746126779773026, 0.25746126779773026, 0.3174585050686418, 0.3174585050686418, 0.3174585050686418, 0.16824448320059093, 0.16824448320059093, 0.16824448320059093, 0.27590578297058677, 0.27590578297058677, 0.27590578297058677, 0.1757038566104473, 0.1757038566104473, 0.1757038566104473, 0.18247331564802005, 0.18247331564802005, 0.18247331564802005, 0.13061195109056212, 0.13061195109056212, 0.13061195109056212, 0.13081197898838925, 0.13081197898838925, 0.13081197898838925, 0.15336354380422834, 0.15336354380422834, 0.15336354380422834, 0.12696090701927987, 0.12696090701927987, 0.12696090701927987, 0.6274446946406005, 0.6274446946406005, 0.6274446946406005, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0032264714335986655, 0.0032264714335986655, 0.0032264714335986655, 0.2398262296274435, 0.2398262296274435, 0.2398262296274435, 0.09764555963613653, 0.09764555963613653, 0.09764555963613653, 0.09919520332449938, 0.09919520332449938, 0.09919520332449938, 0.055607455622672775, 0.055607455622672775, 0.055607455622672775, 0.04787919980965094, 0.04787919980965094, 0.04787919980965094, 0.07784700307451897, 0.07784700307451897, 0.07784700307451897, 0.06968953821966262, 0.06968953821966262, 0.06968953821966262, 0.14183657262346405, 0.14183657262346405, 0.14183657262346405, 0.03822082510860947, 0.03822082510860947, 0.03822082510860947, 0.05417794744652271, 0.05417794744652271, 0.05417794744652271, 0.4655812067120292, 0.4655812067120292, 0.4655812067120292, 0.4617461991807078, 0.4617461991807078, 0.4617461991807078, 0.5377676258086403, 0.5377676258086403, 0.5377676258086403, 0.13998959529280675, 0.13998959529280675, 0.13998959529280675, 0.10790473822265156, 0.10790473822265156, 0.10790473822265156, 0.09283235770836906, 0.09283235770836906, 0.09283235770836906, 0.2950279188426672, 0.2950279188426672, 0.2950279188426672, 0.1853711862598506, 0.1853711862598506, 0.1853711862598506, 0.16322749334212516, 0.16322749334212516, 0.16322749334212516, 0.3165161868110473, 0.3165161868110473, 0.3165161868110473, 0.25757403400576795, 0.25757403400576795, 0.25757403400576795, 0.3570644970706044, 0.3570644970706044, 0.3570644970706044, 0.2036426344130774, 0.2036426344130774, 0.2036426344130774, 0.3136326229332176, 0.3136326229332176, 0.3136326229332176, 0.22994372156639686, 0.22994372156639686, 0.22994372156639686, 0.3155262356115355, 0.3155262356115355, 0.3155262356115355, 0.22465110676793654, 0.22465110676793654, 0.22465110676793654, 0.21284854338779946, 0.21284854338779946, 0.21284854338779946, 0.20107042561164035, 0.20107042561164035, 0.20107042561164035, 0.22321818617818712, 0.22321818617818712, 0.22321818617818712, 0.20003191104792883, 0.20003191104792883, 0.20003191104792883, 0.8042442104445902, 0.8042442104445902, 0.8042442104445902, 0.15826229245421675, 0.15826229245421675, 0.15826229245421675, 0.10677760047916307, 0.10677760047916307, 0.10677760047916307, 0.5570935094438315, 0.5570935094438315, 0.5570935094438315, 0.20986431366155767, 0.20986431366155767, 0.20986431366155767, 0.4391976436367844, 0.4391976436367844, 0.4391976436367844, 0.18421876530333203, 0.18421876530333203, 0.18421876530333203, 0.1895410607803426, 0.1895410607803426, 0.1895410607803426, 0.18383491734607782, 0.18383491734607782, 0.18383491734607782, 0.08738037478763983, 0.08738037478763983, 0.08738037478763983, 0.08912364042222976, 0.08912364042222976, 0.08912364042222976, 0.1186420832182794, 0.1186420832182794, 0.1186420832182794]}, "mutation_prompt": null}
{"id": "728099d6-8d4d-47e5-b4d1-9d7d64079df0", "solution": "import numpy as np\n\nclass AdaptiveParticleSwarmWithDynamicNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.9\n        self.cognitive_weight = 2.0\n        self.social_weight = 1.3\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.95\n        self.elitism_ratio = 0.02\n        self.mutation_scale = 0.05\n        self.neighborhood_size = 5\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best_idx = neighborhood_indices[np.argmin(personal_best_values[neighborhood_indices])]\n                local_best_position = personal_best_positions[local_best_idx]\n                \n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (local_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveParticleSwarmWithDynamicNeighborhood", "description": "A self-adaptive particle swarm optimizer with heterogeneous inertia, dynamic neighborhood, and adaptive mutation for diverse exploration and robust convergence.", "configspace": "", "generation": 48, "fitness": 0.23262305714182838, "feedback": "The algorithm AdaptiveParticleSwarmWithDynamicNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.21.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.7353712013600775, 0.7353712013600775, 0.7353712013600775, 0.6940120223135424, 0.6940120223135424, 0.6940120223135424, 0.6937941969764391, 0.6937941969764391, 0.6937941969764391, 0.06258565021837803, 0.06258565021837803, 0.06258565021837803, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1357001971074946, 0.1357001971074946, 0.1357001971074946, 0.12739939879030338, 0.12739939879030338, 0.12739939879030338, 0.11329499521047892, 0.11329499521047892, 0.11329499521047892, 0.10272036804979756, 0.10272036804979756, 0.10272036804979756, 0.10026378355850396, 0.10026378355850396, 0.10026378355850396, 0.09533928463116004, 0.09533928463116004, 0.09533928463116004, 0.9152769297057335, 0.9152769297057335, 0.9152769297057335, 0.9229203589582126, 0.9229203589582126, 0.9229203589582126, 0.8997528314178135, 0.8997528314178135, 0.8997528314178135, 0.18072794704215378, 0.18072794704215378, 0.18072794704215378, 0.20137187260380018, 0.20137187260380018, 0.20137187260380018, 0.15161770573862254, 0.15161770573862254, 0.15161770573862254, 0.20451765313666137, 0.20451765313666137, 0.20451765313666137, 0.3626282709683062, 0.3626282709683062, 0.3626282709683062, 0.2137828551541482, 0.2137828551541482, 0.2137828551541482, 0.1347724101862081, 0.1347724101862081, 0.1347724101862081, 0.13899621585056665, 0.13899621585056665, 0.13899621585056665, 0.14036513822126595, 0.14036513822126595, 0.14036513822126595, 0.13035233872809915, 0.13035233872809915, 0.13035233872809915, 0.1356093775515217, 0.1356093775515217, 0.1356093775515217, 0.1309406268059976, 0.1309406268059976, 0.1309406268059976, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04308403238664993, 0.04308403238664993, 0.04308403238664993, 0.0551401676743577, 0.0551401676743577, 0.0551401676743577, 0.11406707644148661, 0.11406707644148661, 0.11406707644148661, 0.07642402161810824, 0.07642402161810824, 0.07642402161810824, 0.12821420649405413, 0.12821420649405413, 0.12821420649405413, 0.09624123076436375, 0.09624123076436375, 0.09624123076436375, 0.08192290075697528, 0.08192290075697528, 0.08192290075697528, 0.10727048287461316, 0.10727048287461316, 0.10727048287461316, 0.1958139429025476, 0.1958139429025476, 0.1958139429025476, 0.10679230505446846, 0.10679230505446846, 0.10679230505446846, 0.08252389260779291, 0.08252389260779291, 0.08252389260779291, 0.5126626333430033, 0.5126626333430033, 0.5126626333430033, 0.5572974501929091, 0.5572974501929091, 0.5572974501929091, 0.5266316199172452, 0.5266316199172452, 0.5266316199172452, 0.10879295075691975, 0.10879295075691975, 0.10879295075691975, 0.11199611505897666, 0.11199611505897666, 0.11199611505897666, 0.10238831044531849, 0.10238831044531849, 0.10238831044531849, 0.15055937283712462, 0.15055937283712462, 0.15055937283712462, 0.14294659654867592, 0.14294659654867592, 0.14294659654867592, 0.12449843448720221, 0.12449843448720221, 0.12449843448720221, 0.331029896058039, 0.331029896058039, 0.331029896058039, 0.3423367468978723, 0.3423367468978723, 0.3423367468978723, 0.2975370670757197, 0.2975370670757197, 0.2975370670757197, 0.2661453851946114, 0.2661453851946114, 0.2661453851946114, 0.28172121927436533, 0.28172121927436533, 0.28172121927436533, 0.23794560880677262, 0.23794560880677262, 0.23794560880677262, 0.23608216391691417, 0.23608216391691417, 0.23608216391691417, 0.23141651593552526, 0.23141651593552526, 0.23141651593552526, 0.23891039831204341, 0.23891039831204341, 0.23891039831204341, 0.17323708974140317, 0.17323708974140317, 0.17323708974140317, 0.16643183463155564, 0.16643183463155564, 0.16643183463155564, 0.18480895465740632, 0.18480895465740632, 0.18480895465740632, 0.22335957880686652, 0.22335957880686652, 0.22335957880686652, 0.2209782628463436, 0.2209782628463436, 0.2209782628463436, 0.5537048802673501, 0.5537048802673501, 0.5537048802673501, 0.39711221519193085, 0.39711221519193085, 0.39711221519193085, 0.2041964484897445, 0.2041964484897445, 0.2041964484897445, 0.21082977858697116, 0.21082977858697116, 0.21082977858697116, 0.17212474005915623, 0.17212474005915623, 0.17212474005915623, 0.18544191342007177, 0.18544191342007177, 0.18544191342007177, 0.1735124529831792, 0.1735124529831792, 0.1735124529831792, 0.09895116454692576, 0.09895116454692576, 0.09895116454692576, 0.09049637243890252, 0.09049637243890252, 0.09049637243890252, 0.08086805262389152, 0.08086805262389152, 0.08086805262389152]}, "mutation_prompt": null}
{"id": "3838b287-d847-4bff-8a70-a18cbda77db1", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "51b9ce69-2c83-4815-932b-b75304bf3ba6", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "beb60fe9-d3a2-47f4-9b95-fad99decfb77", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "6e26c27b-cc4f-487f-8be8-3b469d9ce832", "solution": "import numpy as np\n\nclass RefinedVelocitySwarmOptimizerWithExponentialMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 5.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.exp(-evaluations / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "RefinedVelocitySwarmOptimizerWithExponentialMutation", "description": "A refined particle swarm optimizer with adaptive velocity scaling, elitism, and a novel exponential mutation strategy for enhanced exploration and convergence.", "configspace": "", "generation": 52, "fitness": 0.30096240307985717, "feedback": "The algorithm RefinedVelocitySwarmOptimizerWithExponentialMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.27.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.7907492436048952, 0.7907492436048952, 0.7907492436048952, 0.7776483280903732, 0.7776483280903732, 0.7776483280903732, 0.7882474151752334, 0.7882474151752334, 0.7882474151752334, 0.1729318259256486, 0.1729318259256486, 0.1729318259256486, 0.006672433604308026, 0.006672433604308026, 0.006672433604308026, 0.0907995367861486, 0.0907995367861486, 0.0907995367861486, 0.1700126703374064, 0.1700126703374064, 0.1700126703374064, 0.17155771019066468, 0.17155771019066468, 0.17155771019066468, 0.1483775981417682, 0.1483775981417682, 0.1483775981417682, 0.12861269839154232, 0.12861269839154232, 0.12861269839154232, 0.10806806562675031, 0.10806806562675031, 0.10806806562675031, 0.10114732530207271, 0.10114732530207271, 0.10114732530207271, 0.9570114707564811, 0.9570114707564811, 0.9570114707564811, 0.9583947151065273, 0.9583947151065273, 0.9583947151065273, 0.9604052055950644, 0.9604052055950644, 0.9604052055950644, 0.45116808532060393, 0.45116808532060393, 0.45116808532060393, 0.47097572786426767, 0.47097572786426767, 0.47097572786426767, 0.45579822169804984, 0.45579822169804984, 0.45579822169804984, 0.8293314169086861, 0.8293314169086861, 0.8293314169086861, 0.8121826033721957, 0.8121826033721957, 0.8121826033721957, 0.2145221939854537, 0.2145221939854537, 0.2145221939854537, 0.18697755446919673, 0.18697755446919673, 0.18697755446919673, 0.12691400617088588, 0.12691400617088588, 0.12691400617088588, 0.12624321865881938, 0.12624321865881938, 0.12624321865881938, 0.1558998403855698, 0.1558998403855698, 0.1558998403855698, 0.12309586532474037, 0.12309586532474037, 0.12309586532474037, 0.19511651131011254, 0.19511651131011254, 0.19511651131011254, 0.11986134339837318, 0.11986134339837318, 0.11986134339837318, 0.014458671921311672, 0.014458671921311672, 0.014458671921311672, 0.0676283656156762, 0.0676283656156762, 0.0676283656156762, 0.13520260392160122, 0.13520260392160122, 0.13520260392160122, 0.07159731493412969, 0.07159731493412969, 0.07159731493412969, 0.04426743645440823, 0.04426743645440823, 0.04426743645440823, 0.06101279486237776, 0.06101279486237776, 0.06101279486237776, 0.06785812168725402, 0.06785812168725402, 0.06785812168725402, 0.0672887196779891, 0.0672887196779891, 0.0672887196779891, 0.04110250356733414, 0.04110250356733414, 0.04110250356733414, 0.07585338090369065, 0.07585338090369065, 0.07585338090369065, 0.05445406694471311, 0.05445406694471311, 0.05445406694471311, 0.6196658852132039, 0.6196658852132039, 0.6196658852132039, 0.48868095800680456, 0.48868095800680456, 0.48868095800680456, 0.5427338938880838, 0.5427338938880838, 0.5427338938880838, 0.17379440745843788, 0.17379440745843788, 0.17379440745843788, 0.13249477169867152, 0.13249477169867152, 0.13249477169867152, 0.11688838912308508, 0.11688838912308508, 0.11688838912308508, 0.15692952478514977, 0.15692952478514977, 0.15692952478514977, 0.1995215059197173, 0.1995215059197173, 0.1995215059197173, 0.3604645621591368, 0.3604645621591368, 0.3604645621591368, 0.362989049069556, 0.362989049069556, 0.362989049069556, 0.35992689209135775, 0.35992689209135775, 0.35992689209135775, 0.4035251926966422, 0.4035251926966422, 0.4035251926966422, 0.19395969715053296, 0.19395969715053296, 0.19395969715053296, 0.21608049538373053, 0.21608049538373053, 0.21608049538373053, 0.21233484254306068, 0.21233484254306068, 0.21233484254306068, 0.2231077108282482, 0.2231077108282482, 0.2231077108282482, 0.23996957402590136, 0.23996957402590136, 0.23996957402590136, 0.1938531548264304, 0.1938531548264304, 0.1938531548264304, 0.24265402169367511, 0.24265402169367511, 0.24265402169367511, 0.1904003813063998, 0.1904003813063998, 0.1904003813063998, 0.6275947184832291, 0.6275947184832291, 0.6275947184832291, 0.8650328669518532, 0.8650328669518532, 0.8650328669518532, 0.15730717917772763, 0.15730717917772763, 0.15730717917772763, 0.41108842301341897, 0.41108842301341897, 0.41108842301341897, 0.8478317514849434, 0.8478317514849434, 0.8478317514849434, 0.2097777164766288, 0.2097777164766288, 0.2097777164766288, 0.7340428625662077, 0.7340428625662077, 0.7340428625662077, 0.19310012214700778, 0.19310012214700778, 0.19310012214700778, 0.19675988744654893, 0.19675988744654893, 0.19675988744654893, 0.195943965937033, 0.195943965937033, 0.195943965937033, 0.09123249521022792, 0.09123249521022792, 0.09123249521022792, 0.09861272764102269, 0.09861272764102269, 0.09861272764102269, 0.11154658335371803, 0.11154658335371803, 0.11154658335371803]}, "mutation_prompt": null}
{"id": "253a3a2b-c128-481b-832c-214c05df929f", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "1b6426fc-44cf-4fc2-8927-af8c805646c9", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithEnhancedMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n        self.gaussian_mutation_prob = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.gaussian_mutation_prob:\n                    gaussian_mutation_vector = np.random.normal(0, self.mutation_scale, self.dim)\n                    particles[i] += gaussian_mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithEnhancedMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic and Gaussian mutation strategy for enhanced exploration and convergence.", "configspace": "", "generation": 54, "fitness": 0.2869484131423292, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithEnhancedMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.6709338285722899, 0.6709338285722899, 0.6709338285722899, 0.716452362348261, 0.716452362348261, 0.716452362348261, 0.6681931752307422, 0.6681931752307422, 0.6681931752307422, 0.11627900036222782, 0.11627900036222782, 0.11627900036222782, 0.16867856147626792, 0.16867856147626792, 0.16867856147626792, 0.2906825025142128, 0.2906825025142128, 0.2906825025142128, 0.16984616845152578, 0.16984616845152578, 0.16984616845152578, 0.1223985498476221, 0.1223985498476221, 0.1223985498476221, 0.14922099135813283, 0.14922099135813283, 0.14922099135813283, 0.06845985137000643, 0.06845985137000643, 0.06845985137000643, 0.1467120364173612, 0.1467120364173612, 0.1467120364173612, 0.11743352333162804, 0.11743352333162804, 0.11743352333162804, 0.9408315005110298, 0.9408315005110298, 0.9408315005110298, 0.9554685416219354, 0.9554685416219354, 0.9554685416219354, 0.9556460459071382, 0.9556460459071382, 0.9556460459071382, 0.4630518537085959, 0.4630518537085959, 0.4630518537085959, 0.4407999112504337, 0.4407999112504337, 0.4407999112504337, 0.4480715631776382, 0.4480715631776382, 0.4480715631776382, 0.34771972119420813, 0.34771972119420813, 0.34771972119420813, 0.21134397663727578, 0.21134397663727578, 0.21134397663727578, 0.3557147097640603, 0.3557147097640603, 0.3557147097640603, 0.15530453891271734, 0.15530453891271734, 0.15530453891271734, 0.15451202123010954, 0.15451202123010954, 0.15451202123010954, 0.18437280818772295, 0.18437280818772295, 0.18437280818772295, 0.20069353930142375, 0.20069353930142375, 0.20069353930142375, 0.17729114596174167, 0.17729114596174167, 0.17729114596174167, 0.1741411886569425, 0.1741411886569425, 0.1741411886569425, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05417911940994058, 0.05417911940994058, 0.05417911940994058, 0.05862775911862206, 0.05862775911862206, 0.05862775911862206, 0.04788310297417486, 0.04788310297417486, 0.04788310297417486, 0.1844954614397365, 0.1844954614397365, 0.1844954614397365, 0.039423304481286725, 0.039423304481286725, 0.039423304481286725, 0.08546815153526355, 0.08546815153526355, 0.08546815153526355, 0.13209078371358007, 0.13209078371358007, 0.13209078371358007, 0.22266637518879417, 0.22266637518879417, 0.22266637518879417, 0.12187446785726219, 0.12187446785726219, 0.12187446785726219, 0.08073565594249099, 0.08073565594249099, 0.08073565594249099, 0.5725334804097618, 0.5725334804097618, 0.5725334804097618, 0.5514789427916678, 0.5514789427916678, 0.5514789427916678, 0.5180897691542559, 0.5180897691542559, 0.5180897691542559, 0.13403205992537082, 0.13403205992537082, 0.13403205992537082, 0.09370221533411371, 0.09370221533411371, 0.09370221533411371, 0.14529241643804613, 0.14529241643804613, 0.14529241643804613, 0.2952577711579446, 0.2952577711579446, 0.2952577711579446, 0.16276660922126773, 0.16276660922126773, 0.16276660922126773, 0.31724003295544634, 0.31724003295544634, 0.31724003295544634, 0.3293005550918824, 0.3293005550918824, 0.3293005550918824, 0.4016189791478034, 0.4016189791478034, 0.4016189791478034, 0.3305216994209982, 0.3305216994209982, 0.3305216994209982, 0.25013930316983934, 0.25013930316983934, 0.25013930316983934, 0.24305708865515052, 0.24305708865515052, 0.24305708865515052, 0.2489126719475273, 0.2489126719475273, 0.2489126719475273, 0.23203048219881262, 0.23203048219881262, 0.23203048219881262, 0.23011056709690925, 0.23011056709690925, 0.23011056709690925, 0.22617377534416305, 0.22617377534416305, 0.22617377534416305, 0.20339100729499415, 0.20339100729499415, 0.20339100729499415, 0.17648915056038061, 0.17648915056038061, 0.17648915056038061, 0.19527534582396366, 0.19527534582396366, 0.19527534582396366, 0.8891826017709167, 0.8891826017709167, 0.8891826017709167, 0.15694221210016257, 0.15694221210016257, 0.15694221210016257, 0.844558664513849, 0.844558664513849, 0.844558664513849, 0.7208172849398105, 0.7208172849398105, 0.7208172849398105, 0.1674643297011631, 0.1674643297011631, 0.1674643297011631, 0.5731459220251607, 0.5731459220251607, 0.5731459220251607, 0.2061041865908394, 0.2061041865908394, 0.2061041865908394, 0.1984610437225931, 0.1984610437225931, 0.1984610437225931, 0.1775139031024735, 0.1775139031024735, 0.1775139031024735, 0.11129827813206228, 0.11129827813206228, 0.11129827813206228, 0.08402050639761705, 0.08402050639761705, 0.08402050639761705, 0.07546509114635269, 0.07546509114635269, 0.07546509114635269]}, "mutation_prompt": null}
{"id": "cf7453f5-b2d0-412f-8f80-fd414b4c8b2a", "solution": "import numpy as np\n\nclass ImprovedSwarmOptimizerWithDynamicMutationProbability:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                dynamic_mutation_prob = self.mutation_prob * (1 - evaluations / self.budget)\n                if np.random.rand() < dynamic_mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "ImprovedSwarmOptimizerWithDynamicMutationProbability", "description": "An improved particle swarm optimizer with adaptive inertia weight decay, elitism, logarithmic mutation, and dynamic mutation probability for enhanced exploration and convergence.", "configspace": "", "generation": 55, "fitness": 0.3031024950977602, "feedback": "The algorithm ImprovedSwarmOptimizerWithDynamicMutationProbability got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.8112342720880541, 0.8112342720880541, 0.8112342720880541, 0.7914833389654178, 0.7914833389654178, 0.7914833389654178, 0.8158477755820952, 0.8158477755820952, 0.8158477755820952, 0.10051657456433094, 0.10051657456433094, 0.10051657456433094, 0.26479428946985195, 0.26479428946985195, 0.26479428946985195, 0.11493808876497169, 0.11493808876497169, 0.11493808876497169, 0.1491118295517454, 0.1491118295517454, 0.1491118295517454, 0.11852673015542259, 0.11852673015542259, 0.11852673015542259, 0.11313676588122157, 0.11313676588122157, 0.11313676588122157, 0.1332708229732913, 0.1332708229732913, 0.1332708229732913, 0.16455859443171394, 0.16455859443171394, 0.16455859443171394, 0.08895045408546576, 0.08895045408546576, 0.08895045408546576, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.36248602339556657, 0.36248602339556657, 0.36248602339556657, 0.5648203018166031, 0.5648203018166031, 0.5648203018166031, 0.460257118007653, 0.460257118007653, 0.460257118007653, 0.21740937118414527, 0.21740937118414527, 0.21740937118414527, 0.2702148534483395, 0.2702148534483395, 0.2702148534483395, 0.8186564776506264, 0.8186564776506264, 0.8186564776506264, 0.16606219940139488, 0.16606219940139488, 0.16606219940139488, 0.1607172104571447, 0.1607172104571447, 0.1607172104571447, 0.1851369551118872, 0.1851369551118872, 0.1851369551118872, 0.12286163046264864, 0.12286163046264864, 0.12286163046264864, 0.1291711463767935, 0.1291711463767935, 0.1291711463767935, 0.18732989120451826, 0.18732989120451826, 0.18732989120451826, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012577632251547066, 0.012577632251547066, 0.012577632251547066, 0.08272544200177656, 0.08272544200177656, 0.08272544200177656, 0.03855758550104016, 0.03855758550104016, 0.03855758550104016, 0.10757357806221757, 0.10757357806221757, 0.10757357806221757, 0.1135085832144237, 0.1135085832144237, 0.1135085832144237, 0.09685276553895095, 0.09685276553895095, 0.09685276553895095, 0.0867191705708017, 0.0867191705708017, 0.0867191705708017, 0.1261641983211924, 0.1261641983211924, 0.1261641983211924, 0.14807674401635396, 0.14807674401635396, 0.14807674401635396, 0.07348849299233029, 0.07348849299233029, 0.07348849299233029, 0.5149377510145201, 0.5149377510145201, 0.5149377510145201, 0.518122716027031, 0.518122716027031, 0.518122716027031, 0.481441768096851, 0.481441768096851, 0.481441768096851, 0.15201556573186792, 0.15201556573186792, 0.15201556573186792, 0.14497757416846468, 0.14497757416846468, 0.14497757416846468, 0.13704302354006648, 0.13704302354006648, 0.13704302354006648, 0.41913747505827026, 0.41913747505827026, 0.41913747505827026, 0.31980181823636733, 0.31980181823636733, 0.31980181823636733, 0.25447547559551753, 0.25447547559551753, 0.25447547559551753, 0.37199046387018675, 0.37199046387018675, 0.37199046387018675, 0.39938368232863064, 0.39938368232863064, 0.39938368232863064, 0.3995378391859714, 0.3995378391859714, 0.3995378391859714, 0.2903240654071201, 0.2903240654071201, 0.2903240654071201, 0.274148858496033, 0.274148858496033, 0.274148858496033, 0.23233955521837557, 0.23233955521837557, 0.23233955521837557, 0.20642364418062276, 0.20642364418062276, 0.20642364418062276, 0.2299514996219716, 0.2299514996219716, 0.2299514996219716, 0.20338858542435956, 0.20338858542435956, 0.20338858542435956, 0.6639053461501656, 0.6639053461501656, 0.6639053461501656, 0.21033352131284344, 0.21033352131284344, 0.21033352131284344, 0.18056326969236403, 0.18056326969236403, 0.18056326969236403, 0.8839251842239001, 0.8839251842239001, 0.8839251842239001, 0.15794253407787584, 0.15794253407787584, 0.15794253407787584, 0.8514523114100395, 0.8514523114100395, 0.8514523114100395, 0.7010700251840367, 0.7010700251840367, 0.7010700251840367, 0.21060859223587636, 0.21060859223587636, 0.21060859223587636, 0.49413926974424516, 0.49413926974424516, 0.49413926974424516, 0.19196688776090964, 0.19196688776090964, 0.19196688776090964, 0.1862304060922776, 0.1862304060922776, 0.1862304060922776, 0.18074706019778608, 0.18074706019778608, 0.18074706019778608, 0.0927349099348036, 0.0927349099348036, 0.0927349099348036, 0.09678918373364143, 0.09678918373364143, 0.09678918373364143, 0.11597463779835637, 0.11597463779835637, 0.11597463779835637]}, "mutation_prompt": null}
{"id": "ca2e7ca1-6b0e-418e-94eb-05a0834add17", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "34263c9a-5443-434c-acaa-8f520e99dde9", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "23f83a40-ff49-41c1-a8bd-50d6b7418faa", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.15\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.97\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.exp(-evaluations / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "A novel adaptive particle swarm optimizer with enhanced mutation dynamics using a Gaussian-based decay function for improved convergence and robustness.", "configspace": "", "generation": 58, "fitness": 0.2872535920028397, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.7464362997706997, 0.7464362997706997, 0.7464362997706997, 0.7332227734332486, 0.7332227734332486, 0.7332227734332486, 0.7571809412476888, 0.7571809412476888, 0.7571809412476888, 0.06481611671576215, 0.06481611671576215, 0.06481611671576215, 0.1805182680434273, 0.1805182680434273, 0.1805182680434273, 0.11480890713812275, 0.11480890713812275, 0.11480890713812275, 0.13999815467845833, 0.13999815467845833, 0.13999815467845833, 0.13833631500232968, 0.13833631500232968, 0.13833631500232968, 0.0898735375914348, 0.0898735375914348, 0.0898735375914348, 0.11327349067153192, 0.11327349067153192, 0.11327349067153192, 0.1112211905246433, 0.1112211905246433, 0.1112211905246433, 0.12318543992855013, 0.12318543992855013, 0.12318543992855013, 0.9355429932227675, 0.9355429932227675, 0.9355429932227675, 0.9415003668336163, 0.9415003668336163, 0.9415003668336163, 0.9555757355014703, 0.9555757355014703, 0.9555757355014703, 0.4248418122206762, 0.4248418122206762, 0.4248418122206762, 0.4603852446447635, 0.4603852446447635, 0.4603852446447635, 0.47864959610403746, 0.47864959610403746, 0.47864959610403746, 0.20864174422174675, 0.20864174422174675, 0.20864174422174675, 0.27331604007233246, 0.27331604007233246, 0.27331604007233246, 0.21589137831113125, 0.21589137831113125, 0.21589137831113125, 0.1308202731587933, 0.1308202731587933, 0.1308202731587933, 0.1530879040041382, 0.1530879040041382, 0.1530879040041382, 0.4012161368894245, 0.4012161368894245, 0.4012161368894245, 0.18654699008627929, 0.18654699008627929, 0.18654699008627929, 0.12699604636951933, 0.12699604636951933, 0.12699604636951933, 0.1063637409845396, 0.1063637409845396, 0.1063637409845396, 0.1771920617900027, 0.1771920617900027, 0.1771920617900027, 0.013934228566399365, 0.013934228566399365, 0.013934228566399365, 0.06474300687120083, 0.06474300687120083, 0.06474300687120083, 0.04749181350066067, 0.04749181350066067, 0.04749181350066067, 0.06131138267265046, 0.06131138267265046, 0.06131138267265046, 0.09217142886731877, 0.09217142886731877, 0.09217142886731877, 0.052260075905844805, 0.052260075905844805, 0.052260075905844805, 0.1959091726302229, 0.1959091726302229, 0.1959091726302229, 0.08202499313872447, 0.08202499313872447, 0.08202499313872447, 0.1471025062808542, 0.1471025062808542, 0.1471025062808542, 0.22112840916835197, 0.22112840916835197, 0.22112840916835197, 0.055381177920196256, 0.055381177920196256, 0.055381177920196256, 0.4884716364474775, 0.4884716364474775, 0.4884716364474775, 0.5620939400622229, 0.5620939400622229, 0.5620939400622229, 0.49245991162456926, 0.49245991162456926, 0.49245991162456926, 0.1114886324192137, 0.1114886324192137, 0.1114886324192137, 0.11257506808667328, 0.11257506808667328, 0.11257506808667328, 0.13971398153411063, 0.13971398153411063, 0.13971398153411063, 0.5102481472698377, 0.5102481472698377, 0.5102481472698377, 0.20511146626972376, 0.20511146626972376, 0.20511146626972376, 0.3396892068117272, 0.3396892068117272, 0.3396892068117272, 0.34407385783983935, 0.34407385783983935, 0.34407385783983935, 0.4045972213992193, 0.4045972213992193, 0.4045972213992193, 0.3673910022605763, 0.3673910022605763, 0.3673910022605763, 0.31153255428421334, 0.31153255428421334, 0.31153255428421334, 0.30313680617744554, 0.30313680617744554, 0.30313680617744554, 0.2650671001873418, 0.2650671001873418, 0.2650671001873418, 0.23736065047183907, 0.23736065047183907, 0.23736065047183907, 0.2048089930542003, 0.2048089930542003, 0.2048089930542003, 0.2509115839680849, 0.2509115839680849, 0.2509115839680849, 0.22151991168777763, 0.22151991168777763, 0.22151991168777763, 0.19659813864400089, 0.19659813864400089, 0.19659813864400089, 0.205427213690484, 0.205427213690484, 0.205427213690484, 0.8804972126451577, 0.8804972126451577, 0.8804972126451577, 0.15770150040500264, 0.15770150040500264, 0.15770150040500264, 0.8834615716434022, 0.8834615716434022, 0.8834615716434022, 0.4048005979280901, 0.4048005979280901, 0.4048005979280901, 0.21158545022069442, 0.21158545022069442, 0.21158545022069442, 0.5098703059091082, 0.5098703059091082, 0.5098703059091082, 0.18475443897481825, 0.18475443897481825, 0.18475443897481825, 0.18365121848321908, 0.18365121848321908, 0.18365121848321908, 0.18012839945478276, 0.18012839945478276, 0.18012839945478276, 0.10466633442576201, 0.10466633442576201, 0.10466633442576201, 0.08294699326612986, 0.08294699326612986, 0.08294699326612986, 0.10101988197415013, 0.10101988197415013, 0.10101988197415013]}, "mutation_prompt": null}
{"id": "e335dc15-974c-416d-9415-3aa41d2dcaab", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "91eb083c-ce40-44d7-8062-e6cc2ed1349f", "solution": "import numpy as np\n\nclass EnhancedSwarmOptimizerWithStochasticRestarts:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.12\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n        self.restart_prob = 0.02\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                if np.random.rand() < self.restart_prob:\n                    particles[i] = np.random.uniform(self.lb, self.ub, self.dim)\n                else:\n                    particles[i] += velocities[i]\n                \n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedSwarmOptimizerWithStochasticRestarts", "description": "An enhanced swarm optimizer utilizing dynamic inertia, adaptive weights, and stochastic restarts for robust convergence and exploration.", "configspace": "", "generation": 60, "fitness": 0.2875411135027005, "feedback": "The algorithm EnhancedSwarmOptimizerWithStochasticRestarts got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.8084313426707443, 0.8084313426707443, 0.8084313426707443, 0.748829607709306, 0.748829607709306, 0.748829607709306, 0.80021688067873, 0.80021688067873, 0.80021688067873, 0.08377859146553257, 0.08377859146553257, 0.08377859146553257, 0.021994649385083553, 0.021994649385083553, 0.021994649385083553, 0.10904545450143088, 0.10904545450143088, 0.10904545450143088, 0.1732590305619398, 0.1732590305619398, 0.1732590305619398, 0.16424589551327118, 0.16424589551327118, 0.16424589551327118, 0.0880720244910479, 0.0880720244910479, 0.0880720244910479, 0.12187286144078602, 0.12187286144078602, 0.12187286144078602, 0.08074833110570157, 0.08074833110570157, 0.08074833110570157, 0.11510516373369284, 0.11510516373369284, 0.11510516373369284, 0.9490022233977994, 0.9490022233977994, 0.9490022233977994, 0.9481152470794656, 0.9481152470794656, 0.9481152470794656, 0.9554430088366619, 0.9554430088366619, 0.9554430088366619, 0.4908426522034678, 0.4908426522034678, 0.4908426522034678, 0.46685643374874, 0.46685643374874, 0.46685643374874, 0.41703591878358637, 0.41703591878358637, 0.41703591878358637, 0.22330869084692784, 0.22330869084692784, 0.22330869084692784, 0.2677529473871816, 0.2677529473871816, 0.2677529473871816, 0.5890447050920427, 0.5890447050920427, 0.5890447050920427, 0.16967334660609323, 0.16967334660609323, 0.16967334660609323, 0.16718578869631207, 0.16718578869631207, 0.16718578869631207, 0.17812172073084365, 0.17812172073084365, 0.17812172073084365, 0.12855027769758032, 0.12855027769758032, 0.12855027769758032, 0.12405072081419788, 0.12405072081419788, 0.12405072081419788, 0.2175910666749742, 0.2175910666749742, 0.2175910666749742, 0.009035704177901227, 0.009035704177901227, 0.009035704177901227, 0.115282639261168, 0.115282639261168, 0.115282639261168, 0.07123717921220285, 0.07123717921220285, 0.07123717921220285, 0.13630070130326422, 0.13630070130326422, 0.13630070130326422, 0.07327202007636513, 0.07327202007636513, 0.07327202007636513, 0.08729694251608255, 0.08729694251608255, 0.08729694251608255, 0.04242726568238464, 0.04242726568238464, 0.04242726568238464, 0.06351525230983202, 0.06351525230983202, 0.06351525230983202, 0.06840562869554034, 0.06840562869554034, 0.06840562869554034, 0.1525709053621076, 0.1525709053621076, 0.1525709053621076, 0.07631199133079858, 0.07631199133079858, 0.07631199133079858, 0.16166172541956236, 0.16166172541956236, 0.16166172541956236, 0.4900919780919324, 0.4900919780919324, 0.4900919780919324, 0.48093868587225796, 0.48093868587225796, 0.48093868587225796, 0.5199230371074688, 0.5199230371074688, 0.5199230371074688, 0.13136001801271757, 0.13136001801271757, 0.13136001801271757, 0.1806086898249547, 0.1806086898249547, 0.1806086898249547, 0.11720454937897162, 0.11720454937897162, 0.11720454937897162, 0.22995444385422548, 0.22995444385422548, 0.22995444385422548, 0.15578404155690673, 0.15578404155690673, 0.15578404155690673, 0.18664289474979134, 0.18664289474979134, 0.18664289474979134, 0.3616335755884773, 0.3616335755884773, 0.3616335755884773, 0.39183649549905797, 0.39183649549905797, 0.39183649549905797, 0.4129938240447636, 0.4129938240447636, 0.4129938240447636, 0.17647754037960517, 0.17647754037960517, 0.17647754037960517, 0.2644069796730377, 0.2644069796730377, 0.2644069796730377, 0.24257383625921514, 0.24257383625921514, 0.24257383625921514, 0.21747263861848887, 0.21747263861848887, 0.21747263861848887, 0.19641519192851642, 0.19641519192851642, 0.19641519192851642, 0.22956447046103845, 0.22956447046103845, 0.22956447046103845, 0.18432179708513363, 0.18432179708513363, 0.18432179708513363, 0.19950888331840522, 0.19950888331840522, 0.19950888331840522, 0.19402236144102902, 0.19402236144102902, 0.19402236144102902, 0.8789808835086323, 0.8789808835086323, 0.8789808835086323, 0.16502146885658675, 0.16502146885658675, 0.16502146885658675, 0.8077579081463047, 0.8077579081463047, 0.8077579081463047, 0.8396746362467402, 0.8396746362467402, 0.8396746362467402, 0.20709113118280997, 0.20709113118280997, 0.20709113118280997, 0.6505479478085856, 0.6505479478085856, 0.6505479478085856, 0.18976887255658625, 0.18976887255658625, 0.18976887255658625, 0.2057348923889697, 0.2057348923889697, 0.2057348923889697, 0.19372980328503708, 0.19372980328503708, 0.19372980328503708, 0.1004433807410996, 0.1004433807410996, 0.1004433807410996, 0.10044144221901408, 0.10044144221901408, 0.10044144221901408, 0.1345393353077261, 0.1345393353077261, 0.1345393353077261]}, "mutation_prompt": null}
{"id": "0d96a328-e6ab-45f0-a151-8030f0e85365", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "b018c0ab-e357-4d35-ad36-6402adae98c5", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "74f8b908-2223-4944-bc1c-edf601845769", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "b123c161-6e74-48c4-bd71-137d217f1008", "solution": "import numpy as np\n\nclass AdvancedVelocitySwarmOptimizerWithCosineMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.15\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99\n        self.elitism_ratio = 0.1\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.cos(np.pi * evaluations / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdvancedVelocitySwarmOptimizerWithCosineMutation", "description": "An advanced particle swarm optimizer with adaptive velocity, elitist re-sampling, and a cosine-based mutation strategy for enhanced exploration and convergence.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {}, "mutation_prompt": null}
{"id": "688a6236-597b-49d9-b79e-6066dafe513c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.8\n        self.cognitive_weight = 2.0\n        self.social_weight = 1.7\n        self.mutation_prob = 0.12\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.2\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "A dynamic particle swarm optimizer enhanced with adaptive velocity scaling, elitist selection, and adaptive Gaussian mutation for improved exploration and convergence.", "configspace": "", "generation": 65, "fitness": 0.2813260764356238, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.6431423153865007, 0.6431423153865007, 0.6431423153865007, 0.6655230921096865, 0.6655230921096865, 0.6655230921096865, 0.6816411270070949, 0.6816411270070949, 0.6816411270070949, 0.17376475309403372, 0.17376475309403372, 0.17376475309403372, 0.13993911989506946, 0.13993911989506946, 0.13993911989506946, 0.07964115606337796, 0.07964115606337796, 0.07964115606337796, 0.1226782184083719, 0.1226782184083719, 0.1226782184083719, 0.12178495400627476, 0.12178495400627476, 0.12178495400627476, 0.26635508688284204, 0.26635508688284204, 0.26635508688284204, 0.1097648979154272, 0.1097648979154272, 0.1097648979154272, 0.10349265991229495, 0.10349265991229495, 0.10349265991229495, 0.09501216722365369, 0.09501216722365369, 0.09501216722365369, 0.947582454963214, 0.947582454963214, 0.947582454963214, 0.9533279734007329, 0.9533279734007329, 0.9533279734007329, 0.9487632870239179, 0.9487632870239179, 0.9487632870239179, 0.3999165268417285, 0.3999165268417285, 0.3999165268417285, 0.4058263349835405, 0.4058263349835405, 0.4058263349835405, 0.3905436345807871, 0.3905436345807871, 0.3905436345807871, 0.22009270673043235, 0.22009270673043235, 0.22009270673043235, 0.20287937599766048, 0.20287937599766048, 0.20287937599766048, 0.60854018140809, 0.60854018140809, 0.60854018140809, 0.18882105067936206, 0.18882105067936206, 0.18882105067936206, 0.1569333388952604, 0.1569333388952604, 0.1569333388952604, 0.17017288315182777, 0.17017288315182777, 0.17017288315182777, 0.1783862403750185, 0.1783862403750185, 0.1783862403750185, 0.1631809226116564, 0.1631809226116564, 0.1631809226116564, 0.1835207094946152, 0.1835207094946152, 0.1835207094946152, 0.042696200499675485, 0.042696200499675485, 0.042696200499675485, 0.004816072270740546, 0.004816072270740546, 0.004816072270740546, 0.09261673693878147, 0.09261673693878147, 0.09261673693878147, 0.053355813823690035, 0.053355813823690035, 0.053355813823690035, 0.025516584112414198, 0.025516584112414198, 0.025516584112414198, 0.18269082473242038, 0.18269082473242038, 0.18269082473242038, 0.03145768324416709, 0.03145768324416709, 0.03145768324416709, 0.05141238563727635, 0.05141238563727635, 0.05141238563727635, 0.11038839145128876, 0.11038839145128876, 0.11038839145128876, 0.09148027692537486, 0.09148027692537486, 0.09148027692537486, 0.10938518490640559, 0.10938518490640559, 0.10938518490640559, 0.13387446791838686, 0.13387446791838686, 0.13387446791838686, 0.46825187747654806, 0.46825187747654806, 0.46825187747654806, 0.4848481686693301, 0.4848481686693301, 0.4848481686693301, 0.49459265078475056, 0.49459265078475056, 0.49459265078475056, 0.3164619408468696, 0.3164619408468696, 0.3164619408468696, 0.11029894373710525, 0.11029894373710525, 0.11029894373710525, 0.12000524555086756, 0.12000524555086756, 0.12000524555086756, 0.25054344008247353, 0.25054344008247353, 0.25054344008247353, 0.33325503598823747, 0.33325503598823747, 0.33325503598823747, 0.3189758359275574, 0.3189758359275574, 0.3189758359275574, 0.3642352353530226, 0.3642352353530226, 0.3642352353530226, 0.3657988987066636, 0.3657988987066636, 0.3657988987066636, 0.35834929535254445, 0.35834929535254445, 0.35834929535254445, 0.22828521150800096, 0.22828521150800096, 0.22828521150800096, 0.24449289787454542, 0.24449289787454542, 0.24449289787454542, 0.17897936916990853, 0.17897936916990853, 0.17897936916990853, 0.23209450029949374, 0.23209450029949374, 0.23209450029949374, 0.2142099645214497, 0.2142099645214497, 0.2142099645214497, 0.21804311946664434, 0.21804311946664434, 0.21804311946664434, 0.22276552340577427, 0.22276552340577427, 0.22276552340577427, 0.2310499283046864, 0.2310499283046864, 0.2310499283046864, 0.23074212854696963, 0.23074212854696963, 0.23074212854696963, 0.7763187636857489, 0.7763187636857489, 0.7763187636857489, 0.15658362894264122, 0.15658362894264122, 0.15658362894264122, 0.7692623406283994, 0.7692623406283994, 0.7692623406283994, 0.5848212090579323, 0.5848212090579323, 0.5848212090579323, 0.20941239777239584, 0.20941239777239584, 0.20941239777239584, 0.6680913226911049, 0.6680913226911049, 0.6680913226911049, 0.18802174543809147, 0.18802174543809147, 0.18802174543809147, 0.18071071354378876, 0.18071071354378876, 0.18071071354378876, 0.20401851700702178, 0.20401851700702178, 0.20401851700702178, 0.08669541038786843, 0.08669541038786843, 0.08669541038786843, 0.0882736670744978, 0.0882736670744978, 0.0882736670744978, 0.10607078405888604, 0.10607078405888604, 0.10607078405888604]}, "mutation_prompt": null}
{"id": "49da0adc-e165-4457-b6b8-17cc6fe54791", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "fc14c75a-94f9-4251-84c1-f64f242dea17", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "dd9c3aa1-6cf7-4b3d-9cbb-51397bb6b454", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithOppositionLearning:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n        self.opposition_prob = 0.1  # Probability to perform opposition-based learning\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                if np.random.rand() < self.opposition_prob:\n                    opposition_vector = self.lb + self.ub - particles[i]\n                    opposition_value = func(opposition_vector)\n                    evaluations += 1\n                    if opposition_value < personal_best_values[i]:\n                        particles[i] = opposition_vector\n                        personal_best_values[i] = opposition_value\n                        personal_best_positions[i] = particles[i]\n                        if opposition_value < self.global_best_value:\n                            self.global_best_value = opposition_value\n                            self.global_best_position = particles[i]\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithOppositionLearning", "description": "A swarm optimizer with adaptive velocity scaling, elitism, logarithmic mutation, and opposition-based learning for enhanced exploration and convergence.", "configspace": "", "generation": 68, "fitness": 0.3014893030835316, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithOppositionLearning got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.793087819505575, 0.793087819505575, 0.793087819505575, 0.7746179762833567, 0.7746179762833567, 0.7746179762833567, 0.758895062779138, 0.758895062779138, 0.758895062779138, 0.20585214441031796, 0.20585214441031796, 0.20585214441031796, 0.11803601792799634, 0.11803601792799634, 0.11803601792799634, 0.27213540050472407, 0.27213540050472407, 0.27213540050472407, 0.11871165816933549, 0.11871165816933549, 0.11871165816933549, 0.13751905505175743, 0.13751905505175743, 0.13751905505175743, 0.10596438511228812, 0.10596438511228812, 0.10596438511228812, 0.10194668738065482, 0.10194668738065482, 0.10194668738065482, 0.11105254980168267, 0.11105254980168267, 0.11105254980168267, 0.11082862431369267, 0.11082862431369267, 0.11082862431369267, 0.9424929385488166, 0.9424929385488166, 0.9424929385488166, 0.9505748027679978, 0.9505748027679978, 0.9505748027679978, 0.9509050007137295, 0.9509050007137295, 0.9509050007137295, 0.5119158715358859, 0.5119158715358859, 0.5119158715358859, 0.4437107167579085, 0.4437107167579085, 0.4437107167579085, 0.5528084805460018, 0.5528084805460018, 0.5528084805460018, 0.22201710455550472, 0.22201710455550472, 0.22201710455550472, 0.20698955594062585, 0.20698955594062585, 0.20698955594062585, 0.7743162608754426, 0.7743162608754426, 0.7743162608754426, 0.14404544979085654, 0.14404544979085654, 0.14404544979085654, 0.1977394298522679, 0.1977394298522679, 0.1977394298522679, 0.16456719324305125, 0.16456719324305125, 0.16456719324305125, 0.19074115385253754, 0.19074115385253754, 0.19074115385253754, 0.3189173975705518, 0.3189173975705518, 0.3189173975705518, 0.20768684459444253, 0.20768684459444253, 0.20768684459444253, 0.05330457632775887, 0.05330457632775887, 0.05330457632775887, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010977024416419567, 0.010977024416419567, 0.010977024416419567, 0.12669547654488145, 0.12669547654488145, 0.12669547654488145, 0.06902631673041282, 0.06902631673041282, 0.06902631673041282, 0.11657213454036086, 0.11657213454036086, 0.11657213454036086, 0.04175374301094903, 0.04175374301094903, 0.04175374301094903, 0.12512338089026998, 0.12512338089026998, 0.12512338089026998, 0.0791721423724484, 0.0791721423724484, 0.0791721423724484, 0.2734647406287427, 0.2734647406287427, 0.2734647406287427, 0.06482242596945342, 0.06482242596945342, 0.06482242596945342, 0.13163455714581818, 0.13163455714581818, 0.13163455714581818, 0.5108140236655765, 0.5108140236655765, 0.5108140236655765, 0.49597125743553283, 0.49597125743553283, 0.49597125743553283, 0.5072672978667929, 0.5072672978667929, 0.5072672978667929, 0.10334854398566384, 0.10334854398566384, 0.10334854398566384, 0.10828821070813588, 0.10828821070813588, 0.10828821070813588, 0.0807231007772714, 0.0807231007772714, 0.0807231007772714, 0.327209514578493, 0.327209514578493, 0.327209514578493, 0.26017499643627084, 0.26017499643627084, 0.26017499643627084, 0.17317268224114157, 0.17317268224114157, 0.17317268224114157, 0.40724280568611937, 0.40724280568611937, 0.40724280568611937, 0.40362953549221525, 0.40362953549221525, 0.40362953549221525, 0.40433210782382856, 0.40433210782382856, 0.40433210782382856, 0.19542619748526935, 0.19542619748526935, 0.19542619748526935, 0.28373877653154167, 0.28373877653154167, 0.28373877653154167, 0.27105283698592664, 0.27105283698592664, 0.27105283698592664, 0.22377399321512648, 0.22377399321512648, 0.22377399321512648, 0.2591379918114214, 0.2591379918114214, 0.2591379918114214, 0.22535184133533404, 0.22535184133533404, 0.22535184133533404, 0.19176233453531177, 0.19176233453531177, 0.19176233453531177, 0.2202096052814716, 0.2202096052814716, 0.2202096052814716, 0.20713618353483598, 0.20713618353483598, 0.20713618353483598, 0.8574847706630268, 0.8574847706630268, 0.8574847706630268, 0.15801983094613592, 0.15801983094613592, 0.15801983094613592, 0.8379680929312248, 0.8379680929312248, 0.8379680929312248, 0.5235588894511958, 0.5235588894511958, 0.5235588894511958, 0.49549772602695685, 0.49549772602695685, 0.49549772602695685, 0.6184059674233737, 0.6184059674233737, 0.6184059674233737, 0.2030565072867173, 0.2030565072867173, 0.2030565072867173, 0.1906945831222978, 0.1906945831222978, 0.1906945831222978, 0.1832987779571863, 0.1832987779571863, 0.1832987779571863, 0.0936370611645454, 0.0936370611645454, 0.0936370611645454, 0.09456094696425565, 0.09456094696425565, 0.09456094696425565, 0.11056072970042186, 0.11056072970042186, 0.11056072970042186]}, "mutation_prompt": null}
{"id": "4c28d7ac-1b34-4a63-8190-9ed2fa7a7f20", "solution": "import numpy as np\n\nclass RefinedAdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.15\n        self.vel_bound = (self.ub - self.lb) / 5.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.97\n        self.elitism_ratio = 0.1\n        self.mutation_scale = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.exp(-evaluations / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "RefinedAdaptiveVelocitySwarmOptimizer", "description": "A refined particle swarm optimizer with adaptive velocity, enhanced elitism, and exponential decay mutation for robust exploration and precision.", "configspace": "", "generation": 69, "fitness": 0.29859906812952464, "feedback": "The algorithm RefinedAdaptiveVelocitySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.7350309101099519, 0.7350309101099519, 0.7350309101099519, 0.82163371766569, 0.82163371766569, 0.82163371766569, 0.7927463128675794, 0.7927463128675794, 0.7927463128675794, 0.22700203995081691, 0.22700203995081691, 0.22700203995081691, 0.12129093369211408, 0.12129093369211408, 0.12129093369211408, 0.10308713858609642, 0.10308713858609642, 0.10308713858609642, 0.12684434843724668, 0.12684434843724668, 0.12684434843724668, 0.12739653466837753, 0.12739653466837753, 0.12739653466837753, 0.11809728293536903, 0.11809728293536903, 0.11809728293536903, 0.09743644874583912, 0.09743644874583912, 0.09743644874583912, 0.11249350997475993, 0.11249350997475993, 0.11249350997475993, 0.09301540290399457, 0.09301540290399457, 0.09301540290399457, 0.9562631764383623, 0.9562631764383623, 0.9562631764383623, 0.9602385856956308, 0.9602385856956308, 0.9602385856956308, 0.9638917536935269, 0.9638917536935269, 0.9638917536935269, 0.521792214005411, 0.521792214005411, 0.521792214005411, 0.4696596914879263, 0.4696596914879263, 0.4696596914879263, 0.4712401874615354, 0.4712401874615354, 0.4712401874615354, 0.7901119386636314, 0.7901119386636314, 0.7901119386636314, 0.1609381356583801, 0.1609381356583801, 0.1609381356583801, 0.3429841435896577, 0.3429841435896577, 0.3429841435896577, 0.1632408076424675, 0.1632408076424675, 0.1632408076424675, 0.1507596010037645, 0.1507596010037645, 0.1507596010037645, 0.12634135991485096, 0.12634135991485096, 0.12634135991485096, 0.2128179454248419, 0.2128179454248419, 0.2128179454248419, 0.1580369589780768, 0.1580369589780768, 0.1580369589780768, 0.1514427361896422, 0.1514427361896422, 0.1514427361896422, 0.0719159619564993, 0.0719159619564993, 0.0719159619564993, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1002079066524948, 0.1002079066524948, 0.1002079066524948, 0.07732095361386748, 0.07732095361386748, 0.07732095361386748, 0.05552800035925287, 0.05552800035925287, 0.05552800035925287, 0.11895659402180114, 0.11895659402180114, 0.11895659402180114, 0.07811814562842445, 0.07811814562842445, 0.07811814562842445, 0.10949225579259259, 0.10949225579259259, 0.10949225579259259, 0.1671180573467096, 0.1671180573467096, 0.1671180573467096, 0.14233051756504334, 0.14233051756504334, 0.14233051756504334, 0.1728752914693572, 0.1728752914693572, 0.1728752914693572, 0.18093441469458338, 0.18093441469458338, 0.18093441469458338, 0.5058475257709933, 0.5058475257709933, 0.5058475257709933, 0.520192924612741, 0.520192924612741, 0.520192924612741, 0.49792668064226564, 0.49792668064226564, 0.49792668064226564, 0.11257953787765651, 0.11257953787765651, 0.11257953787765651, 0.11448974316828187, 0.11448974316828187, 0.11448974316828187, 0.12012329771498642, 0.12012329771498642, 0.12012329771498642, 0.4039405519711313, 0.4039405519711313, 0.4039405519711313, 0.14033742400557936, 0.14033742400557936, 0.14033742400557936, 0.37396919382080207, 0.37396919382080207, 0.37396919382080207, 0.31875768700479556, 0.31875768700479556, 0.31875768700479556, 0.32273750017511815, 0.32273750017511815, 0.32273750017511815, 0.3638832199547496, 0.3638832199547496, 0.3638832199547496, 0.1749006140574908, 0.1749006140574908, 0.1749006140574908, 0.23666714006687695, 0.23666714006687695, 0.23666714006687695, 0.22217239668268363, 0.22217239668268363, 0.22217239668268363, 0.189396703546306, 0.189396703546306, 0.189396703546306, 0.24068279460908193, 0.24068279460908193, 0.24068279460908193, 0.23992902094786073, 0.23992902094786073, 0.23992902094786073, 0.18698458294547637, 0.18698458294547637, 0.18698458294547637, 0.1825955123348293, 0.1825955123348293, 0.1825955123348293, 0.4824251504297, 0.4824251504297, 0.4824251504297, 0.895732163885376, 0.895732163885376, 0.895732163885376, 0.1578426686708494, 0.1578426686708494, 0.1578426686708494, 0.8791915551239496, 0.8791915551239496, 0.8791915551239496, 0.6573300227996441, 0.6573300227996441, 0.6573300227996441, 0.20938759958116648, 0.20938759958116648, 0.20938759958116648, 0.5280080602839032, 0.5280080602839032, 0.5280080602839032, 0.2035107133400259, 0.2035107133400259, 0.2035107133400259, 0.17882182395948987, 0.17882182395948987, 0.17882182395948987, 0.19761200120121902, 0.19761200120121902, 0.19761200120121902, 0.09096838542341212, 0.09096838542341212, 0.09096838542341212, 0.08043312376974432, 0.08043312376974432, 0.08043312376974432, 0.11902366946142062, 0.11902366946142062, 0.11902366946142062]}, "mutation_prompt": null}
{"id": "9914971f-0b31-465c-920e-f6757e74910e", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "423b18fa-50a2-4631-b916-9607218114cf", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "2ed8a3be-c0af-497b-a268-3f0295f20f42", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "ef9f71a1-cf27-4fcd-90f0-2a8c99363c2b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 2.0\n        self.social_weight = 1.4\n        self.mutation_prob = 0.15\n        self.vel_bound = (self.ub - self.lb) / 5.5\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.12\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.sqrt((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedAdaptiveVelocitySwarmOptimizer", "description": "A dynamically adaptive particle swarm optimizer with enhanced mutation strategies and feedback-driven parameter tuning for robust convergence.", "configspace": "", "generation": 73, "fitness": 0.29496573723880715, "feedback": "The algorithm EnhancedAdaptiveVelocitySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.6495656052893997, 0.6495656052893997, 0.6495656052893997, 0.6355332267821003, 0.6355332267821003, 0.6355332267821003, 0.7083139220639728, 0.7083139220639728, 0.7083139220639728, 0.15632346857318302, 0.15632346857318302, 0.15632346857318302, 0.2103063593716723, 0.2103063593716723, 0.2103063593716723, 0.09987796709390317, 0.09987796709390317, 0.09987796709390317, 0.13964632136048183, 0.13964632136048183, 0.13964632136048183, 0.15967171796558777, 0.15967171796558777, 0.15967171796558777, 0.134706340447879, 0.134706340447879, 0.134706340447879, 0.11795617584532103, 0.11795617584532103, 0.11795617584532103, 0.12308154662971571, 0.12308154662971571, 0.12308154662971571, 0.16536502163287592, 0.16536502163287592, 0.16536502163287592, 0.9421217148370635, 0.9421217148370635, 0.9421217148370635, 0.9474235118430809, 0.9474235118430809, 0.9474235118430809, 0.9561636719741984, 0.9561636719741984, 0.9561636719741984, 0.4779016261975758, 0.4779016261975758, 0.4779016261975758, 0.3953118902592181, 0.3953118902592181, 0.3953118902592181, 0.39760209990432305, 0.39760209990432305, 0.39760209990432305, 0.7198029348781608, 0.7198029348781608, 0.7198029348781608, 0.18964096977114409, 0.18964096977114409, 0.18964096977114409, 0.36954989595319243, 0.36954989595319243, 0.36954989595319243, 0.1826563392090278, 0.1826563392090278, 0.1826563392090278, 0.17410818973001008, 0.17410818973001008, 0.17410818973001008, 0.1771805419945114, 0.1771805419945114, 0.1771805419945114, 0.19975491931572742, 0.19975491931572742, 0.19975491931572742, 0.19042041004358978, 0.19042041004358978, 0.19042041004358978, 0.19829569634493782, 0.19829569634493782, 0.19829569634493782, 0.00365059453685479, 0.00365059453685479, 0.00365059453685479, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10875158570087917, 0.10875158570087917, 0.10875158570087917, 0.08003578060287508, 0.08003578060287508, 0.08003578060287508, 0.07983169246531685, 0.07983169246531685, 0.07983169246531685, 0.13228436030442592, 0.13228436030442592, 0.13228436030442592, 0.025835298518610994, 0.025835298518610994, 0.025835298518610994, 0.1711318276306405, 0.1711318276306405, 0.1711318276306405, 0.06728689011055644, 0.06728689011055644, 0.06728689011055644, 0.19831888049907098, 0.19831888049907098, 0.19831888049907098, 0.13420494975357378, 0.13420494975357378, 0.13420494975357378, 0.05173338762360202, 0.05173338762360202, 0.05173338762360202, 0.4604139354993311, 0.4604139354993311, 0.4604139354993311, 0.514751106708379, 0.514751106708379, 0.514751106708379, 0.4885591641547876, 0.4885591641547876, 0.4885591641547876, 0.10574633867680427, 0.10574633867680427, 0.10574633867680427, 0.12273052559301412, 0.12273052559301412, 0.12273052559301412, 0.12855739095535923, 0.12855739095535923, 0.12855739095535923, 0.23364016887462769, 0.23364016887462769, 0.23364016887462769, 0.22269574226377076, 0.22269574226377076, 0.22269574226377076, 0.1944664936038618, 0.1944664936038618, 0.1944664936038618, 0.37374540322068783, 0.37374540322068783, 0.37374540322068783, 0.3795029201162179, 0.3795029201162179, 0.3795029201162179, 0.38938679322919334, 0.38938679322919334, 0.38938679322919334, 0.23236529035994502, 0.23236529035994502, 0.23236529035994502, 0.2407603510880132, 0.2407603510880132, 0.2407603510880132, 0.29794668611321096, 0.29794668611321096, 0.29794668611321096, 0.24540979921904804, 0.24540979921904804, 0.24540979921904804, 0.238204046408388, 0.238204046408388, 0.238204046408388, 0.21104448247342733, 0.21104448247342733, 0.21104448247342733, 0.2290381943482399, 0.2290381943482399, 0.2290381943482399, 0.4378310061944004, 0.4378310061944004, 0.4378310061944004, 0.4951048191045232, 0.4951048191045232, 0.4951048191045232, 0.8068891615794154, 0.8068891615794154, 0.8068891615794154, 0.15656089162554054, 0.15656089162554054, 0.15656089162554054, 0.7867222213461439, 0.7867222213461439, 0.7867222213461439, 0.6160377940641275, 0.6160377940641275, 0.6160377940641275, 0.2109198410878801, 0.2109198410878801, 0.2109198410878801, 0.636545725116825, 0.636545725116825, 0.636545725116825, 0.20859591085558205, 0.20859591085558205, 0.20859591085558205, 0.1907179200740038, 0.1907179200740038, 0.1907179200740038, 0.19380337602529285, 0.19380337602529285, 0.19380337602529285, 0.1253639256335931, 0.1253639256335931, 0.1253639256335931, 0.09261400647076823, 0.09261400647076823, 0.09261400647076823, 0.09941431605145534, 0.09941431605145534, 0.09941431605145534]}, "mutation_prompt": null}
{"id": "6f78f767-fa61-4ec0-b463-62942652fbbe", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerWithStepwiseMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.sqrt((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "HybridSwarmOptimizerWithStepwiseMutation", "description": "A hybrid optimization algorithm combining adaptive particle swarm optimization with dynamic elitism and a novel stepwise Gaussian mutation for enhanced convergence.", "configspace": "", "generation": 74, "fitness": 0.2989497922496284, "feedback": "The algorithm HybridSwarmOptimizerWithStepwiseMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.8053896821545734, 0.8053896821545734, 0.8053896821545734, 0.7610660028386805, 0.7610660028386805, 0.7610660028386805, 0.7773015220033184, 0.7773015220033184, 0.7773015220033184, 0.16763860375696427, 0.16763860375696427, 0.16763860375696427, 0.19522751905012747, 0.19522751905012747, 0.19522751905012747, 0.0846948851015461, 0.0846948851015461, 0.0846948851015461, 0.13963987570520964, 0.13963987570520964, 0.13963987570520964, 0.13665496182940373, 0.13665496182940373, 0.13665496182940373, 0.1045596849490128, 0.1045596849490128, 0.1045596849490128, 0.13491883885531974, 0.13491883885531974, 0.13491883885531974, 0.16860635820400038, 0.16860635820400038, 0.16860635820400038, 0.10330454493442887, 0.10330454493442887, 0.10330454493442887, 0.9449662843746574, 0.9449662843746574, 0.9449662843746574, 0.9570405406096313, 0.9570405406096313, 0.9570405406096313, 0.9555900778919675, 0.9555900778919675, 0.9555900778919675, 0.48463467133244964, 0.48463467133244964, 0.48463467133244964, 0.42694754238959154, 0.42694754238959154, 0.42694754238959154, 0.45481905222690866, 0.45481905222690866, 0.45481905222690866, 0.21886109418936817, 0.21886109418936817, 0.21886109418936817, 0.35695820037593984, 0.35695820037593984, 0.35695820037593984, 0.23100182379958623, 0.23100182379958623, 0.23100182379958623, 0.18570368277844918, 0.18570368277844918, 0.18570368277844918, 0.12368443847455879, 0.12368443847455879, 0.12368443847455879, 0.16383922146729002, 0.16383922146729002, 0.16383922146729002, 0.18497906043667378, 0.18497906043667378, 0.18497906043667378, 0.15662706725111963, 0.15662706725111963, 0.15662706725111963, 0.13967211657992462, 0.13967211657992462, 0.13967211657992462, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001844363001196836, 0.001844363001196836, 0.001844363001196836, 0.04032387508888402, 0.04032387508888402, 0.04032387508888402, 0.06725598739994165, 0.06725598739994165, 0.06725598739994165, 0.03744506401600722, 0.03744506401600722, 0.03744506401600722, 0.10695987362573034, 0.10695987362573034, 0.10695987362573034, 0.11457602768877218, 0.11457602768877218, 0.11457602768877218, 0.32268692376312125, 0.32268692376312125, 0.32268692376312125, 0.08046954150413366, 0.08046954150413366, 0.08046954150413366, 0.0896721326004668, 0.0896721326004668, 0.0896721326004668, 0.20191208858638188, 0.20191208858638188, 0.20191208858638188, 0.054480360363478586, 0.054480360363478586, 0.054480360363478586, 0.508572803620169, 0.508572803620169, 0.508572803620169, 0.5923439245186259, 0.5923439245186259, 0.5923439245186259, 0.4866298659745659, 0.4866298659745659, 0.4866298659745659, 0.13639608381420332, 0.13639608381420332, 0.13639608381420332, 0.13326865526227427, 0.13326865526227427, 0.13326865526227427, 0.137545381241316, 0.137545381241316, 0.137545381241316, 0.2741985314580343, 0.2741985314580343, 0.2741985314580343, 0.317982258209188, 0.317982258209188, 0.317982258209188, 0.34881899723639476, 0.34881899723639476, 0.34881899723639476, 0.3273781662943944, 0.3273781662943944, 0.3273781662943944, 0.46282216351154415, 0.46282216351154415, 0.46282216351154415, 0.4187345768493783, 0.4187345768493783, 0.4187345768493783, 0.1948283646988641, 0.1948283646988641, 0.1948283646988641, 0.30457553172633534, 0.30457553172633534, 0.30457553172633534, 0.22175890219939265, 0.22175890219939265, 0.22175890219939265, 0.20787221331809413, 0.20787221331809413, 0.20787221331809413, 0.21320189237076492, 0.21320189237076492, 0.21320189237076492, 0.2270165489069913, 0.2270165489069913, 0.2270165489069913, 0.20778405329577343, 0.20778405329577343, 0.20778405329577343, 0.23991145724660923, 0.23991145724660923, 0.23991145724660923, 0.7429045146231134, 0.7429045146231134, 0.7429045146231134, 0.8702635721619517, 0.8702635721619517, 0.8702635721619517, 0.15803012641586267, 0.15803012641586267, 0.15803012641586267, 0.8388576566303036, 0.8388576566303036, 0.8388576566303036, 0.6075613796327934, 0.6075613796327934, 0.6075613796327934, 0.21082956275842102, 0.21082956275842102, 0.21082956275842102, 0.5483449549494552, 0.5483449549494552, 0.5483449549494552, 0.19872781468456235, 0.19872781468456235, 0.19872781468456235, 0.1939545828904693, 0.1939545828904693, 0.1939545828904693, 0.2138734340412649, 0.2138734340412649, 0.2138734340412649, 0.09309454007317763, 0.09309454007317763, 0.09309454007317763, 0.08795981344319226, 0.08795981344319226, 0.08795981344319226, 0.11628912671695035, 0.11628912671695035, 0.11628912671695035]}, "mutation_prompt": null}
{"id": "75e4af17-c719-41f8-a784-cd14d888c441", "solution": "import numpy as np\n\nclass MultiStrategySwarmOptimizerWithAdaptiveInertia:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.inertia_decay = 0.99\n        self.elitism_ratio = 0.1\n        self.mutation_scale = 0.2\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.inertia_decay\n            self.cognitive_weight *= self.inertia_decay\n            self.social_weight *= self.inertia_decay\n        \n        return self.global_best_value", "name": "MultiStrategySwarmOptimizerWithAdaptiveInertia", "description": "A multi-strategy swarm optimizer with adaptive inertia, dynamic elitism, and Gaussian-distributed mutation for robust exploration and faster convergence.", "configspace": "", "generation": 75, "fitness": 0.2846732067958302, "feedback": "The algorithm MultiStrategySwarmOptimizerWithAdaptiveInertia got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.24.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.7051406080724292, 0.7051406080724292, 0.7051406080724292, 0.7074959692423555, 0.7074959692423555, 0.7074959692423555, 0.7199668447533607, 0.7199668447533607, 0.7199668447533607, 0.16049125497949335, 0.16049125497949335, 0.16049125497949335, 0.37099512297583437, 0.37099512297583437, 0.37099512297583437, 0.11558772147777818, 0.11558772147777818, 0.11558772147777818, 0.1416905035772681, 0.1416905035772681, 0.1416905035772681, 0.16352067340687304, 0.16352067340687304, 0.16352067340687304, 0.10070373312112846, 0.10070373312112846, 0.10070373312112846, 0.09483622614336362, 0.09483622614336362, 0.09483622614336362, 0.10394632482634203, 0.10394632482634203, 0.10394632482634203, 0.13845691403788551, 0.13845691403788551, 0.13845691403788551, 0.9464221264673665, 0.9464221264673665, 0.9464221264673665, 0.9494949352857236, 0.9494949352857236, 0.9494949352857236, 0.9581693849620916, 0.9581693849620916, 0.9581693849620916, 0.49267045610832483, 0.49267045610832483, 0.49267045610832483, 0.3981699357104127, 0.3981699357104127, 0.3981699357104127, 0.4530594368393551, 0.4530594368393551, 0.4530594368393551, 0.217389087583563, 0.217389087583563, 0.217389087583563, 0.35782687667191637, 0.35782687667191637, 0.35782687667191637, 0.2383913652757519, 0.2383913652757519, 0.2383913652757519, 0.12387674568363616, 0.12387674568363616, 0.12387674568363616, 0.18318051601963048, 0.18318051601963048, 0.18318051601963048, 0.19196233710563648, 0.19196233710563648, 0.19196233710563648, 0.19790021297580584, 0.19790021297580584, 0.19790021297580584, 0.18481371459647167, 0.18481371459647167, 0.18481371459647167, 0.2449210131524464, 0.2449210131524464, 0.2449210131524464, 0.010322967792142146, 0.010322967792142146, 0.010322967792142146, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.051767707209146474, 0.051767707209146474, 0.051767707209146474, 0.042519594951147544, 0.042519594951147544, 0.042519594951147544, 0.025170346613700545, 0.025170346613700545, 0.025170346613700545, 0.12780567829354006, 0.12780567829354006, 0.12780567829354006, 0.08048511259160318, 0.08048511259160318, 0.08048511259160318, 0.07091935068080579, 0.07091935068080579, 0.07091935068080579, 0.11093365405270594, 0.11093365405270594, 0.11093365405270594, 0.10976103763677036, 0.10976103763677036, 0.10976103763677036, 0.17648144096237262, 0.17648144096237262, 0.17648144096237262, 0.11931023953612219, 0.11931023953612219, 0.11931023953612219, 0.4932832839888086, 0.4932832839888086, 0.4932832839888086, 0.5043709124491205, 0.5043709124491205, 0.5043709124491205, 0.5131622601216372, 0.5131622601216372, 0.5131622601216372, 0.1303879112637325, 0.1303879112637325, 0.1303879112637325, 0.10914466392295563, 0.10914466392295563, 0.10914466392295563, 0.11890300020109446, 0.11890300020109446, 0.11890300020109446, 0.3122909412445428, 0.3122909412445428, 0.3122909412445428, 0.20337319857474945, 0.20337319857474945, 0.20337319857474945, 0.2007783413726717, 0.2007783413726717, 0.2007783413726717, 0.326888110606256, 0.326888110606256, 0.326888110606256, 0.3647966152685844, 0.3647966152685844, 0.3647966152685844, 0.3525676696816118, 0.3525676696816118, 0.3525676696816118, 0.2545249823662944, 0.2545249823662944, 0.2545249823662944, 0.35232082030822554, 0.35232082030822554, 0.35232082030822554, 0.2075171293404443, 0.2075171293404443, 0.2075171293404443, 0.22078065867423058, 0.22078065867423058, 0.22078065867423058, 0.21473611297648554, 0.21473611297648554, 0.21473611297648554, 0.20272342573694668, 0.20272342573694668, 0.20272342573694668, 0.21400879712392495, 0.21400879712392495, 0.21400879712392495, 0.18956756603173042, 0.18956756603173042, 0.18956756603173042, 0.1928484771176031, 0.1928484771176031, 0.1928484771176031, 0.8163553806637429, 0.8163553806637429, 0.8163553806637429, 0.15727725644269408, 0.15727725644269408, 0.15727725644269408, 0.8250711060274174, 0.8250711060274174, 0.8250711060274174, 0.44889467086040347, 0.44889467086040347, 0.44889467086040347, 0.6383065488045285, 0.6383065488045285, 0.6383065488045285, 0.46148541805825327, 0.46148541805825327, 0.46148541805825327, 0.18938862976599435, 0.18938862976599435, 0.18938862976599435, 0.19790080704355528, 0.19790080704355528, 0.19790080704355528, 0.20468041128339687, 0.20468041128339687, 0.20468041128339687, 0.10104657577793896, 0.10104657577793896, 0.10104657577793896, 0.0795370328566185, 0.0795370328566185, 0.0795370328566185, 0.11089500197127966, 0.11089500197127966, 0.11089500197127966]}, "mutation_prompt": null}
{"id": "23c8a915-c47f-4122-9607-00959f816593", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n        self.memory = []\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    if len(self.memory) > 0:\n                        memory_vector = self.memory[np.random.randint(len(self.memory))]\n                        particles[i] += memory_vector * np.random.normal(0, self.mutation_scale, self.dim)\n                    else:\n                        mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                        particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n\n                self.memory.append(particles[i] - velocities[i])\n                \n                if len(self.memory) > 50:\n                    self.memory.pop(0)\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight = 1.5 + 1.5 * np.random.rand()\n            self.social_weight = 1.5 + 1.5 * np.random.rand()\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "An enhanced adaptive particle swarm optimizer with memory-based mutation and dynamic acceleration parameters for more efficient convergence.", "configspace": "", "generation": 76, "fitness": 0.24877299103452094, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.21.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.5178318542779266, 0.5178318542779266, 0.5178318542779266, 0.5026453743791226, 0.5026453743791226, 0.5026453743791226, 0.4907340697743955, 0.4907340697743955, 0.4907340697743955, 0.15111201186387602, 0.15111201186387602, 0.15111201186387602, 0.21324824189049374, 0.21324824189049374, 0.21324824189049374, 0.16660915646625596, 0.16660915646625596, 0.16660915646625596, 0.14231496370798757, 0.14231496370798757, 0.14231496370798757, 0.14547067674047376, 0.14547067674047376, 0.14547067674047376, 0.1311903211576908, 0.1311903211576908, 0.1311903211576908, 0.10808389588176237, 0.10808389588176237, 0.10808389588176237, 0.10883734577175186, 0.10883734577175186, 0.10883734577175186, 0.10250666225757088, 0.10250666225757088, 0.10250666225757088, 0.9451418783455751, 0.9451418783455751, 0.9451418783455751, 0.9620111657662761, 0.9620111657662761, 0.9620111657662761, 0.9560924804026687, 0.9560924804026687, 0.9560924804026687, 0.2749222242020686, 0.2749222242020686, 0.2749222242020686, 0.25305282238636706, 0.25305282238636706, 0.25305282238636706, 0.2623618690979994, 0.2623618690979994, 0.2623618690979994, 0.37894689183564, 0.37894689183564, 0.37894689183564, 0.32374881996321003, 0.32374881996321003, 0.32374881996321003, 0.5901615723402394, 0.5901615723402394, 0.5901615723402394, 0.14320849152385073, 0.14320849152385073, 0.14320849152385073, 0.14858701823665144, 0.14858701823665144, 0.14858701823665144, 0.17215124780528002, 0.17215124780528002, 0.17215124780528002, 0.23725608163431167, 0.23725608163431167, 0.23725608163431167, 0.1462210089471211, 0.1462210089471211, 0.1462210089471211, 0.11266400791671005, 0.11266400791671005, 0.11266400791671005, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006478412145847323, 0.006478412145847323, 0.006478412145847323, 0.052462552042230715, 0.052462552042230715, 0.052462552042230715, 0.0471243915219538, 0.0471243915219538, 0.0471243915219538, 0.0516929261837169, 0.0516929261837169, 0.0516929261837169, 0.10480934199879743, 0.10480934199879743, 0.10480934199879743, 0.014427942141907235, 0.014427942141907235, 0.014427942141907235, 0.038622106796041056, 0.038622106796041056, 0.038622106796041056, 0.043879401601920054, 0.043879401601920054, 0.043879401601920054, 0.06046807474015137, 0.06046807474015137, 0.06046807474015137, 0.08801111122067518, 0.08801111122067518, 0.08801111122067518, 0.04566813560609373, 0.04566813560609373, 0.04566813560609373, 0.39175429991807353, 0.39175429991807353, 0.39175429991807353, 0.41306625192223423, 0.41306625192223423, 0.41306625192223423, 0.43024983175116827, 0.43024983175116827, 0.43024983175116827, 0.10619317243715998, 0.10619317243715998, 0.10619317243715998, 0.12046578764945348, 0.12046578764945348, 0.12046578764945348, 0.10957372413640865, 0.10957372413640865, 0.10957372413640865, 0.2055333629972964, 0.2055333629972964, 0.2055333629972964, 0.18247079221046747, 0.18247079221046747, 0.18247079221046747, 0.243121672721489, 0.243121672721489, 0.243121672721489, 0.29154923799650656, 0.29154923799650656, 0.29154923799650656, 0.29405299323032974, 0.29405299323032974, 0.29405299323032974, 0.2872935110035625, 0.2872935110035625, 0.2872935110035625, 0.24385421249461248, 0.24385421249461248, 0.24385421249461248, 0.2580610653926435, 0.2580610653926435, 0.2580610653926435, 0.17548745600012916, 0.17548745600012916, 0.17548745600012916, 0.20776137815459905, 0.20776137815459905, 0.20776137815459905, 0.21980212552658518, 0.21980212552658518, 0.21980212552658518, 0.20617626639979314, 0.20617626639979314, 0.20617626639979314, 0.23271744076331136, 0.23271744076331136, 0.23271744076331136, 0.20254802736025834, 0.20254802736025834, 0.20254802736025834, 0.2944609336347115, 0.2944609336347115, 0.2944609336347115, 0.6939072474546384, 0.6939072474546384, 0.6939072474546384, 0.15776749261845147, 0.15776749261845147, 0.15776749261845147, 0.7467666271931184, 0.7467666271931184, 0.7467666271931184, 0.47546844620829165, 0.47546844620829165, 0.47546844620829165, 0.2056576622604901, 0.2056576622604901, 0.2056576622604901, 0.4055640496188716, 0.4055640496188716, 0.4055640496188716, 0.20052735485140916, 0.20052735485140916, 0.20052735485140916, 0.1752169136369348, 0.1752169136369348, 0.1752169136369348, 0.1862881509214922, 0.1862881509214922, 0.1862881509214922, 0.08738307339846796, 0.08738307339846796, 0.08738307339846796, 0.09212283281230715, 0.09212283281230715, 0.09212283281230715, 0.12793540923763136, 0.12793540923763136, 0.12793540923763136]}, "mutation_prompt": null}
{"id": "9d07daba-401e-4a14-b534-28d93a0da8b7", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "efd92a2e-9a40-4561-95e2-8b9d7685d0eb", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "76ad6b50-442d-4caa-8524-a518b3a7535a", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "feb8c9ec-a220-48d1-a5b1-1089b3c7827c", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerWithGaussianMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 5.0  # Adjusted velocity bound\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99  # Slightly adjusted decay for slower parameter reduction\n        self.elitism_ratio = 0.1  # Increased elitism ratio to preserve more top solutions\n        self.mutation_scale = 0.2  # Increased mutation scale for greater diversity\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "HybridSwarmOptimizerWithGaussianMutation", "description": "A hybrid swarm optimizer integrating adaptive velocity scaling, elitism, and Gaussian mutation with dynamic parameter adjustment for enhanced exploration and convergence.", "configspace": "", "generation": 80, "fitness": 0.29429327898822016, "feedback": "The algorithm HybridSwarmOptimizerWithGaussianMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.5714627870994663, 0.5714627870994663, 0.5714627870994663, 0.6751313764934388, 0.6751313764934388, 0.6751313764934388, 0.733061905119627, 0.733061905119627, 0.733061905119627, 0.26206636035554054, 0.26206636035554054, 0.26206636035554054, 0.4465059293077154, 0.4465059293077154, 0.4465059293077154, 0.15300045819470864, 0.15300045819470864, 0.15300045819470864, 0.13594600164427428, 0.13594600164427428, 0.13594600164427428, 0.13614287442729978, 0.13614287442729978, 0.13614287442729978, 0.13359237218732045, 0.13359237218732045, 0.13359237218732045, 0.1168396021857323, 0.1168396021857323, 0.1168396021857323, 0.10077893351546008, 0.10077893351546008, 0.10077893351546008, 0.10907764824511201, 0.10907764824511201, 0.10907764824511201, 0.9559236063891778, 0.9559236063891778, 0.9559236063891778, 0.9594137106267694, 0.9594137106267694, 0.9594137106267694, 0.9657890012358705, 0.9657890012358705, 0.9657890012358705, 0.45980975701796356, 0.45980975701796356, 0.45980975701796356, 0.4681230878038337, 0.4681230878038337, 0.4681230878038337, 0.44758607154996943, 0.44758607154996943, 0.44758607154996943, 0.6085425712489629, 0.6085425712489629, 0.6085425712489629, 0.20957159813370774, 0.20957159813370774, 0.20957159813370774, 0.6242941033348375, 0.6242941033348375, 0.6242941033348375, 0.28440122791973665, 0.28440122791973665, 0.28440122791973665, 0.17941135082496185, 0.17941135082496185, 0.17941135082496185, 0.21004310264644055, 0.21004310264644055, 0.21004310264644055, 0.12371066247296403, 0.12371066247296403, 0.12371066247296403, 0.16877769201705073, 0.16877769201705073, 0.16877769201705073, 0.20307775044351806, 0.20307775044351806, 0.20307775044351806, 0.02687115724511857, 0.02687115724511857, 0.02687115724511857, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13242971085842947, 0.13242971085842947, 0.13242971085842947, 0.05795945385659018, 0.05795945385659018, 0.05795945385659018, 0.05474758121295309, 0.05474758121295309, 0.05474758121295309, 0.15144093634144407, 0.15144093634144407, 0.15144093634144407, 0.05572586447509276, 0.05572586447509276, 0.05572586447509276, 0.05548678970757226, 0.05548678970757226, 0.05548678970757226, 0.05502267075377221, 0.05502267075377221, 0.05502267075377221, 0.1512046126614066, 0.1512046126614066, 0.1512046126614066, 0.12110653994598275, 0.12110653994598275, 0.12110653994598275, 0.16632556361284112, 0.16632556361284112, 0.16632556361284112, 0.48091828005873083, 0.48091828005873083, 0.48091828005873083, 0.48756619928724554, 0.48756619928724554, 0.48756619928724554, 0.5132144242651158, 0.5132144242651158, 0.5132144242651158, 0.09851083355689627, 0.09851083355689627, 0.09851083355689627, 0.1262383047429383, 0.1262383047429383, 0.1262383047429383, 0.13810130377699747, 0.13810130377699747, 0.13810130377699747, 0.30807949029910053, 0.30807949029910053, 0.30807949029910053, 0.256891144802493, 0.256891144802493, 0.256891144802493, 0.249884609242356, 0.249884609242356, 0.249884609242356, 0.37895844535013723, 0.37895844535013723, 0.37895844535013723, 0.2866130273104148, 0.2866130273104148, 0.2866130273104148, 0.30921624639470924, 0.30921624639470924, 0.30921624639470924, 0.2049567067322834, 0.2049567067322834, 0.2049567067322834, 0.2728600250179637, 0.2728600250179637, 0.2728600250179637, 0.22547338104824532, 0.22547338104824532, 0.22547338104824532, 0.22794618501899444, 0.22794618501899444, 0.22794618501899444, 0.21944272020387567, 0.21944272020387567, 0.21944272020387567, 0.24096641962435794, 0.24096641962435794, 0.24096641962435794, 0.20957285530533332, 0.20957285530533332, 0.20957285530533332, 0.19290974607125322, 0.19290974607125322, 0.19290974607125322, 0.19955438288380367, 0.19955438288380367, 0.19955438288380367, 0.8004574425066902, 0.8004574425066902, 0.8004574425066902, 0.15654631680435582, 0.15654631680435582, 0.15654631680435582, 0.8233836494246771, 0.8233836494246771, 0.8233836494246771, 0.6579376814905564, 0.6579376814905564, 0.6579376814905564, 0.4587947053321041, 0.4587947053321041, 0.4587947053321041, 0.28530499443961677, 0.28530499443961677, 0.28530499443961677, 0.18238958886661316, 0.18238958886661316, 0.18238958886661316, 0.20251529777225719, 0.20251529777225719, 0.20251529777225719, 0.2207864581559037, 0.2207864581559037, 0.2207864581559037, 0.08908119255746949, 0.08908119255746949, 0.08908119255746949, 0.10650807611131108, 0.10650807611131108, 0.10650807611131108, 0.10703352958438739, 0.10703352958438739, 0.10703352958438739]}, "mutation_prompt": null}
{"id": "ad580128-d6c1-4106-9623-7a87a1635b46", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "a570b62e-45f2-4d22-9d82-6666753d099c", "solution": "import numpy as np\n\nclass HybridAdaptiveVelocitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n        self.dimension_learning_rate = 0.05\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                # Dimensional learning enhancement\n                particles[i] += self.dimension_learning_rate * np.random.normal(0, 1, self.dim)\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "HybridAdaptiveVelocitySwarmOptimizer", "description": "A hybrid particle swarm optimizer with adaptive velocity scaling, elitism, logarithmic mutation, and dimensional learning enhancement for improved exploration and convergence.", "configspace": "", "generation": 82, "fitness": 0.24828990171699114, "feedback": "The algorithm HybridAdaptiveVelocitySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.22.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.48463636980025826, 0.48463636980025826, 0.48463636980025826, 0.45527475657846783, 0.45527475657846783, 0.45527475657846783, 0.49226104147989647, 0.49226104147989647, 0.49226104147989647, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13665623183004916, 0.13665623183004916, 0.13665623183004916, 0.18389572420886247, 0.18389572420886247, 0.18389572420886247, 0.12180638298219604, 0.12180638298219604, 0.12180638298219604, 0.12212898381504655, 0.12212898381504655, 0.12212898381504655, 0.11195736492318542, 0.11195736492318542, 0.11195736492318542, 0.10065372536495454, 0.10065372536495454, 0.10065372536495454, 0.9162308686875623, 0.9162308686875623, 0.9162308686875623, 0.9435660830719019, 0.9435660830719019, 0.9435660830719019, 0.9483789908043359, 0.9483789908043359, 0.9483789908043359, 0.3396870312099408, 0.3396870312099408, 0.3396870312099408, 0.3378314233843218, 0.3378314233843218, 0.3378314233843218, 0.32383143644147494, 0.32383143644147494, 0.32383143644147494, 0.22138622351970783, 0.22138622351970783, 0.22138622351970783, 0.27208177902310815, 0.27208177902310815, 0.27208177902310815, 0.6994852688266056, 0.6994852688266056, 0.6994852688266056, 0.17076416757416568, 0.17076416757416568, 0.17076416757416568, 0.12480367071388354, 0.12480367071388354, 0.12480367071388354, 0.18881935967813446, 0.18881935967813446, 0.18881935967813446, 0.16284114967139596, 0.16284114967139596, 0.16284114967139596, 0.12558211905487238, 0.12558211905487238, 0.12558211905487238, 0.19847428380700616, 0.19847428380700616, 0.19847428380700616, 0.04049735683884226, 0.04049735683884226, 0.04049735683884226, 0.015336269243834022, 0.015336269243834022, 0.015336269243834022, 0.046882166859954166, 0.046882166859954166, 0.046882166859954166, 0.06785212561990916, 0.06785212561990916, 0.06785212561990916, 0.05505922479412839, 0.05505922479412839, 0.05505922479412839, 0.15674825925501612, 0.15674825925501612, 0.15674825925501612, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1228898305646362, 0.1228898305646362, 0.1228898305646362, 0.09566190301521715, 0.09566190301521715, 0.09566190301521715, 0.15295227069333794, 0.15295227069333794, 0.15295227069333794, 0.4470586471244119, 0.4470586471244119, 0.4470586471244119, 0.4415906715757837, 0.4415906715757837, 0.4415906715757837, 0.4397866627503412, 0.4397866627503412, 0.4397866627503412, 0.12882467475599912, 0.12882467475599912, 0.12882467475599912, 0.10508435788645942, 0.10508435788645942, 0.10508435788645942, 0.09033722539800315, 0.09033722539800315, 0.09033722539800315, 0.29790186200310176, 0.29790186200310176, 0.29790186200310176, 0.2852361086375895, 0.2852361086375895, 0.2852361086375895, 0.3212652468107645, 0.3212652468107645, 0.3212652468107645, 0.28978643530452464, 0.28978643530452464, 0.28978643530452464, 0.3073859191333319, 0.3073859191333319, 0.3073859191333319, 0.33429828122406247, 0.33429828122406247, 0.33429828122406247, 0.25157947372921907, 0.25157947372921907, 0.25157947372921907, 0.25748706769518803, 0.25748706769518803, 0.25748706769518803, 0.24892921195885387, 0.24892921195885387, 0.24892921195885387, 0.2127438240856675, 0.2127438240856675, 0.2127438240856675, 0.292011367236218, 0.292011367236218, 0.292011367236218, 0.23772309389353163, 0.23772309389353163, 0.23772309389353163, 0.2046813105240447, 0.2046813105240447, 0.2046813105240447, 0.24054396100820596, 0.24054396100820596, 0.24054396100820596, 0.19376368232881214, 0.19376368232881214, 0.19376368232881214, 0.71765414664393, 0.71765414664393, 0.71765414664393, 0.15707993173361412, 0.15707993173361412, 0.15707993173361412, 0.7560465924546534, 0.7560465924546534, 0.7560465924546534, 0.5175507004266953, 0.5175507004266953, 0.5175507004266953, 0.21082616246812402, 0.21082616246812402, 0.21082616246812402, 0.12723473646509942, 0.12723473646509942, 0.12723473646509942, 0.1776861244829806, 0.1776861244829806, 0.1776861244829806, 0.17134253524530718, 0.17134253524530718, 0.17134253524530718, 0.18077958382269876, 0.18077958382269876, 0.18077958382269876, 0.09537106298981546, 0.09537106298981546, 0.09537106298981546, 0.09988339959495829, 0.09988339959495829, 0.09988339959495829, 0.09988501889516266, 0.09988501889516266, 0.09988501889516266]}, "mutation_prompt": null}
{"id": "5d2fecb0-3d13-47ab-b188-49358c623f23", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "46c5c803-71ff-4590-9ad6-d669db4350c3", "solution": "import numpy as np\n\nclass EnhancedAdaptiveVelocitySwarmOptimizerWithInverseSquareMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale / np.sqrt((evaluations / self.budget) + 1e-5), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight = max(0.4, self.inertia_weight * self.learning_rate_decay)\n            self.cognitive_weight = min(2.0, self.cognitive_weight * self.learning_rate_decay)\n            self.social_weight = min(2.0, self.social_weight * self.learning_rate_decay)\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedAdaptiveVelocitySwarmOptimizerWithInverseSquareMutation", "description": "An enhanced particle swarm optimizer with adaptive velocity, elitism, novel inverse square mutation, and dynamic parameter tuning for balanced exploration and exploitation.", "configspace": "", "generation": 84, "fitness": 0.28813441727270483, "feedback": "The algorithm EnhancedAdaptiveVelocitySwarmOptimizerWithInverseSquareMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.68163866911843, 0.68163866911843, 0.68163866911843, 0.6800683127511469, 0.6800683127511469, 0.6800683127511469, 0.6597062709169936, 0.6597062709169936, 0.6597062709169936, 0.12104498573228262, 0.12104498573228262, 0.12104498573228262, 0.15415220662160078, 0.15415220662160078, 0.15415220662160078, 0.36731154678271616, 0.36731154678271616, 0.36731154678271616, 0.14453249021323977, 0.14453249021323977, 0.14453249021323977, 0.14888082788014567, 0.14888082788014567, 0.14888082788014567, 0.1580281979259096, 0.1580281979259096, 0.1580281979259096, 0.10127113226556106, 0.10127113226556106, 0.10127113226556106, 0.14228394405006917, 0.14228394405006917, 0.14228394405006917, 0.11503686104734023, 0.11503686104734023, 0.11503686104734023, 0.9461886500088164, 0.9461886500088164, 0.9461886500088164, 0.9599801803635611, 0.9599801803635611, 0.9599801803635611, 0.955409247856669, 0.955409247856669, 0.955409247856669, 0.44854441729746, 0.44854441729746, 0.44854441729746, 0.43197164841091107, 0.43197164841091107, 0.43197164841091107, 0.43606422361272346, 0.43606422361272346, 0.43606422361272346, 0.22096274318234232, 0.22096274318234232, 0.22096274318234232, 0.20746655518460666, 0.20746655518460666, 0.20746655518460666, 0.7624850836690368, 0.7624850836690368, 0.7624850836690368, 0.18377691700589016, 0.18377691700589016, 0.18377691700589016, 0.1528532049461524, 0.1528532049461524, 0.1528532049461524, 0.1747949706853047, 0.1747949706853047, 0.1747949706853047, 0.11759403525126344, 0.11759403525126344, 0.11759403525126344, 0.14117570066009344, 0.14117570066009344, 0.14117570066009344, 0.1777073587934972, 0.1777073587934972, 0.1777073587934972, 0.03323429778673548, 0.03323429778673548, 0.03323429778673548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09230160941007304, 0.09230160941007304, 0.09230160941007304, 0.079883384389419, 0.079883384389419, 0.079883384389419, 0.052561697536037566, 0.052561697536037566, 0.052561697536037566, 0.11314578532405573, 0.11314578532405573, 0.11314578532405573, 0.10430635022102253, 0.10430635022102253, 0.10430635022102253, 0.11924811148684478, 0.11924811148684478, 0.11924811148684478, 0.062077172142172454, 0.062077172142172454, 0.062077172142172454, 0.12476915143312217, 0.12476915143312217, 0.12476915143312217, 0.1354120163270256, 0.1354120163270256, 0.1354120163270256, 0.0536650688131034, 0.0536650688131034, 0.0536650688131034, 0.49259903094969315, 0.49259903094969315, 0.49259903094969315, 0.49618568840470934, 0.49618568840470934, 0.49618568840470934, 0.5104184429554881, 0.5104184429554881, 0.5104184429554881, 0.11357116276344892, 0.11357116276344892, 0.11357116276344892, 0.13595610849657513, 0.13595610849657513, 0.13595610849657513, 0.11242453585879353, 0.11242453585879353, 0.11242453585879353, 0.34534126657331254, 0.34534126657331254, 0.34534126657331254, 0.261484306031334, 0.261484306031334, 0.261484306031334, 0.28786496620536206, 0.28786496620536206, 0.28786496620536206, 0.3097546915102568, 0.3097546915102568, 0.3097546915102568, 0.35343407284944617, 0.35343407284944617, 0.35343407284944617, 0.36619098142320095, 0.36619098142320095, 0.36619098142320095, 0.20420676372046642, 0.20420676372046642, 0.20420676372046642, 0.2862863186177814, 0.2862863186177814, 0.2862863186177814, 0.21816320553609336, 0.21816320553609336, 0.21816320553609336, 0.21540475926492852, 0.21540475926492852, 0.21540475926492852, 0.22507444825177958, 0.22507444825177958, 0.22507444825177958, 0.2228069165008041, 0.2228069165008041, 0.2228069165008041, 0.23259128391546224, 0.23259128391546224, 0.23259128391546224, 0.20079474909216355, 0.20079474909216355, 0.20079474909216355, 0.21648345880997166, 0.21648345880997166, 0.21648345880997166, 0.7964754187826177, 0.7964754187826177, 0.7964754187826177, 0.15809420827358323, 0.15809420827358323, 0.15809420827358323, 0.8257318031792076, 0.8257318031792076, 0.8257318031792076, 0.7740904360217369, 0.7740904360217369, 0.7740904360217369, 0.20990228114667975, 0.20990228114667975, 0.20990228114667975, 0.5471930010432731, 0.5471930010432731, 0.5471930010432731, 0.20428126641092237, 0.20428126641092237, 0.20428126641092237, 0.18070327923528273, 0.18070327923528273, 0.18070327923528273, 0.18582046950701103, 0.18582046950701103, 0.18582046950701103, 0.0917248916402954, 0.0917248916402954, 0.0917248916402954, 0.09317920941188074, 0.09317920941188074, 0.09317920941188074, 0.109809594147811, 0.109809594147811, 0.109809594147811]}, "mutation_prompt": null}
{"id": "0df648dd-04d2-4b2b-8af3-32107a8273ad", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithGaussianMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.exp(-evaluations / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithGaussianMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel Gaussian mutation strategy for enhanced exploration and convergence.", "configspace": "", "generation": 85, "fitness": 0.30693025861153533, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithGaussianMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.26.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.7949939528636184, 0.7949939528636184, 0.7949939528636184, 0.7822937252969002, 0.7822937252969002, 0.7822937252969002, 0.7983720560390458, 0.7983720560390458, 0.7983720560390458, 0.11099925897481822, 0.11099925897481822, 0.11099925897481822, 0.3210265286703128, 0.3210265286703128, 0.3210265286703128, 0.07767426569587621, 0.07767426569587621, 0.07767426569587621, 0.1392580820146635, 0.1392580820146635, 0.1392580820146635, 0.1337283712474584, 0.1337283712474584, 0.1337283712474584, 0.10454143360029522, 0.10454143360029522, 0.10454143360029522, 0.12415081743793055, 0.12415081743793055, 0.12415081743793055, 0.1650855978262331, 0.1650855978262331, 0.1650855978262331, 0.1277671227586794, 0.1277671227586794, 0.1277671227586794, 0.9449665400409248, 0.9449665400409248, 0.9449665400409248, 0.9570399195664193, 0.9570399195664193, 0.9570399195664193, 0.9555906704451641, 0.9555906704451641, 0.9555906704451641, 0.4794029919818862, 0.4794029919818862, 0.4794029919818862, 0.5296843918636371, 0.5296843918636371, 0.5296843918636371, 0.5209183923975546, 0.5209183923975546, 0.5209183923975546, 0.219658655736802, 0.219658655736802, 0.219658655736802, 0.2097257140399139, 0.2097257140399139, 0.2097257140399139, 0.7709414482379905, 0.7709414482379905, 0.7709414482379905, 0.12018909050499227, 0.12018909050499227, 0.12018909050499227, 0.12409130867860019, 0.12409130867860019, 0.12409130867860019, 0.17064147276619113, 0.17064147276619113, 0.17064147276619113, 0.1880509159257936, 0.1880509159257936, 0.1880509159257936, 0.15493989244690787, 0.15493989244690787, 0.15493989244690787, 0.18858509944430957, 0.18858509944430957, 0.18858509944430957, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010114033036244696, 0.010114033036244696, 0.010114033036244696, 0.12409930105993228, 0.12409930105993228, 0.12409930105993228, 0.051943373963193484, 0.051943373963193484, 0.051943373963193484, 0.10501763697366606, 0.10501763697366606, 0.10501763697366606, 0.11232618538720784, 0.11232618538720784, 0.11232618538720784, 0.32244908197724675, 0.32244908197724675, 0.32244908197724675, 0.08527735503762379, 0.08527735503762379, 0.08527735503762379, 0.09256543532376438, 0.09256543532376438, 0.09256543532376438, 0.15403931508846458, 0.15403931508846458, 0.15403931508846458, 0.05443545354371526, 0.05443545354371526, 0.05443545354371526, 0.4996815423873303, 0.4996815423873303, 0.4996815423873303, 0.5605699278413336, 0.5605699278413336, 0.5605699278413336, 0.5407519428440578, 0.5407519428440578, 0.5407519428440578, 0.13638690293617406, 0.13638690293617406, 0.13638690293617406, 0.13131833748792743, 0.13131833748792743, 0.13131833748792743, 0.13782573468757386, 0.13782573468757386, 0.13782573468757386, 0.20865041453850497, 0.20865041453850497, 0.20865041453850497, 0.3022748002325225, 0.3022748002325225, 0.3022748002325225, 0.36781811753865357, 0.36781811753865357, 0.36781811753865357, 0.4235824370686593, 0.4235824370686593, 0.4235824370686593, 0.45438352996511644, 0.45438352996511644, 0.45438352996511644, 0.44638364790226104, 0.44638364790226104, 0.44638364790226104, 0.22474212907715863, 0.22474212907715863, 0.22474212907715863, 0.2792665473886712, 0.2792665473886712, 0.2792665473886712, 0.2320039429088343, 0.2320039429088343, 0.2320039429088343, 0.19912911601393035, 0.19912911601393035, 0.19912911601393035, 0.22202079397719277, 0.22202079397719277, 0.22202079397719277, 0.24965544572051235, 0.24965544572051235, 0.24965544572051235, 0.2077643280749445, 0.2077643280749445, 0.2077643280749445, 0.2367154349075561, 0.2367154349075561, 0.2367154349075561, 0.5722672188496387, 0.5722672188496387, 0.5722672188496387, 0.8717076551157268, 0.8717076551157268, 0.8717076551157268, 0.15802362628169309, 0.15802362628169309, 0.15802362628169309, 0.8434187445837726, 0.8434187445837726, 0.8434187445837726, 0.6599875461254872, 0.6599875461254872, 0.6599875461254872, 0.21082787443176798, 0.21082787443176798, 0.21082787443176798, 0.510540510340296, 0.510540510340296, 0.510540510340296, 0.1804804240779766, 0.1804804240779766, 0.1804804240779766, 0.2019106604744082, 0.2019106604744082, 0.2019106604744082, 0.1850530452204009, 0.1850530452204009, 0.1850530452204009, 0.09921663827004945, 0.09921663827004945, 0.09921663827004945, 0.09249462909599837, 0.09249462909599837, 0.09249462909599837, 0.1253400857704371, 0.1253400857704371, 0.1253400857704371]}, "mutation_prompt": null}
{"id": "5cfda2c9-38fc-456f-9543-d870daf90d4d", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "2bbffc95-b906-4202-b9be-0511a49146d7", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "db04edf1-ddbd-4a3b-b02c-c507ada48cbb", "solution": "import numpy as np\n\nclass EnhancedSwarmOptimizerWithRestartAndLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.95  # Slightly faster decay\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n        self.restart_threshold = 0.1  # Restart mechanism threshold\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n            \n            if np.random.rand() < self.restart_threshold:\n                restart_index = np.random.randint(0, self.population_size)\n                particles[restart_index] = np.random.uniform(self.lb, self.ub, self.dim)\n                velocities[restart_index] = np.random.uniform(-self.vel_bound, self.vel_bound, self.dim)\n        \n        return self.global_best_value", "name": "EnhancedSwarmOptimizerWithRestartAndLogarithmicMutation", "description": "An enhanced particle swarm optimizer with adaptive velocity, elitism, random deep-restart, and a logarithmic mutation strategy for robust exploration and convergence.", "configspace": "", "generation": 88, "fitness": 0.28968457702870004, "feedback": "The algorithm EnhancedSwarmOptimizerWithRestartAndLogarithmicMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.25.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.6780065799446131, 0.6780065799446131, 0.6780065799446131, 0.7695169824922083, 0.7695169824922083, 0.7695169824922083, 0.6442124563766344, 0.6442124563766344, 0.6442124563766344, 0.052373972558965365, 0.052373972558965365, 0.052373972558965365, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.052103865530417015, 0.052103865530417015, 0.052103865530417015, 0.15294407362403217, 0.15294407362403217, 0.15294407362403217, 0.14111653674253322, 0.14111653674253322, 0.14111653674253322, 0.08709169298217678, 0.08709169298217678, 0.08709169298217678, 0.10249018081161287, 0.10249018081161287, 0.10249018081161287, 0.08316223994827165, 0.08316223994827165, 0.08316223994827165, 0.08173768571606999, 0.08173768571606999, 0.08173768571606999, 0.9491072961295648, 0.9491072961295648, 0.9491072961295648, 0.9563010320675427, 0.9563010320675427, 0.9563010320675427, 0.9479025844831687, 0.9479025844831687, 0.9479025844831687, 0.4257602046299368, 0.4257602046299368, 0.4257602046299368, 0.3972041471645016, 0.3972041471645016, 0.3972041471645016, 0.4521288436078943, 0.4521288436078943, 0.4521288436078943, 0.8804917255758877, 0.8804917255758877, 0.8804917255758877, 0.20690633122161695, 0.20690633122161695, 0.20690633122161695, 0.23102127902678493, 0.23102127902678493, 0.23102127902678493, 0.18018401765053516, 0.18018401765053516, 0.18018401765053516, 0.18463270857319636, 0.18463270857319636, 0.18463270857319636, 0.14823140867677997, 0.14823140867677997, 0.14823140867677997, 0.1391259953654751, 0.1391259953654751, 0.1391259953654751, 0.1383694270299729, 0.1383694270299729, 0.1383694270299729, 0.21841596832178956, 0.21841596832178956, 0.21841596832178956, 0.17144046015646164, 0.17144046015646164, 0.17144046015646164, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013221420759819358, 0.013221420759819358, 0.013221420759819358, 0.07541862303997515, 0.07541862303997515, 0.07541862303997515, 0.031970081129925165, 0.031970081129925165, 0.031970081129925165, 0.13222193739687593, 0.13222193739687593, 0.13222193739687593, 0.09077544398676107, 0.09077544398676107, 0.09077544398676107, 0.13576060813216795, 0.13576060813216795, 0.13576060813216795, 0.07991722387162603, 0.07991722387162603, 0.07991722387162603, 0.055872865437571306, 0.055872865437571306, 0.055872865437571306, 0.0939071741533517, 0.0939071741533517, 0.0939071741533517, 0.17599463609150356, 0.17599463609150356, 0.17599463609150356, 0.47993286177334316, 0.47993286177334316, 0.47993286177334316, 0.5814404819840869, 0.5814404819840869, 0.5814404819840869, 0.49407250443587114, 0.49407250443587114, 0.49407250443587114, 0.10714564831650186, 0.10714564831650186, 0.10714564831650186, 0.11924988396218172, 0.11924988396218172, 0.11924988396218172, 0.0895262720590807, 0.0895262720590807, 0.0895262720590807, 0.20196962652000372, 0.20196962652000372, 0.20196962652000372, 0.4520955254994815, 0.4520955254994815, 0.4520955254994815, 0.43218068397492393, 0.43218068397492393, 0.43218068397492393, 0.4116371010602118, 0.4116371010602118, 0.4116371010602118, 0.3744742893173224, 0.3744742893173224, 0.3744742893173224, 0.41910297871102975, 0.41910297871102975, 0.41910297871102975, 0.2145530247335551, 0.2145530247335551, 0.2145530247335551, 0.27941556556066105, 0.27941556556066105, 0.27941556556066105, 0.18271159973769502, 0.18271159973769502, 0.18271159973769502, 0.2467730539965859, 0.2467730539965859, 0.2467730539965859, 0.21244053968014964, 0.21244053968014964, 0.21244053968014964, 0.372101924184148, 0.372101924184148, 0.372101924184148, 0.23601934872880714, 0.23601934872880714, 0.23601934872880714, 0.24883318712051206, 0.24883318712051206, 0.24883318712051206, 0.20118538879153425, 0.20118538879153425, 0.20118538879153425, 0.9076785633056458, 0.9076785633056458, 0.9076785633056458, 0.15789876386757606, 0.15789876386757606, 0.15789876386757606, 0.8469472394640443, 0.8469472394640443, 0.8469472394640443, 0.5526239803837603, 0.5526239803837603, 0.5526239803837603, 0.2115189489580961, 0.2115189489580961, 0.2115189489580961, 0.5733335259535783, 0.5733335259535783, 0.5733335259535783, 0.18586250533702742, 0.18586250533702742, 0.18586250533702742, 0.19662254199457407, 0.19662254199457407, 0.19662254199457407, 0.17856363266433095, 0.17856363266433095, 0.17856363266433095, 0.09798924429845379, 0.09798924429845379, 0.09798924429845379, 0.09880319695707518, 0.09880319695707518, 0.09880319695707518, 0.1353462023263342, 0.1353462023263342, 0.1353462023263342]}, "mutation_prompt": null}
{"id": "40787fdc-638a-4295-935c-6d92f8b39481", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "35430cf7-31dc-41be-974b-839f35c85832", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.15  # Slightly increased mutation probability\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n        self.dual_mutation_prob = 0.05  # Added a new parameter for dual mutation\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n\n                if np.random.rand() < self.dual_mutation_prob:  # Apply a secondary mutation strategy\n                    dual_mutation_vector = np.random.laplace(0, self.mutation_scale * np.sqrt((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += dual_mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhanced dynamic particle swarm optimizer with adaptive velocity, elitism, dual mutation strategies, and decaying weights for robust optimization.", "configspace": "", "generation": 90, "fitness": 0.2919212402850822, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.7354437525629018, 0.7354437525629018, 0.7354437525629018, 0.707132367520316, 0.707132367520316, 0.707132367520316, 0.7131973733049214, 0.7131973733049214, 0.7131973733049214, 0.18816940272325466, 0.18816940272325466, 0.18816940272325466, 0.09846089412945802, 0.09846089412945802, 0.09846089412945802, 0.1324171979719302, 0.1324171979719302, 0.1324171979719302, 0.13709261988206034, 0.13709261988206034, 0.13709261988206034, 0.1365248029815772, 0.1365248029815772, 0.1365248029815772, 0.11211609005399858, 0.11211609005399858, 0.11211609005399858, 0.11098836467329143, 0.11098836467329143, 0.11098836467329143, 0.11257135587042644, 0.11257135587042644, 0.11257135587042644, 0.10876138693311765, 0.10876138693311765, 0.10876138693311765, 0.9502059407196265, 0.9502059407196265, 0.9502059407196265, 0.9475726191742159, 0.9475726191742159, 0.9475726191742159, 0.9551804293466654, 0.9551804293466654, 0.9551804293466654, 0.4740868463878509, 0.4740868463878509, 0.4740868463878509, 0.4825088902057998, 0.4825088902057998, 0.4825088902057998, 0.46073424192306645, 0.46073424192306645, 0.46073424192306645, 0.2232872455073991, 0.2232872455073991, 0.2232872455073991, 0.18301620232036453, 0.18301620232036453, 0.18301620232036453, 0.13291559510907247, 0.13291559510907247, 0.13291559510907247, 0.1705379766975893, 0.1705379766975893, 0.1705379766975893, 0.18530061865974523, 0.18530061865974523, 0.18530061865974523, 0.17257823802411643, 0.17257823802411643, 0.17257823802411643, 0.16538573438348247, 0.16538573438348247, 0.16538573438348247, 0.22227499824605468, 0.22227499824605468, 0.22227499824605468, 0.17909961334139857, 0.17909961334139857, 0.17909961334139857, 0.10419639347118137, 0.10419639347118137, 0.10419639347118137, 0.10883512992563615, 0.10883512992563615, 0.10883512992563615, 0.06554433192620313, 0.06554433192620313, 0.06554433192620313, 0.16485438508747252, 0.16485438508747252, 0.16485438508747252, 0.054337030482210724, 0.054337030482210724, 0.054337030482210724, 0.1734997665389859, 0.1734997665389859, 0.1734997665389859, 0.04071831233545076, 0.04071831233545076, 0.04071831233545076, 0.11889401564674795, 0.11889401564674795, 0.11889401564674795, 0.08321624377437054, 0.08321624377437054, 0.08321624377437054, 0.24149893028433644, 0.24149893028433644, 0.24149893028433644, 0.1098669735803478, 0.1098669735803478, 0.1098669735803478, 0.18679108770547903, 0.18679108770547903, 0.18679108770547903, 0.5506270651011682, 0.5506270651011682, 0.5506270651011682, 0.5311785253014807, 0.5311785253014807, 0.5311785253014807, 0.48394488224283616, 0.48394488224283616, 0.48394488224283616, 0.13384171304742554, 0.13384171304742554, 0.13384171304742554, 0.11095870844750555, 0.11095870844750555, 0.11095870844750555, 0.08033012835008868, 0.08033012835008868, 0.08033012835008868, 0.18843989875527456, 0.18843989875527456, 0.18843989875527456, 0.34028797249477494, 0.34028797249477494, 0.34028797249477494, 0.3746277626476817, 0.3746277626476817, 0.3746277626476817, 0.41253290216097616, 0.41253290216097616, 0.41253290216097616, 0.39208953526985413, 0.39208953526985413, 0.39208953526985413, 0.27445004410518403, 0.27445004410518403, 0.27445004410518403, 0.258039422553772, 0.258039422553772, 0.258039422553772, 0.3162476172433124, 0.3162476172433124, 0.3162476172433124, 0.20217603171687637, 0.20217603171687637, 0.20217603171687637, 0.2464138702250449, 0.2464138702250449, 0.2464138702250449, 0.2347766738426974, 0.2347766738426974, 0.2347766738426974, 0.2246080775599858, 0.2246080775599858, 0.2246080775599858, 0.21247820438793752, 0.21247820438793752, 0.21247820438793752, 0.2200978286144687, 0.2200978286144687, 0.2200978286144687, 0.19974491899835844, 0.19974491899835844, 0.19974491899835844, 0.8741197593457011, 0.8741197593457011, 0.8741197593457011, 0.15711924004792888, 0.15711924004792888, 0.15711924004792888, 0.872074126415275, 0.872074126415275, 0.872074126415275, 0.6823775597587549, 0.6823775597587549, 0.6823775597587549, 0.20955570501303888, 0.20955570501303888, 0.20955570501303888, 0.7301610039244343, 0.7301610039244343, 0.7301610039244343, 0.1886995185588909, 0.1886995185588909, 0.1886995185588909, 0.18344355448495242, 0.18344355448495242, 0.18344355448495242, 0.18867483271376317, 0.18867483271376317, 0.18867483271376317, 0.0928538743247298, 0.0928538743247298, 0.0928538743247298, 0.09812555426332004, 0.09812555426332004, 0.09812555426332004, 0.10341938919630289, 0.10341938919630289, 0.10341938919630289]}, "mutation_prompt": null}
{"id": "0e28dc05-92ab-4fb1-a0ef-1b3693b31951", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithGaussianMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.5\n        self.social_weight = 1.8\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale, self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithGaussianMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, Gaussian mutation, and a decaying inertia strategy for robust exploration and convergence.", "configspace": "", "generation": 91, "fitness": 0.2947067698783243, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithGaussianMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.26.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.8075366841181841, 0.8075366841181841, 0.8075366841181841, 0.7600249992295887, 0.7600249992295887, 0.7600249992295887, 0.7852274866918947, 0.7852274866918947, 0.7852274866918947, 0.15301458827160963, 0.15301458827160963, 0.15301458827160963, 0.11767603706242158, 0.11767603706242158, 0.11767603706242158, 0.07515648838285593, 0.07515648838285593, 0.07515648838285593, 0.13088610489172026, 0.13088610489172026, 0.13088610489172026, 0.09781672669571306, 0.09781672669571306, 0.09781672669571306, 0.1705239322204285, 0.1705239322204285, 0.1705239322204285, 0.10592990061452034, 0.10592990061452034, 0.10592990061452034, 0.11690369089163888, 0.11690369089163888, 0.11690369089163888, 0.16639141126420176, 0.16639141126420176, 0.16639141126420176, 0.94719231244901, 0.94719231244901, 0.94719231244901, 0.961391569952449, 0.961391569952449, 0.961391569952449, 0.9560253469117493, 0.9560253469117493, 0.9560253469117493, 0.4613866981922009, 0.4613866981922009, 0.4613866981922009, 0.48934699867614007, 0.48934699867614007, 0.48934699867614007, 0.479789890994761, 0.479789890994761, 0.479789890994761, 0.7998732489886321, 0.7998732489886321, 0.7998732489886321, 0.267135029126491, 0.267135029126491, 0.267135029126491, 0.2162174227412138, 0.2162174227412138, 0.2162174227412138, 0.12464832796537573, 0.12464832796537573, 0.12464832796537573, 0.1834512554740234, 0.1834512554740234, 0.1834512554740234, 0.18206571994022702, 0.18206571994022702, 0.18206571994022702, 0.1201942616126136, 0.1201942616126136, 0.1201942616126136, 0.12401581515339055, 0.12401581515339055, 0.12401581515339055, 0.18104268719711836, 0.18104268719711836, 0.18104268719711836, 0.09739210350223437, 0.09739210350223437, 0.09739210350223437, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014398367636147102, 0.014398367636147102, 0.014398367636147102, 0.1494943632508292, 0.1494943632508292, 0.1494943632508292, 0.02093578520668926, 0.02093578520668926, 0.02093578520668926, 0.11377898789122098, 0.11377898789122098, 0.11377898789122098, 0.14804058919250507, 0.14804058919250507, 0.14804058919250507, 0.14495611719985102, 0.14495611719985102, 0.14495611719985102, 0.15468816459991463, 0.15468816459991463, 0.15468816459991463, 0.059144619610714266, 0.059144619610714266, 0.059144619610714266, 0.1260404074953836, 0.1260404074953836, 0.1260404074953836, 0.05350970584178938, 0.05350970584178938, 0.05350970584178938, 0.48887345807323834, 0.48887345807323834, 0.48887345807323834, 0.5755806878500977, 0.5755806878500977, 0.5755806878500977, 0.5083033538195323, 0.5083033538195323, 0.5083033538195323, 0.14751918169766232, 0.14751918169766232, 0.14751918169766232, 0.14460904319125145, 0.14460904319125145, 0.14460904319125145, 0.1062258991342293, 0.1062258991342293, 0.1062258991342293, 0.2846541177603734, 0.2846541177603734, 0.2846541177603734, 0.23941461367080097, 0.23941461367080097, 0.23941461367080097, 0.19320080380644888, 0.19320080380644888, 0.19320080380644888, 0.40536434152948764, 0.40536434152948764, 0.40536434152948764, 0.2756278237868731, 0.2756278237868731, 0.2756278237868731, 0.44703339472349135, 0.44703339472349135, 0.44703339472349135, 0.2696245494134777, 0.2696245494134777, 0.2696245494134777, 0.3150951555682968, 0.3150951555682968, 0.3150951555682968, 0.2050317905559913, 0.2050317905559913, 0.2050317905559913, 0.2517924057701546, 0.2517924057701546, 0.2517924057701546, 0.2123599260259441, 0.2123599260259441, 0.2123599260259441, 0.23589930977073714, 0.23589930977073714, 0.23589930977073714, 0.20418505796426356, 0.20418505796426356, 0.20418505796426356, 0.17751713830608273, 0.17751713830608273, 0.17751713830608273, 0.19491446801121437, 0.19491446801121437, 0.19491446801121437, 0.8774653914705466, 0.8774653914705466, 0.8774653914705466, 0.15696175977720928, 0.15696175977720928, 0.15696175977720928, 0.8443193166830377, 0.8443193166830377, 0.8443193166830377, 0.5590788091931156, 0.5590788091931156, 0.5590788091931156, 0.20966460930344455, 0.20966460930344455, 0.20966460930344455, 0.6977706243911881, 0.6977706243911881, 0.6977706243911881, 0.2064183971355562, 0.2064183971355562, 0.2064183971355562, 0.2204375140234751, 0.2204375140234751, 0.2204375140234751, 0.18968387366560857, 0.18968387366560857, 0.18968387366560857, 0.09770804677516476, 0.09770804677516476, 0.09770804677516476, 0.09324513630087827, 0.09324513630087827, 0.09324513630087827, 0.11996358495302162, 0.11996358495302162, 0.11996358495302162]}, "mutation_prompt": null}
{"id": "5ee07861-5591-45e1-a102-4b56f5885750", "solution": "import numpy as np\n\nclass EnhancedSwarmOptimizerWithExponentialDecayMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.exp(-evaluations / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "EnhancedSwarmOptimizerWithExponentialDecayMutation", "description": "An enhanced particle swarm optimizer with adaptive velocity, elite preservation, exponential mutation decay, and learning rate annealing for robust exploration and convergence.", "configspace": "", "generation": 92, "fitness": 0.29960852681040495, "feedback": "The algorithm EnhancedSwarmOptimizerWithExponentialDecayMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.25.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.7212818381624316, 0.7212818381624316, 0.7212818381624316, 0.7222031973577043, 0.7222031973577043, 0.7222031973577043, 0.6918465416953332, 0.6918465416953332, 0.6918465416953332, 0.09868577931519451, 0.09868577931519451, 0.09868577931519451, 0.48776056237611287, 0.48776056237611287, 0.48776056237611287, 0.34167828957620605, 0.34167828957620605, 0.34167828957620605, 0.14177598986183404, 0.14177598986183404, 0.14177598986183404, 0.15934645032625105, 0.15934645032625105, 0.15934645032625105, 0.16412649742819008, 0.16412649742819008, 0.16412649742819008, 0.12975273636055173, 0.12975273636055173, 0.12975273636055173, 0.12804779529297716, 0.12804779529297716, 0.12804779529297716, 0.10657574485485255, 0.10657574485485255, 0.10657574485485255, 0.9452363683338482, 0.9452363683338482, 0.9452363683338482, 0.9570641468304253, 0.9570641468304253, 0.9570641468304253, 0.955960647269848, 0.955960647269848, 0.955960647269848, 0.5375284802566194, 0.5375284802566194, 0.5375284802566194, 0.4107162184809655, 0.4107162184809655, 0.4107162184809655, 0.48233411299944173, 0.48233411299944173, 0.48233411299944173, 0.16840817362483262, 0.16840817362483262, 0.16840817362483262, 0.3510040523213309, 0.3510040523213309, 0.3510040523213309, 0.22796270580345057, 0.22796270580345057, 0.22796270580345057, 0.11559722579153586, 0.11559722579153586, 0.11559722579153586, 0.19381926296874086, 0.19381926296874086, 0.19381926296874086, 0.18671803300228396, 0.18671803300228396, 0.18671803300228396, 0.1876039824265049, 0.1876039824265049, 0.1876039824265049, 0.18360359677663018, 0.18360359677663018, 0.18360359677663018, 0.21748177853192263, 0.21748177853192263, 0.21748177853192263, 0.0008345889871230749, 0.0008345889871230749, 0.0008345889871230749, 0.006845190668503753, 0.006845190668503753, 0.006845190668503753, 0.13486991475156396, 0.13486991475156396, 0.13486991475156396, 0.09509260267208197, 0.09509260267208197, 0.09509260267208197, 0.048155557736540455, 0.048155557736540455, 0.048155557736540455, 0.16137528577859173, 0.16137528577859173, 0.16137528577859173, 0.08159049955563369, 0.08159049955563369, 0.08159049955563369, 0.09914799637071758, 0.09914799637071758, 0.09914799637071758, 0.0684050624316569, 0.0684050624316569, 0.0684050624316569, 0.09954908702704268, 0.09954908702704268, 0.09954908702704268, 0.13988378938200408, 0.13988378938200408, 0.13988378938200408, 0.054079895695516855, 0.054079895695516855, 0.054079895695516855, 0.5022067862170536, 0.5022067862170536, 0.5022067862170536, 0.46503299347309335, 0.46503299347309335, 0.46503299347309335, 0.5541730981418702, 0.5541730981418702, 0.5541730981418702, 0.13681596795204132, 0.13681596795204132, 0.13681596795204132, 0.1154867356997683, 0.1154867356997683, 0.1154867356997683, 0.08697371608003235, 0.08697371608003235, 0.08697371608003235, 0.24210634752243188, 0.24210634752243188, 0.24210634752243188, 0.19782091236808697, 0.19782091236808697, 0.19782091236808697, 0.16532581186224593, 0.16532581186224593, 0.16532581186224593, 0.33597548365354246, 0.33597548365354246, 0.33597548365354246, 0.38755195417816, 0.38755195417816, 0.38755195417816, 0.427525797879053, 0.427525797879053, 0.427525797879053, 0.29245801281202977, 0.29245801281202977, 0.29245801281202977, 0.31970200316835684, 0.31970200316835684, 0.31970200316835684, 0.2204951433170277, 0.2204951433170277, 0.2204951433170277, 0.23724149922408788, 0.23724149922408788, 0.23724149922408788, 0.26571690818230287, 0.26571690818230287, 0.26571690818230287, 0.2195529552022496, 0.2195529552022496, 0.2195529552022496, 0.5368761940308993, 0.5368761940308993, 0.5368761940308993, 0.23583782434289702, 0.23583782434289702, 0.23583782434289702, 0.21838562885086787, 0.21838562885086787, 0.21838562885086787, 0.8164560775539182, 0.8164560775539182, 0.8164560775539182, 0.15782411475371305, 0.15782411475371305, 0.15782411475371305, 0.8165754065148383, 0.8165754065148383, 0.8165754065148383, 0.7784320863846994, 0.7784320863846994, 0.7784320863846994, 0.20980426710788358, 0.20980426710788358, 0.20980426710788358, 0.7367961275060935, 0.7367961275060935, 0.7367961275060935, 0.189270386777302, 0.189270386777302, 0.189270386777302, 0.18895341611987293, 0.18895341611987293, 0.18895341611987293, 0.19685493320213898, 0.19685493320213898, 0.19685493320213898, 0.09019225816617549, 0.09019225816617549, 0.09019225816617549, 0.09629233458806397, 0.09629233458806397, 0.09629233458806397, 0.12715106843336288, 0.12715106843336288, 0.12715106843336288]}, "mutation_prompt": null}
{"id": "5e478df9-3780-4afd-b707-b2b9f384efe6", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithRefinedGaussianMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.01\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.sqrt((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithRefinedGaussianMutation", "description": "A dynamic particle swarm optimizer that integrates adaptive learning rates, elitism, and a refined Gaussian mutation strategy for enhanced exploration and stability.", "configspace": "", "generation": 93, "fitness": 0.2990082181012191, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithRefinedGaussianMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.8206925416031665, 0.8206925416031665, 0.8206925416031665, 0.8034869765020881, 0.8034869765020881, 0.8034869765020881, 0.8221015548545119, 0.8221015548545119, 0.8221015548545119, 0.15848581610923462, 0.15848581610923462, 0.15848581610923462, 0.19020635978307765, 0.19020635978307765, 0.19020635978307765, 0.01571426391442221, 0.01571426391442221, 0.01571426391442221, 0.1391589745975509, 0.1391589745975509, 0.1391589745975509, 0.11754344754064072, 0.11754344754064072, 0.11754344754064072, 0.13767902332753834, 0.13767902332753834, 0.13767902332753834, 0.13721122128763275, 0.13721122128763275, 0.13721122128763275, 0.1691482199994342, 0.1691482199994342, 0.1691482199994342, 0.09256039039206787, 0.09256039039206787, 0.09256039039206787, 0.9463599759489413, 0.9463599759489413, 0.9463599759489413, 0.9569818557405084, 0.9569818557405084, 0.9569818557405084, 0.9559189893364821, 0.9559189893364821, 0.9559189893364821, 0.5443105293717473, 0.5443105293717473, 0.5443105293717473, 0.47495480177739535, 0.47495480177739535, 0.47495480177739535, 0.6116634865489409, 0.6116634865489409, 0.6116634865489409, 0.35046800001369927, 0.35046800001369927, 0.35046800001369927, 0.2666494802564582, 0.2666494802564582, 0.2666494802564582, 0.21709341554631634, 0.21709341554631634, 0.21709341554631634, 0.1839158255132447, 0.1839158255132447, 0.1839158255132447, 0.1647076028706671, 0.1647076028706671, 0.1647076028706671, 0.16712661648105953, 0.16712661648105953, 0.16712661648105953, 0.1146126153527699, 0.1146126153527699, 0.1146126153527699, 0.16007326887734175, 0.16007326887734175, 0.16007326887734175, 0.15928763523294143, 0.15928763523294143, 0.15928763523294143, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04653415652835069, 0.04653415652835069, 0.04653415652835069, 0.09299796756125867, 0.09299796756125867, 0.09299796756125867, 0.06301134873445513, 0.06301134873445513, 0.06301134873445513, 0.11904268900306392, 0.11904268900306392, 0.11904268900306392, 0.09445776593372501, 0.09445776593372501, 0.09445776593372501, 0.11001876742549177, 0.11001876742549177, 0.11001876742549177, 0.11165789985537722, 0.11165789985537722, 0.11165789985537722, 0.09305119907560222, 0.09305119907560222, 0.09305119907560222, 0.12289003947522437, 0.12289003947522437, 0.12289003947522437, 0.15774086913237662, 0.15774086913237662, 0.15774086913237662, 0.5713297883107527, 0.5713297883107527, 0.5713297883107527, 0.5876405734902983, 0.5876405734902983, 0.5876405734902983, 0.4944214638583124, 0.4944214638583124, 0.4944214638583124, 0.13812902220750678, 0.13812902220750678, 0.13812902220750678, 0.11958994604012985, 0.11958994604012985, 0.11958994604012985, 0.11192565780307973, 0.11192565780307973, 0.11192565780307973, 0.31340771384555377, 0.31340771384555377, 0.31340771384555377, 0.19033141348867733, 0.19033141348867733, 0.19033141348867733, 0.2589059091848056, 0.2589059091848056, 0.2589059091848056, 0.327967801615898, 0.327967801615898, 0.327967801615898, 0.31514371948251496, 0.31514371948251496, 0.31514371948251496, 0.4329333599980707, 0.4329333599980707, 0.4329333599980707, 0.1972309375521154, 0.1972309375521154, 0.1972309375521154, 0.292861826480766, 0.292861826480766, 0.292861826480766, 0.23395728257696702, 0.23395728257696702, 0.23395728257696702, 0.2882843124334793, 0.2882843124334793, 0.2882843124334793, 0.26899327437727294, 0.26899327437727294, 0.26899327437727294, 0.28686140442490693, 0.28686140442490693, 0.28686140442490693, 0.6792431566437209, 0.6792431566437209, 0.6792431566437209, 0.24181195774958075, 0.24181195774958075, 0.24181195774958075, 0.20487557221041552, 0.20487557221041552, 0.20487557221041552, 0.8844562894894065, 0.8844562894894065, 0.8844562894894065, 0.15800915523126735, 0.15800915523126735, 0.15800915523126735, 0.866647276966354, 0.866647276966354, 0.866647276966354, 0.49975123473402505, 0.49975123473402505, 0.49975123473402505, 0.2101977034109339, 0.2101977034109339, 0.2101977034109339, 0.5812518021464537, 0.5812518021464537, 0.5812518021464537, 0.1802028821148035, 0.1802028821148035, 0.1802028821148035, 0.18324760789248917, 0.18324760789248917, 0.18324760789248917, 0.19191599697396367, 0.19191599697396367, 0.19191599697396367, 0.09795700259142304, 0.09795700259142304, 0.09795700259142304, 0.09723635267006936, 0.09723635267006936, 0.09723635267006936, 0.13215671378695693, 0.13215671378695693, 0.13215671378695693]}, "mutation_prompt": null}
{"id": "a325fd33-8ec6-4738-bb64-344bd55672e0", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "d6c9708f-2250-4c2c-bdb3-819c66142062", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithGaussianMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.2  # Modified mutation scale for Gaussian mutation\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.exp(-(evaluations / self.budget)), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithGaussianMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and enhanced Gaussian mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 95, "fitness": 0.30259208354091166, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithGaussianMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.26.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.8135528001657464, 0.8135528001657464, 0.8135528001657464, 0.7827158439960367, 0.7827158439960367, 0.7827158439960367, 0.7724421932128781, 0.7724421932128781, 0.7724421932128781, 0.11450414055422575, 0.11450414055422575, 0.11450414055422575, 0.13112533030524032, 0.13112533030524032, 0.13112533030524032, 0.04431944465451776, 0.04431944465451776, 0.04431944465451776, 0.14768892785732823, 0.14768892785732823, 0.14768892785732823, 0.12496471257522956, 0.12496471257522956, 0.12496471257522956, 0.11532422582594704, 0.11532422582594704, 0.11532422582594704, 0.13242312518323396, 0.13242312518323396, 0.13242312518323396, 0.15041087608457893, 0.15041087608457893, 0.15041087608457893, 0.12392894323169024, 0.12392894323169024, 0.12392894323169024, 0.9470740797854525, 0.9470740797854525, 0.9470740797854525, 0.9571309005983545, 0.9571309005983545, 0.9571309005983545, 0.9555503523379167, 0.9555503523379167, 0.9555503523379167, 0.48164028866495523, 0.48164028866495523, 0.48164028866495523, 0.4615658869313948, 0.4615658869313948, 0.4615658869313948, 0.44463146053852953, 0.44463146053852953, 0.44463146053852953, 0.7517045258302935, 0.7517045258302935, 0.7517045258302935, 0.2710431952170417, 0.2710431952170417, 0.2710431952170417, 0.8050650295986248, 0.8050650295986248, 0.8050650295986248, 0.12580000597375218, 0.12580000597375218, 0.12580000597375218, 0.12832645609406246, 0.12832645609406246, 0.12832645609406246, 0.18336778361165418, 0.18336778361165418, 0.18336778361165418, 0.17187831460560188, 0.17187831460560188, 0.17187831460560188, 0.14849232608670426, 0.14849232608670426, 0.14849232608670426, 0.20245648639519287, 0.20245648639519287, 0.20245648639519287, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06057050068487024, 0.06057050068487024, 0.06057050068487024, 0.07095919539622697, 0.07095919539622697, 0.07095919539622697, 0.04062061372058867, 0.04062061372058867, 0.04062061372058867, 0.08903656244917091, 0.08903656244917091, 0.08903656244917091, 0.11906490803681424, 0.11906490803681424, 0.11906490803681424, 0.19813048038916148, 0.19813048038916148, 0.19813048038916148, 0.05825097371115229, 0.05825097371115229, 0.05825097371115229, 0.06613096405077945, 0.06613096405077945, 0.06613096405077945, 0.2878506488844421, 0.2878506488844421, 0.2878506488844421, 0.08110708110912579, 0.08110708110912579, 0.08110708110912579, 0.4534008911154288, 0.4534008911154288, 0.4534008911154288, 0.5398462496273784, 0.5398462496273784, 0.5398462496273784, 0.500161297350894, 0.500161297350894, 0.500161297350894, 0.10816862009880845, 0.10816862009880845, 0.10816862009880845, 0.13080672538459515, 0.13080672538459515, 0.13080672538459515, 0.11084991990013682, 0.11084991990013682, 0.11084991990013682, 0.3014102692748337, 0.3014102692748337, 0.3014102692748337, 0.35213151390860076, 0.35213151390860076, 0.35213151390860076, 0.2189785941128769, 0.2189785941128769, 0.2189785941128769, 0.4856183173345595, 0.4856183173345595, 0.4856183173345595, 0.320917214253985, 0.320917214253985, 0.320917214253985, 0.38556264793937056, 0.38556264793937056, 0.38556264793937056, 0.230957368141249, 0.230957368141249, 0.230957368141249, 0.2645556291813863, 0.2645556291813863, 0.2645556291813863, 0.27264754850963435, 0.27264754850963435, 0.27264754850963435, 0.22521192953402025, 0.22521192953402025, 0.22521192953402025, 0.22236771087616214, 0.22236771087616214, 0.22236771087616214, 0.2233055058262584, 0.2233055058262584, 0.2233055058262584, 0.19432836317889202, 0.19432836317889202, 0.19432836317889202, 0.21802714277723045, 0.21802714277723045, 0.21802714277723045, 0.2010420733588012, 0.2010420733588012, 0.2010420733588012, 0.86789732876053, 0.86789732876053, 0.86789732876053, 0.15804107055647398, 0.15804107055647398, 0.15804107055647398, 0.8404768519216579, 0.8404768519216579, 0.8404768519216579, 0.6817801008803676, 0.6817801008803676, 0.6817801008803676, 0.2110107751648429, 0.2110107751648429, 0.2110107751648429, 0.5970830822128281, 0.5970830822128281, 0.5970830822128281, 0.19899078235063594, 0.19899078235063594, 0.19899078235063594, 0.20832879878720856, 0.20832879878720856, 0.20832879878720856, 0.18878834563302838, 0.18878834563302838, 0.18878834563302838, 0.07959897366126623, 0.07959897366126623, 0.07959897366126623, 0.1047400794791844, 0.1047400794791844, 0.1047400794791844, 0.12854870950399888, 0.12854870950399888, 0.12854870950399888]}, "mutation_prompt": null}
{"id": "23fce159-704e-4bcd-8a37-f794b661216e", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "d9c2a2bf-49a4-4399-97a5-c387dd1b824a", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "d9b1147e-5ddc-4347-a09a-033f85fe8afe", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.98\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.1\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithLogarithmicMutation", "description": "A dynamic particle swarm optimizer with adaptive velocity scaling, elitism, and a novel logarithmic mutation strategy for improved exploration and convergence.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.785342254189554, 0.785342254189554, 0.785342254189554, 0.7770891862223415, 0.7770891862223415, 0.7770891862223415, 0.7938016333226311, 0.7938016333226311, 0.7938016333226311, 0.10261985386478023, 0.10261985386478023, 0.10261985386478023, 0.2941220153030347, 0.2941220153030347, 0.2941220153030347, 0.06447554315440429, 0.06447554315440429, 0.06447554315440429, 0.13732122154477788, 0.13732122154477788, 0.13732122154477788, 0.11764955357442397, 0.11764955357442397, 0.11764955357442397, 0.10681274427153842, 0.10681274427153842, 0.10681274427153842, 0.13430723581749648, 0.13430723581749648, 0.13430723581749648, 0.14426406906073264, 0.14426406906073264, 0.14426406906073264, 0.10030443783939957, 0.10030443783939957, 0.10030443783939957, 0.9449703776363639, 0.9449703776363639, 0.9449703776363639, 0.9570190534930814, 0.9570190534930814, 0.9570190534930814, 0.9556288076564019, 0.9556288076564019, 0.9556288076564019, 0.5031259140320046, 0.5031259140320046, 0.5031259140320046, 0.44938507881234824, 0.44938507881234824, 0.44938507881234824, 0.47960656314687466, 0.47960656314687466, 0.47960656314687466, 0.20392491196471252, 0.20392491196471252, 0.20392491196471252, 0.8217734304983368, 0.8217734304983368, 0.8217734304983368, 0.827982193362547, 0.827982193362547, 0.827982193362547, 0.16178277544050412, 0.16178277544050412, 0.16178277544050412, 0.16841923947288107, 0.16841923947288107, 0.16841923947288107, 0.185773543561233, 0.185773543561233, 0.185773543561233, 0.12157055703288022, 0.12157055703288022, 0.12157055703288022, 0.14370956652762523, 0.14370956652762523, 0.14370956652762523, 0.1535256801443542, 0.1535256801443542, 0.1535256801443542, 0.003635590822729906, 0.003635590822729906, 0.003635590822729906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.016419176766468646, 0.016419176766468646, 0.016419176766468646, 0.06910981470957756, 0.06910981470957756, 0.06910981470957756, 0.05008282387982621, 0.05008282387982621, 0.05008282387982621, 0.10080702398002339, 0.10080702398002339, 0.10080702398002339, 0.08933905788757657, 0.08933905788757657, 0.08933905788757657, 0.10991056710234137, 0.10991056710234137, 0.10991056710234137, 0.08787336504387167, 0.08787336504387167, 0.08787336504387167, 0.08491473297947882, 0.08491473297947882, 0.08491473297947882, 0.1448674862086422, 0.1448674862086422, 0.1448674862086422, 0.05398500965241815, 0.05398500965241815, 0.05398500965241815, 0.5257615197437726, 0.5257615197437726, 0.5257615197437726, 0.5669856895976958, 0.5669856895976958, 0.5669856895976958, 0.5101645044448627, 0.5101645044448627, 0.5101645044448627, 0.14945755803086413, 0.14945755803086413, 0.14945755803086413, 0.16350044458582047, 0.16350044458582047, 0.16350044458582047, 0.13796567096214585, 0.13796567096214585, 0.13796567096214585, 0.26657983398668117, 0.26657983398668117, 0.26657983398668117, 0.35275594148937894, 0.35275594148937894, 0.35275594148937894, 0.3093673208153237, 0.3093673208153237, 0.3093673208153237, 0.3849359826705473, 0.3849359826705473, 0.3849359826705473, 0.30065164937734756, 0.30065164937734756, 0.30065164937734756, 0.4178297554298408, 0.4178297554298408, 0.4178297554298408, 0.2860416106690675, 0.2860416106690675, 0.2860416106690675, 0.25023963899917423, 0.25023963899917423, 0.25023963899917423, 0.17711877333139325, 0.17711877333139325, 0.17711877333139325, 0.22156988954675205, 0.22156988954675205, 0.22156988954675205, 0.21006870699763658, 0.21006870699763658, 0.21006870699763658, 0.2256575401695593, 0.2256575401695593, 0.2256575401695593, 0.5811351303344123, 0.5811351303344123, 0.5811351303344123, 0.2231132186265793, 0.2231132186265793, 0.2231132186265793, 0.20336274138217392, 0.20336274138217392, 0.20336274138217392, 0.8682791455202455, 0.8682791455202455, 0.8682791455202455, 0.15801003483078913, 0.15801003483078913, 0.15801003483078913, 0.8481353795879203, 0.8481353795879203, 0.8481353795879203, 0.815900518622625, 0.815900518622625, 0.815900518622625, 0.21033615526332938, 0.21033615526332938, 0.21033615526332938, 0.5966569537928352, 0.5966569537928352, 0.5966569537928352, 0.21227767690029797, 0.21227767690029797, 0.21227767690029797, 0.18929385162573042, 0.18929385162573042, 0.18929385162573042, 0.19061069523543128, 0.19061069523543128, 0.19061069523543128, 0.08947937821055707, 0.08947937821055707, 0.08947937821055707, 0.1014345149533874, 0.1014345149533874, 0.1014345149533874, 0.11136027563308248, 0.11136027563308248, 0.11136027563308248]}, "mutation_prompt": null}
{"id": "3784742e-1384-40ca-a24a-d82237adcf8b", "solution": "import numpy as np\n\nclass AdaptiveVelocitySwarmOptimizerWithEnhancedMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 100\n        self.inertia_weight = 0.7\n        self.cognitive_weight = 1.8\n        self.social_weight = 1.5\n        self.mutation_prob = 0.1\n        self.vel_bound = (self.ub - self.lb) / 6.0\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.learning_rate_decay = 0.99  # Slightly adjusted decay for smoother transition\n        self.elitism_ratio = 0.05\n        self.mutation_scale = 0.15  # Increased mutation scale for more exploration\n\n    def __call__(self, func):\n        np.random.seed(42)\n        particles = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.vel_bound, self.vel_bound, (self.population_size, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_values = np.array([func(p) for p in particles])\n        \n        self.global_best_position = personal_best_positions[np.argmin(personal_best_values)]\n        self.global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            sorted_indices = np.argsort(personal_best_values)\n            elitism_count = int(self.elitism_ratio * self.population_size)\n            \n            for i in range(self.population_size):\n                if i < elitism_count:\n                    particles[i] = personal_best_positions[sorted_indices[i]]\n                    continue\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_weight * r1 * (personal_best_positions[i] - particles[i]) +\n                                 self.social_weight * r2 * (self.global_best_position - particles[i]))\n\n                velocities[i] = np.clip(velocities[i], -self.vel_bound, self.vel_bound)\n                \n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                if np.random.rand() < self.mutation_prob:\n                    mutation_vector = np.random.normal(0, self.mutation_scale * np.log1p((self.budget - evaluations) / self.budget), self.dim)\n                    particles[i] += mutation_vector\n                    particles[i] = np.clip(particles[i], self.lb, self.ub)\n                \n                current_value = func(particles[i])\n                evaluations += 1\n\n                if current_value < personal_best_values[i]:\n                    personal_best_values[i] = current_value\n                    personal_best_positions[i] = particles[i]\n                \n                if current_value < self.global_best_value:\n                    self.global_best_value = current_value\n                    self.global_best_position = particles[i]\n                \n                if evaluations >= self.budget:\n                    break\n\n            self.inertia_weight *= self.learning_rate_decay\n            self.cognitive_weight *= self.learning_rate_decay\n            self.social_weight *= self.learning_rate_decay\n            self.mutation_scale *= self.learning_rate_decay\n        \n        return self.global_best_value", "name": "AdaptiveVelocitySwarmOptimizerWithEnhancedMutation", "description": "A refined dynamic particle swarm optimizer with adaptive velocity decay, elitism, and enhanced mutation for improved exploration and robust convergence.", "configspace": "", "generation": 99, "fitness": 0.29966591551619576, "feedback": "The algorithm AdaptiveVelocitySwarmOptimizerWithEnhancedMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.24.", "error": "", "parent_id": "5750a18c-8351-4c43-ba46-884d43ed3182", "metadata": {"aucs": [0.72997568206091, 0.72997568206091, 0.72997568206091, 0.6858354017106427, 0.6858354017106427, 0.6858354017106427, 0.7260341583860892, 0.7260341583860892, 0.7260341583860892, 0.49463400599069185, 0.49463400599069185, 0.49463400599069185, 0.4954472093846497, 0.4954472093846497, 0.4954472093846497, 0.3675936057938286, 0.3675936057938286, 0.3675936057938286, 0.13495623746949537, 0.13495623746949537, 0.13495623746949537, 0.15756729866898744, 0.15756729866898744, 0.15756729866898744, 0.1643993829657887, 0.1643993829657887, 0.1643993829657887, 0.13589151689753765, 0.13589151689753765, 0.13589151689753765, 0.1066906033778483, 0.1066906033778483, 0.1066906033778483, 0.10817175293556791, 0.10817175293556791, 0.10817175293556791, 0.9452357533618575, 0.9452357533618575, 0.9452357533618575, 0.9570685798033015, 0.9570685798033015, 0.9570685798033015, 0.9559602745792395, 0.9559602745792395, 0.9559602745792395, 0.5241425987563181, 0.5241425987563181, 0.5241425987563181, 0.5523488432080824, 0.5523488432080824, 0.5523488432080824, 0.43445344541665265, 0.43445344541665265, 0.43445344541665265, 0.16840817362483262, 0.16840817362483262, 0.16840817362483262, 0.2707350799326831, 0.2707350799326831, 0.2707350799326831, 0.2781709936170065, 0.2781709936170065, 0.2781709936170065, 0.11830478133180755, 0.11830478133180755, 0.11830478133180755, 0.1822310186871554, 0.1822310186871554, 0.1822310186871554, 0.1911113396692239, 0.1911113396692239, 0.1911113396692239, 0.1878748939566095, 0.1878748939566095, 0.1878748939566095, 0.1650199583524422, 0.1650199583524422, 0.1650199583524422, 0.18822672747015845, 0.18822672747015845, 0.18822672747015845, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004730597737898967, 0.004730597737898967, 0.004730597737898967, 0.1773154441580782, 0.1773154441580782, 0.1773154441580782, 0.08078861148816707, 0.08078861148816707, 0.08078861148816707, 0.09193326258983903, 0.09193326258983903, 0.09193326258983903, 0.1655192196164813, 0.1655192196164813, 0.1655192196164813, 0.06674460744501143, 0.06674460744501143, 0.06674460744501143, 0.06931995840607375, 0.06931995840607375, 0.06931995840607375, 0.07408916206326122, 0.07408916206326122, 0.07408916206326122, 0.07168623883127534, 0.07168623883127534, 0.07168623883127534, 0.13219631547792265, 0.13219631547792265, 0.13219631547792265, 0.057010602023350065, 0.057010602023350065, 0.057010602023350065, 0.4709471811169098, 0.4709471811169098, 0.4709471811169098, 0.5130592155003765, 0.5130592155003765, 0.5130592155003765, 0.4985102588056576, 0.4985102588056576, 0.4985102588056576, 0.1360454279847605, 0.1360454279847605, 0.1360454279847605, 0.12470527816777555, 0.12470527816777555, 0.12470527816777555, 0.08868877403244291, 0.08868877403244291, 0.08868877403244291, 0.28332856019934605, 0.28332856019934605, 0.28332856019934605, 0.18467322398107722, 0.18467322398107722, 0.18467322398107722, 0.42056114217257834, 0.42056114217257834, 0.42056114217257834, 0.3511649879311154, 0.3511649879311154, 0.3511649879311154, 0.3975907038179306, 0.3975907038179306, 0.3975907038179306, 0.45034133878300997, 0.45034133878300997, 0.45034133878300997, 0.229496589931941, 0.229496589931941, 0.229496589931941, 0.27496476234239997, 0.27496476234239997, 0.27496476234239997, 0.190745918146624, 0.190745918146624, 0.190745918146624, 0.1880113864239844, 0.1880113864239844, 0.1880113864239844, 0.2145855815941503, 0.2145855815941503, 0.2145855815941503, 0.22088372428592762, 0.22088372428592762, 0.22088372428592762, 0.23322517352803707, 0.23322517352803707, 0.23322517352803707, 0.23985751854518644, 0.23985751854518644, 0.23985751854518644, 0.23344717163068984, 0.23344717163068984, 0.23344717163068984, 0.8183004546996474, 0.8183004546996474, 0.8183004546996474, 0.15783436128400608, 0.15783436128400608, 0.15783436128400608, 0.8349223058899345, 0.8349223058899345, 0.8349223058899345, 0.5674775936668826, 0.5674775936668826, 0.5674775936668826, 0.20989700433055525, 0.20989700433055525, 0.20989700433055525, 0.7244896536506746, 0.7244896536506746, 0.7244896536506746, 0.1997745981666601, 0.1997745981666601, 0.1997745981666601, 0.19488881520894652, 0.19488881520894652, 0.19488881520894652, 0.20291893409546724, 0.20291893409546724, 0.20291893409546724, 0.0909011607174427, 0.0909011607174427, 0.0909011607174427, 0.08959385777895801, 0.08959385777895801, 0.08959385777895801, 0.12218992150823127, 0.12218992150823127, 0.12218992150823127]}, "mutation_prompt": null}

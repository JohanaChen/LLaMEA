{"role": "LLaMEA", "time": "2024-10-23 22:36:23.654571", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# "}
{"role": "gpt-4o", "time": "2024-10-23 22:36:31.018834", "content": "# Description: A hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-23 22:38:46.904617", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHyDEPSO: A hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation. (Score: 0.33034606652083165)\n\nThe selected solution to update is:\nA hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation.\n\nWith code:\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm HyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 22:38:56.461662", "content": "# Description: An enhanced hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with dynamic parameter adaptation for better optimization performance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = np.random.uniform(0.4, 0.9)  # Dynamic differential weight\n        self.CR = np.random.uniform(0.8, 1.0) # Dynamic crossover probability\n        self.w = 0.5 + np.random.rand() * 0.2  # Randomized inertia weight\n        self.c1 = 1.5 + np.random.rand() * 0.5 # Randomized cognitive coefficient\n        self.c2 = 1.5 + np.random.rand() * 0.5 # Randomized social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation with dynamic adjustment\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(self.personal_best[i]):\n                        self.personal_best[i] = trial\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update with adaptive parameters\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 22:41:19.928322", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHyDEPSO: A hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation. (Score: 0.33034606652083165)\n\nThe selected solution to update is:\nA hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation.\n\nWith code:\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm HyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 22:41:32.842812", "content": "# Description: HyPEB: A hybrid Particle Swarm Optimization and Evolutionary Bees algorithm using adaptive control for enhanced exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass HyPEB:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Differential weight for mutation\n        self.CR = 0.85 # Crossover probability for DE\n        self.w = 0.6  # Inertia weight for PSO\n        self.c1 = 1.7 # Cognitive coefficient for PSO\n        self.c2 = 1.7 # Social coefficient for PSO\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Evolutionary Bees local search\n            num_local_searches = int(0.2 * self.population_size)\n            for _ in range(num_local_searches):\n                bee_index = np.random.choice(self.population_size)\n                bee_position = self.population[bee_index] + np.random.uniform(-0.1, 0.1, self.dim)\n                bee_position = np.clip(bee_position, self.lower_bound, self.upper_bound)\n                bee_fitness = func(bee_position)\n                evals += 1\n                if bee_fitness < fitness[bee_index]:\n                    self.population[bee_index] = bee_position\n                    fitness[bee_index] = bee_fitness\n                    if bee_fitness < self.best_fitness:\n                        self.global_best = bee_position\n                        self.best_fitness = bee_fitness\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-23 22:43:54.401919", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHyDEPSO: A hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation. (Score: 0.33034606652083165)\n\nThe selected solution to update is:\nA hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation.\n\nWith code:\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm HyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 22:44:05.071477", "content": "# Description: A hybrid Differential Evolution and Particle Swarm Optimization algorithm with dynamic parameter adaptation and elite preservation for enhanced convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.w = 0.7  # Adjusted inertia weight for better exploration\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.elite_rate = 0.1  # Proportion of elites to be preserved\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            elite_count = int(self.elite_rate * self.population_size)\n            elite_indices = np.argsort(fitness)[:elite_count]\n            elites = self.population[elite_indices]\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Preserve elites\n            self.population[elite_indices] = elites\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-23 22:46:30.052935", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHyDEPSO: A hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation. (Score: 0.33034606652083165)\n\nThe selected solution to update is:\nA hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation.\n\nWith code:\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm HyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 22:46:38.938694", "content": "# Description: A novel hybridization of Differential Evolution, Particle Swarm Optimization, and Simulated Annealing leveraging adaptive parameters and cooling schedule for enhanced exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass HyDEPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim\n        self.F = 0.6  # Differential weight\n        self.CR = 0.85 # Crossover probability\n        self.w = 0.4  # Inertia weight\n        self.c1 = 1.7 # Cognitive coefficient\n        self.c2 = 1.4 # Social coefficient\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.temperature = 1.0\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Simulated Annealing perturbation\n                perturbation = np.random.normal(0, self.temperature, self.dim)\n                trial = np.clip(trial + perturbation, self.lower_bound, self.upper_bound)\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection with Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.exp((fitness[i] - trial_fitness) / self.temperature) > np.random.rand():\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-23 22:49:37.380545", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHyDEPSO: A hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation. (Score: 0.33034606652083165)\n\nThe selected solution to update is:\nA hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation.\n\nWith code:\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm HyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 22:49:45.813606", "content": "# Description: An enhanced hybrid Differential Evolution and Particle Swarm Optimization with adaptive inertia weight and elite selection for improved exploration-exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_end = 0.4   # Final inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            w = self.w_init - ((self.w_init - self.w_end) * (evals / self.budget))\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection with elite preservation\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(self.personal_best[i]):\n                        self.personal_best[i] = trial\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-23 22:52:06.862795", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHyDEPSO: A hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation. (Score: 0.33034606652083165)\n\nThe selected solution to update is:\nA hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation.\n\nWith code:\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm HyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 22:52:13.709631", "content": "# Description: A novel hybrid algorithm fusing Differential Evolution, Particle Swarm Optimization, and adaptive exploration-exploitation balancing to enhance convergence performance.\n# Code:\n```python\nimport numpy as np\n\nclass HyDEPES:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.7  # Differential weight modified for exploration\n        self.CR = 0.8 # Crossover probability adjusted for diversity\n        self.w = 0.4  # Inertia weight reduced for swift convergence\n        self.c1 = 2.0 # Increased cognitive coefficient for enhanced local search\n        self.c2 = 1.7 # Increased social coefficient for better global search\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Adaptive PSO update\n            adapt_inertia = 0.9 - (0.9 - 0.4) * (evals / self.budget)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = adapt_inertia * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 22:54:40.385752", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHyDEPSO: A hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation. (Score: 0.33034606652083165)\n\nThe selected solution to update is:\nA hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation.\n\nWith code:\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm HyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 22:54:48.808381", "content": "# Description: A hybrid Differential Evolution and Particle Swarm Optimization algorithm with adaptive inertia weight for enhanced exploration and convergence.\n# Code:\n# ```python\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w_initial = 0.9  # Initial inertia weight\n        self.w_final = 0.4  # Final inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            # Adaptive inertia weight\n            w = self.w_initial - (self.w_initial - self.w_final) * (evals / self.budget)\n            \n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n# ```"}
{"role": "LLaMEA", "time": "2024-10-23 22:54:48.811674", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHyDEPSO: A hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation. (Score: 0.33034606652083165)\n\nThe selected solution to update is:\nA hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation.\n\nWith code:\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm HyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 22:54:58.255033", "content": "# Description: An enhanced hybrid Differential Evolution and Particle Swarm Optimization algorithm with adaptive learning rate and dynamic population sizing for improved convergence.\n# Code:\n```python\nimport numpy as np\n\nclass HyDEPSO_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.decay_rate = 0.99  # Decay for dynamic sizing\n        self.learning_rate = 0.1  # Adaptive learning rate\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if evals % (self.budget // 10) == 0:\n                self.population_size = max(5, int(self.population_size * self.decay_rate))\n                self.population = self.population[:self.population_size]\n                self.velocities = self.velocities[:self.population_size]\n                fitness = fitness[:self.population_size]\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = x_r1 + self.F * (x_r2 - x_r3) * (1 + np.random.randn() * self.learning_rate)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-23 22:54:58.351714", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nHyDEPSO: A hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation. (Score: 0.33034606652083165)\n\nThe selected solution to update is:\nA hybrid Differential Evolution and Particle Swarm Optimization algorithm leveraging adaptive parameter control for effective exploration and exploitation.\n\nWith code:\nimport numpy as np\n\nclass HyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive coefficient\n        self.c2 = 1.5 # Social coefficient\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm HyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 22:55:14.519105", "content": "# Description: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 22:57:28.257956", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 22:57:37.924031", "content": "# Description: Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Enhanced Dynamic Strategy Tuning for improved search efficiency.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.7  # Slightly more aggressive Differential weight\n        self.CR = 0.9 # Higher Crossover probability\n        self.w = 0.5  # Balanced Inertia weight\n        self.c1 = 1.5 # Moderate cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = self.population[np.argmin([float('inf')] * self.population_size)]\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Wider range for adaptation\n                self.CR = 0.8 + 0.15 * np.random.rand()  # Slightly tighter range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-23 22:59:55.747846", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:00:04.639989", "content": "# Description: Enhanced Hybrid Metaheuristic fusing Genetic Algorithms with Adaptive Dynamic Strategy for efficient convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 15 * dim\n        self.F = 0.5  # Differential weight for variation\n        self.CR = 0.9 # Crossover probability for diversity\n        self.w = 0.5  # Inertia weight for balance\n        self.c1 = 2.0 # Emphasis on cognitive learning\n        self.c2 = 1.5 # Emphasis on social learning\n        self.mutation_rate = 0.05 # Mutation probability for genetic diversity\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.1 * np.random.rand()  # Randomize within a range\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Introduce mutation for diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(-1, 1, self.dim)\n                    trial = np.clip(trial + mutation_vector, self.lower_bound, self.upper_bound)\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:02:29.489354", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:02:38.046010", "content": "# Description: Enhanced Adaptive Hybrid Optimization with Differential Evolution and Particle Swarm featuring Adaptive Mutation Control and Diversity-based Strategy Switching.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Increased population size for better exploration\n        self.F = 0.6\n        self.CR = 0.85\n        self.w = 0.3 # Further decreased inertia weight for faster convergence\n        self.c1 = 1.5 # Balanced cognitive component\n        self.c2 = 1.5 # Balanced social component\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound) # Slightly reduced velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n        \n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Adaptive mutation control\n                self.F = 0.5 + 0.3 * np.random.rand()  # Broaden mutation range\n                self.CR = 0.6 + 0.3 * np.random.rand()  # Broaden crossover range\n\n            for i in range(self.population_size):\n                if evals >= self.budget:\n                    break\n\n                # Differential Evolution mutation with diversity-based strategy\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate and select trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:04:52.020074", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:05:00.470696", "content": "# Description: Enhanced Adaptive Hybrid Optimization utilizing Differential Evolution and Particle Swarm with Dynamic Parameter Tuning and Elite Retention for improved convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Adjusted Differential weight for dynamic balance\n        self.CR = 0.9 # Higher Crossover probability for diversity\n        self.w = 0.5  # Balanced Inertia weight for exploration\n        self.c1 = 1.5 # Balanced cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Modified velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.elite_factor = 0.05 # Elite population retention factor\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            elite_size = int(self.elite_factor * self.population_size)\n            elite_indices = fitness.argsort()[:elite_size]\n            elite_population = self.population[elite_indices]\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.elite_factor and i not in elite_indices:\n                    continue  # Skip non-elite to provide elite advantage\n\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update with elite retention\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reintroduce elite members to maintain diversity\n            self.population[:elite_size] = elite_population\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:07:21.354978", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:07:32.179046", "content": "# Description: Enhanced Adaptive Hybrid Optimization combining Differential Evolution and Particle Swarm with a novel velocity-refinement mechanism for robust exploration-exploitation balance.  \n# Code:\n# ```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.1 * np.random.rand()  # Randomized Differential weight for diversity\n        self.CR = 0.75 + 0.1 * np.random.rand() # Slightly increased crossover probability\n        self.w = 0.5  # Adjusted inertia weight to balance exploration and exploitation\n        self.c1 = 1.5 # Lowered cognitive learning to enhance global search\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound) # Moderately increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.5 + 0.1 * np.random.rand()\n                self.CR = 0.75 + 0.1 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n# ```"}
{"role": "LLaMEA", "time": "2024-10-23 23:07:32.181835", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:07:42.454342", "content": "# Description: Enhanced Hybrid Optimization using Adaptive Strategies with Stochastic Initialization and Dynamic Exploration-Exploitation Control.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim\n        self.F = 0.5 + 0.3 * np.random.rand()  # Stochastic Differential weight\n        self.CR = 0.9 # Higher Crossover probability for diversity\n        self.w = 0.3 + 0.2 * np.random.rand()  # Adaptive Inertia weight\n        self.c1 = 1.5 # Moderate emphasis on cognitive learning\n        self.c2 = 1.5 # Balanced emphasis on social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.8 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-23 23:09:58.573182", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:10:05.619706", "content": "# Description: Enhanced Hybrid Optimization combining Differential Evolution and Particle Swarm with Adaptive Strategy for Improved Convergence and Diversity Maintenance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Slightly larger population for diversity\n        self.F = 0.5 + 0.3 * np.random.rand()  # Randomized within a range for adaptive differential weight\n        self.CR = 0.9  # Increased Crossover probability for more mixing\n        self.w = 0.3  # Lowered Inertia weight for improved exploitation\n        self.c1 = 1.5  # Balanced cognitive learning\n        self.c2 = 1.5  # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)  # Higher velocity clamp for broader exploration\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.5 + 0.3 * np.random.rand()\n                self.CR = 0.8 + 0.1 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:12:20.226767", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:12:27.194860", "content": "# Description: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Dynamic Strategy Selection and Adaptive Learning Rates for robust exploration-exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.3 * np.random.rand()  # Wider range for F\n        self.CR = 0.8  # Fixed crossover probability for stability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly reduced cognitive learning\n        self.c2 = 1.5 # Equal emphasis on social learning\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound) # Reduced velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.3 * np.random.rand()  # Randomize within a wider range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:14:43.819595", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:14:52.298511", "content": "# Description: Enhanced Hybrid Optimization using Adaptive Differential Evolution and Particle Swarm with Dynamic Strategy and Adaptive Parameters for optimal convergence speed and solution quality.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Slightly increased population size\n        self.F = 0.5  # Adaptive Differential weight\n        self.CR = 0.9 # Higher Crossover probability\n        self.w = 0.3  # Further decreased Inertia weight for faster convergence\n        self.c1 = 1.8 # Further emphasis on cognitive learning\n        self.c2 = 1.2 # Slight further decrease in social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection with adaptive parameters\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.4 * np.random.rand()  # Randomize within a wider range\n                self.CR = 0.6 + 0.3 * np.random.rand()  # Randomize with a broader range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:17:04.357394", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:17:13.039841", "content": "# Description: Improved Hybrid Optimization using Adaptive Differential Evolution and Particle Swarm with Enhanced Strategy Adaptation for Diverse Optimization Tasks.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.3 * np.random.rand()  # More adaptive Differential weight\n        self.CR = 0.75 + 0.15 * np.random.rand() # Slightly narrower range for Crossover probability\n        self.w = 0.5  # Adjusted Inertia weight for balance\n        self.c1 = 1.5 # Lowered cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound) # Decreased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # More adaptive range for F\n                self.CR = 0.75 + 0.15 * np.random.rand()  # Slightly narrower range for CR\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(self.personal_best[i]):\n                        self.personal_best[i] = trial\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:19:31.059965", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:19:39.118125", "content": "# Description: Adaptive Selection of Differential Evolution and Particle Swarm Strategies with Enhanced Randomization for Robust Optimization.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHyDEPSOv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.7  # Further increased Differential weight\n        self.CR = 0.9 # Higher Crossover probability\n        self.w = 0.5  # Increased Inertia weight for enhanced exploration\n        self.c1 = 1.5 # Balanced cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Keep dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Expanded randomization range\n                self.CR = 0.8 + 0.2 * np.random.rand()  # Randomize within an adjusted range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:21:58.161671", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:22:06.015459", "content": "# Description: Enhanced Hybrid Optimization using Differential Evolution and Particle Swarm with Dynamic Strategy and Adaptive Learning Rates for robust balance between exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Adjusted population size for better resource allocation\n        self.F = 0.5 + 0.1 * np.random.rand()  # Dynamic Differential weight based on iterations\n        self.CR = 0.8  # Increased Crossover probability for better exploration\n        self.w = 0.6  # Adjusted Inertia weight for stable convergence\n        self.c1 = 1.5  # Balanced cognitive learning\n        self.c2 = 1.5  # Equal emphasis on social learning\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.1 * np.random.rand()  # Randomize F within a narrow range for stability\n                self.CR = 0.75 + 0.1 * np.random.rand()  # Randomize CR within a range\n                \n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:24:25.792150", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:24:35.252533", "content": "# Description: Enhanced Hybrid Optimization combining Differential Evolution and Particle Swarm with dynamic learning rate adjustment for improved convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Slightly larger population\n        self.F = 0.5 + 0.1 * np.random.rand()  # Dynamic Differential weight\n        self.CR = 0.8  # Higher Crossover probability for exploration\n        self.w = 0.3 + 0.1 * np.random.rand()  # Dynamic inertia weight\n        self.c1 = 1.5  # Balance cognitive learning\n        self.c2 = 1.5  # Balance social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)  # Enhanced velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.dynamic_learning_rate = True  # Enable dynamic learning strategy\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.dynamic_learning_rate:  # Dynamic adaptation\n                self.F = 0.3 + 0.4 * np.random.rand()  # Wider range\n                self.w = 0.2 + 0.3 * np.random.rand()  # Adjust inertia randomly\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:26:48.845285", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:26:56.820240", "content": "# Description: Enhanced Hybrid Optimization integrating Adaptive Differential Evolution and Particle Swarm dynamics with probabilistic strategy switching.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = 0.5 + 0.1 * np.random.rand()  # Dynamic Differential weight\n        self.CR = 0.9  # Increased Crossover probability for diversity\n        self.w = 0.5  # Moderate Inertia weight for balanced exploration\n        self.c1 = 1.5  # Balanced cognitive learning factor\n        self.c2 = 1.7  # Increased emphasis on social learning for convergence\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)  # Reduced velocity clamp for precision\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_switch_prob = 0.3  # Probability to switch strategy\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if np.random.rand() < self.strategy_switch_prob:\n                self.F = 0.5 + 0.2 * np.random.rand()\n                self.CR = 0.8 + 0.1 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:29:15.710386", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:29:24.841537", "content": "# Description: Hybrid Swarm Optimization integrating Differential Evolution with Dynamic Adaptation and Particle Swarm approaches for improved convergence and robustness.\n# Code:\n```python\nimport numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability for exploration\n        self.w = 0.5  # Balanced Inertia weight\n        self.c1 = 1.5 # Cognitive learning rate\n        self.c2 = 1.5 # Social learning rate\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound) # Moderate velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.4 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.3 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:31:39.296804", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:31:49.988437", "content": "# Description: Enhanced Adaptive Hybrid Evolution integrating Simulated Annealing with Differential Evolution and Particle Swarm for refined dynamic exploration-exploitation.\n# Code:\n# ```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDESAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Differential weight\n        self.CR = 0.9 # Higher Crossover probability for diversity\n        self.w = 0.5  # Increased Inertia weight for balance\n        self.c1 = 1.5 # Slightly reduced cognitive learning\n        self.c2 = 1.5 # Equal emphasis on social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n        self.temperature = 1.0 # Initial temperature for Simulated Annealing\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation with temperature cooling\n                self.F = 0.4 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.3 * np.random.rand()  # Randomize within a range\n                self.temperature *= 0.95  # Simulated Annealing temperature decrease\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection with Simulated Annealing acceptance\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / max(self.temperature, 1e-9)):\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n# ```"}
{"role": "LLaMEA", "time": "2024-10-23 23:31:49.991636", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:32:00.197292", "content": "# Description: Enhanced Adaptive Hybrid Optimization using an improved Differential Evolution and Particle Swarm with Adaptive Velocity and Strategy Tuning.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.1 * np.random.rand()  # Dynamic Differential weight\n        self.CR = 0.9 # Increased Crossover probability for diversity\n        self.w = 0.5 + 0.3 * np.random.rand()  # Adaptive Inertia weight for balance\n        self.c1 = 1.5 # Adjusted cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Enhanced velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Maintain dynamic strategy\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Further dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Broaden differential weight range\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Reduce range for crossover probability\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:34:22.506351", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:34:34.460565", "content": "# Description: Enhanced Hybrid Optimization integrating Adaptive Differential Evolution and Particle Swarm with Incremental Learning Rate Adjustments for improved convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Adjusted Differential weight for fine-tuning\n        self.CR = 0.8 # Optimized Crossover probability\n        self.w = 0.5  # Balanced Inertia weight\n        self.c1 = 1.8 # Enhanced cognitive learning\n        self.c2 = 1.4 # Enhanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Continue dynamic strategy selection\n        self.learning_rate = 0.8 # Initial learning rate for adaptation\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation with learning rate adjustment\n                self.F = 0.3 + self.learning_rate * np.random.rand()  # Using learning rate\n                self.CR = 0.6 + self.learning_rate * np.random.rand()  # Using learning rate\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Incremental learning rate adjustments\n            self.learning_rate = np.clip(self.learning_rate * 0.99, 0.1, 1.0)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:36:51.984352", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:37:00.128315", "content": "Certainly! Here's a refined version of the algorithm with a slight probability-driven modification to enhance its strategy:\n\n# Description: Dynamic Co-evolutionary Optimization using adaptive mutation and cooperative learning for robust search performance.\n# Code:\n```python\nimport numpy as np\n\nclass DynamicCoEvoOpt:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F_base = 0.5  # Base Differential weight\n        self.CR_base = 0.8 # Base Crossover probability\n        self.w_base = 0.5  # Base Inertia weight\n        self.c1_base = 1.5 # Base cognitive learning weight\n        self.c2_base = 1.5 # Base social learning weight\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            # Adaptive control parameters\n            self.F = self.F_base + 0.2 * np.sin(evals / self.budget * np.pi)\n            self.CR = self.CR_base + 0.1 * np.cos(evals / self.budget * np.pi)\n            self.w = self.w_base - 0.1 * np.sin(evals / self.budget * np.pi)\n\n            # Hybrid strategy\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1_base * r1 * (self.personal_best - self.population)\n            social = self.c2_base * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-23 23:39:17.514087", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:39:28.279975", "content": "# Description: Enhanced Hybrid Optimization utilizing Adaptive Mutation and Intelligent Velocity Control for robust exploration-exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.3 * np.random.rand()  # Increased randomness in Differential weight\n        self.CR = 0.8 + 0.1 * np.random.rand() # Fine-tuned Crossover probability\n        self.w = 0.5  # Balanced Inertia weight\n        self.c1 = 1.5 # Adjusted cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.5 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = self.population[np.argmin([float('inf')] * self.population_size)]\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.75 + 0.15 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:41:44.507783", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:42:05.220523", "content": "# Description: Hybrid Optimization using Adaptive Differential Evolution and Particle Swarm with Randomized Strategy Switching for enhanced solution diversity.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.2 * np.random.rand()  # Randomized Differential weight\n        self.CR = 0.8  # Fixed Crossover probability\n        self.w = 0.3 + 0.1 * np.random.rand()  # Randomized Inertia weight\n        self.c1 = 1.5 + 0.3 * np.random.rand() # Randomized cognitive learning factor\n        self.c2 = 1.5  # Fixed social learning factor\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = np.random.rand() > 0.3  # 70% probability dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation with randomness\n                self.F = 0.4 + 0.3 * np.random.rand()  # Randomize within a broader range\n                self.CR = 0.6 + 0.3 * np.random.rand()  # Randomize within a broader range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:44:19.961395", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:44:30.016006", "content": "# Description: Enhanced Hybrid Optimization leveraging Adaptive Differential Evolution and Particle Swarm with Stochastic Strategy Tuning for robust convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Adjusted population size for increased diversity\n        self.F = 0.5 + 0.1 * np.random.rand()  # Stochastic Differential weight\n        self.CR = 0.8  # Fixed Crossover probability\n        self.w = 0.5  # Adjusted Inertia weight for balanced exploration\n        self.c1 = 1.5 # Reduced cognitive component\n        self.c2 = 1.5 # Equal emphasis on social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)  # Increased velocity clamp for wider search\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Maintain dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.1 * np.random.rand()  # Stochastic adjustment within a tighter range\n                self.CR = 0.75 + 0.15 * np.random.rand()  # Stochastic adjustment within a tighter range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:46:46.332086", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:46:59.341886", "content": "# Description: Quantum-Inspired Hybrid Optimization leveraging Differential Evolution, Particle Swarm, and Quantum Tunneling for enhanced global convergence.\n# Code:\n```python\nimport numpy as np\n\nclass QuantumHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.4 * np.random.rand()  # Dynamically adjusted Differential weight\n        self.CR = 0.9  # Increased Crossover probability for better diversity\n        self.w = 0.5  # Balanced Inertia weight for stability\n        self.c1 = 1.5 # Refined cognitive learning factor\n        self.c2 = 1.5 # Balanced social learning factor\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def quantum_tunneling(self, solution):\n        tunneling_factor = 0.05\n        perturbation = np.random.normal(0, tunneling_factor, self.dim)\n        return np.clip(solution + perturbation, self.lower_bound, self.upper_bound)\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.4 * np.random.rand()  # Randomize within a range\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Quantum Tunneling\n                if np.random.rand() < 0.05:  # Small probability for quantum tunneling\n                    trial = self.quantum_tunneling(trial)\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:49:22.387237", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:49:34.671227", "content": "# Description: Enhanced Hybrid Optimization with Adaptive Differential Evolution and Particle Swarm featuring Stochastic Variance Reduction for improved convergence and stability.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.2 * np.random.rand()  # More dynamic range for Differential weight\n        self.CR = 0.8  # Fine-tuned Crossover probability\n        self.w = 0.3 + 0.1 * np.random.rand()  # Randomized inertia for variance reduction\n        self.c1 = 1.8  # Fine-tuned cognitive learning\n        self.c2 = 1.5  # Fine-tuned social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.zeros((self.population_size, dim))  # Start with zero velocities\n        self.personal_best = np.copy(self.population)\n        self.fitness = np.full(self.population_size, np.inf)\n        self.global_best = None\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        for i in range(self.population_size):\n            self.fitness[i] = func(self.population[i])\n            evals += 1\n            if self.fitness[i] < self.best_fitness:\n                self.global_best = self.population[i]\n                self.best_fitness = self.fitness[i]\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < self.fitness[i]:\n                    self.population[i] = trial\n                    self.fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:52:03.758857", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:52:11.703180", "content": "# Description: Dynamic Hybrid Optimization leveraging Adaptive Strategy Switching between Differential Evolution and Particle Swarm for improved convergence across complex landscapes.\n# Code:\n```python\nimport numpy as np\n\nclass DynamicHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Slightly increased population size for diversity\n        self.F = 0.5 + 0.2 * np.random.rand()  # Randomized Differential weight\n        self.CR = 0.8  # Balanced crossover probability\n        self.w = 0.5  # Adjusted inertia weight\n        self.c1 = 1.6  # Cognitive component\n        self.c2 = 1.4  # Social component\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)  # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = self.population[np.argmin([float('inf')] * self.population_size)]\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Dynamic strategy toggling\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic strategy\n                self.F = 0.45 + 0.25 * np.random.rand()  # Further randomized\n                self.CR = 0.75 + 0.15 * np.random.rand()  # Random crossover rate\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:54:34.329084", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:54:42.608586", "content": "# Description: Adaptive Dual Strategy Optimization leveraging dynamic learning rates and competition-based selection to enhance convergence efficiency.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveDualStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9 # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5 # Cognitive learning factor\n        self.c2 = 1.5 # Social learning factor\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound) # Velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.dynamic_learning = True # Dynamic learning rate adjustment\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.dynamic_learning:  # Adaptive learning rates\n                self.F = 0.5 + 0.1 * np.random.rand()  # Adjusted range\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Adjusted range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection via competition\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(self.personal_best[i]):\n                        self.personal_best[i] = trial\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:57:00.625750", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:57:07.906312", "content": "# Description: Dynamic Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Enhanced Strategy and Momentum Control for robust exploration-exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = 0.5  # Further adjusted Differential weight\n        self.CR = 0.9 # Increased Crossover probability\n        self.w = 0.5  # Balanced Inertia weight\n        self.c1 = 1.5 # Balanced cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.3 + 0.3 * np.random.rand()  # More variability in the range\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Slightly more stable range\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            momentum = np.exp(-fitness / np.max(fitness))  # New momentum factor\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = (self.w + momentum) * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-23 23:57:07.919760", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:57:15.197942", "content": "# Description: Improved Adaptive Hybrid Optimization incorporating Differential Evolution and Particle Swarm with Enhanced Dynamic Strategy and Parameter Tuning.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Reduced population to increase convergence speed\n        self.F = 0.5  # Maintain flexibility in Differential weight\n        self.CR = 0.9 # Increased Crossover probability for diversity\n        self.w = 0.5  # Slightly higher inertia weight to balance exploration\n        self.c1 = 1.5 # Balanced cognitive learning\n        self.c2 = 1.7 # Increased emphasis on social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Higher velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Continue dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.4 * np.random.rand()  # Broader range for adaptation\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Narrow range for stability\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-23 23:59:41.428637", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-23 23:59:49.381857", "content": "# Description: Enhanced Adaptive Hybrid Optimization with Multi-faceted Strategy Selection using Differential Evolution, Particle Swarm, and Stochastic Local Search for diverse exploration-exploitation coordination.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Increased population size for diversity\n        self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n        self.CR = 0.8 + 0.1 * np.random.rand()  # Adaptive crossover probability\n        self.w = 0.5  # Adjusted inertia weight for balanced exploration\n        self.c1 = 1.5 # Moderated emphasis on cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Enhanced velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Keep dynamic strategy selection\n        self.local_search_prob = 0.1 # Probability of applying local search\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.5 + 0.3 * np.random.rand()\n                self.CR = 0.8 + 0.1 * np.random.rand()\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n                # Stochastic Local Search\n                if np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.uniform(-0.1, 0.1, self.dim)\n                    local_trial_fitness = func(np.clip(local_trial, self.lower_bound, self.upper_bound))\n                    evals += 1\n                    if local_trial_fitness < trial_fitness:\n                        self.population[i] = local_trial\n                        fitness[i] = local_trial_fitness\n                        if local_trial_fitness < self.best_fitness:\n                            self.global_best = local_trial\n                            self.best_fitness = local_trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:02:15.999494", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:02:23.902403", "content": "# Description: Hybrid Optimization with Dynamic Strategy and Adaptive Parameters for Enhanced Exploration-Exploitation Harmony.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Adaptive Differential weight\n        self.CR = 0.9 # Increased Crossover probability\n        self.w = 0.5  # Adaptive Inertia weight\n        self.c1 = 1.5 # Reduced emphasis on cognitive learning for better exploration\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp for stability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.fitness_memory = np.full(self.population_size, np.inf)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.1 * np.random.rand()  # Randomize within a range\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:04:51.565481", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:05:03.057326", "content": "# Description: Augmented Hybrid Optimization utilizing Adaptive Differential Evolution and Particle Swarm with Enhanced Strategy and Learning for Superior Convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Slightly increased population size\n        self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive Differential weight\n        self.CR = 0.8  # Crossover probability slightly adjusted\n        self.w = 0.5  # Dynamically adjusted Inertia weight\n        self.c1 = 2.0  # Higher cognitive component for individual learning\n        self.c2 = 1.5  # Moderate social component\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = self.population[np.argmin(np.full(self.population_size, float('inf')))]\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.5 + 0.3 * np.random.rand()\n                self.CR = 0.75 + 0.2 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(self.personal_best[i]):\n                        self.personal_best[i] = trial\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:07:32.744192", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:07:42.094004", "content": "# Description: Dynamic Hybrid Optimization leveraging Adaptive Differential Evolution and Particle Swarm with Reinforced Strategy Adjustment for enhanced performance.\n# Code:\n```python\nimport numpy as np\n\nclass DynamicHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Slightly increased population size for better diversity\n        self.F = 0.5  # Balanced Differential weight\n        self.CR = 0.9 # Increased Crossover probability for more mixing\n        self.w = 0.3  # Further decreased Inertia weight for faster convergence\n        self.c1 = 1.5 # Balanced cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound) # Decreased velocity clamp for stability\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.4 * np.random.rand()  # Expanded randomization range\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Slightly higher minimum crossover rate\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:09:56.341431", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:10:05.756616", "content": "# Description: Enhanced Hybrid Optimization using Multi-Strategy Adaptation with Dynamic Learning Rates for Improved Convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive DE weight\n        self.CR = 0.8 + 0.1 * np.random.rand() # Adaptive crossover probability\n        self.w = 0.5  # Slightly increased Inertia weight\n        self.c1 = 1.5 # Balanced cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Moderated velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.adaptive_strategy = True # Enable multi-strategy adaptation\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.adaptive_strategy:  # Dynamic adaptation\n                self.F = 0.4 + 0.4 * np.random.rand()  # Randomize within a wider range\n                self.CR = 0.6 + 0.3 * np.random.rand()  # Randomize within a wider range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:12:32.927468", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:12:41.975670", "content": "# Description: Enhanced Diversity and Inertia Strategy with Self-Adaptive Parameters for Robust Convergence in Hybrid Differential Evolution and Particle Swarm Optimization.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Adaptive Differential weight\n        self.CR = 0.8  # Crossover probability\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive learning factor\n        self.c2 = 1.7  # Social learning factor\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.5 + 0.3 * np.random.rand()\n                self.CR = 0.75 + 0.25 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:15:06.590199", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:15:19.831005", "content": "# Description: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Reinforced Dynamic Strategy and Diversity Maintenance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.2 * np.random.rand()  # Dynamic Differential weight\n        self.CR = 0.75 + 0.1 * np.random.rand() # Dynamic Crossover probability\n        self.w = 0.5  # Balanced Inertia weight\n        self.c1 = 1.8 # Further emphasis on cognitive learning\n        self.c2 = 1.5 # Increased social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Enhanced velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Dynamic strategy remains enabled\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.75 + 0.1 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice([idx for idx in range(self.population_size) if idx != i], 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:18:02.710162", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:18:12.500424", "content": "# Description: Enhanced Adaptive Hybrid Optimization integrating Differential Evolution, Particle Swarm, and Adaptive Mutation for balanced exploration-exploitation and faster convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = 0.55  # Slightly decreased Differential weight for stability\n        self.CR = 0.9  # Increased Crossover probability for diversity\n        self.w = 0.5  # Balanced Inertia weight\n        self.c1 = 1.6 # Fine-tuned cognitive learning\n        self.c2 = 1.4 # Balanced social learning\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound)  # Reduced velocity clamp for control\n        self.dynamic_mutation_prob = 0.1  # Probability for adaptive mutation\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection and mutation\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.1 * np.random.rand()  # Randomize within a narrower range\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Randomize within a narrower range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Adaptive Mutation\n                if np.random.rand() < self.dynamic_mutation_prob:\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n                    trial = np.clip(trial + mutation_vector, self.lower_bound, self.upper_bound)\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:20:46.726377", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:20:55.025455", "content": "# Description: Enhanced Hybrid Optimization combining Differential Evolution, Particle Swarm, and Adaptive Mutation for robust global search and local refinement.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPAM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Increased to enhance diversity\n        self.F_base = 0.5\n        self.CR_base = 0.8\n        self.w = 0.3  # Further decreased inertia for faster convergence\n        self.c1 = 1.5 # Adjusted cognitive influence\n        self.c2 = 1.5 # Balanced social influence\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound) # Further increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = self.F_base + 0.2 * np.random.rand()\n                self.CR = self.CR_base + 0.2 * np.random.rand()\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation with adaptive strategy\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:23:14.542978", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:23:26.783678", "content": "# Description: Enhanced Hybrid Metaheuristic combining Differential Evolution, Particle Swarm, and Adaptive Learning Rates for robust optimization.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Adjusted population size\n        self.F = 0.5 + np.random.rand() * 0.2  # Dynamic Differential weight\n        self.CR = 0.7 + np.random.rand() * 0.3  # Dynamic Crossover probability\n        self.w = 0.3 + np.random.rand() * 0.2  # Dynamic Inertia weight\n        self.c1 = 1.5  # Balanced cognitive learning\n        self.c2 = 1.5  # Balanced social learning\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                self.F = 0.5 + 0.2 * np.random.rand()  # Randomize Differential weight within a range\n                self.CR = 0.6 + 0.4 * np.random.rand()  # Randomize Crossover probability\n\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-24 00:26:00.272484", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:26:09.760098", "content": "# Description: A Hybrid Optimization blending Adaptive Differential Evolution and Particle Swarm with a Probabilistic Strategy Adjustment for enhanced search efficiency.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHyDEPSO_Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Reduced population size for faster convergence\n        self.F = 0.5  # Adjusted Differential weight\n        self.CR = 0.9 # Increased Crossover probability for more mixing\n        self.w = 0.3  # Further reduced Inertia weight\n        self.c1 = 2.0 # Increased cognitive learning factor\n        self.c2 = 1.5 # Slightly increased social learning\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound) # Decreased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Maintain dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic and np.random.rand() < 0.3:  # Probabilistic adaptation\n                self.F = 0.5 + 0.1 * np.random.rand()  # Narrower range\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Slightly narrower range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-24 00:28:44.339834", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:28:56.379845", "content": "# Description: Synergistic Evolutionary Optimization combining Adaptive Differential Evolution and Particle Swarm with Enhanced Diversity Preservation to tackle diverse optimization landscapes.\n# Code:\n```python\nimport numpy as np\n\nclass SynergisticEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = 0.5  # Adaptive Differential weight\n        self.CR = 0.8 # Increased Crossover probability\n        self.w = 0.5  # Inertia weight for balance between exploration-exploitation\n        self.c1 = 2.0 # Emphasis on cognitive learning\n        self.c2 = 1.5 # Emphasis on social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Enhanced velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.4 * np.random.rand()  # Randomize within a wider range\n                self.CR = 0.6 + 0.3 * np.random.rand()  # Randomize within a wider range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Diversity preservation\n            diversity_threshold = 0.1\n            if np.std(fitness) < diversity_threshold:\n                self.population += np.random.uniform(-0.1, 0.1, self.population.shape)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:31:38.236792", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:31:50.354211", "content": "# Description: Synergistic Evolutionary Algorithm leveraging Dual Strategy Mutation and Adaptive PSO for dynamic optimization control.\n# Code:\n```python\nimport numpy as np\n\nclass SynergisticEvoPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim\n        self.F = 0.5 + 0.1 * np.random.rand()  # Adaptive Differential weight\n        self.CR = 0.7 + 0.1 * np.random.rand() # Adaptive Crossover probability\n        self.w = 0.5  # Inertia weight for balanced convergence\n        self.c1 = 1.5 # Cognitive learning factor\n        self.c2 = 1.5 # Social learning factor\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound) # Velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.5 + 0.2 * np.random.rand()\n                self.CR = 0.6 + 0.1 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:34:11.367200", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:34:19.426054", "content": "# Description: Quantum-Enhanced Differential Evolution and Particle Swarm Algorithm with Quantum-inspired Strategy Selection for high-dimensional and complex optimization.\n# Code:\n```python\nimport numpy as np\n\nclass QuantumHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Increased population size for diversity\n        self.F = 0.5  # Balanced Differential weight\n        self.CR = 0.9  # Enhanced Crossover probability\n        self.w = 0.5  # Medium Inertia weight\n        self.c1 = 1.5  # Balanced cognitive learning\n        self.c2 = 1.5  # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Medium velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = self.population[np.argmin([float('inf')] * self.population_size)]\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                q_rand = np.random.normal(0, 1)  # Quantum random number\n                self.F = 0.3 + 0.3 * np.abs(q_rand)\n                self.CR = 0.8 + 0.1 * np.abs(q_rand)\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(self.personal_best[i]):\n                        self.personal_best[i] = trial\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:36:51.838919", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:37:04.923879", "content": "# Description: Enhanced Adaptive Hybrid Optimization with Triple Agent Strategy and Self-Adaptive Mechanism for Robust Exploration and Exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Slightly increased population size\n        self.F = 0.5 + 0.3 * np.random.rand()  # Self-adaptive Differential weight\n        self.CR = 0.8  # Adjusted Crossover probability\n        self.w = 0.5  # Increased Inertia weight for better balance\n        self.c1 = 1.4  # Balanced cognitive learning\n        self.c2 = 1.6  # Increased social learning factor\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)  # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.triple_agent_strategy = True  # Introduce triple agent strategy\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.75 + 0.2 * np.random.rand()  # Randomize within a range\n\n            agents = np.random.choice(['DE', 'PSO', 'Hybrid'], size=self.population_size, p=[0.3, 0.3, 0.4])\n            for i in range(self.population_size):\n                if agents[i] == 'DE':\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[indices]\n                    mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    trial = np.where(crossover, mutant, self.population[i])\n                elif agents[i] == 'PSO':\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    cognitive = self.c1 * r1 * (self.personal_best[i] - self.population[i])\n                    social = self.c2 * r2 * (self.global_best - self.population[i])\n                    self.velocities[i] = self.w * self.velocities[i] + cognitive + social\n                    self.velocities[i] = np.clip(self.velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                    trial = np.clip(self.population[i] + self.velocities[i], self.lower_bound, self.upper_bound)\n                else:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    x_r1, x_r2, x_r3 = self.population[indices]\n                    mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n                    crossover = np.random.rand(self.dim) < self.CR\n                    trial = np.where(crossover, mutant, self.population[i])\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    cognitive = self.c1 * r1 * (self.personal_best[i] - trial)\n                    social = self.c2 * r2 * (self.global_best - trial)\n                    trial_velocity = self.w * self.velocities[i] + cognitive + social\n                    self.velocities[i] = np.clip(trial_velocity, -self.velocity_clamp, self.velocity_clamp)\n                    trial = np.clip(trial + self.velocities[i], self.lower_bound, self.upper_bound)\n                    \n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:40:01.526863", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:40:11.288669", "content": "# Description: Stochastic Hybrid Optimizer integrating Differential Evolution and Particle Swarm with dynamic adaptation for diverse exploration and balanced convergence.\n# Code:\n```python\nimport numpy as np\n\nclass StochasticHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.3 * np.random.rand()  # Dynamic Differential weight adaptation\n        self.CR = 0.9  # Slightly increased Crossover probability\n        self.w = 0.5  # Adjusted Inertia weight for better balance\n        self.c1 = 1.5 # Slightly reduced cognitive emphasis\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection with random factor\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.4 * np.random.rand()  # Vary within a broader range\n                self.CR = 0.6 + 0.3 * np.random.rand()  # Vary within a broader range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:42:30.820181", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:42:43.001578", "content": "# Description: Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Enhanced Dynamic Strategy and Memory for Efficient Exploration and Convergence.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = max(10 * dim, 50)  # Ensuring a minimum population size\n        self.F = 0.5 + 0.2 * np.random.rand()  # Adaptive Differential weight\n        self.CR = 0.8  # Stabilized Crossover probability\n        self.w = 0.5  # Balanced Inertia weight\n        self.c1 = 1.8  # Emphasized cognitive learning\n        self.c2 = 1.4  # Increased social learning\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.personal_best_fitness = np.full(self.population_size, np.inf)\n        self.global_best = np.copy(self.population[np.argmin(self.personal_best_fitness)])\n        self.best_fitness = np.inf\n        self.strategy_dynamic = True  # Enable enhanced dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        # Update personal best fitness records\n        self.personal_best_fitness = np.minimum(self.personal_best_fitness, fitness)\n        idx = self.personal_best_fitness < np.array([func(x) for x in self.personal_best])\n        self.personal_best[idx] = self.population[idx]\n\n        # Update global best\n        min_idx = np.argmin(fitness)\n        if fitness[min_idx] < self.best_fitness:\n            self.global_best = self.population[min_idx]\n            self.best_fitness = fitness[min_idx]\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Enhanced dynamic adaptation\n                self.F = 0.4 + 0.3 * np.random.rand()  # Adapt within a new range\n                self.CR = 0.75 + 0.1 * np.random.rand()  # Adapt within a new range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_best_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_best_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:45:23.698039", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:45:31.817399", "content": "# Description: Enhanced Adaptive Hybrid Optimization with Multi-swarm Strategy and Improved Parameter Tuning for Superior Exploration-Exploitation.\n\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = 0.5 + 0.1 * np.random.rand()  # Increased randomization for exploration\n        self.CR = 0.75 + 0.1 * np.random.rand()  # Adjusted for balancing exploration-exploitation\n        self.w = 0.5  # Adjusted inertia for stability\n        self.c1 = 1.5  # Rebalanced learning coefficients\n        self.c2 = 1.5\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.5 + 0.1 * np.random.rand()\n                self.CR = 0.75 + 0.1 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:47:49.303520", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:47:57.899294", "content": "# Description: Enhanced Hybrid Strategy using Adaptive Differential Evolution and Particle Swarm with Randomized Topology for Diversified Exploration and Robust Convergence.\n# Code:\n# ```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.1 * np.random.rand()  # Adaptive Differential weight\n        self.CR = 0.8 + 0.1 * np.random.rand() # Adjusted Crossover probability\n        self.w = 0.5  # Adjusted Inertia weight for exploration\n        self.c1 = 1.5 # Balanced cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Adaptive strategy selection\n        self.topology_randomization = True # Enable topology randomization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.3 * np.random.rand()  # Broader randomization range\n                self.CR = 0.75 + 0.25 * np.random.rand() # Broader randomization range\n                \n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            if self.topology_randomization:  # Randomize connections\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                cognitive = self.c1 * r1 * (self.personal_best - self.population)\n                social = self.c2 * r2 * (self.global_best - self.population)\n                self.velocities = self.w * self.velocities + cognitive + social\n                self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n                self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n# ```"}
{"role": "LLaMEA", "time": "2024-10-24 00:47:57.902010", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:48:09.801678", "content": "# Description: Quantum-Inspired Hybrid Optimization leveraging Differential Evolution, Particle Swarm, and Quantum Superposition for enhanced diversity and convergence.\n# Code:\n```python\nimport numpy as np\n\nclass QuantumHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5  # Balanced Differential weight\n        self.CR = 0.9 # Higher Crossover probability to encourage diversity\n        self.w = 0.5  # Balanced Inertia weight\n        self.c1 = 1.5 # Slightly decreased cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.4 * (self.upper_bound - self.lower_bound) # Increased velocity clamp for wider search\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Keep dynamic strategy selection\n        self.qbits = np.random.uniform(0, np.pi, (self.population_size, dim)) # Quantum superposition states\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.4 * np.random.rand()  # Wider range for randomization\n                self.CR = 0.6 + 0.3 * np.random.rand()  # Wider range for randomization\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Quantum-inspired variation\n            self.qbits = (self.qbits + np.pi * (np.random.rand(self.population_size, self.dim) - 0.5)) % (2 * np.pi)\n            quantum_variation = self.lower_bound + (self.upper_bound - self.lower_bound) * (np.sin(self.qbits) ** 2)\n            self.population = np.clip(quantum_variation, self.lower_bound, self.upper_bound)\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:50:48.475561", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:51:02.338167", "content": "# Description: Adaptive Hybrid Optimization using Enhanced Differential Evolution and Particle Swarm with Reinforced Dynamic Strategy Selection for improved convergence and diversity.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Increased population size for better diversity\n        self.F = 0.5 + 0.3 * np.random.rand()  # Wider range for dynamic F\n        self.CR = 0.75 + 0.15 * np.random.rand()  # Adjusted Crossover probability for adaptability\n        self.w = 0.3 + 0.1 * np.random.rand()  # Dynamic inertia weight for better balance\n        self.c1 = 1.8  # Increased cognitive learning\n        self.c2 = 1.2  # Reduced social learning for exploration\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp for control\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Dynamic strategy remains enabled\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.45 + 0.25 * np.random.rand()  # Further fine-tuned randomization range\n                self.CR = 0.65 + 0.3 * np.random.rand()  # Adjusted randomization range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 00:53:20.330927", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:53:31.259457", "content": "# Description: Quantum-inspired Adaptive Hybrid Optimization integrating Differential Evolution and Particle Swarm with Quantum Tunneling for enhanced exploration.\n# Code:\n```python\nimport numpy as np\n\nclass QuantumAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Reduced population size for efficiency\n        self.F = 0.5 + 0.1 * np.random.rand()  # Variable Differential weight\n        self.CR = 0.8  # Slightly adjusted Crossover probability\n        self.w = 0.5  # Slightly increased inertia for a balance\n        self.c1 = 1.5  # Adjusted cognitive learning factor\n        self.c2 = 1.5  # Equalized social learning factor\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.q_tunnel_prob = 0.05  # Probability for quantum tunneling\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.1 * np.random.rand()  # Randomize within a narrower range\n                self.CR = 0.75 + 0.15 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n                # Quantum tunneling\n                if np.random.rand() < self.q_tunnel_prob:\n                    tunnel_candidate = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n                    tunnel_fitness = func(tunnel_candidate)\n                    evals += 1\n                    if tunnel_fitness < fitness[i]:\n                        self.population[i] = tunnel_candidate\n                        fitness[i] = tunnel_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-24 00:55:53.992261", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:56:05.478690", "content": "# Description: Dynamic Hybrid Optimization using Adaptive Differential Evolution and Particle Swarm with Enhanced Exploration-Exploitation via Adaptive Parameters.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Slightly larger population for diversity\n        self.F = 0.5  # Adjusted Differential weight\n        self.CR = 0.9  # Higher Crossover probability for more combinations\n        self.w = 0.3  # Reduced Inertia weight for faster convergence\n        self.c1 = 2.0  # Increased emphasis on cognitive learning\n        self.c2 = 1.0  # Slightly reduced social learning emphasis\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)  # Larger velocity clamp for wider search\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.8 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < func(self.personal_best[i]):\n                        self.personal_best[i] = trial\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-24 00:58:22.707577", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 00:58:33.998455", "content": "# Description: Enhanced Adaptive Hybrid Optimization with integrated Simulated Annealing dynamics for improved exploration and convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.5 + 0.1 * np.random.rand()  # Randomized Differential weight\n        self.CR = 0.8 + 0.1 * np.random.rand() # Slightly adjusted Crossover probability\n        self.w = 0.5  # Adjusted inertia weight to balance exploration and exploitation\n        self.c1 = 1.5 # Balanced cognitive learning\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.temperature = 100.0 # Initial temperature for Simulated Annealing\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation with Simulated Annealing dynamics\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Simulated Annealing acceptance criterion\n                if trial_fitness < fitness[i] or np.exp((fitness[i] - trial_fitness) / self.temperature) > np.random.rand():\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n            \n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:00:33.884637", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nAdaptiveHyDEPSO: Adaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance. (Score: 0.34349079566765867)\n\nThe selected solution to update is:\nAdaptive Hybrid Optimization employing Differential Evolution and Particle Swarm with Dynamic Strategy Selection for optimal exploration-exploitation balance.\n\nWith code:\nimport numpy as np\n\nclass AdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = 0.6  # Slightly increased Differential weight\n        self.CR = 0.85 # Adjusted Crossover probability\n        self.w = 0.4  # Decreased Inertia weight for quicker convergence\n        self.c1 = 1.7 # Higher emphasis on cognitive learning\n        self.c2 = 1.3 # Slight decrease in social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    self.personal_best[i] = trial if trial_fitness < func(self.personal_best[i]) else self.personal_best[i]\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm AdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:00:44.007866", "content": "# Description: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-24 01:03:17.015687", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:03:27.896709", "content": "# Description: Dynamic Adaptive Evolutionary and Swarm Algorithm with Probabilistic Strategy Update and Context-Aware Adjustments.\n# Code:\n```python\nimport numpy as np\n\nclass DynamicAdaptiveEvoSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Adjusted population size for faster convergence\n        self.F = np.random.uniform(0.5, 0.9)  # Adjustable Differential weight for more exploration\n        self.CR = np.random.uniform(0.6, 0.8) # Crossover probability tuned for better exploration\n        self.w = 0.4  # Lower inertia for more responsive particles\n        self.c1 = 1.7 # Enhanced cognitive learning\n        self.c2 = 1.3 # Reduced social learning for individual exploration\n        self.velocity_clamp = 0.1 * (self.upper_bound - self.lower_bound) # Reduced velocity clamp for fine-tuning\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic and np.random.rand() < 0.3:  # Probabilistic dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()\n                self.CR = 0.6 + 0.2 * np.random.rand()\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-24 01:06:11.483558", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:06:20.589698", "content": "# Description: Adaptive Strategy Self-tuning for Enhanced Hybrid Optimization utilizing DE and PSO with Probabilistic Exploration.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveSelfTuningHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = np.random.uniform(0.4, 0.9)  # Broader range for F\n        self.CR = np.random.uniform(0.6, 0.95) # Wider range for CR\n        self.w = np.random.uniform(0.4, 0.6)  # Randomized inertia weight\n        self.c1 = np.random.uniform(1.3, 1.7) # Diverse cognitive learning\n        self.c2 = np.random.uniform(1.3, 1.7) # Diverse social learning\n        self.velocity_clamp = 0.4 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.4 + 0.5 * np.random.rand()\n                self.CR = 0.6 + 0.35 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-24 01:08:54.174810", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:09:06.432910", "content": "# Description: RobustSynergyEvolution: Robust Synergistic Optimization using Adaptive Differential Evolution and Particle Swarm with Enhanced Exploration and Exploitation Balance.\n# Code:\n# ```python\nimport numpy as np\n\nclass RobustSynergyEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Slightly reduced population for efficiency\n        self.F = np.random.uniform(0.5, 0.9)  # Broader variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability\n        self.w = 0.6  # Slightly increased inertia weight for exploration\n        self.c1 = 1.2 # Lower cognitive learning to focus more on global search\n        self.c2 = 1.8 # Higher social learning to enhance convergence\n        self.velocity_clamp = 0.4 * (self.upper_bound - self.lower_bound) # Further increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Continued dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Continued dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a broader range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a specific range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n# ```"}
{"role": "LLaMEA", "time": "2024-10-24 01:09:06.435702", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:09:23.832982", "content": "# Description: Adaptive Bi-phase Hybrid Evolution using Dynamic Strategy Adaptation and Local Search Integration.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveBiPhaseHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Slightly smaller population for faster convergence\n        self.F = np.random.uniform(0.5, 0.9)  # Adjusted F range for better exploration\n        self.CR = np.random.uniform(0.6, 0.9)  # Broader crossover probability\n        self.w = 0.6  # Higher inertia weight for improved exploration\n        self.c1 = 1.8  # Increased cognitive learning factor\n        self.c2 = 1.3  # Decreased social learning factor for balance\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound)  # Decreased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.local_search_prob = 0.3  # Probability of local search execution\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.3 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Local search phase with probability\n            if np.random.rand() < self.local_search_prob:\n                for i in range(self.population_size):\n                    candidate = self.population[i] + np.random.uniform(-0.1, 0.1, self.dim)\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    evals += 1\n                    if candidate_fitness < fitness[i]:\n                        self.population[i] = candidate\n                        fitness[i] = candidate_fitness\n                        if candidate_fitness < self.best_fitness:\n                            self.global_best = candidate\n                            self.best_fitness = candidate_fitness\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:11:40.365112", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:11:51.260441", "content": "# Description: Enhanced Adaptive Hybrid Optimization with Differential Evolution and Particle Swarm using Diversity-driven Dynamic Adaptation and Improved Learning Mechanisms.\n# Code:\n# ```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Slightly increased population for more diversity\n        self.F = np.random.uniform(0.5, 0.9)  # Increased upper limit for more exploration\n        self.CR = np.random.uniform(0.6, 0.85) # Slightly adjusted crossover probability for balance\n        self.w = 0.4  # Slightly reduced inertia weight for quicker convergence\n        self.c1 = 1.7 # Increased cognitive learning for more self-exploration\n        self.c2 = 1.4 # Adjusted social learning for better global optimization\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Retain dynamic strategy selection\n        self.successful_strategies = [] # Track successful strategies\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                if np.random.rand() > 0.3:  # Adjust adaptation probability\n                    self.F = 0.5 + 0.2 * np.random.rand()  # Randomize within a range\n                    self.CR = 0.65 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n                        self.successful_strategies.append((self.F, self.CR))  # Log successful strategy\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        # Use successful strategies to inform future runs\n        if len(self.successful_strategies) > 0:\n            avg_F, avg_CR = np.mean(self.successful_strategies, axis=0)\n            self.F, self.CR = avg_F, avg_CR\n\n        return self.global_best, self.best_fitness\n# ```"}
{"role": "LLaMEA", "time": "2024-10-24 01:11:51.263346", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:12:02.587273", "content": "# Description: Advanced Stochastic Search Optimization with Adaptive Differential Evolution and Confidence-Driven Particle Swarm.\n# Code:\n```python\nimport numpy as np\n\nclass AdvancedStochasticSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(12.5 * dim)  # Adjusted population size for scalability\n        self.F = np.random.uniform(0.3, 0.9)  # Extended range for differential weight\n        self.CR = np.random.uniform(0.6, 0.95) # Broadened crossover probability\n        self.w = np.random.uniform(0.4, 0.7)  # Dynamic inertia weight\n        self.c1 = 1.4 # Slightly reduced cognitive learning factor\n        self.c2 = 1.7 # Slightly increased social learning factor\n        self.velocity_clamp = 0.35 * (self.upper_bound - self.lower_bound) # Modified velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Dynamic strategy adaptation enabled\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.3 * np.random.rand()  # More variance in F\n                self.CR = 0.6 + 0.3 * np.random.rand()  # More variance in CR\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:14:36.217645", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:14:45.952300", "content": "# Description: Adaptive Gaussian-Mutated Differential Evolution and Particle Swarm for Improved Convergence with Dynamic Strategy Selection and Velocity Control.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveGaussianDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Slightly reduced population for efficiency\n        self.F = np.random.uniform(0.5, 0.9)  # Increased range for Differential weight\n        self.CR = np.random.uniform(0.6, 0.85) # Modified crossover probability\n        self.w = 0.4  # Adjusted inertia weight\n        self.c1 = 1.3 # Adjusted cognitive learning\n        self.c2 = 1.7 # Slightly increased social learning\n        self.velocity_clamp = 0.4 * (self.upper_bound - self.lower_bound) # Tweaked velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Dynamic strategy selection enabled\n        self.gaussian_mutation_prob = 0.2 # Probability of applying Gaussian mutation\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()\n                self.CR = 0.6 + 0.25 * np.random.rand()\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Apply Gaussian mutation with a probability\n                if np.random.rand() < self.gaussian_mutation_prob:\n                    gaussian_noise = np.random.normal(0, 0.1, self.dim)\n                    mutant = np.clip(mutant + gaussian_noise, self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:17:28.618878", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:17:40.796026", "content": "# Description: Adaptive Hybrid Algorithm using Differential Evolution and Particle Swarm with Progressive Learning and Variable Strategies.\n# Code:\n```python\nimport numpy as np\n\nclass AdaptiveHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Adjust population size for faster convergence\n        self.F = np.random.uniform(0.5, 0.9)  # Adjust range for differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjust crossover probability\n        self.w = 0.6  # Increment inertia weight for exploration\n        self.c1 = 1.7 # Increment cognitive learning\n        self.c2 = 1.3 # Decrement social learning\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjust velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = False # Disable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if not self.strategy_dynamic:  # Static strategy\n                self.F = 0.5 + 0.3 * np.random.rand()  # Keep differential weight constant\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Keep crossover probability constant\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:20:14.921603", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:20:25.673080", "content": "# Description: Multi-strategy hybrid optimization blending Differential Evolution, Particle Swarm Optimization, and Simulated Annealing for adaptive convergence.\n# Code:\n```python\nimport numpy as np\n\nclass MultiStrategyHyDEPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Slightly reduced population for computational efficiency\n        self.F = np.random.uniform(0.5, 0.9)  # Increased range for mutation factor\n        self.CR = np.random.uniform(0.6, 0.95) # Wider crossover probability range\n        self.w = 0.4  # Slightly reduced inertia for faster convergence\n        self.c1 = 1.4 # Lower cognitive learning factor\n        self.c2 = 1.6 # Higher social learning factor\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Reduced velocity clamp for finer adjustments\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.temp = 1.0  # Initial temperature for simulated annealing\n        self.cooling_rate = 0.99  # Cooling rate for temperature decay\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection using simulated annealing\n                if trial_fitness < fitness[i] or np.random.rand() < np.exp((fitness[i] - trial_fitness) / self.temp):\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            self.temp *= self.cooling_rate  # Update temperature\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:23:05.862910", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:23:23.110625", "content": "# Description: Synergistic DE-PSO Hybrid Optimization with Dynamic Parameter Tuning and Adaptive Population Strategy for Enhanced Exploration and Exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass SynergisticDEPSOHybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Reduced size for focused search\n        self.F = np.random.uniform(0.3, 0.9)  # Extended range for differential weight\n        self.CR = np.random.uniform(0.6, 1.0)  # Broader crossover probability\n        self.w = 0.4  # Lower inertia for rapid adaptation\n        self.c1 = 1.3  # Slightly lower cognitive learning\n        self.c2 = 1.7  # Higher social learning for better convergence\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound)  # Modified velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Keep dynamic strategy selection\n        self.adaptive_population = np.random.choice([True, False], p=[0.7, 0.3])  # Adaptive strategy for population\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.3 + 0.6 * np.random.rand()  # Extended range adjustment\n                self.CR = 0.6 + 0.4 * np.random.rand()  # Broader range for crossover\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Adaptive population strategy\n            if self.adaptive_population and evals < self.budget * 0.8:  # Apply only in the initial 80% of evaluations\n                best_half_idx = np.argsort(fitness)[:self.population_size // 2]\n                self.population[best_half_idx] = self.population[best_half_idx] + np.random.normal(0, 0.1, (self.population_size // 2, self.dim))\n                fitness[best_half_idx] = [func(ind) for ind in self.population[best_half_idx]]\n                evals += len(best_half_idx)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:25:29.893667", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:25:40.739382", "content": "# Description: Enhanced Hybrid Metaheuristic using Adaptive Differential Evolution and Particle Swarm Optimization with Randomized Strategy Adjustments and Velocity Clamping.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 12 * dim  # Increased population for more diversity\n        self.F = np.random.uniform(0.3, 0.9)  # Wider range for differential weight\n        self.CR = np.random.uniform(0.6, 0.95) # Extended crossover probability range\n        self.w = 0.6  # Modified inertia weight for PSO\n        self.c1 = 1.6 # Higher cognitive learning factor\n        self.c2 = 1.4 # Lower social learning factor for balance\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = self.population[np.argmin([func(ind) for ind in self.population])]\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.3 + 0.6 * np.random.rand()\n                self.CR = 0.6 + 0.35 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:25:40.744085", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:25:59.727338", "content": "# Description: Advanced Adaptive DE-PSO Hybrid with Strategy Switching and Adaptive Control for Dynamic Optimization.\n# Code:\n# ```python\nimport numpy as np\n\nclass AdvancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Adjusted population size for efficiency\n        self.F = np.random.uniform(0.5, 0.9)  # Adjusted DE weight for exploration\n        self.CR = np.random.uniform(0.6, 0.8) # Wider crossover probability\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 2.0  # Increased cognitive learning factor\n        self.c2 = 1.3  # Decreased social learning for balance\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_switch_prob = 0.3  # Probability to switch strategies\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if np.random.rand() < self.strategy_switch_prob:  # Probabilistic strategy switching\n                self.F = 0.5 + 0.3 * np.random.rand()\n                self.CR = 0.6 + 0.2 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n# ```"}
{"role": "LLaMEA", "time": "2024-10-24 01:25:59.730979", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:26:15.681929", "content": "# Description: Dynamic Diverse Hybrid Optimization using Adaptive Differential Evolution and Particle Swarm with Confidence-based Search.\n# Code:\n```python\nimport numpy as np\n\nclass DynamicDiverseHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = max(10, 5 * dim)  # Ensure a minimum population size for smaller dimensions\n        self.F = np.random.uniform(0.5, 0.9)  # Broaden range for DE variation\n        self.CR = np.random.uniform(0.6, 0.95) # Wider crossover probability range\n        self.w = 0.4  # Slightly reduced inertia for quicker adaptation\n        self.c1 = 1.7 # Increased cognitive learning for exploration\n        self.c2 = 1.3 # Decreased social learning for better balance\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Moderately increase velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = self.population[np.argmin([float('inf')] * self.population_size)]\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Dynamic strategy adaptation enabled\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.5 + 0.3 * np.random.rand()  # Dynamic scaling factor\n                self.CR = 0.6 + 0.3 * np.random.rand()  # Dynamic crossover rate\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:28:49.279239", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:29:01.926732", "content": "# Description: Evolutionary Cooperative Algorithm combining Differential Evolution and Particle Swarm with Adaptive Strategy and Velocity Boost.\n# Code:\n```python\nimport numpy as np\n\nclass EvolutionaryCoopDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.5, 0.9)  # Slightly wider variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.95) # Wider crossover probability for exploration\n        self.w = 0.4  # Slightly lower inertia weight for exploration\n        self.c1 = 1.7 # Slightly more cognitive learning\n        self.c2 = 1.3 # Slightly less social learning to avoid premature convergence\n        self.velocity_clamp = 0.4 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.boost_factor = 1.2  # Velocity boost factor for exploitation\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.4 * np.random.rand()  # Randomize within an extended range\n                self.CR = 0.6 + 0.35 * np.random.rand()  # Randomize within a wider range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities *= self.boost_factor  # Apply velocity boost\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:31:35.142160", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:31:55.015486", "content": "# Description: Hybrid Adaptive Differential Evolution and Particle Swarm Optimization with Dynamic Strategy Selection and Fitness-Based Learning.\n# Code:\n```python\nimport numpy as np\n\nclass HybridAdaptiveDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Slightly reduced population size to allocate more evaluations\n        self.F = np.random.uniform(0.5, 0.9)  # Adjusted differential weight range\n        self.CR = np.random.uniform(0.6, 0.8) # Narrow crossover probability for exploration-exploitation balance\n        self.w = 0.6  # Adjusted inertia weight for faster convergence\n        self.c1 = 1.4 # Adjusted cognitive coefficient\n        self.c2 = 1.7 # Enhanced social coefficient for stronger global guidance\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Balanced velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.1 * np.random.rand()  # Randomize within a new range\n                self.CR = 0.6 + 0.1 * np.random.rand()  # Randomize within a new range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:34:29.131759", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:34:44.778739", "content": "# Description: Dynamic Self-Adaptive Hybrid Optimization combining Differential Evolution, Particle Swarm, and Adaptive Learning Rate.\n# Code:\n```python\nimport numpy as np\n\nclass DynamicSelfAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim\n        self.F = np.random.uniform(0.5, 0.9)  # Adjusted variation range\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability range\n        self.w = np.random.uniform(0.4, 0.6)  # Dynamic inertia weight\n        self.c1 = 1.2  # Adjusted cognitive learning\n        self.c2 = 1.7  # Adjusted social learning\n        self.velocity_clamp = 0.4 * (self.upper_bound - self.lower_bound) # Modified velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n        self.learning_rate = 0.1  # New adaptive learning rate\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.5 + 0.3 * np.random.rand()\n                self.CR = 0.6 + 0.2 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Adaptive learning rate influence\n            self.w = np.clip(self.w + self.learning_rate * (self.best_fitness - np.min(fitness)), 0.1, 0.9)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:37:17.603674", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nEnhancedAdaptiveHyDEPSO: Enhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search. (Score: 0.3500932596873941)\n\nThe selected solution to update is:\nEnhanced Adaptive Hybrid Optimization using Differential Evolution and Particle Swarm with Adaptive Strategy and Confidence-based Search.\n\nWith code:\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Large population for diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Wider variation in Differential weight\n        self.CR = np.random.uniform(0.7, 0.9) # Slightly wider crossover probability\n        self.w = 0.5  # Balanced inertia weight\n        self.c1 = 1.5 # Slightly adjusted cognitive learning for balance\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Further increase in velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True # Enable dynamic strategy selection\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.2 * np.random.rand()  # Randomize within a range\n                self.CR = 0.7 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm EnhancedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.29.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:37:38.779636", "content": "# Description: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:40:16.237623", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:40:28.497395", "content": "# Description: A refined adaptive hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with adaptive parameters, dynamic strategy selection, and stagnation-based population reinitialization.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = np.random.uniform(0.4, 0.9)  # Broadened the range for F to explore more\n        self.CR = np.random.uniform(0.5, 0.8)  # Broadened CR range for enhanced exploration\n        self.w = 0.5  # Adjusted inertia weight for balanced exploration and exploitation\n        self.c1 = 1.7  # Enhanced cognitive learning factor\n        self.c2 = 1.3  # Reduced social learning factor for diversity\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)  # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = self.population[np.argmin([func(ind) for ind in self.population])]\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n        self.reinit_threshold = 0.15 * self.population_size  # Increased threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.4 + 0.5 * np.random.rand()\n                self.CR = 0.5 + 0.3 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:40:28.501801", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:40:38.392397", "content": "# Description: An enhanced hybrid optimization algorithm combining advanced DE and PSO with stochastic parameters and an energy-based reinitialization approach for escaping local minima.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedStochasticHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = np.random.uniform(0.5, 0.9)\n        self.CR = np.random.uniform(0.6, 0.9)  # Increased upper bound for crossover probability\n        self.w = 0.3 + 0.1 * np.random.rand()  # Stochastic inertia weight\n        self.c1 = 1.5 + 0.4 * np.random.rand()  # Stochastic cognitive learning factor\n        self.c2 = 1.2 + 0.6 * np.random.rand()  # Stochastic social learning factor\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)  # Enhanced velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.energy_level = np.zeros(self.population_size)\n        self.reinit_threshold = np.percentile(self.energy_level, 10)\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            energy_change = np.abs(fitness - self.personal_fitness)\n            self.energy_level = 0.5 * self.energy_level + 0.5 * energy_change  # Update energy level\n\n            if np.any(self.energy_level < self.reinit_threshold):\n                reinit_indices = np.where(self.energy_level < self.reinit_threshold)[0]\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:43:12.069812", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:43:26.873842", "content": "# Description: A hybrid optimization algorithm that dynamically adjusts Differential Evolution parameters and integrates Particle Swarm Optimization with adaptive reinitialization to efficiently explore and exploit search spaces.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = np.random.uniform(0.5, 0.9)\n        self.CR = np.random.uniform(0.6, 0.8)\n        self.w = 0.3  # Adjusted for better convergence\n        self.c1 = 2.0 # Increased to enhance exploration\n        self.c2 = 1.2 # Decreased to maintain diversity\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Modified velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.dynamic_F_CR = True  # Enable dynamic strategy adaptation\n        self.reinit_threshold = 0.15 * self.population_size  # Adjusted reinitialization threshold\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.dynamic_F_CR:  # Dynamic adaptation\n                self.F = 0.4 + 0.5 * np.random.rand()  # Expanded range for more adaptability\n                self.CR = 0.5 + 0.3 * np.random.rand()  # Expanded range for crossover\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-6:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:46:03.190290", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:46:13.253292", "content": "# Description: A refined hybrid optimization algorithm integrating enhanced Differential Evolution and Particle Swarm mechanisms with adaptive strategies and advanced exploration capabilities.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Increased population for better diversity\n        self.F = np.random.uniform(0.6, 0.8)  # Balanced variation in Differential weight\n        self.CR = np.random.uniform(0.5, 0.9)  # Wider range for crossover probability to enhance exploration\n        self.w = 0.5  # Moderate inertia weight to balance exploration and exploitation\n        self.c1 = 1.5  # Balanced cognitive learning\n        self.c2 = 1.5  # Balanced social learning\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.15 * self.population_size  # Increased threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.4 * np.random.rand()  # Randomize within a broader range\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Randomize within a broader range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-6:  # Increased sensitivity to stagnation\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:48:51.502990", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:49:07.465011", "content": "# Description: A refined hybrid optimizer combining Differential Evolution and Particle Swarm with dynamic parameter tuning and strategic reinitialization for robust exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Slightly increased population for diversity\n        self.F = np.random.uniform(0.4, 0.9)  # Wider range for Differential weight variation\n        self.CR = np.random.uniform(0.5, 0.9) # Wider range for crossover probability\n        self.w = 0.5  # Adjusted inertia weight for balanced convergence\n        self.c1 = 1.5 # Adjusted cognitive learning factor\n        self.c2 = 1.5 # Adjusted social learning factor\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Increased velocity clamp for exploration\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.2 * self.population_size  # Increased reinitialization threshold\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.5 * np.random.rand()  # Randomize within a wider range\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Randomize within a wider range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-4:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:51:43.382254", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:51:55.128078", "content": "Here is a refined version of the ImprovedAdaptiveHyDEPSO algorithm with modifications based on the given probability of change.\n\n# Description: A dynamically balanced hybrid of Differential Evolution and Particle Swarm Optimization with adaptive parameters and intelligent reinitialization to maintain diversity and prevent premature convergence.\n# Code:\n```python\nimport numpy as np\n\nclass DynamicBalancedHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = np.random.uniform(0.4, 0.9)  # Broadened range for F to enhance exploration\n        self.CR = np.random.uniform(0.5, 0.8)  # Broadened CR range for exploration and exploitation balance\n        self.w = 0.5  # Slightly increased inertia weight to enhance exploration phase\n        self.c1 = 1.5  # Enhanced cognitive learning slightly to maintain diversity\n        self.c2 = 1.5  # Balanced social learning to improve stability\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp for finer movements\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n        self.reinit_threshold = 0.05 * self.population_size # Adjusted reinitialization threshold for finer control\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.4 + 0.5 * np.random.rand()  # Adjusted range for dynamic F adaptation\n                self.CR = 0.5 + 0.3 * np.random.rand()  # Adjusted range for dynamic CR adaptation\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-24 01:54:31.617834", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:54:43.835595", "content": "# Description: A multi-strategy optimization algorithm combining Differential Evolution and Particle Swarm dynamics with adaptive parameters and periodic population rejuvenation for enhanced exploration and exploitation balance.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Slightly increased population size for better diversity\n        self.F = np.random.uniform(0.4, 0.9)  # Expanded range for differential weight\n        self.CR = np.random.uniform(0.5, 0.9)  # Broadened crossover probability range\n        self.w = 0.5  # Adjusted inertia weight for improved convergence\n        self.c1 = 1.5  # Balanced cognitive learning factor\n        self.c2 = 1.7  # Increased social learning factor for better global influence\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)  # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = np.random.rand() < 0.3  # Probabilistic dynamic strategy\n        self.reinit_threshold = 0.2 * self.population_size  # Higher threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.5 * np.random.rand()  # Wider randomization range\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Wider randomization range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 01:57:23.489780", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 01:57:41.330033", "content": "# Description: Hybrid Metaheuristic Algorithm combining Differential Evolution and Particle Swarm with enhanced adaptive parameters and innovative neighborhood-based reinitialization strategy to improve exploration and convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Population size carefully chosen for balance\n        self.F = np.random.uniform(0.4, 0.9)  # Wider range for Differential weight\n        self.CR = np.random.uniform(0.5, 0.9) # Wider range for crossover probability\n        self.w = 0.5  # Moderate inertia weight for balanced exploration and exploitation\n        self.c1 = 1.7 # Enhanced cognitive component for personal exploration\n        self.c2 = 1.3 # Reduced social learning for diversity\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Maintain dynamic strategy adaptation\n        self.reinit_threshold = 0.15 * self.population_size  # Increased threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Enhanced dynamic adaptation\n                self.F = 0.4 + 0.5 * np.random.rand()  # Wider randomization range\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Wider randomization range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Neighborhood-based Reinitialization\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                for idx in reinit_indices:\n                    neighbors = np.random.choice(self.population_size, 3, replace=False)\n                    self.population[idx] = np.mean(self.population[neighbors], axis=0) + np.random.normal(0, 0.1, self.dim)\n                    self.population[idx] = np.clip(self.population[idx], self.lower_bound, self.upper_bound)\n                    fitness[idx] = func(self.population[idx])\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:00:19.898898", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:00:38.446769", "content": "# Description: A refined hybrid algorithm integrating adaptive Differential Evolution and Particle Swarm Optimization with enhanced reinitialization and diversity maintenance for improved exploration and convergence.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Increased population for better exploration\n        self.F = np.random.uniform(0.4, 0.9)  # Broader variation in Differential weight for diversity\n        self.CR = np.random.uniform(0.5, 0.9) # Expanded crossover probability for exploration-exploitation balance\n        self.w = 0.5  # Slightly increased inertia weight for improved balance between exploration and exploitation\n        self.c1 = 1.8 # Further increased cognitive learning to enhance individual search\n        self.c2 = 1.2 # Further decreased social learning to preserve diversity\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Expanded velocity clamp for enhanced movement\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Dynamic strategy selection\n        self.reinit_threshold = 0.2 * self.population_size  # Increased reinitialization threshold for improved exploration\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.5 * np.random.rand()  # Increased range for adaptation\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Increased range for adaptation\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-6:  # Tighter threshold for stagnation\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```\n"}
{"role": "LLaMEA", "time": "2024-10-24 02:03:14.430344", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:03:45.869322", "content": "# Description: An enhanced hybrid optimization algorithm combining Differential Evolution and Particle Swarm with adaptive operators and periodic diversity injection to improve exploration and convergence.\n# Code:\n```python\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Adjusted population size for more diversity\n        self.F = np.random.uniform(0.4, 0.9)  # Expanded range for differential weight\n        self.CR = np.random.uniform(0.5, 0.9) # Expanded range for crossover probability\n        self.w = 0.3  # Further reduced inertia weight for quicker convergence\n        self.c1 = 1.8 # Enhanced cognitive learning component for better exploration\n        self.c2 = 1.2 # Reduced social learning component for diversity\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.15 * self.population_size  # Increased threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.5 * np.random.rand()  # Randomize within an expanded range\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Randomize within an expanded range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population to maintain diversity\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:06:23.292068", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:06:43.849496", "content": "# Description: A refined hybrid optimization algorithm integrating Dynamic Differential Evolution and Particle Swarm with adaptive strategies and a diversity-preserving mechanism.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedDynamicHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Increased population for better diversity\n        self.F = np.random.uniform(0.4, 0.8)  # Adjusted differential weight range for flexibility\n        self.CR = np.random.uniform(0.5, 0.9) # Wider crossover range for exploration\n        self.w = 0.5  # Adjusted inertia weight for balance\n        self.c1 = 1.5 # Balanced cognitive parameter\n        self.c2 = 1.5 # Balanced social parameter\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.15 * self.population_size  # Slightly increased reinitialization threshold\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.4 * np.random.rand()  # Randomize within a broader range\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Randomize within a broader range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:09:20.042197", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:09:39.834558", "content": "# Description: An enhanced hybrid optimization algorithm combining Differential Evolution and Particle Swarm Optimization with adaptive strategies and a randomized subpopulation reinitialization for better exploration.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = int(10 * dim)  # Larger population for increased diversity\n        self.F = np.random.uniform(0.4, 0.9)  # Wider range for Differential weight\n        self.CR = np.random.uniform(0.5, 0.9) # Wider range for crossover probability\n        self.w = 0.5  # Adjusted inertia weight\n        self.c1 = 1.5 # Balanced cognitive component\n        self.c2 = 1.5 # Balanced social component\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n        self.reinit_threshold = 0.15 * self.population_size  # Higher reinitialization threshold\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.4 + 0.5 * np.random.rand()\n                self.CR = 0.5 + 0.4 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:12:17.453779", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:12:39.700691", "content": "# Description: EnhancedHybridPSO-DE: An enhanced hybrid algorithm combining Particle Swarm Optimization with Differential Evolution and adaptive tuning for improved exploration and exploitation.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Increase population to enhance diversity\n        self.F = np.random.uniform(0.4, 0.9)  # Broadened variation range for more flexibility\n        self.CR = np.random.uniform(0.5, 0.8) # Broadened crossover probability\n        self.w = 0.5  # Slightly increased inertia weight for balance\n        self.c1 = 1.5 # Slightly more balanced cognitive learning factor\n        self.c2 = 1.5 # Balanced social learning factor\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.2 * self.population_size  # Increased threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.5 * np.random.rand()  # Randomize within a broader range\n                self.CR = 0.5 + 0.3 * np.random.rand()  # Randomize within a broader range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:15:15.876268", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:15:45.570967", "content": "# Description: An enhanced adaptive hybrid algorithm combining Differential Evolution and Particle Swarm Optimization with adaptive strategies and a dynamic reinitialization mechanism for improved convergence and diversity management.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Increased population for more diversity\n        self.F = np.random.uniform(0.4, 0.9)  # Increased range for Differential weight\n        self.CR = np.random.uniform(0.5, 0.9) # Broadened crossover probability for exploration\n        self.w = 0.3  # Lower inertia weight for rapid convergence\n        self.c1 = 1.7 # Increased cognitive learning for better exploration\n        self.c2 = 1.3 # Further decreased social learning for diversity\n        self.velocity_clamp = 0.15 * (self.upper_bound - self.lower_bound) # Tighter velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.2 * self.population_size  # Higher threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.5 * np.random.rand()  # Randomize within a broader range\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Randomize within a broader range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:18:22.026995", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:18:56.830360", "content": "# Description: A refined hybrid optimization combining Differential Evolution and Particle Swarm with dynamic strategy adjustment and diversity enhancement to better escape local optima.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population for increased pressure\n        self.F = np.random.uniform(0.4, 0.9)  # Broaden range for more diversity\n        self.CR = np.random.uniform(0.5, 0.9)  # Increase range for crossover probability\n        self.w = 0.4  # Inertia weight for convergence\n        self.c1 = 1.6  # Cognitive component\n        self.c2 = 1.4  # Social component\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n        self.reinit_threshold = 0.15 * self.population_size  # Increased threshold for more reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.4 + 0.5 * np.random.rand()  # Broadened range for F\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Broadened range for CR\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:21:33.874228", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:21:46.017033", "content": "# Description: A synergistic metaheuristic algorithm that dynamically integrates Differential Evolution and Particle Swarm Optimization with adaptive learning rates and a diversity enhancement technique ensuring robust performance over diverse optimization landscapes.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Larger population for better diversity\n        self.F = np.random.uniform(0.4, 0.9)  # Wider range for Differential weight\n        self.CR = np.random.uniform(0.5, 0.9) # Enhanced crossover probability for exploration\n        self.w = 0.3  # Lower inertia weight to favor exploration\n        self.c1 = 1.8 # Increased cognitive learning to boost individual exploration\n        self.c2 = 1.2 # Reduced social learning to maintain diversity\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound) # Enhanced velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.15 * self.population_size  # Higher reinitialization threshold\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.5 * np.random.rand()  # Randomize within a wider range\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Randomize within a wider range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:24:23.132724", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:24:48.127053", "content": "# Description: An improved hybrid optimization algorithm combining Differential Evolution, Particle Swarm, and stochastic gradient-like updates with adaptive exploration strategies to enhance convergence speed and robustness.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Slightly larger population for diversity\n        self.F = np.random.uniform(0.6, 0.9)  # Increased range for mutation factor\n        self.CR = np.random.uniform(0.5, 0.9) # Broader crossover probability for flexibility\n        self.w = 0.3  # Lower inertia weight for quicker response to changes\n        self.c1 = 1.5 # Balanced cognitive factor for individual learning\n        self.c2 = 1.5 # Balanced social factor for global learning\n        self.velocity_clamp = 0.25 * (self.upper_bound - self.lower_bound) # Increased velocity limits\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enables dynamic adaptation of strategies\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitializing stagnant solutions\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.6 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Gradient-like stochastic update for local refinement\n            if np.random.rand() < 0.2:\n                random_individuals = np.random.choice(self.population_size, size=int(0.1 * self.population_size))\n                for idx in random_individuals:\n                    gradient_step = np.random.normal(0, 1, self.dim) * 0.05  # Small step with normal distribution\n                    candidate = self.population[idx] + gradient_step\n                    candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n                    candidate_fitness = func(candidate)\n                    evals += 1\n                    if candidate_fitness < fitness[idx]:\n                        self.population[idx] = candidate\n                        fitness[idx] = candidate_fitness\n                        if candidate_fitness < self.personal_fitness[idx]:\n                            self.personal_best[idx] = candidate\n                            self.personal_fitness[idx] = candidate_fitness\n                        if candidate_fitness < self.best_fitness:\n                            self.global_best = candidate\n                            self.best_fitness = candidate_fitness\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:27:23.272473", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:27:36.727026", "content": "# Description: An enhanced hybrid optimization algorithm combining Differential Evolution and Particle Swarm, featuring dynamic parameter tuning and a congestion-aware reinitialization method for persistent exploration.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Increased population for better exploration\n        self.F = np.random.uniform(0.4, 0.9)  # Wider range for differential weight\n        self.CR = np.random.uniform(0.5, 0.9) # More flexibility in crossover probability\n        self.w = 0.5  # Balanced inertia weight for exploration and exploitation\n        self.c1 = 1.7 # Slightly higher cognitive component for exploration\n        self.c2 = 1.3 # Slightly lower social component to manage convergence\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Increased velocity clamp for larger steps\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.05 * self.population_size  # Lower threshold for more frequent reinitialization\n        self.reinit_congestion_threshold = dim * 0.2 # Congestion level to trigger reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.4 + 0.5 * np.random.rand()  # Randomized differential weight\n                self.CR = 0.5 + 0.4 * np.random.rand()  # Randomized crossover probability\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5 or np.count_nonzero(np.abs(self.velocities) < 1e-6) > self.reinit_congestion_threshold:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:30:13.624504", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:30:28.825949", "content": "# Description: Enhanced hybrid algorithm with adaptive learning rates and survivor-based selection to improve diversity and convergence.\n# Code:\n```python\nimport numpy as np\n\nclass EnhancedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 10 * dim  # Increase population size for better exploration\n        self.F = np.random.uniform(0.4, 0.9)  # Wider variation in Differential weight for flexibility\n        self.CR = np.random.uniform(0.4, 0.9) # Broadened crossover probability range\n        self.w = 0.5  # Minor increase in inertia weight for balanced exploration\n        self.c1 = 1.5 # Reduced cognitive learning to stabilize search\n        self.c2 = 1.5 # Balanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound) # Increased velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True\n        self.reinit_threshold = 0.2 * self.population_size  # Higher threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:\n                self.F = 0.4 + 0.5 * np.random.rand()\n                self.CR = 0.4 + 0.5 * np.random.rand()\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            if np.std(fitness) < 1e-5:\n                survivor_count = int(self.reinit_threshold)\n                survivors = np.argsort(fitness)[:self.population_size - survivor_count]\n                self.population[survivors] = np.random.uniform(self.lower_bound, self.upper_bound, (len(survivors), self.dim))\n                fitness[survivors] = [func(ind) for ind in self.population[survivors]]\n                evals += len(survivors)\n\n        return self.global_best, self.best_fitness\n```"}
{"role": "LLaMEA", "time": "2024-10-24 02:33:04.247866", "content": "You are a highly skilled computer scientist in the field of natural computing. Your task is to design novel metaheuristic algorithms to solve black box optimization problems.\n\nThe optimization algorithm should handle a wide range of tasks, which is evaluated on the BBOB test suite of 24 noiseless functions. Your task is to write the optimization algorithm in Python code. The code should contain an `__init__(self, budget, dim)` function and the function `def __call__(self, func)`, which should optimize the black box function `func` using `self.budget` function evaluations.\nThe func() can only be called as many times as the budget allows, not more. Each of the optimization functions has a search space between -5.0 (lower bound) and 5.0 (upper bound). The dimensionality can be varied.\nGive an excellent and novel heuristic algorithm to solve this task and also give it a one-line description with the main idea.\n\nThe current population of algorithms already evaluated (name, description, score) is:\nImprovedAdaptiveHyDEPSO: An improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima. (Score: 0.36816958746513606)\n\nThe selected solution to update is:\nAn improved hybrid optimization algorithm blending Differential Evolution and Particle Swarm with adaptive parameters and a novel reinitialization mechanism to escape local optima.\n\nWith code:\nimport numpy as np\n\nclass ImprovedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim  # Smaller population to increase selection pressure\n        self.F = np.random.uniform(0.5, 0.9)  # Further increased variation in Differential weight\n        self.CR = np.random.uniform(0.6, 0.8) # Adjusted crossover probability for exploration\n        self.w = 0.4  # Lower inertia weight for faster convergence\n        self.c1 = 1.6 # Slightly increased cognitive learning to encourage exploration\n        self.c2 = 1.4 # Slightly decreased social learning to manage diversity\n        self.velocity_clamp = 0.2 * (self.upper_bound - self.lower_bound) # Adjusted velocity clamp\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.strategy_dynamic = True  # Enable dynamic strategy selection\n        self.reinit_threshold = 0.1 * self.population_size  # Threshold for reinitialization\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            if self.strategy_dynamic:  # Dynamic adaptation\n                self.F = 0.5 + 0.3 * np.random.rand()  # Randomize within a range\n                self.CR = 0.6 + 0.2 * np.random.rand()  # Randomize within a range\n\n            for i in range(self.population_size):\n                # Differential Evolution mutation\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x_r1, x_r2, x_r3 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3), self.lower_bound, self.upper_bound)\n\n                # Crossover\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                # Evaluate trial solution\n                trial_fitness = func(trial)\n                evals += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                # Update global best\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            # Particle Swarm Optimization update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            # Reinitialization of a portion of the population if stagnation is detected\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n\nThe algorithm ImprovedAdaptiveHyDEPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.30.\n\nYou must follow the probability 0.3 to change the individual lines of the selected solution to refine its strategy.\n\nProvide the Python code and a one-line description with the main idea (without enters). Give the response in the format:\n# Description: <short-description>\n# Code:\n# ```python\n# <code>\n# ```\n# \n"}
{"role": "gpt-4o", "time": "2024-10-24 02:33:18.431437", "content": "# Description: A refined hybrid optimization algorithm merging Differential Evolution and Particle Swarm with adaptive parameters, enhanced mutation strategies, and a novel stagnation detection approach to improve global search capabilities.\n# Code:\n```python\nimport numpy as np\n\nclass RefinedAdaptiveHyDEPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 8 * dim\n        self.F = np.random.uniform(0.4, 0.9)  # Wider range for Differential weight\n        self.CR = np.random.uniform(0.5, 0.9) # Increased range of crossover probability\n        self.w = 0.5  # Adjusted inertia weight\n        self.c1 = 1.5 # Enhanced cognitive learning\n        self.c2 = 1.5 # Enhanced social learning\n        self.velocity_clamp = 0.3 * (self.upper_bound - self.lower_bound)\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, dim))\n        self.velocities = np.random.uniform(-1, 1, (self.population_size, dim)) * self.velocity_clamp\n        self.personal_best = np.copy(self.population)\n        self.global_best = np.copy(self.population[np.argmin([float('inf')] * self.population_size)])\n        self.best_fitness = float('inf')\n        self.reinit_threshold = 0.15 * self.population_size\n\n    def __call__(self, func):\n        evals = 0\n        fitness = np.array([func(ind) for ind in self.population])\n        self.personal_fitness = np.copy(fitness)\n        evals += self.population_size\n\n        while evals < self.budget:\n            self.F = 0.4 + 0.5 * np.random.rand()  # Randomize within a wider range\n            self.CR = 0.5 + 0.4 * np.random.rand()  # Randomize within a wider range\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 4, replace=False)\n                x_r1, x_r2, x_r3, x_r4 = self.population[indices]\n                mutant = np.clip(x_r1 + self.F * (x_r2 - x_r3) + self.F * (x_r3 - x_r4), self.lower_bound, self.upper_bound)\n\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, self.population[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.personal_fitness[i]:\n                        self.personal_best[i] = trial\n                        self.personal_fitness[i] = trial_fitness\n\n                if trial_fitness < self.best_fitness:\n                    self.global_best = trial\n                    self.best_fitness = trial_fitness\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            cognitive = self.c1 * r1 * (self.personal_best - self.population)\n            social = self.c2 * r2 * (self.global_best - self.population)\n            self.velocities = self.w * self.velocities + cognitive + social\n            self.velocities = np.clip(self.velocities, -self.velocity_clamp, self.velocity_clamp)\n            self.population = np.clip(self.population + self.velocities, self.lower_bound, self.upper_bound)\n\n            if np.std(fitness) < 1e-5:\n                reinit_indices = np.random.choice(self.population_size, int(self.reinit_threshold), replace=False)\n                self.population[reinit_indices] = np.random.uniform(self.lower_bound, self.upper_bound, (len(reinit_indices), self.dim))\n                fitness[reinit_indices] = [func(ind) for ind in self.population[reinit_indices]]\n                evals += len(reinit_indices)\n\n        return self.global_best, self.best_fitness\n```"}
